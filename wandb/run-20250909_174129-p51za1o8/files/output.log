📋 실험명: fold-0-0909-1741-20250909_1741_swin_base_patch4_window12_384_in22k_ensemble_tta
🔗 WandB URL: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/p51za1o8
/home/ieyeppo/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/timm/models/_factory.py:117: UserWarning: Mapping deprecated model name swin_base_patch4_window12_384_in22k to current swin_base_patch4_window12_384.ms_in22k.
  model = create_fn(
/home/ieyeppo/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/torch/functional.py:534: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3595.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
2025-09-09 17:41:31 | [MULTI-MODEL] Fold 0 using model: swin_base_patch4_window12_384_in22k
/home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/src/training/train_highperf.py:425: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  scaler = GradScaler() if cfg["train"].get("mixed_precision", True) else None
2025-09-09 17:41:31 | [DATA] build highperf loaders | img_size=384 bs=64
2025-09-09 17:41:31 | [DATA] augmentation: baseline-advanced (normal + hard augmentation)
/home/ieyeppo/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/albumentations/augmentations/transforms.py:1692: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584
  warnings.warn(
2025-09-09 17:41:32 | [HighPerfDataset] size=1256 img_size=384 epoch=0/3 p_hard=0.200 is_train=True
2025-09-09 17:41:32 | [HighPerfDataset] size=314 img_size=384 epoch=0/3 p_hard=0.000 is_train=False
2025-09-09 17:41:32 | [DATA] dataset sizes | train=1256 valid=314
2025-09-09 17:41:32 | [HighPerfDataset] updated epoch=1, p_hard=0.300
2025-09-09 17:41:32 | [EPOCH 1] >>> TRAIN start | steps=20 mixup=True
Train Epoch 1:   0%|                                                          | 0/20 [00:00<?, ?it/s]/home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/src/training/train_highperf.py:92: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler is not None):      # AMP 자동 캐스팅 적용
2025-09-09 17:41:52 | [EPOCH 1][TRAIN step 1/20] loss=2.97849 lr=0.000260 bs=64
Train Epoch 1:   5%|██▌                                               | 1/20 [00:20<06:28, 20.47s/it]/home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/src/training/train_highperf.py:84: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler is not None):
Train Epoch 1: 100%|█████████████████████████████████████████████████| 20/20 [05:18<00:00, 15.92s/it]
2025-09-09 17:46:50 | [EPOCH 1][TRAIN step 20/20] loss=1.71924 lr=0.000260 bs=40
2025-09-09 17:46:50 | [EPOCH 1] <<< TRAIN end | loss=2.03146
2025-09-09 17:46:50 | [EPOCH 1] >>> VALID start | steps=5
Valid Epoch 1: 100%|███████████████████████████████████████████████████| 5/5 [00:40<00:00,  8.03s/it]
2025-09-09 17:47:30 | [EPOCH 1] <<< VALID end | loss=0.88041 macro_f1=0.63208
2025-09-09 17:47:32 | [FOLD 0] NEW BEST F1: 0.63208 (epoch 1)
2025-09-09 17:47:32 | [DATA] build highperf loaders | img_size=384 bs=64
2025-09-09 17:47:32 | [DATA] augmentation: baseline-advanced (normal + hard augmentation)
/home/ieyeppo/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/albumentations/augmentations/transforms.py:1692: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584
  warnings.warn(
2025-09-09 17:47:32 | [HighPerfDataset] size=1256 img_size=384 epoch=1/3 p_hard=0.300 is_train=True
2025-09-09 17:47:32 | [HighPerfDataset] size=314 img_size=384 epoch=1/3 p_hard=0.000 is_train=False
2025-09-09 17:47:32 | [DATA] dataset sizes | train=1256 valid=314
2025-09-09 17:47:32 | [HighPerfDataset] updated epoch=2, p_hard=0.400
2025-09-09 17:47:32 | [EPOCH 2] >>> TRAIN start | steps=20 mixup=True
Train Epoch 2:   0%|                                                          | 0/20 [00:00<?, ?it/s]/home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/src/training/train_highperf.py:92: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler is not None):      # AMP 자동 캐스팅 적용
2025-09-09 17:47:48 | [EPOCH 2][TRAIN step 1/20] loss=1.27204 lr=0.000195 bs=64
Train Epoch 2:   5%|██▌                                               | 1/20 [00:16<05:18, 16.78s/it]/home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/src/training/train_highperf.py:84: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler is not None):
Train Epoch 2: 100%|█████████████████████████████████████████████████| 20/20 [05:19<00:00, 15.97s/it]
2025-09-09 17:52:51 | [EPOCH 2][TRAIN step 20/20] loss=0.57549 lr=0.000195 bs=40
2025-09-09 17:52:51 | [EPOCH 2] <<< TRAIN end | loss=1.02173
2025-09-09 17:52:51 | [EPOCH 2] >>> VALID start | steps=5
Valid Epoch 2: 100%|███████████████████████████████████████████████████| 5/5 [00:42<00:00,  8.56s/it]
2025-09-09 17:53:34 | [EPOCH 2] <<< VALID end | loss=0.36171 macro_f1=0.82417
2025-09-09 17:53:36 | [FOLD 0] NEW BEST F1: 0.82417 (epoch 2)
2025-09-09 17:53:36 | [DATA] build highperf loaders | img_size=384 bs=64
2025-09-09 17:53:36 | [DATA] augmentation: baseline-advanced (normal + hard augmentation)
/home/ieyeppo/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/albumentations/augmentations/transforms.py:1692: UserWarning: Using default interpolation INTER_NEAREST, which is sub-optimal.Please specify interpolation mode for downscale and upscale explicitly.For additional information see this PR https://github.com/albumentations-team/albumentations/pull/584
  warnings.warn(
2025-09-09 17:53:36 | [HighPerfDataset] size=1256 img_size=384 epoch=2/3 p_hard=0.400 is_train=True
2025-09-09 17:53:36 | [HighPerfDataset] size=314 img_size=384 epoch=2/3 p_hard=0.000 is_train=False
2025-09-09 17:53:36 | [DATA] dataset sizes | train=1256 valid=314
2025-09-09 17:53:36 | [HighPerfDataset] updated epoch=3, p_hard=0.500
2025-09-09 17:53:36 | [EPOCH 3] >>> TRAIN start | steps=20 mixup=True
Train Epoch 3:   0%|                                                          | 0/20 [00:00<?, ?it/s]/home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/src/training/train_highperf.py:84: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler is not None):
2025-09-09 17:53:53 | [EPOCH 3][TRAIN step 1/20] loss=1.14218 lr=0.000065 bs=64
Train Epoch 3:  10%|█████                                             | 2/20 [00:35<05:21, 17.88s/it]/home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/src/training/train_highperf.py:92: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with autocast(enabled=scaler is not None):      # AMP 자동 캐스팅 적용
Train Epoch 3:  30%|███████████████                                   | 6/20 [01:52<04:22, 18.78s/it]
2025-09-09 17:55:28 | [ERROR] Training failed: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
2025-09-09 17:55:28 | [SHUTDOWN] Training pipeline ended
2025-09-09 17:55:28 | ❌ [PIPELINE] Failed: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
2025-09-09 17:55:28 | 🏁 [PIPELINE] Full pipeline ended
❌ Optimization failed: CUDA error: out of memory
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.
