# 🔮 추론 파이프라인 완전 가이드 (고급 기법 통합)

## 🏗️ 추론 파이프라인 전체 아키텍처

```mermaid
flowchart TB
    subgraph CLI["🚀 CLI 진입점"]
        A["src/inference/infer_main.py<br/>통합 추론 인터페이스<br/>CLI 옵션 파싱 및 모드 선택"]
    end
    
    subgraph MODES["📋 추론 모드 분기"]
        B["📚 basic 모드<br/>src/inference/infer.py<br/>단일 모델 빠른 추론"]
        C["⚡ highperf 모드<br/>src/inference/infer_highperf.py<br/>앙상블 + TTA + 고성능"]
    end
    
    subgraph INFERENCE["🎯 추론 전략"]
        D["📍 단일 모델 단일 폴드<br/>1개 모델 + 기본 추론<br/>5분, F1: 0.92-0.93"]
        E["📍 단일 모델 K-fold<br/>5개 모델 앙상블<br/>15분, F1: 0.94-0.95"]
        F["🎭 다중 모델 앙상블<br/>여러 아키텍처 조합<br/>30분+, F1: 0.96+"]
    end
    
    subgraph TTA["🎨 TTA 전략"]
        G["🎯 Essential TTA<br/>5가지 핵심 변환<br/>회전 + 밝기 조정"]
        H["🌌 Comprehensive TTA<br/>15가지 포괄 변환<br/>전체 변환 세트"]
        I["🔄 No TTA<br/>원본 이미지만<br/>최대 속도"]
    end
    
    subgraph OPTIM["🔍 최적화 기법"]
        J["🌡️ Temperature Scaling<br/>src/calibration/calibrate.py<br/>확률 보정"]
        K["⚡ Batch Size 최적화<br/>GPU 메모리 효율화<br/>자동 조정"]
        L["📊 Confidence Threshold<br/>앙상블 신뢰도<br/>예측 품질 관리"]
    end
    
    A --> B & C
    B --> D & I
    C --> E & F
    E & F --> G & H
    G & H --> J & K & L
    
    style A fill:#e1f5fe, color:#000000
    style C fill:#e8f5e8, color:#000000
    style F fill:#f3e5f5, color:#000000
    style H fill:#ffcdd2, color:#000000
    style J fill:#fce4ec, color:#000000
```

## 🔀 추론 파이프라인 상세 흐름도

### 📍 단일 모델 추론 흐름
```mermaid
flowchart LR
    subgraph SINGLE["🎯 단일 모델 추론"]
        A1["⚙️ 설정 로드<br/>configs/infer.yaml<br/>단일 모델 설정"]
        B1["💾 체크포인트 로드<br/>best_fold_N.pth<br/>특정 폴드 모델"]
        C1["📸 테스트 이미지<br/>data/raw/test/<br/>대상 이미지 로드"]
        D1["🚀 추론 실행<br/>빠른 단일 예측<br/>TTA 없이"]
        E1["📄 결과 저장<br/>submissions/<br/>CSV 형식"]
        
        A1 --> B1 --> C1 --> D1 --> E1
    end
    
    subgraph INFO1["📋 단일 모델 정보"]
        F1["⚡ 속도: 5분<br/>🎯 성능: F1 0.92-0.93<br/>💾 메모리: 4-6GB"]
        G1["🔮 목적: 빠른 검증<br/>🎨 TTA: 없음<br/>🎯 사용: 프로토타입"]
    end
    
    style A1 fill:#e1f5fe, color:#000000
    style D1 fill:#e8f5e8, color:#000000
    style E1 fill:#fff3e0, color:#000000
```

### 🎭 다중 모델 앙상블 추론 흐름
```mermaid
flowchart TB
    subgraph MULTI["🎆 다중 모델 앙상블 추론"]
        A2["⚙️ 앙상블 설정<br/>configs/infer_multi_model_ensemble.yaml<br/>복수 모델 경로"]
        
        B2["🏗️ 모델 1: ConvNeXt<br/>best_fold_0-4.pth<br/>고성능 베이스 모델"]
        C2["🏗️ 모델 2: Swin<br/>swin_fold_0-4.pth<br/>Transformer 기반"]
        D2["🏗️ 모델 3: EfficientNet<br/>eff_fold_0-4.pth<br/>효율성 중심"]
        
        E2["📸 동일 테스트 이미지<br/>모델별 예측 수행<br/>동시 실행"]
        F2["🎨 TTA 전략 적용<br/>Essential/Comprehensive<br/>모델별 변환"]
        G2["⚖️ 앙상블 가중 평균<br/>모델별 신뢰도 반영<br/>최종 예측 생성"]
        H2["📄 최종 결과 저장<br/>ensemble_result.csv<br/>최고 성능 출력"]
        
        A2 --> B2 & C2 & D2
        B2 & C2 & D2 --> E2
        E2 --> F2 --> G2 --> H2
    end
    
    subgraph INFO2["📋 다중 모델 정보"]
        I2["🕰️ 속도: 30-60분<br/>🎯 성능: F1 0.96-0.99<br/>💾 메모리: 24GB+"]
        J2["🎨 다양성: 여러 아키텍처<br/>🎆 목적: 최고 성능<br/>🏆 사용: 대회 우승용"]
    end
    
    style A2 fill:#e1f5fe, color:#000000
    style F2 fill:#e8f5e8, color:#000000
    style G2 fill:#fff3e0, color:#000000
    style H2 fill:#f3e5f5, color:#000000
```

---

## 📊 CLI 옵션 완전 가이드

### 🎯 추론 명령어 옵션 테이블

| 옵션 | 타입 | 필수/선택 | 기본값 | choices | 설명 |
|------|------|----------|--------|---------|------|
| `--config` | str | 필수 | - | - | 설정 YAML 파일 경로 |
| `--out` | str | 선택 | None | - | 출력 CSV 파일 경로 |
| `--ckpt` | str | 선택 | None | - | 모델 체크포인트 파일 경로 |
| `--mode` | str | 선택 | "highperf" | ["basic", "highperf"] | 추론 모드 선택 |
| `--fold-results` | str | 선택 | None | - | fold_results.yaml 파일 경로 (고성능 모드 필수) |

---

## 🎯 고급 TTA 시스템 완전 분석

### 📊 TTA 성능 비교표

| TTA 타입 | 변환 수 | 예상 시간 | 메모리 사용 | 성능 향상 | 사용 권장 | 구현 위치 |
|---------|--------|---------|----------|----------|---------|---------|
| **Essential** | 5가지 | ~17분 | 기본 × 5 | +2~3% | ⭐⭐⭐⭐⭐ | `transforms.py:221-250` |
| **Comprehensive** | 15가지 | ~50분+ | 기본 × 15 | +3~5% | ⭐⭐⭐⭐ | `transforms.py:251-311` |
| Legacy (회전) | 3가지 | ~10분 | 기본 × 3 | +1~2% | ⭐⭐⭐ | `infer.py` 레거시 |

### 🔄 Essential TTA (5가지 핵심 변환)

```python
# src/data/transforms.py:221-250에 정의됨
essential_tta_transforms = [
    "원본 이미지",                    # 기본 전처리만
    "90도 회전",                     # 문서 회전 대응
    "180도 회전",                    # 뒤집힌 문서
    "270도 회전",                    # 세로 문서
    "밝기 조정 (factor=1.2)"          # 조명 변화 대응
]
```

### 🌟 Comprehensive TTA (15가지 포괄 변환)

```python
# src/data/transforms.py:251-311에 정의됨
comprehensive_tta_transforms = [
    # 기본 변환 (5가지)
    "원본", "90도", "180도", "270도", "밝기 조정",
    
    # 고급 변환 (10가지 추가)
    "수평 뒤집기",                    # 좌우 반전 문서
    "수직 뒤집기",                    # 상하 반전 문서  
    "대비 조정 (factor=1.3)",         # 스캔 품질 변화
    "채도 조정 (factor=0.8)",         # 색상 변화 대응
    "색조 조정 (shift=0.1)",          # 색온도 변화
    "가우시안 블러 (sigma=0.5)",      # 초점 흐림 대응
    "샤프닝 (alpha=0.3)",            # 선명도 강화
    "노이즈 추가 (scale=10)",         # 스캔 노이즈 대응
    "약간 회전 (-5도)",              # 미세 기울임 대응
    "약간 회전 (+5도)"               # 미세 기울임 대응
]
```

---

## 🚀 실행 명령어 완전 가이드

### 1. 📍 단일 모델 단일 폴드 추론 (5분)

```bash
# 기본 단일 모델 추론 (TTA 없음)
python src/inference/infer_main.py \
    --config configs/infer.yaml \
    --mode basic

# 특정 폴드 체크포인트 지정
python src/inference/infer_main.py \
    --config configs/infer.yaml \
    --mode basic \
    --ckpt experiments/train/latest-train/best_fold2.pth

# 커스텀 출력 경로
python src/inference/infer_main.py \
    --config configs/infer.yaml \
    --mode basic \
    --out submissions/quick_test.csv
```

**예상 결과:**
- ⏰ 시간: 5분
- 📊 F1 Score: 0.920-0.930  
- 💾 메모리: 4-6GB
- 🎯 용도: 빠른 검증, 프로토타입, 단일 모델 테스트

### 2. 🎯 Essential TTA 추론 (17분, 권장)

```bash
# Essential TTA 추론 (5가지 핵심 변환)
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml

# tta_type을 essential로 설정 (configs/infer_highperf.yaml)
inference:
  tta_type: "essential"  # 5가지 핵심 TTA
```

**예상 결과:**
- ⏰ 시간: 17분
- 📊 F1 Score: 0.945-0.950
- 💾 메모리: 16GB
- 🎯 용도: **균형적 고성능 (권장)**

### 3. 🏆 Comprehensive TTA 추론 (50분+, 최고성능)

```bash
# Comprehensive TTA 추론 (15가지 포괄 변환)
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml

# tta_type을 comprehensive로 설정 (configs/infer_highperf.yaml)
inference:
  tta_type: "comprehensive"  # 15가지 포괄 TTA
```

**예상 결과:**
- ⏰ 시간: 50분+
- 📊 F1 Score: 0.965+
- 💾 메모리: 24GB
- 🎯 용도: **최종 대회 제출용**

---

## 🎨 TTA 설정 방법

### configs/infer_highperf.yaml 설정

```yaml
# Team 고성능 추론 설정
model:
  name: "convnext_base_384_in22ft1k"  # Team 모델
  drop_rate: 0.05
  drop_path_rate: 0.1

inference:
  tta: true                           # TTA 활성화
  tta_type: "essential"               # "essential" 또는 "comprehensive"
  confidence_threshold: 0.9           # 앙상블 신뢰도

# TTA 타입별 특징
# essential: 5가지, 17분, +2~3% 성능
# comprehensive: 15가지, 50분+, +3~5% 성능
```

## 📁 파일 간 의존 관계 및 데이터 흐름 다이어그램

### 🎯 추론 시스템 전체 의존 관계
```mermaid
graph TB
    subgraph CONFIGS["⚙️ 추론 설정 파일"]
        CONFIG1["configs/infer.yaml<br/>📍 단일 모델 추론<br/>빠른 검증용"]
        CONFIG2["configs/infer_highperf.yaml<br/>⚡ K-fold 앙상블 + TTA<br/>최고 성능용"]
        CONFIG3["configs/infer_multi_model_ensemble.yaml<br/>🎭 다중 모델 앙상블<br/>여러 아키텍처"]
        CONFIG4["configs/infer_calibrated.yaml<br/>🌡️ Temperature Scaling<br/>Optuna 최적화 연동"]
    end
    
    subgraph CORE["🧠 핵심 추론 시스템"]
        MAIN["src/inference/infer_main.py<br/>🚀 메인 CLI 인터페이스<br/>모드 선택 및 옵션"]
        INFER_BASIC["src/inference/infer.py<br/>📚 단일 모델 추론<br/>기본 TTA 또는 TTA 없음"]
        INFER_HIGH["src/inference/infer_highperf.py<br/>⚡ 고성능 앙상블 추론<br/>K-fold + Essential/Comprehensive TTA"]
        INFER_CALIB["src/inference/infer_calibrated.py<br/>🌡️ 보정된 추론<br/>Temperature Scaling 적용"]
    end
    
    subgraph SUPPORT["🔧 지원 시스템"]
        MODELS["src/models/build.py<br/>🏗️ 모델 빌더<br/>체크포인트 로드"]
        DATA["src/data/dataset.py<br/>📊 테스트 데이터 로더<br/>전처리 파이프라인"]
        TRANSFORMS["src/data/transforms.py<br/>🎨 TTA 변환<br/>Essential/Comprehensive TTA"]
        CALIBRATION["src/calibration/calibrate.py<br/>🌡️ Temperature Scaling<br/>모델 보정"]
        OPTIMIZATION["src/optimization/<br/>🔍 최적화 연동<br/>추론 파라미터 튜닝"]
    end
    
    subgraph INPUT["📥 입력 데이터"]
        TEST_IMGS["data/raw/test/<br/>📸 테스트 이미지<br/>예측 대상"]
        SAMPLE_CSV["data/raw/sample_submission.csv<br/>📄 제출 형식<br/>결과 템플릿"]
        FOLD_RESULTS["experiments/train/*/fold_results.yaml<br/>📊 폴드 메타데이터<br/>모델 경로 + 성능"]
        CHECKPOINTS["experiments/train/*/ckpt/*.pth<br/>💾 학습된 모델<br/>가중치 파일"]
    end
    
    subgraph OUTPUT["📤 출력 결과"]
        SINGLE_OUT["submissions/YYYYMMDD/<br/>📍 단일 모델 결과<br/>single_model_*.csv"]
        ENSEMBLE_OUT["submissions/YYYYMMDD/<br/>🎭 K-fold 앙상블 결과<br/>ensemble_*.csv"]
        MULTI_OUT["submissions/YYYYMMDD/<br/>🎆 다중 모델 결과<br/>multi_model_*.csv"]
        CALIB_OUT["submissions/YYYYMMDD/<br/>🌡️ 보정 결과<br/>calibrated_*.csv"]
        LOGS["logs/YYYYMMDD/infer/<br/>📝 추론 로그<br/>성능 기록"]
    end
    
    %% 설정 파일 → 메인 시스템 연결
    CONFIG1 --> MAIN
    CONFIG2 --> MAIN
    CONFIG3 --> MAIN
    CONFIG4 --> MAIN
    
    %% 메인 시스템 → 추론 로직 분기
    MAIN --> INFER_BASIC
    MAIN --> INFER_HIGH
    MAIN --> INFER_CALIB
    
    %% 추론 로직 → 지원 시스템 의존
    INFER_BASIC --> MODELS & DATA
    INFER_HIGH --> MODELS & DATA & TRANSFORMS
    INFER_CALIB --> MODELS & DATA & CALIBRATION & OPTIMIZATION
    
    %% 입력 데이터 → 추론 시스템
    TEST_IMGS --> DATA
    SAMPLE_CSV --> INFER_BASIC & INFER_HIGH & INFER_CALIB
    FOLD_RESULTS --> INFER_HIGH & INFER_CALIB
    CHECKPOINTS --> MODELS
    
    %% 추론 → 출력 생성
    INFER_BASIC --> SINGLE_OUT & LOGS
    INFER_HIGH --> ENSEMBLE_OUT & MULTI_OUT & LOGS
    INFER_CALIB --> CALIB_OUT & LOGS
    
    style CONFIG2 fill:#e8f5e8, color:#000000
    style CONFIG3 fill:#f3e5f5, color:#000000
    style MAIN fill:#fff3e0, color:#000000
    style INFER_HIGH fill:#ffcdd2, color:#000000
    style ENSEMBLE_OUT fill:#e1f5fe, color:#000000
    style MULTI_OUT fill:#fce4ec, color:#000000
```

---

## 📈 추론 모드별 성능 및 특징 분석

### 🎯 추론 전략별 비교 분석

| 추론 전략 | 속도 | 예상 F1 | GPU 메모리 | TTA 전략 | 최적 활용 상황 |
|------------|------|---------|-----------|----------|---------------|
| **📍 단일 모델 추론** | ⚡ 5분 | 0.92-0.93 | 4-6GB | No TTA | 초기 검증, 빠른 테스트 |
| **🎯 단일 모델 + TTA** | 🕰️ 17뵤 | 0.94-0.95 | 8GB | Essential | 균형적 성능 |
| **🔀 K-fold 앙상블** | 🔄 30분 | 0.95-0.97 | 16GB | Essential/Comp | 안정적 고성능 |
| **🎭 다중 모델** | 🎆 60분 | 0.96-0.99 | 24GB+ | Comprehensive | 대회 우승용 |

### 🏆 TTA 변환별 성능 기여도

| TTA 방식 | 변환 수 | 시간 비용 | 성능 기여 | 추천 상황 | 구현 위치 |
|------------|--------|---------|----------|----------|----------|
| **No TTA** | 1개 | ⚡ 기준 | 기준 | 초기 검증 | `infer.py` |
| **Essential TTA** | 5개 | 5배 | **+2.0%** | **균형적 추천** | `transforms.py:221-250` |
| **Comprehensive TTA** | 15개 | 15배 | **+4.0%** | 최고 성능 | `transforms.py:251-311` |
| **Legacy TTA** | 3개 | 3배 | +1.0% | 레거시 | 기존 코드 |

### 🔍 Optuna 최적화 연동 추론 전략

#### 추론 시 Optuna 활용 방식
- **Temperature Scaling 최적화**: 예측 확률 보정
- **TTA 가중치 최적화**: 변환별 가중치 자동 튜닝
- **Ensemble 가중치 최적화**: 모델별 기여도 자동 조정
- **Confidence Threshold 최적화**: 예측 신뢰도 임계값 튜닝

#### Optuna 최적화 성능 향상
| 기본 추론 | Optuna 최적화 | 성능 향상 |
|-----------|-----------------|----------|
| F1: 0.950 | F1: 0.965+ | **+1.5%** |
| 매드 설정 | 자동 튜닝 | **안정성** |

### 🏆 고급 기법 vs 기존 성능 비교

| 구분 | 모델 | TTA | 앙상블 | F1 Score | 성능 향상 | 시간 |
|------|------|-----|-------|----------|----------|------|
| 기존 베이스라인 | EfficientNet B3 | 없음 | 단일 | 0.9238 | - | 5분 |
| 기존 + 회전 TTA | EfficientNet B3 | Legacy | 단일 | 0.9289 | +0.51% | 10분 |
| **Essential 기법** | ConvNeXt Base | Essential | 5-fold | **0.9489** | **+2.51%** | **17분** |
| **Comprehensive 기법** | ConvNeXt Base | Comprehensive | 5-fold | **0.9652** | **+4.14%** | **50분+** |
| **다중 모델 최고** | Multi-Model | Comprehensive | Multi | **0.9750+** | **+5.12%** | **90분+** |

### 🎯 추론 모드 선택 가이드

```mermaid
flowchart TD
    A[추론 목적] --> B{상황에 따른 선택}
    
    B -->|빠른 검증 필요| C[📍 단일 모델<br/>5분<br/>F1: 0.92-0.93]
    B -->|균형적 성능| D[🎯 Essential TTA<br/>17분<br/>F1: 0.945-0.950]
    B -->|고성능 앙상블| E[🔀 K-fold 앙상블<br/>30분<br/>F1: 0.95-0.97]
    B -->|최고 성능| F[🎆 다중 모델<br/>60분+<br/>F1: 0.96-0.99]
    
    C --> G[단일 체크포인트<br/>--mode basic<br/>빠른 프로토타입]
    D --> H[TTA 전략 적용<br/>--mode highperf<br/>실용적 고성능]
    E --> I[5-fold 앙상블<br/>fold_results.yaml<br/>안정적 성능]
    F --> J[다중 모델 조합<br/>multi_model_ensemble<br/>대회 우승 수준]
    
    %% 추가 기법 분기
    H --> K{TTA 유형}
    K -->|균형| L[Essential TTA<br/>5가지 변환]
    K -->|최고| M[Comprehensive TTA<br/>15가지 변환]
    
    I --> N{옵션 기법}
    N -->|기본| O[기본 앙상블]
    N -->|보정| P[Temperature Scaling<br/>--use-calibration]
    N -->|최적화| Q[Optuna 튜닝<br/>threshold 최적화]
    
    style D fill:#e8f5e8, color:#000000
    style E fill:#f3e5f5, color:#000000
    style H fill:#c8e6c9, color:#000000
    style I fill:#ffcdd2, color:#000000
    style P fill:#fce4ec, color:#000000
```

---

## 🛠️ 고급 사용법

### 1. 커스텀 출력 경로 지정

```bash
# 특정 경로에 결과 저장
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml \
    --out submissions/custom/final_submission.csv
```

### 2. 특정 체크포인트 사용

```bash
# 직접 체크포인트 지정 (basic 모드에서만)
python src/inference/infer_main.py \
    --config configs/infer.yaml \
    --mode basic \
    --ckpt experiments/train/20250910/convnext/ckpt/best_fold2.pth \
    --out submissions/fold2_result.csv
```

### 3. GPU 메모리 최적화

```yaml
# configs/infer_highperf.yaml에서 배치 크기 조정
train:
  batch_size: 32    # RTX 3080용 (원래 48)
  
# 또는 16으로 더 감소 (RTX 3070용)
train:
  batch_size: 16
```

---

## 📊 결과 파일 분석

### 생성되는 파일들

```bash
# 실행 후 생성되는 파일 구조
submissions/20250910/
├── 20250910_1430_convnext_base_384_essential_tta.csv      # Essential TTA 결과
├── 20250910_1520_convnext_base_384_comprehensive_tta.csv  # Comprehensive TTA 결과
└── 20250910_1200_efficientnet_b3_basic.csv               # Basic 모드 결과

logs/20250910/infer/
├── infer_highperf_20250910_1430.log                      # 고성능 추론 로그
└── infer_basic_20250910_1200.log                         # 기본 추론 로그
```

### 결과 검증

```bash
# CSV 파일 검증
python -c "
import pandas as pd
df = pd.read_csv('submissions/20250910/20250910_1430_convnext_base_384_essential_tta.csv')
print(f'Shape: {df.shape}')
print(f'Columns: {df.columns.tolist()}')
print(f'Missing values: {df.isnull().sum().sum()}')
print(f'Unique predictions: {df.iloc[:, 1].nunique()}')
"
```

---

## ⚠️ 문제해결 가이드

### 자주 발생하는 오류

#### 1. fold_results.yaml 없음
```bash
FileNotFoundError: fold_results.yaml not found
```
**해결방법:**
```bash
# 학습 먼저 실행하여 fold_results.yaml 생성
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# 또는 기존 결과 사용
--fold-results experiments/train/20250910/convnext_base_384_team/fold_results.yaml
```

#### 2. CUDA 메모리 부족
```bash
RuntimeError: CUDA out of memory (TTA)
```
**해결방법:**
```yaml
# configs/infer_highperf.yaml에서 배치 크기 감소
train:
  batch_size: 16  # 48 → 16으로 감소

# 또는 Essential TTA로 전환
inference:
  tta_type: "essential"  # comprehensive → essential
```

#### 3. 테스트 이미지 없음
```bash
FileNotFoundError: test image not found
```
**해결방법:**
```bash
# 테스트 데이터 경로 확인
ls data/raw/test/
head -5 data/raw/sample_submission.csv

# 설정에서 경로 수정
data:
  image_dir_test: "./data/raw/test"
  sample_csv: "./data/raw/sample_submission.csv"
```

---

## 🏁 최종 제출 워크플로우

### Phase 1: 빠른 검증 (5분)
```bash
# 1. 기본 모델 검증
python src/inference/infer_main.py --config configs/infer.yaml --mode basic
```

### Phase 2: 실용적 고성능 (17분, 권장)
```bash
# 2. Essential TTA 추론
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml

# configs/infer_highperf.yaml에서:
# inference.tta_type: "essential"
```

### Phase 3: 최종 우승용 (50분+)
```bash
# 3. Comprehensive TTA 추론
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml

# configs/infer_highperf.yaml에서:
# inference.tta_type: "comprehensive"
```

### 🎯 제출 파일 선택
```bash
# 가장 성능 좋은 결과 선택
BEST_FILE=$(ls -t submissions/$(date +%Y%m%d)/*comprehensive*.csv | head -1)
echo "최종 제출 파일: $BEST_FILE"

# 백업 생성
cp "$BEST_FILE" "submissions/FINAL_SUBMISSION_$(date +%Y%m%d_%H%M).csv"
```