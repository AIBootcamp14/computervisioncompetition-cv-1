# 🛠️ 문제 해결 가이드 (Team ConvNeXt 기법 포함)

## 📈 Team 기법 관련 문제 해결

### 🎯 Team ConvNeXt 최적화 문제 진단

| 문제 유형 | 증상 | 예상 성능 | 해결 방법 | 대안 | 사용 명령어 |
|----------|------|-----------|---------|------|-----------|
| **TTA 메모리 부족** | CUDA OOM | F1: 0.9652 → 사용 불가 | Essential TTA 사용 | tta_type: "essential" | `--config infer_highperf.yaml` |
| **배치 크기 초과** | 학습 실패 | F1: 0.9489 기대 | 배치 크기 감소 | batch_size: 32 → 16 | `auto_batch_size.py` |
| **fold_results.yaml 없음** | 추론 오류 | 앱상블 불가 | 학습 먼저 실행 | highperf 모드 완료 | `train_main.py --mode highperf` |
| **GPU 메모리 부족** | ConvNeXt 실행 불가 | RTX 3060 에서 실패 | 배치 크기 16 | EfficientNet 대안 | `--batch-size 16` |

### 🚀 Team TTA 시스템 문제해결

#### 1. Comprehensive TTA CUDA OOM 오류
```bash
# 오류: RuntimeError: CUDA out of memory (Comprehensive TTA)
RuntimeError: CUDA out of memory. Tried to allocate 2.50 GiB (GPU 0; 9.78 GiB total capacity)

# 해결방법 1: Essential TTA로 전환 (F1: 0.9565)
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml
# configs/infer_highperf.yaml에서: tta_type: "essential"

# 해결방법 2: 배치 크기 감소
# train.batch_size: 48 → 32 → 16
```

#### 2. ConvNeXt Base 384 메모리 부족
```bash
# RTX 3060/3070에서 ConvNeXt 실행 시 메모리 부족

# 자동 최적화
python src/utils/gpu_optimization/auto_batch_size.py \
    --config configs/train_highperf.yaml \
    --model-type convnext \
    --safety-factor 0.8

# 수동 설정 예시 (RTX 3060)
# configs/train_highperf.yaml:
# train:
#   batch_size: 16  # 48에서 16으로 감소
#   accumulate_grad_batches: 3  # 실질 배치 48 유지
```

#### 3. fold_results.yaml 파일 없음
```bash
# 오류: FileNotFoundError: fold_results.yaml not found

# 해결방법: 학습 먼저 완료
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode highperf

# 학습 완료 후 자동 생성된 경로 확인
ls experiments/train/lastest-train/fold_results.yaml

# 수동 경로 지정
python src/inference/infer_main.py \
    --fold-results experiments/train/20250910/convnext_base_384_team/fold_results.yaml
```

## 🚨 일반적인 문제들

## 🎯 Team ConvNeXt 성능 진단 도구

### Team 모델 성능 체크리스트

| 확인 항목 | 기대값 | 확인 명령어 | 문제 시 해결방법 |
|----------|-------|------------|----------------|
| **기본 ConvNeXt** | F1: 0.9489 | 학습 로그 확인 | 하이퍼파라미터 조정 |
| **Essential TTA** | F1: 0.9565 | 추론 실행 확인 | tta_type 설정 검증 |
| **Comprehensive TTA** | F1: 0.9652 | GPU 메모리 충분성 | RTX 3080+ 필요 |
| **Temperature Scaling** | 신뢰도 개선 | 학습 설정 확인 | 설정 파일 검증 |
| **Hard Augmentation** | 학습 안정성 | 배치 크기 검증 | 메모리 최적화 |

### Team 모델 파일 자동 찾기
```bash
# Team ConvNeXt 전용 모델 찾기
find experiments/train -name "*convnext*" -o -name "*team*" | head -10
find experiments/train -path "*/lastest-train/best_fold*.pth"

# Team 최신 결과 확인
ls -la experiments/train/lastest-train/
echo "Team fold_results.yaml 존재 확인"
test -f experiments/train/lastest-train/fold_results.yaml && echo "✅ 발견됨" || echo "❌ 없음 - 학습 필요"

# Team 모델 성능 예상치 확인
echo "=== Team ConvNeXt 예상 성능 ==="
echo "기본 모델: F1 0.9489 (10-15분 추론)"
echo "Essential TTA: F1 0.9565 (17분 추론)"  
echo "Comprehensive TTA: F1 0.9652 (50분+ 추론)"
```

### 1. GPU 메모리 부족 (CUDA Out of Memory)

#### Team ConvNeXt 최적화 해결법
```bash
# 1) 현재 GPU 상태 또는 Team 모델 메모리 사용량 확인
nvidia-smi
echo "ConvNeXt Base 384 메모리 요구사항: RTX 3080 10GB 이상 권장"

# 2) Team 모델 메모리 정리 및 최적화
python -c "import torch; torch.cuda.empty_cache(); print('Team ConvNeXt 메모리 정리 완료')"

# 3) Team 최적화 자동 배치 크기 결정
python src/utils/gpu_optimization/auto_batch_size.py \
    --config configs/train_highperf.yaml \
    --model-type convnext \
    --safety-factor 0.85 \
    --target-f1 0.9550

# 4) GPU별 Team ConvNeXt 최적 배치 크기
echo "RTX 4090 (24GB): batch_size 64, F1 0.9652 기대"
echo "RTX 3080 (10GB): batch_size 32, F1 0.9550 기대"
echo "RTX 3060 (8GB):  batch_size 16, F1 0.9520 기대"
```

### 2. Team ConvNeXt 모델 파일을 찾을 수 없음

#### Team 최적화 해결법
```bash
# 1) Team ConvNeXt 모델 찾기
find experiments/train -name "*convnext*" -path "*/results/ckpt/*.pth" | head -5
find experiments/train -path "*/lastest-train/best_fold*.pth" | head -5

# 2) Team 최신 모델 자동 선택
TEAM_MODEL=$(find experiments/train -path "*/lastest-train/best_fold0.pth" | head -1)
echo "Team ConvNeXt 최신 모델: $TEAM_MODEL"

# 3) Team 모델 직접 지정 추론 (F1: 0.9652 목표)
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml

# 4) Team 모델 상태 확인
ls -la experiments/train/lastest-train/
echo "fold_results.yaml 존재 여부 확인 중..."
```

### 3. 학습이 진행되지 않음

#### 해결 방법
```bash
# 1) 로그 확인
tail -20 logs/$(date +%Y%m%d)/train/*.log

# 2) 데이터 경로 확인
ls -la data/raw/train/ | head -5
ls -la data/raw/test/ | head -5

# 3) 환경 재설정
eval "$(pyenv init --path)" && pyenv activate cv_py3_11_9
pip install -r requirements.txt
```

### 4. 설정 파일 오류

#### 해결 방법
```bash
# 1) YAML 문법 확인
python -c "import yaml; yaml.safe_load(open('configs/train.yaml'))"

# 2) 기본 설정으로 초기화
cp configs/train.yaml.backup configs/train.yaml  # 백업이 있는 경우

# 3) 설정 날짜 업데이트
python src/utils/config/update_config_dates.py
```

## � 실행 스크립트 문제

### Python 스크립트 실행 오류

#### 문제: 스크립트를 직접 실행하려 할 때 오류 발생
```bash
# ❌ 잘못된 실행 방법
src/utils/gpu_optimization/auto_batch_size.py --config configs/train.yaml

# ✅ 올바른 실행 방법
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train.yaml
```

#### 해결 방법
```bash
# 1) Python 인터프리터로 실행
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train_highperf.yaml
python src/utils/gpu_optimization/team_gpu_check.py

# 2) 실행 권한 확인 및 설정 (선택사항)
chmod +x src/utils/**/*.py

# 3) shebang 추가 (스크립트 맨 위에)
#!/usr/bin/env python3
```

### 로그 파일 저장 위치 문제

#### 문제: 추론 로그가 예상과 다른 위치에 저장됨
```bash
# 실제 저장 위치: logs/infer/
# 예상 위치: logs/YYYYMMDD/infer/
```

#### 현재 상황
```bash
# 추론 로그 실제 저장 위치
ls -la logs/infer/
# 출력: infer_YYYYMMDD-HHMM_modelname-inference.log

# 학습 로그는 날짜별 폴더에 저장
ls -la logs/YYYYMMDD/train/
```

#### 임시 해결 방법
```bash
# 1) 현재 추론 로그 확인
tail -20 logs/infer/*.log

# 2) 최신 추론 로그 찾기
ls -t logs/infer/*.log | head -1

# 3) 수동으로 날짜별 폴더로 이동 (선택사항)
mkdir -p logs/$(date +%Y%m%d)/infer/
mv logs/infer/*.log logs/$(date +%Y%m%d)/infer/
```

## �📊 성능 문제

### 성능이 예상보다 낮을 때

#### 해결 방법
```bash
# 1) 데이터 검증
python -c "
import pandas as pd
df = pd.read_csv('data/raw/train.csv')
print(f'데이터 크기: {len(df)}')
print(f'클래스 분포:\n{df.iloc[:, 1].value_counts()}')
"

# 2) 하이퍼파라미터 최적화
python src/training/train_main.py \
    --config configs/train.yaml \
    --optimize \
    --n-trials 10

# 3) 검증된 설정 사용
python src/training/train_main.py --config configs/train.yaml --mode basic
```

### 학습이 너무 느릴 때

#### 해결 방법
```bash
# 1) GPU 성능 확인
python src/utils/gpu_optimization/team_gpu_check.py

# 2) 배치 크기 최적화
python src/utils/gpu_optimization/auto_batch_size.py --config configs/train.yaml

# 3) 빠른 설정 사용
python src/training/train_main.py --config configs/train_fast.yaml --mode basic
```

## 🔧 환경 문제

### Python 환경 문제

#### 해결 방법
```bash
# 1) Python 버전 확인
python3 --version  # 3.11.9 필요

# 2) 가상환경 재설정
pyenv deactivate
pyenv activate cv_py3_11_9

# 3) 의존성 재설치
pip install -r requirements.txt --force-reinstall
```

### CUDA 환경 문제

#### 해결 방법
```bash
# 1) CUDA 버전 확인
nvidia-smi
nvcc --version

# 2) PyTorch CUDA 호환성 확인
python -c "
import torch
print(f'PyTorch: {torch.__version__}')
print(f'CUDA available: {torch.cuda.is_available()}')
print(f'CUDA version: {torch.version.cuda}')
"

# 3) PyTorch 재설치 (필요시)
pip uninstall torch torchvision
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

## 📋 로그 분석

### 로그 파일 위치
```bash
# 최신 로그 확인
ls -la logs/$(date +%Y%m%d)/

# 학습 로그
tail -f logs/$(date +%Y%m%d)/train/*.log

# 추론 로그
tail -f logs/$(date +%Y%m%d)/infer/*.log
```

### 오류 패턴 찾기
```bash
# GPU 메모리 오류
grep -i "out of memory\|cuda\|memory" logs/$(date +%Y%m%d)/*/*.log

# 파일 경로 오류
grep -i "not found\|no such file" logs/$(date +%Y%m%d)/*/*.log

# 성능 지표
grep -i "f1\|accuracy\|loss" logs/$(date +%Y%m%d)/*/*.log
```

## 🆘 긴급 복구

### 모든 것이 작동하지 않을 때
```bash
# 1) 기본 테스트
python -c "
import torch, pandas, numpy
print('✅ 기본 라이브러리 정상')
print(f'GPU: {torch.cuda.is_available()}')
"

# 2) 최소 설정으로 테스트
python src/training/train_main.py --config configs/train.yaml --mode basic --epochs 1

# 3) 전체 환경 재구성
# (필요시 README.md의 환경 설정 섹션 참조)
```
