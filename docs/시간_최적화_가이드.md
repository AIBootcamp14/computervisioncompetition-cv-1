# 시간 최적화 가이드 문서

## 개요
컴퓨터 비전 경진대회를 위한 전체 파이프라인을 30분 이내에 완료하기 위한 설정 가이드입니다.

## 시간에 가장 큰 영향을 미치는 설정들

### 1. 학습 설정 (가장 중요)

#### epochs (학습 에포크 수)
- **기본값**: 3-5 에포크
- **빠른 실행**: 1-2 에포크
- **영향**: 에포크당 약 5-10분 소요
- **권장**: 30분 완료 시 epochs: 1 설정

```yaml
train:
  epochs: 1  # 기존 3-5에서 1로 감소
```

#### batch_size (배치 크기)
- **기본값**: 64-96
- **빠른 실행**: 128-160
- **영향**: 배치 크기가 클수록 빠른 학습 (메모리 허용 범위 내)
- **권장**: RTX 4090 기준 128-160

```yaml
train:
  batch_size: 128  # 기존 64에서 128로 증가
```

### 2. Cross-Validation 설정

#### folds (K-폴드 개수)
- **기본값**: 5 폴드
- **빠른 실행**: 2-3 폴드
- **영향**: 폴드당 전체 학습 시간이 곱해짐
- **권장**: 30분 완료 시 folds: 2 설정

```yaml
data:
  folds: 2  # 기존 5에서 2로 감소
```

### 3. Optuna 최적화 설정

#### n_trials (최적화 시도 횟수)
- **기본값**: 10-30 trials
- **빠른 실행**: 3-5 trials
- **영향**: trial당 약 5-15분 소요
- **권장**: 30분 완료 시 n_trials: 3-5

```yaml
optuna:
  n_trials: 5  # 기존 10-30에서 5로 감소
```

#### timeout (최적화 타임아웃)
- **기본값**: 5400초 (90분)
- **빠른 실행**: 1200-1800초 (20-30분)
- **영향**: 전체 최적화 시간 제한
- **권장**: timeout: 1800 (30분)

```yaml
optuna:
  timeout: 1800  # 기존 5400에서 1800으로 감소
```

#### quick_validation epochs
- **기본값**: 10 에포크
- **빠른 실행**: 1-2 에포크
- **영향**: Optuna 평가 시간 단축
- **권장**: epochs: 1

```yaml
optuna:
  quick_validation:
    epochs: 1  # 기존 10에서 1로 감소
```

### 4. 데이터 로딩 최적화

#### num_workers (데이터 로더 워커 수)
- **기본값**: 4
- **빠른 실행**: 8-12 (CPU 코어 수에 따라)
- **영향**: 데이터 로딩 속도 향상
- **권장**: RTX 4090 환경에서 8-12

```yaml
project:
  num_workers: 8  # 기존 4에서 8로 증가
```

#### pin_memory & persistent_workers
- **권장 설정**: true로 설정하여 GPU 전송 속도 향상

```yaml
project:
  pin_memory: true
  persistent_workers: true
```

### 5. 모델 관련 설정

#### mixed_precision (혼합 정밀도)
- **권장**: true 설정으로 메모리 효율성과 속도 향상

```yaml
train:
  mixed_precision: true
```

## 설정 파일별 최적화 예시

### train_multi_model_ensemble.yaml (메인 학습)
```yaml
# 시간 단축을 위한 핵심 설정
data:
  folds: 2  # 5 -> 2

train:
  epochs: 1          # 3 -> 1
  batch_size: 128    # auto -> 128
  mixed_precision: true
```

### optuna_config.yaml (최적화)
```yaml
optuna:
  n_trials: 5        # 10 -> 5
  timeout: 1800      # 5400 -> 1800
  
  quick_validation:
    epochs: 1        # 10 -> 1
```

## 시간 계산 예시

### 기존 설정 (약 180분)
- K-fold: 5 × epochs: 3 × 5분 = 75분 (학습)
- Optuna: 10 trials × 10분 = 100분 (최적화)
- 추론: 5분
- **총합: 180분**

### 최적화된 설정 (약 25분)
- K-fold: 2 × epochs: 1 × 3분 = 6분 (학습)
- Optuna: 5 trials × 3분 = 15분 (최적화)
- 추론: 4분
- **총합: 25분**

## 주의사항

1. **성능 vs 시간**: 시간을 단축하면 일반적으로 성능이 다소 감소할 수 있습니다.
2. **메모리 제한**: batch_size를 너무 크게 하면 Out of Memory 에러가 발생할 수 있습니다.
3. **하드웨어 의존성**: RTX 4090 기준으로 최적화된 설정이므로 다른 GPU에서는 조정이 필요합니다.

## 빠른 테스트용 설정 예시

30분 이내 완료를 위한 최소 설정:

```yaml
# train_multi_model_ensemble.yaml
data:
  folds: 2

train:
  epochs: 1
  batch_size: 128

# optuna_config.yaml  
optuna:
  n_trials: 3
  timeout: 1200
  quick_validation:
    epochs: 1
```

이 설정으로 전체 파이프라인이 20-30분 내에 완료됩니다.