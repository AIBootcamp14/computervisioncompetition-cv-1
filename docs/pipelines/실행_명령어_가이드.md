# 🚀 실행 명령어 완전 가이드

## 📋 목차
1. [환경 설정](#환경-설정)
2. [통합 CLI 인터페이스](#통합-cli-인터페이스)
3. [학습 파이프라인](#학습-파이프라인)
4. [추론 파이프라인](#추론-파이프라인)
5. [최적화 및 캘리브레이션](#최적화-및-캘리브레이션)
6. [전체 파이프라인](#전체-파이프라인)
7. [단위 테스트](#단위-테스트)
8. [로그 및 결과 확인](#로그-및-결과-확인)
9. [고급 사용법](#고급-사용법)
10. [문제 해결](#문제-해결)

---

## 🔧 환경 설정

### **1. 기본 환경 확인**
```bash
# 현재 디렉토리 확인
pwd
# 출력: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN

# Python 환경 확인
python3 --version
# 출력: Python 3.11.9

# pyenv 가상환경 활성화
pyenv activate cv_py3_11_9
echo $VIRTUAL_ENV
```

### **2. 의존성 설치**
```bash
# 필수 패키지 설치 (Optuna, scikit-learn 포함)
pip install -r requirements.txt

# 설치 확인
pip list | grep -E "torch|pandas|numpy|matplotlib|optuna|sklearn"

# 핵심 모듈 import 테스트
python3 -c "
import torch, pandas, numpy, matplotlib, optuna
from src.utils.common import load_yaml
from src.data.dataset import HighPerfDocClsDataset
from src.optimization.optuna_tuner import OptunaTuner
from src.calibration.temperature_scaling import TemperatureScaling
print('✅ 모든 의존성 정상 설치됨')
"
```

---

## 🎯 통합 CLI 인터페이스

### **새로운 통합 실행 방식**
모든 학습 모드가 하나의 CLI로 통합되었습니다:

```bash
python src/training/train_main.py [OPTIONS]
```

#### **기본 옵션들:**
- `--config`: 설정 파일 경로 (필수)
- `--mode`: 실행 모드 (basic, highperf, full-pipeline)
- `--optimize`: Optuna 하이퍼파라미터 최적화 사용
- `--n-trials`: 최적화 시도 횟수 (기본값: 20)
- `--use-calibration`: Temperature Scaling 캘리브레이션 사용
- `--auto-continue`: 최적화 후 자동으로 전체 학습 진행
- `--skip-training`: 학습 건너뛰고 추론만 실행 (full-pipeline 모드)

#### **도움말 확인:**
```bash
python src/training/train_main.py --help

## 🚀 전체 파이프라인

### **1. 완전 자동화 파이프라인 (최고 성능)**

#### **권장 실행 명령어**
```bash
# 환경 설정
pyenv activate cv_py3_11_9

# 완전 최적화 파이프라인
python src/training/train_main.py 
    --config configs/train_highperf.yaml 
    --optimize 
    --n-trials 20 
    --use-calibration 
    --mode full-pipeline 
    --auto-continue
```

이 명령어의 실행 순서:
1. **🔍 Optuna 최적화**: 하이퍼파라미터 20번 시도 최적화
2. **🎯 자동 학습**: 최적화된 설정으로 전체 K-Fold 학습
3. **🌡️ 캘리브레이션**: Temperature Scaling 모델 보정
4. **🔮 고성능 추론**: 앙상블 + TTA 추론
5. **📤 제출 파일**: 자동 생성 및 저장

### **2. 빠른 실행 (최적화 건너뛰기)**
```bash
# 사전 최적화된 설정으로 바로 실행
python src/training/train_main.py 
    --config configs/train_optimized_20250907_1825.yaml 
    --use-calibration 
    --mode full-pipeline
```

### **3. 추론만 실행**
```bash
# 기학습된 모델로 추론만 실행
python src/training/train_main.py 
    --config configs/train_highperf.yaml 
    --mode full-pipeline 
    --skip-training 
    --use-calibration
```

---

## 🧪 단위 테스트

### **모듈별 테스트**
```bash
# 전체 테스트 실행
python -m pytest tests/ -v

# 특정 모듈 테스트
python -m pytest tests/test_optimization.py -v
python -m pytest tests/test_calibration.py -v

# 핵심 기능 테스트
python -c "
from src.optimization.optuna_tuner import OptunaTuner
from src.calibration.temperature_scaling import TemperatureScaling
print('✅ 최적화 및 캘리브레이션 모듈 정상')
"
```

---

## 📊 로그 및 결과 확인

### **새로운 로그 파일명 형식**

#### **증강 타입 구분**
- **기본 증강**: `train_basic_augmentation_YYYYMMDD-HHMM_model.log`
- **고급 증강**: `train_highperf_advanced_augmentation_YYYYMMDD-HHMM_model.log`

#### **로그 파일 위치**
```bash
# 학습 로그
ls -la logs/train/

# 최적화 로그
ls -la logs/optimization/

# 파이프라인 로그
ls -la logs/pipeline/

# 추론 로그
ls -la logs/infer/
```

### **실험 결과 확인**
```bash
# 실험 폴더 (타임스탬프 기반)
ls -la experiments/train/20250907/

# 최적화 결과
ls -la experiments/optimization/

# 제출 파일
ls -la submissions/20250907/
```

---

## 🎯 고급 사용법

### **1. 증강 설정 커스텀**

#### **기본 증강으로 변경**
`configs/train_highperf.yaml` 수정:
```yaml
train:
  use_advanced_augmentation: false  # false = 기본 증강
```

#### **고급 증강으로 변경**
```yaml
train:
  use_advanced_augmentation: true   # true = 고급 증강
```

### **2. Optuna 설정 커스텀**

#### **최적화 범위 조정**
`configs/optuna_config.yaml` 수정:
```yaml
search_space:
  lr: [1e-5, 1e-3]          # 학습률 범위
  weight_decay: [1e-6, 1e-2] # Weight decay 범위
  batch_size: [16, 64]       # 배치 크기 범위
```

### **3. GPU 메모리 최적화**
```bash
# 작은 배치 크기로 시작
python src/training/train_main.py 
    --config configs/train_highperf.yaml 
    --mode highperf

# 배치 크기를 수동으로 설정 후 config 파일 수정
```

---

## ❗ 문제 해결

### **일반적인 문제들**

#### **1. 환경 문제**
```bash
# pyenv 환경 재설정
pyenv deactivate
pyenv activate cv_py3_11_9

# 의존성 재설치
pip install -r requirements.txt --force-reinstall
```

#### **2. GPU 메모리 부족**
```bash
# 배치 크기 줄이기 (config 파일 수정)
# train_highperf.yaml에서 batch_size: 16 -> 8

# 또는 명령어로 제한
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 python src/training/train_main.py ...
```

#### **3. Optuna 최적화 오류**
```bash
# Optuna 재설치
pip install optuna>=4.0.0 --force-reinstall

# 시도 횟수 줄이기
python src/training/train_main.py --optimize --n-trials 5 ...
```

#### **4. 로그 파일명 확인**
```bash
# 증강 설정 확인
grep "use_advanced_augmentation" configs/train_highperf.yaml

# 로그 파일 패턴 확인
ls -la logs/train/*augmentation*
```

### **디버깅 명령어**
```bash
# 설정 파일 검증
python -c "
from src.utils.common import load_yaml
cfg = load_yaml('configs/train_highperf.yaml')
print(f'증강 설정: {cfg["train"]["use_advanced_augmentation"]}')
print(f'모델: {cfg["model"]["name"]}')
"

# 모듈 import 테스트
python -c "
from src.optimization.optuna_tuner import OptunaTuner
from src.calibration.temperature_scaling import TemperatureScaling
print('✅ 모든 모듈 정상')
"
```
```bash
# CUDA 사용 가능 여부 확인
python3 -c "import torch; print(f'CUDA available: {torch.cuda.is_available()}')"

# GPU 정보 확인
nvidia-smi

# PyTorch CUDA 버전 확인
python3 -c "import torch; print(f'PyTorch version: {torch.__version__}')"
```

---

## 🏃 기본 실행 명령어

### **프로젝트 구조 확인**
```bash
# 전체 구조 확인
tree -L 3 -I '__pycache__'

# 주요 디렉토리 확인
ls -la src/
ls -la configs/
ls -la data/raw/
ls -la notebooks/
```

### **설정 파일 검증**
```bash
# YAML 파일 유효성 확인
python3 -c "
import yaml
configs = ['configs/train.yaml', 'configs/train_highperf.yaml', 'configs/infer.yaml']
for config in configs:
    try:
        with open(config) as f:
            yaml.safe_load(f)
        print(f'✅ {config}')
    except Exception as e:
        print(f'❌ {config}: {e}')
"
```

---

## 🎓 학습 파이프라인

### **사전 준비 (필수 단계)**
```bash
## 🎓 학습 파이프라인

### **1. 기본 학습 (Basic Mode)**

#### **기본 증강 학습**
```bash
# pyenv 환경 활성화
pyenv activate cv_py3_11_9

# 기본 모드 (basic augmentation)
python src/training/train_main.py \
    --config configs/train.yaml \
    --mode basic
```

### **2. 고성능 학습 (High Performance Mode) - 권장**

#### **고급 증강 학습**
```bash
# 고성능 모드 (advanced augmentation + mixup)
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode highperf
```

---

## 🔍 최적화 및 캘리브레이션

### **1. Optuna 하이퍼파라미터 최적화**

#### **기본 최적화 (20번 시도)**
```bash
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --mode highperf
```

#### **커스텀 시도 횟수**
```bash
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 50 \
    --mode highperf
```

### **2. Temperature Scaling 캘리브레이션**

#### **캘리브레이션 적용 학습**
```bash
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --use-calibration \
    --mode full-pipeline
```

### **3. 완전 최적화 (Optuna + Calibration)**

#### **권장 설정**
```bash
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 20 \
    --use-calibration \
    --mode full-pipeline \
    --auto-continue
```

이 명령어는 다음을 수행합니다:
1. **Optuna 최적화**: 20번 시도로 하이퍼파라미터 최적화
2. **자동 진행**: 최적화 완료 후 자동으로 전체 학습 시작
3. **Temperature Scaling**: 모델 캘리브레이션 적용
4. **통합 파이프라인**: 학습 + 추론 + 제출 파일 생성

---

## � 추론 파이프라인

### **1. 기본 추론**
```bash
python src/training/train_main.py \
    --config configs/train.yaml \
    --mode full-pipeline \
    --skip-training
```

### **2. 고성능 추론 (앙상블 + TTA)**
```bash
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode full-pipeline \
    --skip-training \
    --use-calibration
```
```bash
# 고성능 설정 최적화
pyenv activate cv_py3_11_9
python src/utils/team_gpu_check.py
python src/utils/auto_batch_size.py --config configs/train_highperf.yaml
```

#### **전체 K-Fold 학습**
```bash
# 고성능 모드 (5-fold 전체)
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# 고성능 설정 파일 지정
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# 백그라운드 실행 (장시간 학습)
nohup python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf > training.log 2>&1 &

# 실행 상태 확인
tail -f training.log
```

#### **완전한 실행 시퀀스 (권장)**
```bash
# 1-4. 사전 준비
pyenv activate cv_py3_11_9
python src/utils/team_gpu_check.py
python src/utils/auto_batch_size.py --config configs/train_highperf.yaml

# 5. 고성능 학습 시작
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
```

#### **특정 Fold들만 학습**
```bash
# Fold 0, 1, 2만 학습 (매개변수 지원 시)
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# 단일 Fold 고성능 모드 (매개변수 지원 시)  
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
```

#### **WandB 통합 학습**
```bash
# WandB 로그인 (최초 1회)
wandb login

# WandB 통합 학습 (올바른 방법) - WandB는 설정파일에서 제어
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# 특정 프로젝트명 지정
WANDB_PROJECT="cv-competition-1sen" python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
```

### **3. 학습 모니터링**

#### **실시간 로그 확인**
```bash
# 최신 학습 로그 확인
ls -t logs/$(date +%Y%m%d)/train/ | head -1 | xargs -I {} tail -f logs/$(date +%Y%m%d)/train/{}

# 특정 로그 파일 확인
tail -f logs/$(date +%Y%m%d)/train/train_20250905-1400_v087-abc123.log

# 학습 진행률 확인 (에포크별)
grep "Epoch" logs/$(date +%Y%m%d)/train/train_*.log | tail -10
```

#### **학습 중단 및 재시작**
```bash
# 학습 중단
pkill -f "python src/training/train_main.py"

# 체크포인트에서 재시작 (구현 필요시)
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf --resume experiments/train/20250905/fold_0/checkpoint.pth
```

---

## 🔮 추론 파이프라인

### **1. 기본 추론**

#### **단일 모델 추론**
```bash
# 기본 추론
python src/inference/infer_main.py

# 설정 파일 지정
python src/inference/infer_main.py --config configs/infer.yaml

# 특정 모델 파일 사용
python src/inference/infer_main.py --model-path experiments/train/20250905/fold_0/best_model.pth

# GPU 지정
CUDA_VISIBLE_DEVICES=0 python src/inference/infer_main.py
```

### **2. 고성능 추론 (Fold 앙상블)**

#### **Fold 결과 앙상블**
```bash
# 고성능 추론 (모든 fold 앙상블)
python src/inference/infer_main.py --mode highperf --fold-results experiments/train/20250905/fold_results

# 특정 fold들만 앙상블
python src/inference/infer_main.py --mode highperf --fold-results experiments/train/20250905/fold_results --folds 0,1,2,3,4

# 앙상블 방법 지정
python src/inference/infer_main.py --mode highperf --fold-results experiments/train/20250905/fold_results --ensemble-method mean
```

#### **실행 예시**
```bash
# 날짜별 실험 결과 확인
ls -la experiments/train/

# 최신 실험의 fold 결과 사용
LATEST_EXP=$(ls -t experiments/train/ | head -1)
python src/inference/infer_main.py --mode highperf --fold-results experiments/train/$LATEST_EXP/fold_results

# 출력 예시:
# 📋 추론 설정 로드 완료
# 🎯 모델: swin_base_patch4_window7_224
# 📁 Fold 결과 디렉토리: experiments/train/20250905/fold_results
# 🔍 발견된 fold 모델: [0, 1, 2, 3, 4]
# 📊 테스트 데이터: 3,141개 샘플
# [1/5] Fold 0 추론 완료
# ...
# 🎯 앙상블 추론 완료
# 💾 제출 파일 저장: submissions/20250905/submission.csv
```

### **3. 추론 결과 확인**

#### **제출 파일 검증**
```bash
# 최신 제출 파일 확인
ls -la submissions/$(ls -t submissions/ | head -1)/

# 제출 파일 형식 확인
head -10 submissions/$(ls -t submissions/ | head -1)/*.csv

# 제출 파일 통계
python3 -c "
import pandas as pd
import glob
latest_sub = sorted(glob.glob('submissions/*/submission.csv'))[-1]
df = pd.read_csv(latest_sub)
print(f'제출 파일: {latest_sub}')
print(f'샘플 수: {len(df)}')
print(f'클래스 분포: {df.iloc[:, 1].value_counts().head()}')
"
```

---

## 🔄 전체 파이프라인

### **사전 준비 (전체 파이프라인용)**
```bash
# pyenv 가상환경 활성화
pyenv activate cv_py3_11_9

# GPU 호환성 체크
python src/utils/team_gpu_check.py

# 학습용 배치 크기 최적화
python src/utils/auto_batch_size.py --config configs/train_highperf.yaml

# 추론용 배치 크기 최적화 (옵션)
python src/utils/auto_batch_size.py --config configs/infer.yaml --test-only
```

### **1. 완전 자동화 파이프라인**
```bash
# 학습 + 추론 전체 파이프라인
python src/pipeline/full_pipeline.py

# 설정 파일 지정
python src/pipeline/full_pipeline.py --train-config configs/train_highperf.yaml --infer-config configs/infer.yaml

# 백그라운드 실행
nohup python src/pipeline/full_pipeline.py > full_pipeline.log 2>&1 &
```

### **2. 단계별 실행**
```bash
# 사전 준비
pyenv activate cv_py3_11_9
python src/utils/team_gpu_check.py
python src/utils/auto_batch_size.py --config configs/train_highperf.yaml

# 1단계: 고성능 학습
echo "🎓 1단계: 학습 시작..."
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# 2단계: 결과 확인
echo "📊 2단계: 학습 결과 확인..."
ls -la experiments/train/$(ls -t experiments/train/ | head -1)/fold_results/

# 3단계: 앙상블 추론
echo "🔮 3단계: 앙상블 추론 시작..."
LATEST_EXP=$(ls -t experiments/train/ | head -1)
python src/inference/infer_main.py --mode highperf --fold-results experiments/train/$LATEST_EXP/fold_results

# 4단계: 결과 검증
echo "✅ 4단계: 최종 결과 확인..."
ls -la submissions/$(ls -t submissions/ | head -1)/
```

---

## 🧪 단위 테스트

### **1. Jupyter 노트북 실행**

#### **노트북 서버 시작**
```bash
# Jupyter Notebook 시작
jupyter notebook --port=8888 --no-browser

# JupyterLab 시작 (권장)
jupyter lab --port=8888 --no-browser

# 백그라운드 실행
nohup jupyter lab --port=8888 --no-browser > jupyter.log 2>&1 &
```

#### **개별 단위 테스트 노트북**
```bash
# 1. 고성능 데이터셋 테스트
# notebooks/unit_tests/test_highperf_dataset.ipynb

# 2. Mixup 증강 테스트  
# notebooks/unit_tests/test_mixup_augmentation.ipynb

# 3. Swin 모델 테스트
# notebooks/unit_tests/test_swin_model.ipynb

# 4. 로깅 통합 테스트 (예시)
# notebooks/test_highperf_dataset_with_logging.ipynb
```

### **2. 통합 테스트 노트북**

#### **전체 파이프라인 테스트**
```bash
# 전체 파이프라인 검증
# notebooks/test_full_pipeline.ipynb

# WandB 통합 테스트
# notebooks/test_wandb_integration.ipynb
```

### **3. 명령줄에서 노트북 실행**
```bash
# nbconvert로 노트북 실행 (선택적)
jupyter nbconvert --to notebook --execute notebooks/unit_tests/test_highperf_dataset.ipynb

# 결과 HTML로 변환
jupyter nbconvert --to html notebooks/unit_tests/test_highperf_dataset.ipynb
```

---

## 📊 로그 및 결과 확인

### **1. 학습 로그 분석**

#### **기본 로그 확인**
```bash
# 최신 학습 로그 확인
ls -t logs/train/ | head -5

# 특정 로그 내용 확인
cat logs/$(date +%Y%m%d)/train/train_20250905-1400_v087-abc123.log

# 에러 로그만 확인
grep -i "error\|fail" logs/$(date +%Y%m%d)/train/train_*.log

# 성능 지표 추출
grep "Val F1\|Best F1" logs/$(date +%Y%m%d)/train/train_*.log | tail -10
```

#### **실시간 모니터링**
```bash
# 실시간 로그 스트림
tail -f logs/$(date +%Y%m%d)/train/train_*.log

# 특정 패턴 모니터링
tail -f logs/$(date +%Y%m%d)/train/train_*.log | grep --line-buffered "Epoch\|F1"

# 다중 로그 모니터링
multitail logs/$(date +%Y%m%d)/train/train_*.log logs/$(date +%Y%m%d)/infer/infer_*.log
```

### **2. 추론 로그 분석**

#### **추론 결과 확인**
```bash
# 최신 추론 로그
ls -t logs/infer/ | head -3

# 추론 성능 확인
grep "Inference completed\|Processing time" logs/$(date +%Y%m%d)/infer/infer_*.log

# 앙상블 결과 확인
grep "Ensemble\|Average" logs/infer/infer_*.log
```

### **3. 단위 테스트 로그 (로깅 시스템 사용시)**

#### **로깅 시스템 결과 확인**
```bash
# 단위 테스트 로그 디렉토리
ls -la logs/unit_test/

# 특정 테스트 결과 확인
TEST_NAME="highperf_dataset"
LATEST_RUN=$(ls -t logs/unit_test/$TEST_NAME/ | head -1)
ls -la logs/unit_test/$TEST_NAME/$LATEST_RUN/

# 테스트 요약 JSON 확인
cat logs/unit_test/$TEST_NAME/$LATEST_RUN/test_summary.json | jq

# 저장된 이미지 확인
ls logs/unit_test/$TEST_NAME/$LATEST_RUN/images/

# 처리된 데이터 확인
ls logs/unit_test/$TEST_NAME/$LATEST_RUN/data/
```

### **4. 실험 결과 관리**

#### **실험 디렉토리 구조**
```bash
# 실험 결과 확인
tree experiments/ -L 3

# 특정 날짜 실험 확인
ls -la experiments/train/20250905/

# Fold별 결과 확인
ls -la experiments/train/20250905/fold_results/

# 모델 파일 확인
find experiments/ -name "*.pth" -type f | head -10
```

#### **제출 파일 관리**
```bash
# 제출 파일 히스토리
ls -la submissions/

# 최신 제출 파일 분석
python3 -c "
import pandas as pd
import glob
import os

# 최신 제출 파일 찾기
submission_files = glob.glob('submissions/*/submission.csv')
if submission_files:
    latest = max(submission_files, key=os.path.getctime)
    df = pd.read_csv(latest)
    print(f'최신 제출 파일: {latest}')
    print(f'생성 시간: {pd.Timestamp.fromtimestamp(os.path.getctime(latest))}')
    print(f'파일 크기: {len(df)} 행')
    print(f'클래스 분포:')
    print(df.iloc[:, 1].value_counts().head())
else:
    print('제출 파일이 없습니다.')
"
```

---

## 🎛️ 고급 사용법

### **1. 환경 변수 활용**

#### **GPU 관리**
```bash
# 특정 GPU 사용
export CUDA_VISIBLE_DEVICES=0
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# 멀티 GPU 사용
export CUDA_VISIBLE_DEVICES=0,1
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# GPU 메모리 제한
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
```

#### **WandB 설정**
```bash
# WandB 프로젝트 설정
export WANDB_PROJECT="cv-competition-1sen"
export WANDB_ENTITY="your-team-name"

# WandB 실행 이름 설정
export WANDB_RUN_NAME="highperf-swin-fold-all"
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
```

#### **로깅 레벨 설정**
```bash
# 디버그 모드
export LOG_LEVEL=DEBUG
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# 조용한 모드
export LOG_LEVEL=WARNING
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
```

### **2. 배치 스크립트**

#### **전체 실험 자동화**
```bash
#!/bin/bash
# run_full_experiment.sh

set -e  # 에러시 중단

echo "🚀 전체 실험 시작: $(date)"

# 1. 환경 확인
echo "📋 환경 확인..."
python3 -c "from src.utils.common import load_yaml; print('✅ 환경 준비 완료')"

# 2. 학습 실행
echo "🎓 학습 시작..."
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# 3. 최신 실험 결과 찾기
LATEST_EXP=$(ls -t experiments/train/ | head -1)
echo "📁 최신 실험: $LATEST_EXP"

# 4. 추론 실행
echo "🔮 추론 시작..."
python src/inference/infer_main.py --mode highperf --fold-results experiments/train/$LATEST_EXP/fold_results

# 5. 결과 확인
echo "✅ 실험 완료: $(date)"
ls -la submissions/$(ls -t submissions/ | head -1)/

echo "🎯 실험 요약:"
echo "   학습 결과: experiments/train/$LATEST_EXP/"
echo "   제출 파일: submissions/$(ls -t submissions/ | head -1)/"
```

#### **스크립트 실행**
```bash
# 실행 권한 부여
chmod +x run_full_experiment.sh

# 백그라운드 실행
nohup ./run_full_experiment.sh > experiment.log 2>&1 &

# 진행 상황 모니터링
tail -f experiment.log
```

### **3. 성능 최적화**

#### **메모리 최적화**
```bash
# 배치 크기 줄이기
sed -i 's/batch_size: 16/batch_size: 8/' configs/train_highperf.yaml

# 이미지 크기 줄이기
sed -i 's/img_size: 384/img_size: 224/' configs/train_highperf.yaml

# 메모리 사용량 모니터링
watch -n 1 nvidia-smi
```

#### **속도 최적화**
```bash
# 데이터 로더 워커 수 증가
export NUM_WORKERS=8
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf

# 혼합 정밀도 학습 (구현시)
export USE_AMP=true
python src/training/train_main.py --config configs/train_highperf.yaml --mode highperf
```

---

## 🔧 문제 해결

### **1. 일반적인 문제**

#### **Import 에러**
```bash
# 문제: ModuleNotFoundError
# 해결: Python 경로 확인
echo $PYTHONPATH
export PYTHONPATH="${PYTHONPATH}:$(pwd)"

# 또는 sys.path 추가
python3 -c "import sys; sys.path.append('.'); from src.utils.common import load_yaml"
```

#### **CUDA 에러**
```bash
# 문제: CUDA out of memory
# 해결: 배치 크기 줄이기
export BATCH_SIZE=4
python src/training/train_main.py --fold 0

# GPU 메모리 정리
python3 -c "import torch; torch.cuda.empty_cache()"
```

#### **파일 경로 에러**
```bash
# 문제: 데이터 파일을 찾을 수 없음
# 해결: 현재 디렉토리 확인
pwd
ls -la data/raw/

# 프로젝트 루트로 이동
cd /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN
```

### **2. 로그 기반 디버깅**

#### **에러 로그 분석**
```bash
# 최근 에러 찾기
grep -r -i "error\|exception\|failed" logs/ | tail -10

# 특정 에러 패턴 찾기
grep -r "CUDA\|memory\|import" logs/ | tail -5

# 스택트레이스 확인
grep -A 10 -B 2 "Traceback" logs/train/train_*.log
```

#### **성능 이슈 디버깅**
```bash
# 학습 속도 확인
grep "Epoch.*Time" logs/train/train_*.log | tail -5

# 메모리 사용량 확인
grep -i "memory\|GPU" logs/train/train_*.log | tail -5

# 데이터 로딩 시간 확인
grep -i "loading\|batch" logs/train/train_*.log | tail -5
```

### **3. 검증 명령어**

#### **전체 시스템 검증**
```bash
# 종합 건강도 검사
python3 -c "
import sys
sys.path.append('.')

# 1. 모듈 import 테스트
try:
    from src.utils.common import load_yaml
    from src.data.dataset import HighPerfDocClsDataset
    from src.models.build import build_model
    print('✅ 모든 모듈 import 성공')
except Exception as e:
    print(f'❌ 모듈 import 실패: {e}')
    sys.exit(1)

# 2. 설정 파일 테스트
try:
    cfg = load_yaml('configs/train_highperf.yaml')
    print('✅ 설정 파일 로드 성공')
except Exception as e:
    print(f'❌ 설정 파일 로드 실패: {e}')
    sys.exit(1)

# 3. 데이터 파일 테스트
import os
required_files = [
    'data/raw/train.csv',
    'data/raw/meta.csv', 
    'data/raw/sample_submission.csv'
]
for file in required_files:
    if os.path.exists(file):
        print(f'✅ {file} 존재')
    else:
        print(f'❌ {file} 없음')

print('🎯 시스템 검증 완료!')
"
```

#### **성능 벤치마크**
```bash
# 빠른 학습 테스트 (1 에포크)
python3 -c "
import sys
sys.path.append('.')
import time
from src.training.train import train_model
from src.utils.common import load_yaml

cfg = load_yaml('configs/train.yaml')
cfg['training']['epochs'] = 1
cfg['training']['batch_size'] = 4

start_time = time.time()
# train_model(cfg, fold=0)  # 실제 실행시 주석 해제
end_time = time.time()

print(f'⏱️ 1 에포크 예상 시간: {end_time - start_time:.1f}초')
"
```

---

## 📞 추가 지원

### **로그 수집**
```bash
# 문제 발생시 로그 수집
mkdir -p debug_logs/$(date +%Y%m%d_%H%M%S)
cp -r logs/ debug_logs/$(date +%Y%m%d_%H%M%S)/
cp configs/*.yaml debug_logs/$(date +%Y%m%d_%H%M%S)/
```

### **시스템 정보 수집**
```bash
# 시스템 정보 저장
echo "=== 시스템 정보 ===" > system_info.txt
date >> system_info.txt
uname -a >> system_info.txt
python3 --version >> system_info.txt
pip list | grep -E "torch|pandas|numpy" >> system_info.txt
nvidia-smi >> system_info.txt
```
