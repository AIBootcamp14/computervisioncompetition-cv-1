# 🚀 시간 최적화 가이드 (Team ConvNeXt 전략)

## 🎯 Team 기법 시간 전략 개요

Team ConvNeXt로 0.9652 F1 Score를 달성하기 위한 시간 최적화 전략입니다. 빠른 검증부터 최고 성능까지의 단계적 접근법을 제시합니다.

### 📈 Team 시간 vs 성능 매트릭스

| 전략 | 시간 | F1 Score | TTA | 용도 | GPU 요구사항 |
|------|------|----------|-----|------|-----------|
| **빠른 검증** | 5분 | 0.920-0.930 | 없음 | 프로토타입 | RTX 3060+ |
| **균형 성능** | 17분 | 0.945-0.950 | Essential | 추천 | RTX 3070+ |
| **최고 성능** | 50분+ | **0.9652** | Comprehensive | 대회 제출 | RTX 4080+ |
| **최적화 반복** | 3시간+ | 0.970+ | Optuna | 연구/개발 | RTX 4090 |

## 📈 Team ConvNeXt 시간 전략별 상세 가이드

### Phase 1: 빠른 검증 (5분) - EfficientNet B3

```bash
# 베이스라인 빠른 검증
python src/inference/infer_main.py \
    --config configs/infer.yaml \
    --mode basic

# 기대 성능: F1 0.920-0.930
# 용도: 시스템 검증, 빠른 프로토타입
```

### Phase 2: Team Essential TTA (17분, 추천) - ConvNeXt Base

```bash
# Team ConvNeXt + Essential TTA
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode highperf

# TTA 추론 (Essential - 5가지 변환)
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml

# configs/infer_highperf.yaml: tta_type: "essential"
# 기대 성능: F1 0.945-0.950
# 추천 이유: 성능/시간 최적 균형
```

### Phase 3: Team Comprehensive TTA (50분+, 최고 성능)

```bash
# Team ConvNeXt + Comprehensive TTA
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode highperf

# Comprehensive TTA 추론 (15가지 변환)
python src/inference/infer_main.py \
    --config configs/infer_highperf.yaml \
    --mode highperf \
    --fold-results experiments/train/lastest-train/fold_results.yaml

# configs/infer_highperf.yaml: tta_type: "comprehensive"
# 기대 성능: F1 0.9652 (최고)
# 용도: 대회 최종 제출, 우승 목표
```

## 🚀 시간 최적화 정밀 설정

### 1. Team ConvNeXt 학습 설정 (가장 중요)

#### epochs (ConvNeXt 학습 에포크)
- **Team 기본값**: 5 에포크 (F1: 0.9489)
- **빠른 검증**: 3 에포크 (F1: 0.9450)
- **실전 최적화**: 5-7 에포크 (F1: 0.9652)
- **영향**: ConvNeXt는 에포크당 40-50분 소요

```yaml
# Team ConvNeXt 단계별 에포크 설정
train:
  # 빠른 검증: 3 에포크 (2시간)
  # 균형 성능: 5 에포크 (3시간)
  # 최고 성능: 7 에포크 (4시간+)
  epochs: 5  # Team 최적 값
```

#### batch_size (Team ConvNeXt 배치 최적화)
- **RTX 4090 (24GB)**: batch_size: 64 (F1: 0.9652)
- **RTX 3080 (10GB)**: batch_size: 32 (F1: 0.9550)
- **RTX 3060 (8GB)**: batch_size: 16 (F1: 0.9520)
- **영향**: ConvNeXt Base 384는 메모리 집약적

```yaml
# GPU별 Team ConvNeXt 배치 최적화
train:
  # RTX 4090: batch_size: 64
  # RTX 3080: batch_size: 32  
  # RTX 3060: batch_size: 16
  batch_size: 32  # RTX 3080 기준 최적화
```

### 2. Cross-Validation 설정

#### folds (K-폴드 개수)
- **기본값**: 5 폴드
- **빠른 실행**: 2-3 폴드
- **영향**: 폴드당 전체 학습 시간이 곱해짐
- **권장**: 30분 완료 시 folds: 2 설정

```yaml
data:
  folds: 2  # 기존 5에서 2로 감소
```

### 3. Optuna 최적화 설정

#### n_trials (최적화 시도 횟수)
- **기본값**: 10-30 trials
- **빠른 실행**: 3-5 trials
- **영향**: trial당 약 5-15분 소요
- **권장**: 30분 완료 시 n_trials: 3-5

```yaml
optuna:
  n_trials: 5  # 기존 10-30에서 5로 감소
```

#### timeout (최적화 타임아웃)
- **기본값**: 5400초 (90분)
- **빠른 실행**: 1200-1800초 (20-30분)
- **영향**: 전체 최적화 시간 제한
- **권장**: timeout: 1800 (30분)

```yaml
optuna:
  timeout: 1800  # 기존 5400에서 1800으로 감소
```

#### quick_validation epochs
- **기본값**: 10 에포크
- **빠른 실행**: 1-2 에포크
- **영향**: Optuna 평가 시간 단축
- **권장**: epochs: 1

```yaml
optuna:
  quick_validation:
    epochs: 1  # 기존 10에서 1로 감소
```

### 4. 데이터 로딩 최적화

#### num_workers (데이터 로더 워커 수)
- **기본값**: 4
- **빠른 실행**: 8-12 (CPU 코어 수에 따라)
- **영향**: 데이터 로딩 속도 향상
- **권장**: RTX 4090 환경에서 8-12

```yaml
project:
  num_workers: 8  # 기존 4에서 8로 증가
```

#### pin_memory & persistent_workers
- **권장 설정**: true로 설정하여 GPU 전송 속도 향상

```yaml
project:
  pin_memory: true
  persistent_workers: true
```

### 5. 모델 관련 설정

#### mixed_precision (혼합 정밀도)
- **권장**: true 설정으로 메모리 효율성과 속도 향상

```yaml
train:
  mixed_precision: true
```

## 설정 파일별 최적화 예시

### train_multi_model_ensemble.yaml (메인 학습)
```yaml
# 시간 단축을 위한 핵심 설정
data:
  folds: 2  # 5 -> 2

train:
  epochs: 1          # 3 -> 1
  batch_size: 128    # auto -> 128
  mixed_precision: true
```

### optuna_config.yaml (최적화)
```yaml
optuna:
  n_trials: 5        # 10 -> 5
  timeout: 1800      # 5400 -> 1800
  
  quick_validation:
    epochs: 1        # 10 -> 1
```

## 시간 계산 예시

### 기존 설정 (약 180분)
- K-fold: 5 × epochs: 3 × 5분 = 75분 (학습)
- Optuna: 10 trials × 10분 = 100분 (최적화)
- 추론: 5분
- **총합: 180분**

### 최적화된 설정 (약 25분)
- K-fold: 2 × epochs: 1 × 3분 = 6분 (학습)
- Optuna: 5 trials × 3분 = 15분 (최적화)
- 추론: 4분
- **총합: 25분**

## 주의사항

1. **성능 vs 시간**: 시간을 단축하면 일반적으로 성능이 다소 감소할 수 있습니다.
2. **메모리 제한**: batch_size를 너무 크게 하면 Out of Memory 에러가 발생할 수 있습니다.
3. **하드웨어 의존성**: RTX 4090 기준으로 최적화된 설정이므로 다른 GPU에서는 조정이 필요합니다.

## 빠른 테스트용 설정 예시

30분 이내 완료를 위한 최소 설정:

```yaml
# train_multi_model_ensemble.yaml
data:
  folds: 2

train:
  epochs: 1
  batch_size: 128

# optuna_config.yaml  
optuna:
  n_trials: 3
  timeout: 1200
  quick_validation:
    epochs: 1
```

이 설정으로 전체 파이프라인이 20-30분 내에 완료됩니다.