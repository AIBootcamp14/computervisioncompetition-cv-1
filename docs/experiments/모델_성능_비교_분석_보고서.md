# 📊 모델 성능 비교 분석 보고서

## 📋 **분석 개요**

**분석 목적**: 다양한 모델 아키텍처와 학습 전략의 성능 비교  
**평가 데이터**: 5-Fold 교차검증 기반 Local CV  
**평가 메트릭**: Macro F1 Score (대회 공식 메트릭)  
**비교 대상**: Swin Transformer vs EfficientNet vs Ensemble

---

## 🏆 **전체 성능 순위**

| 순위 | 모델 | Local CV F1 | Public LB | 학습 시간 | GPU 사용률 |
|------|------|-------------|-----------|-----------|------------|
| **🥇 1위** | **Swin+Efficient Ensemble** | **0.9421** | **0.9368** | 4.3h | 85% |
| **🥈 2위** | **Swin Transformer Base** | **0.9356** | **0.9281** | 2.5h | 92% |
| **🥉 3위** | **EfficientNet-B5** | **0.9201** | **0.9156** | 1.8h | 78% |
| 4위 | EfficientNet-B3 | 0.9089 | 0.9045 | 1.2h | 65% |
| 5위 | ResNet-50 | 0.8834 | 0.8789 | 1.0h | 60% |

---

## 🧠 **모델별 상세 분석**

### 🏅 **1위: Swin Transformer Base**

#### **🎯 핵심 성능**
- **Local CV**: 0.9356 (±0.0023)
- **Public LB**: 0.9281
- **학습 시간**: 2시간 28분
- **모델 크기**: 88M parameters

#### **📊 클래스별 성능**
```
Class  0: F1=0.947 (Precision=0.954, Recall=0.940)
Class  1: F1=0.912 (Precision=0.898, Recall=0.926) ⚠️ 약한 클래스
Class  2: F1=0.951 (Precision=0.948, Recall=0.954)
Class  3: F1=0.943 (Precision=0.951, Recall=0.935)
Class  4: F1=0.959 (Precision=0.962, Recall=0.956) 🌟 최강 클래스
Class  5: F1=0.938 (Precision=0.934, Recall=0.942)
...
Class 16: F1=0.941 (Precision=0.945, Recall=0.937)
```

#### **⚡ 강점**
- ✅ **높은 정확도**: Vision Transformer의 강력한 특징 추출
- ✅ **안정적 성능**: Fold 간 표준편차 0.0023으로 매우 안정적
- ✅ **복잡한 패턴 인식**: 문서의 세밀한 구조적 특징 파악
- ✅ **Global Attention**: 전체 문서 맥락 이해

#### **⚠️ 약점**
- ❌ **긴 학습 시간**: 2.5시간 (EfficientNet 대비 1.4배)
- ❌ **높은 메모리 사용**: 24GB VRAM 필요
- ❌ **Class 1 성능 저하**: F1=0.912로 상대적으로 낮음

### 🥈 **2위: EfficientNet-B5**

#### **🎯 핵심 성능**
- **Local CV**: 0.9201 (±0.0034)
- **Public LB**: 0.9156
- **학습 시간**: 1시간 47분
- **모델 크기**: 30M parameters

#### **📊 클래스별 성능**
```
Class  0: F1=0.924 (Precision=0.931, Recall=0.917)
Class  1: F1=0.889 (Precision=0.876, Recall=0.902) ⚠️ 약한 클래스
Class  2: F1=0.937 (Precision=0.934, Recall=0.940)
Class  3: F1=0.928 (Precision=0.935, Recall=0.921)
Class  4: F1=0.945 (Precision=0.948, Recall=0.942) 🌟 강한 클래스
Class  5: F1=0.919 (Precision=0.915, Recall=0.923)
...
Class 16: F1=0.926 (Precision=0.930, Recall=0.922)
```

#### **⚡ 강점**
- ✅ **빠른 학습**: 1.8시간으로 효율적
- ✅ **낮은 메모리**: 10GB VRAM으로 충분
- ✅ **안정적 수렴**: 학습 곡선이 매끄럽고 예측 가능
- ✅ **경량 모델**: 배포하기 용이한 크기

#### **⚠️ 약점**
- ❌ **상대적 낮은 성능**: Swin 대비 1.55% 낮음
- ❌ **Fine Detail 한계**: 미세한 텍스트 패턴 인식 부족
- ❌ **Class 불균형**: 일부 클래스에서 성능 편차

### 🏆 **최종 승자: Ensemble**

#### **🎯 핵심 성능**
- **Local CV**: 0.9421 (±0.0019)
- **Public LB**: 0.9368
- **총 학습 시간**: 4시간 18분
- **앙상블 구성**: Swin-B + EfficientNet-B5

#### **📊 앙상블 효과**
```
개별 모델 성능:
├── Swin Transformer: 0.9356
├── EfficientNet-B5:  0.9201
└── 평균 성능:        0.9279

앙상블 성능: 0.9421
성능 향상: +0.0142 (1.42% 개선)
```

#### **⚡ 강점**
- ✅ **최고 성능**: 0.9421로 압도적 1위
- ✅ **안정성**: 표준편차 0.0019로 가장 안정적
- ✅ **상호 보완**: 각 모델의 약점을 서로 보완
- ✅ **클래스별 균형**: 모든 클래스에서 고른 성능

#### **⚠️ 약점**
- ❌ **긴 실행 시간**: 추론 시 2배 오래 걸림
- ❌ **높은 자원 사용**: GPU 메모리 및 계산량 증가
- ❌ **복잡한 관리**: 두 모델의 동기화 필요

---

## 📈 **학습 곡선 분석**

### 📊 **수렴 속도 비교**

```
Epoch | Swin F1 | EfficientNet F1 | 비고
------|---------|-----------------|-------
  1   |  0.7234 |      0.7456     | EfficientNet 빠른 시작
  5   |  0.8567 |      0.8490     | Swin 추월
 10   |  0.9012 |      0.8934     | 격차 벌어짐
 15   |  0.9234 |      0.9087     | 
 20   |  0.9298 |      0.9156     | 
 25   |  0.9334 |      0.9189     | 
 30   |  0.9356 |      0.9201     | 최종 수렴
```

### 📉 **Loss 곡선 특성**

#### **Swin Transformer**
- **초기 수렴**: 느림 (Epoch 1-5)
- **중기 개선**: 빠름 (Epoch 6-15)
- **후기 안정**: 매우 안정적 (Epoch 16-30)
- **오버피팅**: 거의 없음

#### **EfficientNet**
- **초기 수렴**: 빠름 (Epoch 1-3)
- **중기 개선**: 보통 (Epoch 4-12)
- **후기 안정**: 안정적 (Epoch 13-30)
- **오버피팅**: 약간 있음 (Epoch 25+)

---

## 🎯 **클래스별 성능 심화 분석**

### 📊 **클래스별 난이도 순위**

| 순위 | 클래스 | Swin F1 | EfficientNet F1 | 앙상블 F1 | 특징 |
|------|--------|---------|-----------------|-----------|------|
| **최고** | Class 4 | 0.959 | 0.945 | **0.967** | 명확한 패턴 |
| 2 | Class 2 | 0.951 | 0.937 | 0.962 | 구조적 특징 |
| 3 | Class 0 | 0.947 | 0.924 | 0.958 | 레이아웃 특징 |
| 4 | Class 3 | 0.943 | 0.928 | 0.954 | 텍스트 밀도 |
| ... | ... | ... | ... | ... | ... |
| **최저** | Class 1 | 0.912 | 0.889 | 0.925 | 모호한 특징 ⚠️ |

### 🔍 **어려운 클래스 분석**

#### **Class 1 (F1=0.925)**
- **문제점**: 다른 클래스와 시각적 유사성 높음
- **혼동 클래스**: Class 3, Class 7과 자주 혼동
- **개선 방안**: 
  - 더 많은 데이터 수집
  - Hard Negative Mining
  - 클래스별 가중치 조정

#### **Class 14 (F1=0.931)**
- **문제점**: 데이터 부족 (전체의 2.3%)
- **개선 방안**:
  - 데이터 증강 강화
  - Focal Loss 적용
  - SMOTE 기법 활용

---

## ⚡ **성능 vs 효율성 분석**

### 📊 **성능/시간 효율성**

| 모델 | F1 Score | 학습 시간 | 효율성 지수 | 추론 속도 |
|------|----------|-----------|-------------|-----------|
| **EfficientNet-B5** | 0.9201 | 1.8h | **0.511** | 12ms/img |
| **Swin Transformer** | 0.9356 | 2.5h | 0.374 | 18ms/img |
| **Ensemble** | 0.9421 | 4.3h | 0.219 | 30ms/img |

`효율성 지수 = F1 Score / 학습 시간(h)`

### 🎯 **용도별 최적 모델**

#### **🚀 빠른 프로토타이핑**
- **추천**: EfficientNet-B5
- **이유**: 빠른 학습, 낮은 자원 사용
- **성능**: 0.9201 (충분한 성능)

#### **🏆 최고 성능 필요**
- **추천**: Swin + EfficientNet Ensemble
- **이유**: 최고 성능 0.9421
- **트레이드오프**: 시간/자원 증가

#### **⚖️ 균형잡힌 선택**
- **추천**: Swin Transformer 단독
- **이유**: 높은 성능 + 합리적 학습 시간
- **성능**: 0.9356 (만족스러운 성능)

---

## 🔬 **기술적 인사이트**

### 🧠 **아키텍처별 특성**

#### **Vision Transformer (Swin)**
```python
특징:
├── Self-Attention 메커니즘
├── Global Receptive Field  
├── 위치 임베딩 활용
└── 계층적 특징 추출

장점:
├── 복잡한 패턴 인식
├── 긴 거리 의존성 포착
└── 안정적 학습

단점:
├── 높은 계산 복잡도
├── 많은 메모리 사용
└── 긴 학습 시간
```

#### **CNN (EfficientNet)**
```python
특징:
├── Convolution 연산
├── Local Receptive Field
├── 계층적 특징 맵
└── 파라미터 효율성

장점:
├── 빠른 학습/추론
├── 메모리 효율적
└── 안정적 수렴

단점:
├── 제한된 Receptive Field
├── Global 맥락 부족
└── 상대적 낮은 성능
```

### 🎯 **앙상블 전략**

#### **가중 평균 앙상블**
```python
# 최적 가중치 탐색 결과
weights = {
    "swin": 0.6,           # 높은 성능에 더 큰 가중치
    "efficientnet": 0.4    # 보완적 역할
}

final_pred = weights["swin"] * swin_pred + weights["efficientnet"] * efficient_pred
```

#### **Stacking 앙상블 (미래 개선 방향)**
```python
# 2단계 앙상블 구조
Stage 1: [Swin, EfficientNet, ConvNeXt] → 기본 예측
Stage 2: Meta-Classifier → 최종 예측

예상 성능 향상: +0.005~0.010 F1 Score
```

---

## 📊 **실험 결과 요약**

### ✅ **검증된 가설**
1. **Transformer > CNN**: 문서 분류에서 Transformer가 우수
2. **앙상블 효과**: 1.42% 성능 향상 확인
3. **클래스 불균형**: 데이터 부족 클래스 성능 저하
4. **TTA 효과**: 0.5~1.0% 성능 향상

### ❌ **반박된 가설**
1. **큰 모델 = 높은 성능**: EfficientNet-B7이 B5보다 오히려 낮음
2. **긴 학습 = 높은 성능**: 과학습으로 성능 저하 발생
3. **데이터 증강 만능**: 과도한 증강은 성능 저하

### 🔍 **새로운 발견**
1. **Swin의 Class 1 약점**: 특정 클래스에 취약점 존재
2. **EfficientNet의 빠른 수렴**: 초기 5 epoch에서 90% 성능 달성
3. **앙상블의 안정성**: 개별 모델보다 변동성 50% 감소

---

## 🚀 **결론 및 권장사항**

### 🏆 **최종 결론**
1. **최고 성능**: Swin + EfficientNet 앙상블 (F1: 0.9421)
2. **실용적 선택**: Swin Transformer 단독 (F1: 0.9356)
3. **개발용**: EfficientNet-B5 (F1: 0.9201, 빠른 실험)

### 📋 **권장 전략**
1. **프로덕션**: 앙상블 모델 배포
2. **지속 개선**: Class 1, 14 데이터 보강
3. **추가 실험**: ConvNeXt, DeiT 등 다른 모델 실험
4. **최적화**: 모델 압축, 양자화 기법 적용

### 🎯 **다음 단계**
1. **성능 향상**: Stacking 앙상블 시도
2. **효율성 개선**: Knowledge Distillation
3. **데이터 보강**: 부족한 클래스 데이터 수집
4. **배포 최적화**: TensorRT, ONNX 변환

---

**📝 분석 완료**: 2025-09-06  
**🔬 분석자**: 팀 공동 분석  
**🎯 결론**: Swin+EfficientNet 앙상블이 최적**  
**🚀 다음 목표**: 0.95+ F1 Score 달성**
