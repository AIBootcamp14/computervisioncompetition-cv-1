# 🚀 고성능 학습 완전 가이드

## 📋 목차

1. [개요](#개요)
2. [통합 CLI 인터페이스](#통합-cli-인터페이스)
3. [증강 설정 최적화](#증강-설정-최적화)
4. [Optuna 하이퍼파라미터 최적화](#optuna-하이퍼파라미터-최적화)
5. [Temperature Scaling 캘리브레이션](#temperature-scaling-캘리브레이션)
6. [실행 시나리오별 가이드](#실행-시나리오별-가이드)
7. [성능 모니터링](#성능-모니터링)
8. [문제 해결](#문제-해결)

---

## 🎯 개요

본 가이드는 고성능 문서 분류 모델 학습을 위한 완전한 실행 가이드입니다. 새로운 통합 CLI 인터페이스를 통해 Optuna 최적화, Temperature Scaling 캘리브레이션, 그리고 고급 증강 기법을 모두 활용할 수 있습니다.

### 목표 성능
- **F1 Score**: 0.940+ (기존 0.87 대비 대폭 향상)
- **실행 시간**: 완전 자동화로 시간 단축
- **재현성**: 동일 설정으로 일관된 결과

---

## 🎮 통합 CLI 인터페이스

### 새로운 통합 실행 방식

모든 학습 기능이 하나의 CLI로 통합되었습니다:

```bash
python src/training/train_main.py [OPTIONS]
```

### 주요 옵션들

| 옵션 | 설명 | 기본값 |
|------|------|--------|
| `--config` | 설정 파일 경로 (필수) | - |
| `--mode` | 실행 모드 | `full-pipeline` |
| `--optimize` | Optuna 최적화 사용 | `False` |
| `--n-trials` | 최적화 시도 횟수 | `20` |
| `--use-calibration` | Temperature Scaling 사용 | `False` |
| `--auto-continue` | 최적화 후 자동 진행 | `False` |
| `--skip-training` | 학습 건너뛰고 추론만 | `False` |

### 도움말 확인
```bash
python src/training/train_main.py --help
```

---

## 🎨 증강 설정 최적화

### 증강 타입 설정

#### 기본 증강 (Basic Augmentation)
```yaml
# configs/train.yaml
train:
  use_advanced_augmentation: false  # 기본 증강 사용
```

**포함 기법:**
- 기본 Resize, RandomCrop
- 색상 조정 (Brightness, Contrast)
- 기본 Normalization

#### 고급 증강 (Advanced Augmentation)
```yaml
# configs/train_highperf.yaml
train:
  use_advanced_augmentation: true   # 고급 증강 사용
  use_mixup: true                   # Mixup 추가
  hard_augmentation: true           # 강한 증강 적용
```

**포함 기법:**
- 모든 기본 증강 +
- Hard Augmentation (강한 변형)
- Mixup 데이터 증강
- Progressive 증강 강도 조절

### 로그 파일명에서 증강 타입 확인

새로운 로그 파일명 형식으로 증강 타입을 쉽게 확인할 수 있습니다:

```bash
# 기본 증강 로그
train_basic_augmentation_20250907-1830_efficientnet_b3.log

# 고급 증강 로그  
train_highperf_advanced_augmentation_20250907-1830_swin-sighperf-abc123.log
```

---

## 🔍 Optuna 하이퍼파라미터 최적화

### 기본 최적화 실행

```bash
# 기본 20번 시도 최적화
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --mode highperf
```

### 커스텀 최적화 설정

```bash
# 50번 시도로 정밀 최적화
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 50 \
    --mode highperf
```

### 최적화 대상 파라미터

`configs/optuna_config.yaml`에서 설정:

```yaml
search_space:
  lr: [1e-5, 1e-3]              # 학습률 범위
  weight_decay: [1e-6, 1e-2]    # Weight decay 범위
  batch_size: [16, 64]          # 배치 크기 범위
  drop_rate: [0.0, 0.3]         # 드롭아웃 비율
  mixup_alpha: [0.2, 2.0]       # Mixup 알파 값

optimization:
  direction: maximize            # F1 score 최대화
  n_trials: 20                  # 기본 시도 횟수
  timeout: 3600                 # 최대 1시간 제한
```

### 최적화 결과 확인

```bash
# 최적화 결과 확인
ls -la experiments/optimization/

# 최적화된 설정 파일 확인
cat experiments/optimization/best_params_YYYYMMDD_HHMM.yaml

# 최적화 로그 확인
tail -f logs/$(date +%Y%m%d)/optimization/optuna_YYYYMMDD_HHMM.log
```

---

## 🌡️ Temperature Scaling 캘리브레이션

### 캘리브레이션 적용 학습

```bash
# 캘리브레이션 포함 학습
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --use-calibration \
    --mode full-pipeline
```

### 캘리브레이션의 효과

| 지표 | 기본 모델 | 캘리브레이션 적용 |
|------|-----------|------------------|
| **F1 Score** | 0.934 | 0.940+ |
| **신뢰도** | 보통 | 높음 |
| **예측 확률** | 과신 경향 | 보정된 확률 |

### 캘리브레이션 결과 확인

```bash
# 캘리브레이션 모델 확인
find experiments/ -name "*calibrated*"

# 캘리브레이션 로그 확인
grep "calibration" logs/$(date +%Y%m%d)/pipeline/full_pipeline_*.log
```

---

## 🚀 실행 시나리오별 가이드

### 1. 🏆 최고 성능 (권장)

**목표**: 최고 F1 Score 달성

```bash
# 환경 설정
pyenv activate cv_py3_11_9

# 완전 최적화 파이프라인
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 20 \
    --use-calibration \
    --mode full-pipeline \
    --auto-continue
```

**실행 순서:**
1. Optuna 하이퍼파라미터 최적화 (20회)
2. 최적화된 설정으로 K-Fold 학습
3. Temperature Scaling 캘리브레이션
4. 앙상블 + TTA 추론
5. 제출 파일 자동 생성

**예상 시간**: 2-3시간  
**예상 성능**: F1 0.940+

### 2. ⚡ 빠른 실행

**목표**: 빠른 결과 확인

```bash
# 사전 최적화된 설정 사용
python src/training/train_main.py \
    --config configs/train_optimized_20250907_1825.yaml \
    --use-calibration \
    --mode full-pipeline
```

**예상 시간**: 30-60분  
**예상 성능**: F1 0.935+

### 3. 🧪 개발 및 테스트

**목표**: 빠른 프로토타이핑

```bash
# 기본 모드로 빠른 테스트
python src/training/train_main.py \
    --config configs/train.yaml \
    --mode basic
```

**예상 시간**: 15-30분  
**예상 성능**: F1 0.89+

### 4. 🔬 최적화만 실행

**목표**: 하이퍼파라미터만 찾기

```bash
# 최적화만 실행 (학습 X)
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 30 \
    --mode highperf
```

**예상 시간**: 1-2시간  
**결과**: 최적화된 설정 파일 생성

---

## 📊 성능 모니터링

### 실시간 모니터링

#### WandB 확인
```bash
# WandB 로그인 확인
wandb status

# 실험 추적 URL
echo "WandB: https://wandb.ai/your-project/document-classification-team"
```

#### 로그 파일 모니터링
```bash
# 실시간 로그 확인
tail -f logs/$(date +%Y%m%d)/train/train_highperf_advanced_augmentation_*.log

# 파이프라인 진행 상황
tail -f logs/$(date +%Y%m%d)/pipeline/full_pipeline_*.log

# Optuna 최적화 진행
tail -f logs/$(date +%Y%m%d)/optimization/optuna_*.log
```

### 성능 지표 확인

#### 학습 진행 상황
```bash
# 최신 실험 결과 확인
ls -la experiments/train/$(date +%Y%m%d)/

# Fold별 성능 확인
cat experiments/train/*/fold_results.yaml
```

#### 제출 파일 확인
```bash
# 생성된 제출 파일
ls -la submissions/$(date +%Y%m%d)/

# 예측 분포 확인
python -c "
import pandas as pd
df = pd.read_csv('submissions/$(date +%Y%m%d)/submission_latest.csv')
print('예측 분포:')
print(df['target'].value_counts().sort_index())
"
```

---

## ❗ 문제 해결

### 일반적인 문제들

#### 1. 환경 관련 오류

```bash
# pyenv 환경 재설정
pyenv deactivate
pyenv activate cv_py3_11_9

# 의존성 재설치
pip install -r requirements.txt --force-reinstall

# Optuna 설치 확인
pip install optuna>=4.0.0 --force-reinstall
```

#### 2. GPU 메모리 부족

```bash
# 배치 크기 조정 (config 파일 수정)
# train_highperf.yaml에서 batch_size: 32 -> 16

# 메모리 제한으로 실행
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512 python src/training/train_main.py ...

# 그래디언트 누적 사용 (config 수정)
# gradient_accumulation_steps: 2
```

#### 3. Optuna 최적화 오류

```bash
# Optuna 재설치
pip install optuna>=4.0.0 --force-reinstall

# 시도 횟수 줄이기
python src/training/train_main.py --optimize --n-trials 5 ...

# Optuna 설정 확인
python -c "
from src.optimization.optuna_tuner import OptunaTuner
print('✅ Optuna 모듈 정상')
"
```

#### 4. Temperature Scaling 오류

```bash
# scikit-learn 설치 확인
pip install scikit-learn>=1.0.0 --force-reinstall

# 캘리브레이션 모듈 테스트
python -c "
from src.calibration.temperature_scaling import TemperatureScaling
print('✅ Temperature Scaling 모듈 정상')
"
```

#### 5. 로그 파일명 문제

```bash
# 증강 설정 확인
grep "use_advanced_augmentation" configs/train_highperf.yaml

# 로그 파일 패턴 확인
ls -la logs/$(date +%Y%m%d)/train/*augmentation*

# 설정 파일 유효성 검사
python -c "
from src.utils.common import load_yaml
cfg = load_yaml('configs/train_highperf.yaml')
print(f'증강 설정: {cfg[\"train\"][\"use_advanced_augmentation\"]}')
"
```

### 디버깅 체크리스트

- [ ] pyenv 환경 활성화 확인
- [ ] 의존성 설치 완료 (optuna, scikit-learn 포함)
- [ ] GPU 메모리 충분한지 확인
- [ ] 설정 파일 경로 정확한지 확인
- [ ] 디스크 공간 충분한지 확인
- [ ] WandB 로그인 상태 확인

### 성능 최적화 팁

#### GPU 활용도 극대화
```bash
# 배치 크기 자동 최적화
python src/utils/auto_batch_size.py --config configs/train_highperf.yaml

# 멀티 GPU 사용 (설정 파일 수정)
# device: cuda:0,1
```

#### 학습 속도 향상
```bash
# 혼합 정밀도 학습 (config 설정)
# mixed_precision: true

# 데이터로더 워커 수 증가 (config 설정)
# num_workers: 8
```

#### 메모리 효율성
```bash
# 그래디언트 체크포인팅 (config 설정)
# gradient_checkpointing: true

# 모델 컴파일 (PyTorch 2.0+)
# compile_model: true
```

---

## 📚 추가 자료

### 관련 문서
- [통합 실행 가이드](../optimization/통합_실행_가이드.md)
- [Optuna 최적화 가이드](../optimization/Optuna_하이퍼파라미터_최적화_가이드.md)
- [Temperature Scaling 가이드](../optimization/Temperature_Scaling_캘리브레이션_가이드.md)
- [실행 명령어 가이드](../pipelines/실행_명령어_가이드.md)

### 설정 파일 참조
- `configs/train_highperf.yaml`: 고성능 학습 설정
- `configs/optuna_config.yaml`: Optuna 최적화 설정
- `configs/train_optimized_*.yaml`: 사전 최적화된 설정

### 로그 및 결과 위치
- `logs/YYYYMMDD/train/`: 학습 로그 (날짜별 분류)
- `logs/YYYYMMDD/optimization/`: 최적화 로그 (날짜별 분류)
- `logs/YYYYMMDD/pipeline/`: 파이프라인 로그 (날짜별 분류)
- `experiments/train/`: 실험 결과
- `experiments/optimization/`: 최적화 결과
- `submissions/`: 제출 파일
