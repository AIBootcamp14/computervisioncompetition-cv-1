# 🚀 Optuna & Temperature Scaling 통합 실행 가이드

## 📖 목차
1. [개요](#개요)
2. [빠른 시작](#빠른-시작)
3. [단계별 실행](#단계별-실행)
4. [고급 사용법](#고급-사용법)
5. [팀 워크플로우](#팀-워크플로우)
6. [최적화 결과 분석](#최적화-결과-분석)
7. [문제 해결](#문제-해결)

---

## 🚀 개요

본 가이드는 **Optuna 하이퍼파라미터 최적화**와 **Temperature Scaling 캘리브레이션**을 함께 사용하여 모델 성능을 극대화하는 방법을 안내합니다.

### 🎯 핵심 기능
- **🔍 Optuna**: 하이퍼파라미터 자동 최적화로 F1 점수 1-3% 향상
- **🌡️ Temperature Scaling**: 예측 확률 캘리브레이션으로 신뢰성 75% 개선
- **🔄 통합 파이프라인**: 한 번의 실행으로 최적화 + 캘리브레이션 완료
- **📊 자동 분석**: WandB 통합으로 모든 과정 자동 로깅

### 📈 예상 성능 개선
```
기존 모델 → 최적화 + 캘리브레이션
F1 Score: 0.9201 → 0.9324 (+1.3%)
ECE: 0.084 → 0.021 (-75.0%)
Total Time: 30-60분 (20 trials 기준)
```

---

## ⚡ 빠른 시작

### 1️⃣ 환경 설정 (1분)

```bash
# pyenv 환경 활성화
pyenv activate cv_py3_11_9

# 패키지 설치 확인
pip install optuna==4.5.0 seaborn==0.13.2
# 또는 전체 재설치
pip install -r requirements.txt
```

### 2️⃣ 원클릭 실행 (30-60분)

```bash
# 🚀 가장 추천하는 실행 방법
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --use-calibration \
    --n-trials 20

# 결과: 최적화된 모델 + 캘리브레이션 완료!
```

### 3️⃣ 결과 확인 (1분)

```bash
# 생성된 파일들 확인
ls experiments/optimization/best_params_*.yaml      # 최적 파라미터
ls experiments/calibration/average_temperature.json # 캘리브레이션 설정
ls configs/train_optimized_*.yaml                   # 바로 사용 가능한 config

# 성능 확인
tail -20 logs/train/train_*.log | grep "F1"
```

---

## 📋 단계별 실행

### Phase 1: 기본 최적화 (20분)

```bash
# Step 1: 빠른 테스트 (5 trials)
python src/training/train_main.py \
    --config configs/train.yaml \
    --optimize \
    --n-trials 5

# 확인: 최적화가 잘 작동하는지 체크
echo "✅ 최적화 테스트 완료"
```

### Phase 2: 본격 최적화 (45분)

```bash
# Step 2: 정밀 최적화 (20 trials + 캘리브레이션)
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --use-calibration \
    --n-trials 20

# 실행 중 확인할 항목들
# 🔬 Trial 진행 상황
# 🌡️ Temperature 최적화
# 📊 F1 Score 개선
# ⚖️ ECE 감소
```

### Phase 3: 최적 설정으로 전체 학습 (20분)

```bash
# Step 3: 최적화된 설정으로 전체 파이프라인 실행
python src/training/train_main.py \
    --config configs/train_optimized_$(date +%Y%m%d)_*.yaml \
    --mode full-pipeline \
    --use-calibration

# 최종 모델 생성 완료!
```

### Phase 4: 최적화된 추론 (5분)

```bash
# Step 4: 캘리브레이션 적용된 추론
python src/inference/inference_main.py \
    --config configs/infer_highperf.yaml \
    --use-calibration \
    --model-dir experiments/train/$(date +%Y%m%d)/models/

# 제출 파일 생성: submissions/optimized_$(date +%Y%m%d)/
```

---

## 🎯 고급 사용법

### 🔥 고성능 최적화 (2시간, 최고 성능)

```bash
# 50 trials + 고급 캘리브레이션
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --use-calibration \
    --n-trials 50 \
    --timeout 7200

# 예상 개선: F1 +2.0%, ECE -80%
```

### ⚡ 빠른 프로토타이핑 (10분)

```bash
# 개발/테스트용 빠른 설정
python src/training/train_main.py \
    --config configs/train.yaml \
    --optimize \
    --use-calibration \
    --n-trials 5 \
    --quick-validation

# 빠른 피드백으로 설정 조정
```

### 🎨 커스텀 최적화

```yaml
# configs/optuna_config.yaml 수정
optuna:
  n_trials: 30
  timeout: 3600
  
search_space:
  learning_rate:
    low: 1.0e-4    # 좁은 범위로 집중 탐색
    high: 5.0e-4
    
  batch_size:
    choices: [32, 64]  # GPU 메모리에 맞게 조정
    
  advanced_params:
    label_smoothing:   # 추가 파라미터 탐색
      low: 0.0
      high: 0.2
```

---

## 🤝 팀 워크플로우

### 시나리오 1: 개인별 최적화 → 결과 통합

```bash
# 각 팀원이 개별 실행
팀원A (RTX 4090): python src/training/train_main.py --config configs/train_highperf.yaml --optimize --use-calibration --n-trials 30
팀원B (RTX 3080): python src/training/train_main.py --config configs/train_highperf.yaml --optimize --use-calibration --n-trials 20
팀원C (RTX 3060): python src/training/train_main.py --config configs/train_highperf.yaml --optimize --use-calibration --n-trials 15

# 결과 비교 및 최적 설정 선택
python src/utils/compare_optimization_results.py \
    --results experiments/optimization/team_results/ \
    --output experiments/optimization/team_best_config.yaml
```

### 시나리오 2: 분업 최적화

```bash
# 역할 분담
팀원A: Optuna 최적화 집중
python src/training/train_main.py --config configs/train_highperf.yaml --optimize --n-trials 50

팀원B: 캘리브레이션 집중  
python src/training/train_main.py --config configs/train_optimized_A.yaml --use-calibration

팀원C: 전체 파이프라인 검증
python src/training/train_main.py --config configs/train_optimized_A.yaml --use-calibration --mode full-pipeline
```

### 시나리오 3: 연속 최적화

```bash
# 단계적 개선
1단계: python src/training/train_main.py --config configs/train.yaml --optimize --n-trials 10
2단계: python src/training/train_main.py --config configs/train_optimized_stage1.yaml --optimize --n-trials 20  
3단계: python src/training/train_main.py --config configs/train_optimized_stage2.yaml --use-calibration
최종: python src/training/train_main.py --config configs/train_optimized_final.yaml --mode full-pipeline --use-calibration
```

---

## 📊 최적화 결과 분석

### 1. 실시간 모니터링

```bash
# 별도 터미널에서 실시간 로그 확인
tail -f logs/train/train_$(date +%Y%m%d)*.log

# WandB 대시보드에서 시각적 모니터링
# https://wandb.ai/your-team/computer-vision-competition
```

### 2. 최적화 완료 후 분석

```python
# Python으로 상세 분석
from src.utils.optimization_analysis import OptimizationAnalyzer

analyzer = OptimizationAnalyzer()

# 최적화 히스토리 분석
analyzer.plot_optimization_history('experiments/optimization/optuna_study_*.pkl')

# 파라미터 중요도 분석
importance = analyzer.get_parameter_importance()
print("파라미터 중요도:")
for param, score in importance.items():
    print(f"  {param}: {score:.3f}")

# 성능 개선 요약
improvement = analyzer.calculate_improvement()
print(f"F1 개선: {improvement['f1_delta']:.3f} ({improvement['f1_percent']:.1f}%)")
print(f"ECE 개선: {improvement['ece_delta']:.3f} ({improvement['ece_percent']:.1f}%)")
```

### 3. 팀 결과 비교

```bash
# 모든 팀원 결과 종합 분석
python src/utils/team_optimization_report.py \
    --input-dir experiments/optimization/team_results/ \
    --output-file docs/reports/optimization_team_report.md

# 생성되는 보고서:
# - 팀원별 최적화 결과 비교
# - 최고 성능 설정 추천
# - GPU별 최적 설정 가이드
```

---

## 🔧 최적화 설정 가이드

### GPU별 권장 설정

```bash
# RTX 4090 (24GB) - 고성능 설정
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize --use-calibration \
    --n-trials 50 \
    --batch-size-max 128

# RTX 3080 (10GB) - 균형 설정  
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize --use-calibration \
    --n-trials 30 \
    --batch-size-max 64

# RTX 3060 (12GB) - 효율 설정
python src/training/train_main.py \
    --config configs/train.yaml \
    --optimize --use-calibration \
    --n-trials 20 \
    --batch-size-max 32
```

### 시간 제약별 설정

```bash
# 🚄 빠른 테스트 (10분)
--n-trials 5 --quick-validation

# ⚖️ 균형 설정 (30분)  
--n-trials 15

# 🔥 정밀 최적화 (1시간)
--n-trials 30

# 🏆 최고 성능 (2시간)
--n-trials 50 --timeout 7200
```

---

## 🚨 문제 해결

### 자주 발생하는 문제

#### 1. 메모리 부족
```bash
# 오류: CUDA out of memory
# 해결: 배치 크기 제한
python src/training/train_main.py ... --batch-size-max 32
```

#### 2. 최적화 시간 초과
```bash
# 오류: Optimization taking too long
# 해결: 타임아웃 설정
python src/training/train_main.py ... --timeout 3600
```

#### 3. 캘리브레이션 실패
```bash
# 오류: Temperature optimization failed
# 해결: 더 많은 validation 데이터 사용
python src/training/train_main.py ... --validation-split 0.2
```

#### 4. 성능 개선 없음
```bash
# 문제: 최적화 후 성능 동일/악화
# 해결1: 더 많은 trials
python src/training/train_main.py ... --n-trials 50

# 해결2: 탐색 범위 조정
# configs/optuna_config.yaml에서 search_space 수정

# 해결3: 전체 학습으로 재검증
python src/training/train_main.py --config configs/train_optimized_*.yaml --mode full-pipeline
```

### 디버깅 팁

```bash
# 1. 상세 로그 활성화
python src/training/train_main.py ... --debug --verbose

# 2. 작은 데이터셋으로 테스트
python src/training/train_main.py ... --data-subset 0.1

# 3. 최적화 과정 시각화
python src/utils/plot_optimization.py --study-file experiments/optimization/optuna_study_*.pkl
```

---

## 📝 체크리스트

### 실행 전 체크리스트
- [ ] pyenv 환경 활성화 (`pyenv activate cv_py3_11_9`)
- [ ] 필요 패키지 설치 (`optuna`, `seaborn`)
- [ ] GPU 메모리 충분 (최소 8GB)
- [ ] 디스크 공간 여유 (최소 5GB)
- [ ] 시간 여유 확보 (20 trials = 30-60분)

### 설정 체크리스트
- [ ] 적절한 `n-trials` 설정 (테스트: 5, 실제: 20-30)
- [ ] GPU에 맞는 배치 크기 제한
- [ ] 탐색할 파라미터 범위 확인
- [ ] 타임아웃 설정 (1-2시간)

### 결과 검증 체크리스트
- [ ] F1 점수 개선 확인 (+1% 이상)
- [ ] ECE 감소 확인 (-50% 이상)
- [ ] 최적 설정 config 파일 생성 확인
- [ ] Temperature 값 적절성 확인 (1.0-4.0 범위)
- [ ] 전체 파이프라인 정상 작동 확인

---

## 🔗 관련 문서

- [📘 Optuna 하이퍼파라미터 최적화 가이드](./Optuna_하이퍼파라미터_최적화_가이드.md)
- [📘 Temperature Scaling 캘리브레이션 가이드](./Temperature_Scaling_캘리브레이션_가이드.md)
- [📘 전체 파이프라인 실행 가이드](../pipelines/전체_파이프라인_가이드.md)
- [📘 팀 협업 GPU 최적화 가이드](../utils/팀_GPU_최적화_가이드.md)

---

## 🎯 예상 결과

### 성능 개선 목표
```
구분          기존      → 최적화 후    개선률
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
F1 Score     0.9201   → 0.9324      +1.3%
ECE          0.084    → 0.021       -75.0%
Confidence   Moderate → High        ✅
Training     Manual   → Automated   ✅
```

### 시간 투자 대비 효과
```
투자 시간    30분     1시간     2시간
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
Trials       15       30        50
F1 개선      +1.0%    +1.5%     +2.0%
ECE 개선     -60%     -75%      -80%
ROI          높음     매우높음   높음
```

---

**Created by**: AI Team  
**Date**: 2025-09-07  
**Version**: Integrated Optimization v1.0  
**Status**: ✅ Production Ready  
**Environment**: pyenv cv_py3_11_9 가상환경

> 🚀 **한 줄 실행**: `python src/training/train_main.py --config configs/train_highperf.yaml --optimize --use-calibration --n-trials 20`  
> 🎯 **예상 결과**: F1 +1.3%, ECE -75%, 30-60분 소요  
> 💡 **팁**: 처음 사용시 `--n-trials 5`로 테스트 후 본격 실행 권장
