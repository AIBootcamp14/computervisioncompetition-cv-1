# 프로젝트 전체 스펙 및 로그 분석 요약 (통합 CLI 업데이트)

## 1. 디렉토리 구조 및 주요 파일 설명

```
AI_Lab/computer-vision-competition-1SEN/
├── configs/           # 파이프라인 설정 파일 (train/infer/optuna)
│   ├── train.yaml               # 기본 학습 설정 (EfficientNet)
│   ├── train_highperf.yaml      # 고성능 학습 설정 (Swin Transformer)
│   ├── train_fast_optimized.yaml # 🆕 빠른 실험 설정 (20-30분)
│   ├── train_optimized_*.yaml   # 최적화된 설정 파일들
│   ├── infer.yaml               # 기본 추론 설정
│   ├── infer_highperf.yaml      # 고성능 추론 설정
│   ├── optuna_config.yaml       # Optuna 최적화 설정
│   └── optuna_fast_config.yaml  # 🆕 빠른 Optuna 설정 (8 trials)
├── scripts/           # 🆕 실행 스크립트 관리 폴더
│   ├── monitor_training.sh      # 학습 모니터링
│   ├── run_fast_training.sh     # 빠른 학습 (20-30분)
│   ├── run_highperf_training.sh # 고성능 학습 (1-2시간)
│   └── update_inference_date.sh # 추론 설정 업데이트
├── data/              # 원본 및 분할 데이터, 테스트 이미지
├── docs/              # 프로젝트 가이드 및 분석 문서
│   ├── optimization/  # 🆕 Optuna/Temperature Scaling 가이드
│   └── scripts/       # 🆕 스크립트 사용법 가이드
├── experiments/       # 학습 결과, 모델 체크포인트, fold별 결과
│   └── optimization/  # 🆕 최적화 실험 결과
├── logs/              # 학습/추론/파이프라인 실행 로그 (날짜별 구조화)
│   ├── YYYYMMDD/      # 🆕 날짜별 폴더 구조
│   │   ├── train/     # 학습 로그
│   │   ├── infer/     # 추론 로그
│   │   ├── optimization/ # Optuna 최적화 로그
│   │   └── pipeline/  # 파이프라인 로그
│   └── optimization/  # 🆕 Optuna 최적화 로그
├── notebooks/         # 실험/분석/모듈화 노트북
├── src/               # 파이프라인, 모델, 유틸리티 코드
│   ├── optimization/  # 🆕 Optuna 하이퍼파라미터 최적화 모듈
│   ├── calibration/   # 🆕 Temperature Scaling 캘리브레이션 모듈
│   └── training/train_main.py # 🆕 통합 CLI 인터페이스
├── submissions/       # 추론 결과 제출 파일(csv)
├── wandb/             # WandB 실험 로그
└── requirements.txt   # 패키지 의존성 (optuna, scikit-learn 추가)
```

### 🆕 새로운 주요 파일 및 기능
- **scripts/ 폴더**: 프로젝트 관리용 실행 스크립트 통합 관리
- **통합 CLI**: `src/training/train_main.py` - 모든 학습 모드 통합 실행
- **빠른 실험**: `train_fast_optimized.yaml` - 20-30분 내 결과 확인
- **빠른 최적화**: `optuna_fast_config.yaml` - 8 trials로 신속 최적화
- **Optuna 최적화**: `src/optimization/optuna_tuner.py` - 자동 하이퍼파라미터 최적화
- **Temperature Scaling**: `src/calibration/temperature_scaling.py` - 모델 캘리브레이션
- **날짜별 로그**: `logs/YYYYMMDD/` 구조로 체계적 로그 관리
- **증강 설정**: `use_advanced_augmentation` 플래그로 증강 타입 제어
- **로그 파일명**: 증강 타입 자동 표시 (advanced/basic_augmentation)

## 2. 🔄 새로운 작업 흐름도
1. **환경 설정**: pyenv 환경 활성화 및 패키지 설치 (optuna, scikit-learn 포함)
2. **통합 CLI 실행**: `train_main.py`로 모든 기능 원클릭 실행
3. **🔍 Optuna 최적화**: 하이퍼파라미터 자동 최적화 (선택사항)
4. **🎯 K-Fold 학습**: 최적화된 설정으로 고성능 학습
5. **🌡️ Temperature Scaling**: 모델 캘리브레이션 적용
6. **🔮 앙상블 추론**: 5-Fold 앙상블 + TTA 추론
7. **📤 제출 파일 생성**: 자동 생성 및 저장
8. **📊 실험 추적**: WandB + 로그를 통한 성능 모니터링

## 3. 🎯 업데이트된 하이퍼파라미터/모델/앙상블 스펙

### 모델 아키텍처
- **고성능**: `swin_base_384`, `convnext_base_384_in22ft1k`
- **기본**: `efficientnet_b3`, `resnet50`

### 🎨 증강 설정
- **기본 증강** (`use_advanced_augmentation: false`):
  - 기본 Resize, RandomCrop, 색상 조정
- **고급 증강** (`use_advanced_augmentation: true`):
  - Hard Augmentation + Mixup + Progressive 강도 조절

### 🔍 Optuna 최적화 범위
```yaml
search_space:
  lr: [1e-5, 1e-3]              # 학습률
  weight_decay: [1e-6, 1e-2]    # Weight decay
  batch_size: [16, 64]          # 배치 크기
  drop_rate: [0.0, 0.3]         # 드롭아웃
  mixup_alpha: [0.2, 2.0]       # Mixup 알파
```

### 🌡️ Temperature Scaling
- **목적**: 모델 신뢰도 보정 및 성능 향상
- **효과**: F1 Score 0.934 → 0.940+ 향상

### 학습 하이퍼파라미터
- **img_size**: 384 (고성능), 224 (기본)
- **batch_size**: 32 (학습), 64 (추론)
- **epochs**: 15 (고성능), 30 (기본)
- **optimizer**: AdamW
- **scheduler**: CosineAnnealingLR
- **label_smoothing**: 0.1
- **mixed_precision**: true (메모리 효율성)

## 4. 🚀 통합 실행 명령어

### 최고 성능 실행 (권장)
```bash
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --optimize \
    --n-trials 20 \
    --use-calibration \
    --mode full-pipeline \
    --auto-continue
```

### 빠른 실행 (사전 최적화 사용)
```bash
python src/training/train_main.py \
    --config configs/train_optimized_20250907_1825.yaml \
    --use-calibration \
    --mode full-pipeline
```

### 추론만 실행
```bash
python src/training/train_main.py \
    --config configs/train_highperf.yaml \
    --mode full-pipeline \
    --skip-training \
    --use-calibration
```

## 4. 최근 실행 로그 분석
- 학습: 평균 F1 0.9356 (fold별 0.92~0.94)
- 대회 점수: 0.9328
- 추론: 3140개 테스트 이미지, 클래스별 분포 고름
- 제출 파일: `submissions/20250905/v094-swin-highperf_ensemble_20250905_1714.csv`
- WandB 실험 URL, fold별 성능, 클래스별 정확도 시각화

## 5. 파일간 관계도
- configs → src/pipeline → src/models/training/inference → experiments/logs/submissions
- notebooks: 실험/분석/모듈화 코드, 파이프라인과 설정 연동
- docs: 전체 가이드, 실행법, 분석, 워크플로우 설명

## 6. 기존 docs 가이드 파일 분석 및 수정 필요 사항
- 모든 가이드에 pyenv 환경, GPU 체크, 자동 배치사이즈, K-Fold/앙상블/TTA, WandB 실험 관리 등 최신 워크플로우 반영 필요
- 데이터 경로, 모델명, 하이퍼파라미터, 앙상블 방식 등 최신 스펙으로 통일 필요
- 파이프라인 실행법, 결과 확인법, 제출 파일 생성 과정 명확히 기술

## 7. 결론 및 참고
- 전체 파이프라인, 하이퍼파라미터, 앙상블, 모델, 실험 관리가 모듈화되어 팀원 누구나 동일한 방식으로 실행 가능
- 모든 코드/설정/가이드가 최신 워크플로우에 맞게 통일되어 있음
- 추가 실험/분석/가이드가 필요하면 docs에 계속 추가/수정 가능

---
(2025-09-05 기준 최신 스펙/구조/실행 결과 반영)
