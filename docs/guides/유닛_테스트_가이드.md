# 📚 단위 테스트 노트북 가이드

> 고성능 문서 분류 모델의 개별 컴포넌트를 체계적으로 테스트하기 위한 단위 테스트 노트북 활용 가이드

## 🎯 개요

이 가이드는 모듈화된 고성능 학습 시스템의 각 컴포넌트를 개별적으로 테스트하고 최적화하기 위한 5개의 단위 테스트 노트북의 사용법을 제공합니다. 모든 테스트는 로깅 시스템과 통합되어 결과를 체계적으로 기록하고 분석할 수 있습니다.

### 📁 노트북 구성

```
notebooks/
├── test_highperf_dataset.ipynb      # 데이터셋 및 증강 기법 테스트
├── test_mixup_augmentation.ipynb    # Mixup 기법 심화 분석
├── test_swin_model.ipynb           # Swin Transformer 모델 벤치마크
├── test_wandb_integration.ipynb    # WandB 실험 추적 시스템 테스트
└── test_full_pipeline.ipynb        # 전체 파이프라인 통합 테스트
```

### 🗂️ 로그 디렉토리 구조

모든 테스트 결과는 다음과 같이 체계적으로 저장됩니다:

```
logs/unit_test/
├── highperf_dataset/
│   └── 20250905_143052/
│       ├── logs/           # 텍스트 로그 파일들
│       ├── images/         # 시각화 결과 이미지들
│       ├── data/           # 처리된 데이터 파일들
│       ├── results/        # 테스트 결과 JSON 파일들
│       └── test_summary.json
├── mixup_augmentation/
├── swin_model/
├── wandb_integration/
└── full_pipeline/
```

---

## 📊 1. 고성능 데이터셋 테스트 (`test_highperf_dataset.ipynb`)

### 🎯 목적
- HighPerfDocClsDataset 클래스의 동작 검증
- Hard Augmentation 기법 효과 분석
- Mixup 데이터 증강 시각적 확인
- 에포크별 증강 강도 변화 모니터링

### 🔬 주요 테스트 항목

#### 1. 기본 데이터셋 로딩 테스트
- CSV 파일 읽기 및 파싱
- 이미지 파일 존재 여부 확인
- 클래스 분포 분석
- 데이터 타입 및 형태 검증

#### 2. Hard Augmentation 효과 분석
```python
# 에포크별 증강 강도 변화
for epoch in [1, 5, 10, 20, 30]:
    prob = calculate_hard_aug_prob(epoch, total_epochs=30)
    # 시각화 및 로깅
```

#### 3. Mixup 데이터 증강 검증
- Alpha/Beta 파라미터별 시각적 결과 비교
- 혼합 비율에 따른 이미지 품질 평가
- 성능 영향 분석

#### 4. 성능 벤치마크
- 데이터 로딩 속도 측정
- 메모리 사용량 모니터링
- 배치 처리 효율성 평가

### 📋 사용법

1. **노트북 실행 전 준비**
   ```bash
   # 필요한 의존성 확인
   pip install torch torchvision albumentations
   
   # 데이터 경로 확인
   ls data/raw/train/
   ls data/raw/test/
   ```

2. **테스트 실행**
   - 노트북의 모든 셀을 순차적으로 실행
   - 각 섹션별 결과 확인
   - 로그 디렉토리에서 상세 결과 분석

3. **결과 분석**
   - `logs/unit_test/highperf_dataset/[timestamp]/` 에서 결과 확인
   - 시각화 이미지로 증강 효과 검토
   - 성능 메트릭으로 최적 설정 탐색

### 🎯 최적화 포인트

- **Hard Augmentation 스케줄링**: 에포크별 적절한 강도 조절
- **Mixup 파라미터**: Alpha=0.2~0.4 범위에서 최적값 탐색
- **배치 크기**: 메모리와 성능의 균형점 찾기
- **Workers 수**: 데이터 로딩 병렬화 최적화

---

## 🎨 2. Mixup 증강 기법 테스트 (`test_mixup_augmentation.ipynb`)

### 🎯 목적
- Mixup 데이터 증강의 심화 분석
- 다양한 Alpha/Beta 파라미터 조합 실험
- 클래스별 Mixup 효과 차이 분석
- 최적 Mixup 전략 도출

### 🔬 주요 테스트 항목

#### 1. Mixup 파라미터 스위핑
```python
alpha_values = [0.1, 0.2, 0.4, 0.8, 1.0]
for alpha in alpha_values:
    # Beta 분포 시각화
    # 혼합 결과 비교
    # 성능 영향 평가
```

#### 2. 클래스 조합별 효과 분석
- 유사 클래스 간 Mixup 효과
- 이질적 클래스 간 Mixup 결과
- 클래스 불균형 상황에서의 영향

#### 3. Mixup vs 기본 증강 비교
- CutMix와의 성능 비교
- 전통적 증강 기법과의 조합 효과
- 학습 안정성 분석

#### 4. 실시간 시각화
- 원본 이미지 쌍과 혼합 결과 비교
- 혼합 비율별 연속적 변화 애니메이션
- 레이블 스무딩 효과 시각화

### 📊 분석 메트릭

- **시각적 품질**: 혼합된 이미지의 자연스러움
- **다양성 지수**: 생성된 샘플의 다양성 측정
- **클래스 보존도**: 원본 클래스 특성 유지 정도
- **학습 수렴성**: 모델 학습에 미치는 영향

### 🎯 최적화 가이드

1. **Alpha 값 선택**
   - 문서 분류: α = 0.2 ~ 0.4 권장
   - 세밀한 텍스트: α = 0.1 ~ 0.2
   - 거친 레이아웃: α = 0.4 ~ 0.8

2. **적용 전략**
   - 학습 초기: 낮은 α 값 사용
   - 중후반: 점진적 α 증가
   - Fine-tuning: Mixup 비율 감소

---

## 🧠 3. Swin Transformer 모델 테스트 (`test_swin_model.ipynb`)

### 🎯 목적
- Swin Transformer 모델의 성능 벤치마크
- 다양한 이미지 크기별 처리 능력 측정
- 메모리 사용량 및 추론 속도 분석
- 모델 구조별 특성 비교

### 🔬 주요 테스트 항목

#### 1. 모델 아키텍처 분석
```python
# 모델 구조 시각화
model_info = {
    'total_params': count_parameters(model),
    'model_size_mb': get_model_size(model),
    'layer_breakdown': analyze_layers(model)
}
```

#### 2. 이미지 크기별 성능 측정
- 224×224: 기본 성능 기준선
- 384×384: 고해상도 처리 성능
- 512×512: 최대 해상도 한계 테스트
- 배치 크기별 처리량 비교

#### 3. 추론 속도 벤치마크
```python
image_sizes = [224, 384, 512]
batch_sizes = [1, 4, 8, 16, 32]

for img_size in image_sizes:
    for batch_size in batch_sizes:
        # 처리 시간 측정
        # 메모리 사용량 모니터링
        # FPS 계산
```

#### 4. Feature Map 분석
- 각 Transformer 블록의 출력 시각화
- Attention Map 분석
- 계층별 특성 추출 능력 평가

### 📊 성능 메트릭

- **처리 속도**: FPS (Frames Per Second)
- **메모리 효율성**: GPU 메모리 사용량
- **정확도**: 샘플 데이터 분류 성능
- **안정성**: 다양한 입력에 대한 견고성

### 🎯 최적화 전략

1. **이미지 크기 선택**
   - 정확도 우선: 384×384 이상
   - 속도 우선: 224×224
   - 균형점: 320×320

2. **배치 크기 조정**
   - GPU 메모리에 따른 최적화
   - Gradient Accumulation 활용
   - Mixed Precision 적용

---

## 📊 4. WandB 통합 테스트 (`test_wandb_integration.ipynb`)

### 🎯 목적
- WandB 로깅 시스템의 완전한 기능 검증
- 팀 프로젝트 워크플로우 테스트
- 실험 추적 및 비교 기능 확인
- 자동화된 실험 관리 시스템 구축

### 🔬 주요 테스트 항목

#### 1. 로그인 및 프로젝트 설정
```python
# WandB 인증 테스트
wandb.login()

# 프로젝트 초기화
wandb.init(
    project="document-classification-team",
    name=f"unit-test-{timestamp}",
    tags=["unit-test", "integration"]
)
```

#### 2. 메트릭 로깅 테스트
- 실시간 손실 함수 그래프
- F1 스코어 추적
- 하이퍼파라미터 로깅
- 커스텀 메트릭 추가

#### 3. 시각화 업로드 테스트
- Matplotlib 차트 자동 업로드
- 이미지 샘플 로깅
- Confusion Matrix 시각화
- 히스토그램 분포 그래프

#### 4. 모델 아티팩트 관리
- 체크포인트 자동 업로드
- 모델 버전 관리
- 메타데이터 태깅
- 모델 다운로드 테스트

### 🚀 팀 협업 워크플로우

1. **개별 실험 관리**
   ```python
   experiment_name = f"{member_name}_{model_type}_{timestamp}"
   tags = [member_name, model_type, "experiment"]
   ```

2. **결과 공유 및 비교**
   - 팀 대시보드 구성
   - 성능 메트릭 비교
   - 최고 성능 모델 식별

3. **자동 알림 설정**
   - 목표 성능 달성 시 알림
   - 실험 완료 상태 공유
   - 에러 발생 시 알림

### 💡 활용 팁

- **로깅 빈도 조절**: 너무 자주 로깅하면 성능 저하
- **이미지 해상도**: 적절한 크기로 업로드 시간 단축
- **태그 전략**: 체계적인 태그로 실험 관리 효율화

---

## 🚀 5. 전체 파이프라인 테스트 (`test_full_pipeline.ipynb`)

### 🎯 목적
- 전체 시스템의 통합 테스트
- End-to-End 파이프라인 검증
- 에러 상황 대응 능력 테스트
- 실제 운영 환경 시뮬레이션

### 🔬 주요 테스트 항목

#### 1. 소규모 데이터 테스트
```python
# 각 클래스에서 5개씩 샘플링
mini_train = train_df.groupby('target').head(5)
mini_test = test_df.head(50)

# 빠른 학습 설정
test_config = {
    'epochs': 2,
    'batch_size': 4,
    'n_folds': 2,
    'img_size': 224
}
```

#### 2. 파이프라인 실행 테스트
- 설정 파일 검증
- 데이터 로딩 확인
- 모델 학습 과정
- 추론 및 제출 파일 생성

#### 3. 에러 시나리오 테스트
- 잘못된 설정 파일 처리
- 존재하지 않는 데이터 경로
- 메모리 부족 상황 시뮬레이션
- 네트워크 연결 오류 처리

#### 4. 성능 프로파일링
- CPU/GPU 사용률 모니터링
- 메모리 사용 패턴 분석
- 디스크 I/O 최적화
- 병목 구간 식별

### 📊 검증 항목

1. **기능적 검증**
   - [ ] 모든 모듈 정상 import
   - [ ] 설정 파일 올바른 파싱
   - [ ] 데이터 로딩 성공
   - [ ] 모델 학습 완료
   - [ ] 추론 결과 생성

2. **성능 검증**
   - [ ] 메모리 사용량 < 8GB (예시)
   - [ ] 학습 시간 < 10분 (소규모)
   - [ ] 추론 속도 > 100 FPS
   - [ ] CPU 사용률 < 80%

3. **안정성 검증**
   - [ ] 에러 상황 graceful 처리
   - [ ] 메모리 누수 없음
   - [ ] 재현 가능한 결과
   - [ ] 로그 정상 기록

---

## 🎯 개발 단계별 활용 가이드

### 1️⃣ 데이터 준비 단계
- **사용 노트북**: `test_highperf_dataset.ipynb`
- **목표**: 데이터 파이프라인 최적화
- **체크포인트**: 
  - 데이터 로딩 속도 > 목표치
  - 증강 효과 시각적 확인
  - 클래스 균형 분석 완료

### 2️⃣ 모델 최적화 단계
- **사용 노트북**: `test_swin_model.ipynb`
- **목표**: 모델 구조 및 하이퍼파라미터 최적화
- **체크포인트**:
  - 모델 크기별 성능 비교
  - 추론 속도 벤치마크
  - 메모리 사용량 최적화

### 3️⃣ 증강 기법 최적화 단계
- **사용 노트북**: `test_mixup_augmentation.ipynb`
- **목표**: 데이터 증강 전략 개선
- **체크포인트**:
  - 최적 Mixup 파라미터 도출
  - 클래스별 효과 분석
  - 성능 향상 확인

### 4️⃣ 실험 추적 설정 단계
- **사용 노트북**: `test_wandb_integration.ipynb`
- **목표**: 체계적인 실험 관리 시스템 구축
- **체크포인트**:
  - WandB 프로젝트 설정 완료
  - 팀 대시보드 구성
  - 자동 로깅 검증

### 5️⃣ 전체 시스템 검증 단계
- **사용 노트북**: `test_full_pipeline.ipynb`
- **목표**: 통합 시스템의 안정성 확인
- **체크포인트**:
  - End-to-End 테스트 통과
  - 에러 처리 검증
  - 성능 요구사항 만족

---

## 🔧 문제 해결 시나리오

### 🚨 성능 저하 발생
1. **증상**: F1 스코어 예상보다 낮음
2. **진단 순서**:
   - `test_highperf_dataset.ipynb` → 데이터 품질 확인
   - `test_mixup_augmentation.ipynb` → 증강 설정 검토
   - `test_swin_model.ipynb` → 모델 구조 분석

### 💾 메모리 부족 문제
1. **증상**: CUDA out of memory 에러
2. **해결 과정**:
   - `test_swin_model.ipynb` → 배치 크기 최적화
   - `test_full_pipeline.ipynb` → 시스템 리소스 확인
   - Gradient Accumulation 적용

### 🐌 학습 속도 저하
1. **증상**: 에포크당 시간 과도하게 길어짐
2. **최적화 단계**:
   - `test_highperf_dataset.ipynb` → 데이터 로딩 병렬화
   - `test_swin_model.ipynb` → Mixed Precision 적용
   - Workers 수 조정

### 📊 WandB 연동 문제
1. **증상**: 로그 업로드 실패
2. **해결 방법**:
   - `test_wandb_integration.ipynb` → 연결 상태 확인
   - API 키 재설정
   - 네트워크 방화벽 확인

---

## 📋 테스트 체크리스트

### 데일리 테스트 (매일 실행)
- [ ] `test_full_pipeline.ipynb` 기본 기능 테스트
- [ ] 새로운 코드 변경사항 검증
- [ ] 로그 파일 용량 체크

### 위클리 테스트 (주간 실행)
- [ ] 모든 단위 테스트 노트북 전체 실행
- [ ] 성능 벤치마크 비교 분석
- [ ] 메모리 누수 검사

### 실험 전 테스트 (중요 실험 전)
- [ ] `test_highperf_dataset.ipynb` 데이터 검증
- [ ] `test_swin_model.ipynb` 모델 안정성 확인
- [ ] `test_wandb_integration.ipynb` 로깅 시스템 점검

### 배포 전 테스트 (최종 제출 전)
- [ ] 전체 파이프라인 End-to-End 테스트
- [ ] 제출 파일 형식 검증
- [ ] 재현성 테스트 (동일 시드로 동일 결과)

---

## 🎉 결론

이 단위 테스트 시스템을 통해 다음과 같은 이점을 얻을 수 있습니다:

### ✅ 개발 효율성
- **빠른 디버깅**: 문제 원인 신속 파악
- **점진적 개선**: 컴포넌트별 독립적 최적화
- **안전한 실험**: 전체 시스템 영향 없이 테스트

### 📊 품질 관리
- **체계적 검증**: 모든 기능의 정확성 보장
- **성능 모니터링**: 지속적인 성능 추적
- **재현성 확보**: 동일한 결과 재현 가능

### 🚀 팀 협업
- **표준화된 테스트**: 팀원 간 일관된 테스트 환경
- **지식 공유**: 테스트 결과를 통한 경험 공유
- **품질 보증**: 코드 품질의 일정 수준 유지
