{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n",
    "* 필요한 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# # 필요한 라이브러리를 설치합니다.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam, AdamW  # AdamW 추가\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR  # OneCycleLR 추가\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precision용\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "\n",
    "# WandB 관련 import 추가\n",
    "import wandb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1-1. WandB Login and Configuration\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "🚀 팀원 사용 가이드:\n",
    "\n",
    "1. WandB 계정 생성: https://wandb.ai/signup\n",
    "2. 이 셀 실행 시 로그인 프롬프트가 나타나면 개인 API 키 입력\n",
    "3. EXPERIMENT_NAME을 다음과 같이 변경:\n",
    "   - \"member1-baseline\"\n",
    "   - \"member2-augmentation-test\"  \n",
    "   - \"member3-hyperparameter-tuning\"\n",
    "   등등 각자 다른 이름 사용\n",
    "\n",
    "4. 팀 대시보드 URL: [여기에 당신의 프로젝트 URL 추가]\n",
    "\n",
    "⚠️ 주의사항:\n",
    "- 절대 API 키를 코드에 하드코딩하지 마세요\n",
    "- EXPERIMENT_NAME만 변경하고 PROJECT_NAME은 그대로 두세요\n",
    "- 각자 개인 계정으로 로그인해서 실험을 추가하세요\n",
    "\"\"\"\n",
    "\n",
    "# WandB 로그인 (각자 실행)\n",
    "try:\n",
    "    if wandb.api.api_key is None:\n",
    "        print(\"WandB에 로그인이 필요합니다.\")\n",
    "        wandb.login()\n",
    "    else:\n",
    "        print(f\"WandB 로그인 상태: {wandb.api.viewer()['username']}\")\n",
    "except:\n",
    "    print(\"WandB 로그인을 진행합니다...\")\n",
    "    wandb.login()\n",
    "\n",
    "# 프로젝트 설정 (각자 수정할 부분)\n",
    "PROJECT_NAME = \"document-classification-team\"  # 모든 팀원 동일\n",
    "ENTITY = None  # 각자 개인 계정 사용\n",
    "EXPERIMENT_NAME = \"swinb-convnext-ensemble\"  # 팀원별로 변경 (예: \"member1-hyperopt\", \"member2-augmentation\")\n",
    "\n",
    "print(f\"프로젝트: {PROJECT_NAME}\")\n",
    "print(f\"실험명: {EXPERIMENT_NAME}\")\n",
    "print(\"팀원들은 EXPERIMENT_NAME을 각자 다르게 변경해주세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device 및 기본 설정\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"📱 Using device: {device}\")\n",
    "\n",
    "data_path = '/root/home/cv_contest/CV_data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 모델 설정\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    'swin_b': {\n",
    "        'model_name': 'swin_base_patch4_window12_384_in22k',\n",
    "        'img_size': 384,\n",
    "        'batch_size': 16,\n",
    "        'lr': 5e-4,\n",
    "        'architecture': 'Swin Transformer',\n",
    "        'weight_decay': 0.01\n",
    "    },\n",
    "    'convnext': {\n",
    "        'model_name': 'convnext_base_in22k',\n",
    "        'img_size': 224,\n",
    "        'batch_size': 16,\n",
    "        'lr': 3e-4,\n",
    "        'architecture': 'ConvNeXt',\n",
    "        'weight_decay': 0.01\n",
    "    }\n",
    "}\n",
    "\n",
    "# 사용할 모델들 선택\n",
    "ACTIVE_MODELS = ['swin_b', 'convnext']\n",
    "EPOCHS = 50\n",
    "num_workers = 30\n",
    "N_FOLDS = 5\n",
    "\n",
    "print(f\"📊 사용할 모델: {ACTIVE_MODELS}\")\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    config = MODEL_CONFIGS[model_key]\n",
    "    print(f\"  🤖 {model_key}: {config['model_name']} ({config['img_size']}x{config['img_size']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Resolution Dataset 클래스\n",
    "\n",
    "class MultiResImageDataset(Dataset):\n",
    "    def __init__(self, data, path, img_sizes, epoch=0, total_epochs=10, is_train=True):\n",
    "        \"\"\"\n",
    "        다중 해상도를 지원하는 Dataset\n",
    "        \"\"\"\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.img_sizes = img_sizes\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation 확률 계산\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # 각 해상도별 transform 생성\n",
    "        self.transforms = {}\n",
    "        for model_key, img_size in img_sizes.items():\n",
    "            # Normal augmentation\n",
    "            normal_aug = A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.OneOf([\n",
    "                    A.Rotate(limit=[90,90], p=1.0),\n",
    "                    A.Rotate(limit=[180,180], p=1.0),\n",
    "                    A.Rotate(limit=[270,270], p=1.0),\n",
    "                ], p=0.6),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "                A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "            \n",
    "            # Hard augmentation\n",
    "            hard_aug = A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.OneOf([\n",
    "                    A.Rotate(limit=[90,90], p=1.0),\n",
    "                    A.Rotate(limit=[180,180], p=1.0),\n",
    "                    A.Rotate(limit=[270,270], p=1.0),\n",
    "                    A.Rotate(limit=[-15,15], p=1.0),\n",
    "                ], p=0.8),\n",
    "                A.OneOf([\n",
    "                    A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                    A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "                ], p=0.95),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "                A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "                A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "            \n",
    "            self.transforms[model_key] = {\n",
    "                'normal': normal_aug,\n",
    "                'hard': hard_aug\n",
    "            }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # 각 모델별로 다른 해상도의 이미지 생성\n",
    "        images = {}\n",
    "        for model_key in self.img_sizes.keys():\n",
    "            # 배치별 증강 선택\n",
    "            if self.is_train and random.random() < self.p_hard:\n",
    "                aug_img = self.transforms[model_key]['hard'](image=img)['image']\n",
    "            else:\n",
    "                aug_img = self.transforms[model_key]['normal'](image=img)['image']\n",
    "            images[model_key] = aug_img\n",
    "        \n",
    "        return images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 모델 학습 함수들\n",
    "\n",
    "def train_multi_models_epoch(loaders, models, optimizers, loss_fns, device, epoch=None, fold=None):\n",
    "    \"\"\"다중 모델을 동시에 학습하는 함수\"\"\"\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # 모든 모델을 학습 모드로\n",
    "    for model in models.values():\n",
    "        model.train()\n",
    "    \n",
    "    model_losses = {key: 0 for key in models.keys()}\n",
    "    model_preds = {key: [] for key in models.keys()}\n",
    "    targets_list = []\n",
    "    \n",
    "    # 첫 번째 loader 기준으로 iteration\n",
    "    first_key = list(loaders.keys())[0]\n",
    "    pbar = tqdm(loaders[first_key], desc=f\"Training Epoch {epoch+1 if epoch else '?'}\")\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(pbar):\n",
    "        images_dict, targets = batch_data\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # 각 모델별로 학습\n",
    "        batch_losses = {}\n",
    "        for model_key in models.keys():\n",
    "            model = models[model_key]\n",
    "            optimizer = optimizers[model_key]\n",
    "            loss_fn = loss_fns[model_key]\n",
    "            \n",
    "            image = images_dict[model_key].to(device)\n",
    "            \n",
    "            # Mixup 확률 (30% 유지)\n",
    "            mixup_applied = False\n",
    "            if random.random() < 0.3:\n",
    "                mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "                with autocast():\n",
    "                    preds = model(mixed_x)\n",
    "                loss = lam * loss_fn(preds.float(), y_a) + (1 - lam) * loss_fn(preds.float(), y_b)\n",
    "                mixup_applied = True\n",
    "            else:\n",
    "                with autocast():\n",
    "                    preds = model(image)\n",
    "                loss = loss_fn(preds.float(), targets)\n",
    "            \n",
    "            # 역전파\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            batch_losses[model_key] = loss.item()\n",
    "            model_losses[model_key] += loss.item()\n",
    "            model_preds[model_key].extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        \n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "        \n",
    "        # 배치별 로깅\n",
    "        if batch_idx % 100 == 0 and wandb.run is not None:\n",
    "            step = epoch * len(pbar) + batch_idx if epoch is not None else batch_idx\n",
    "            log_data = {f\"fold_{fold}/batch_step\": step}\n",
    "            for model_key, loss_val in batch_losses.items():\n",
    "                log_data[f\"fold_{fold}/{model_key}_batch_loss\"] = loss_val\n",
    "            log_data[f\"fold_{fold}/mixup_applied\"] = int(mixup_applied)\n",
    "            wandb.log(log_data)\n",
    "        \n",
    "        pbar.set_description(f\"Losses: {', '.join([f'{k}: {v:.4f}' for k, v in batch_losses.items()])}\")\n",
    "    \n",
    "    # 각 모델별 결과 계산\n",
    "    results = {}\n",
    "    for model_key in models.keys():\n",
    "        model_losses[model_key] /= len(pbar)\n",
    "        train_acc = accuracy_score(targets_list, model_preds[model_key])\n",
    "        train_f1 = f1_score(targets_list, model_preds[model_key], average='macro')\n",
    "        \n",
    "        results[model_key] = {\n",
    "            \"train_loss\": model_losses[model_key],\n",
    "            \"train_acc\": train_acc,\n",
    "            \"train_f1\": train_f1,\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def validate_multi_models_epoch(loaders, models, loss_fns, device, epoch=None, fold=None, log_confusion=False):\n",
    "    \"\"\"다중 모델을 동시에 검증하는 함수\"\"\"\n",
    "    \n",
    "    # 모든 모델을 평가 모드로\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    \n",
    "    model_losses = {key: 0 for key in models.keys()}\n",
    "    model_preds = {key: [] for key in models.keys()}\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        first_key = list(loaders.keys())[0]\n",
    "        pbar = tqdm(loaders[first_key], desc=f\"Validating Epoch {epoch+1 if epoch else '?'}\")\n",
    "        \n",
    "        for batch_data in pbar:\n",
    "            images_dict, targets = batch_data\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            batch_losses = {}\n",
    "            for model_key in models.keys():\n",
    "                model = models[model_key]\n",
    "                loss_fn = loss_fns[model_key]\n",
    "                \n",
    "                image = images_dict[model_key].to(device)\n",
    "                preds = model(image)\n",
    "                loss = loss_fn(preds, targets)\n",
    "                \n",
    "                batch_losses[model_key] = loss.item()\n",
    "                model_losses[model_key] += loss.item()\n",
    "                model_preds[model_key].extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            \n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "            pbar.set_description(f\"Val Losses: {', '.join([f'{k}: {v:.4f}' for k, v in batch_losses.items()])}\")\n",
    "    \n",
    "    # 각 모델별 결과 계산\n",
    "    results = {}\n",
    "    for model_key in models.keys():\n",
    "        model_losses[model_key] /= len(pbar)\n",
    "        val_acc = accuracy_score(targets_list, model_preds[model_key])\n",
    "        val_f1 = f1_score(targets_list, model_preds[model_key], average='macro')\n",
    "        \n",
    "        # Confusion Matrix 로깅 (마지막 epoch에만)\n",
    "        if log_confusion and wandb.run is not None:\n",
    "            try:\n",
    "                wandb.log({\n",
    "                    f\"fold_{fold}/{model_key}_confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                        probs=None,\n",
    "                        y_true=targets_list,\n",
    "                        preds=model_preds[model_key],\n",
    "                        class_names=[f\"Class_{i}\" for i in range(17)]\n",
    "                    )\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ {model_key} Confusion matrix 로깅 실패: {e}\")\n",
    "        \n",
    "        results[model_key] = {\n",
    "            \"val_loss\": model_losses[model_key],\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1\": val_f1,\n",
    "        }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB Config 설정\n",
    "\n",
    "config = {\n",
    "    # Multi-Model config\n",
    "    \"ensemble_models\": ACTIVE_MODELS,\n",
    "    \"model_configs\": MODEL_CONFIGS,\n",
    "    \"multi_resolution\": True,\n",
    "    \n",
    "    # Training config\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"device\": str(device),\n",
    "    \n",
    "    # K-Fold config\n",
    "    \"n_folds\": N_FOLDS,\n",
    "    \"seed\": SEED,\n",
    "    \"cv_strategy\": \"StratifiedKFold\",\n",
    "    \n",
    "    # Augmentation & Training techniques\n",
    "    \"mixup_alpha\": 1.0,\n",
    "    \"mixup_prob\": 0.3,\n",
    "    \"label_smoothing\": 0.1,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"mixed_precision\": True,\n",
    "    \n",
    "    # Data\n",
    "    \"data_path\": data_path,\n",
    "    \"train_transforms\": \"Progressive_Hard_Augmentation\",\n",
    "    \"test_transforms\": \"Basic\",\n",
    "}\n",
    "\n",
    "print(\"✅ 하이퍼파라미터 설정 완료!\")\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    config_detail = MODEL_CONFIGS[model_key]\n",
    "    print(f\"🤖 {model_key}: {config_detail['model_name']} ({config_detail['img_size']}px, LR={config_detail['lr']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 클래스 가중치 계산\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "train_df = pd.read_csv(\"CV_data/train.csv\")\n",
    "print(f\"📊 학습 데이터: {len(train_df)}개 샘플\")\n",
    "\n",
    "# 클래스 분포 확인\n",
    "class_counts = train_df['target'].value_counts().sort_index()\n",
    "print(f\"📊 클래스 분포: {dict(class_counts)}\")\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "total_samples = len(train_df)\n",
    "num_classes = 17\n",
    "class_weights = torch.tensor([\n",
    "    total_samples / (num_classes * class_counts[i]) for i in range(num_classes)\n",
    "], dtype=torch.float32).to(device)\n",
    "\n",
    "# 가중치 정규화\n",
    "class_weights = class_weights / class_weights.mean()\n",
    "print(f\"📊 정규화된 클래스 가중치 범위: {class_weights.min():.3f} ~ {class_weights.max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold 결과 저장용 변수\n",
    "\n",
    "all_fold_results = {model_key: [] for model_key in ACTIVE_MODELS}\n",
    "all_fold_models = {model_key: [] for model_key in ACTIVE_MODELS}\n",
    "\n",
    "# 현재 사용할 이미지 크기들\n",
    "img_sizes = {model_key: MODEL_CONFIGS[model_key]['img_size'] for model_key in ACTIVE_MODELS}\n",
    "print(f\"📊 이미지 크기 설정: {img_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB 메인 실험 시작\n",
    "\n",
    "main_run = wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    entity=ENTITY,\n",
    "    name=f\"{EXPERIMENT_NAME}\",\n",
    "    config=config,\n",
    "    tags=[\"multi-model\", \"swin-convnext\", \"k-fold-cv\", \"ensemble\", \"main-experiment\"],\n",
    "    group=\"multi-model-experiment\",\n",
    "    job_type=\"cross-validation\",\n",
    "    notes=f\"Swin-B + ConvNeXt with {N_FOLDS}-Fold Cross Validation\"\n",
    ")\n",
    "\n",
    "print(f\"🚀 WandB 실험 시작!\")\n",
    "print(f\"📊 대시보드: {main_run.url}\")\n",
    "print(f\"📋 실험명: {main_run.name}\")\n",
    "\n",
    "# 데이터셋 정보 로깅\n",
    "wandb.log({\n",
    "    \"dataset/total_samples\": len(train_df),\n",
    "    \"dataset/num_classes\": 17,\n",
    "    \"dataset/samples_per_fold\": len(train_df) // N_FOLDS,\n",
    "})\n",
    "\n",
    "# 클래스 분포 시각화\n",
    "class_dist_data = [[f\"Class_{i}\", count] for i, count in enumerate(class_counts)]\n",
    "wandb.log({\n",
    "    \"dataset/class_distribution\": wandb.plot.bar(\n",
    "        wandb.Table(data=class_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "        \"Class\", \"Count\", \n",
    "        title=\"Training Data Class Distribution\"\n",
    "    )\n",
    "})\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"🎯 {N_FOLDS}-FOLD MULTI-MODEL CROSS VALIDATION 시작\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation Loop\n",
    "\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"📁 FOLD {fold + 1}/{N_FOLDS} - Multi-Model Training\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 각 fold별 child run 생성\n",
    "    fold_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        entity=ENTITY,\n",
    "        name=f\"fold-{fold+1}-multi-{datetime.now().strftime('%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"fold\", f\"fold-{fold+1}\", \"multi-model\", \"child-run\"],\n",
    "        group=\"multi-model-experiment\",\n",
    "        job_type=f\"fold-{fold+1}\",\n",
    "        reinit=True\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 Fold {fold+1} Dashboard: {fold_run.url}\")\n",
    "    \n",
    "    # 데이터 분할\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # Fold별 클래스 분포 확인\n",
    "    train_class_dist = train_fold_df['target'].value_counts().sort_index()\n",
    "    val_class_dist = val_fold_df['target'].value_counts().sort_index()\n",
    "    \n",
    "    print(f\"📊 Fold {fold+1} 클래스 분포:\")\n",
    "    print(f\"  Train: {len(train_fold_df)}개 샘플\")\n",
    "    print(f\"  Val: {len(val_fold_df)}개 샘플\")\n",
    "    \n",
    "    wandb.log({\n",
    "        \"fold_info/fold_number\": fold + 1,\n",
    "        \"fold_info/train_samples\": len(train_fold_df),\n",
    "        \"fold_info/val_samples\": len(val_fold_df),\n",
    "        \"fold_info/train_ratio\": len(train_fold_df) / len(train_df),\n",
    "        \"fold_info/val_ratio\": len(val_fold_df) / len(train_df),\n",
    "    })\n",
    "    \n",
    "    # 다중 해상도 Dataset 생성\n",
    "    trn_dataset = MultiResImageDataset(\n",
    "        train_fold_df,\n",
    "        \"/root/home/cv_contest/CV_data/train\",\n",
    "        img_sizes,\n",
    "        epoch=0,\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = MultiResImageDataset(\n",
    "        val_fold_df,\n",
    "        \"/root/home/cv_contest/CV_data/train\",\n",
    "        img_sizes,\n",
    "        epoch=0,\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    # 각 모델별 DataLoader 생성\n",
    "    trn_loaders = {}\n",
    "    val_loaders = {}\n",
    "    \n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        batch_size = MODEL_CONFIGS[model_key]['batch_size']\n",
    "        \n",
    "        trn_loaders[model_key] = DataLoader(\n",
    "            trn_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "        \n",
    "        val_loaders[model_key] = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    # 각 모델 생성\n",
    "    models = {}\n",
    "    optimizers = {}\n",
    "    schedulers = {}\n",
    "    loss_fns = {}\n",
    "    best_models = {model_key: None for model_key in ACTIVE_MODELS}\n",
    "    best_f1s = {model_key: 0.0 for model_key in ACTIVE_MODELS}\n",
    "    \n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        config_detail = MODEL_CONFIGS[model_key]\n",
    "        \n",
    "        # 모델 생성\n",
    "        models[model_key] = timm.create_model(\n",
    "            config_detail['model_name'],\n",
    "            pretrained=True,\n",
    "            num_classes=17\n",
    "        ).to(device)\n",
    "        \n",
    "        # 옵티마이저 생성\n",
    "        optimizers[model_key] = AdamW(\n",
    "            models[model_key].parameters(),\n",
    "            lr=config_detail['lr'],\n",
    "            weight_decay=config_detail['weight_decay']\n",
    "        )\n",
    "        \n",
    "        # 스케줄러 생성\n",
    "        schedulers[model_key] = CosineAnnealingLR(optimizers[model_key], T_max=EPOCHS)\n",
    "        \n",
    "        # 손실 함수 생성 (클래스 가중치 적용)\n",
    "        loss_fns[model_key] = nn.CrossEntropyLoss(\n",
    "            weight=class_weights,\n",
    "            label_smoothing=0.1\n",
    "        )\n",
    "        \n",
    "        model_params = sum(p.numel() for p in models[model_key].parameters())\n",
    "        print(f\"🤖 {model_key} 모델 생성: {config_detail['model_name']} ({model_params:,} parameters)\")\n",
    "    \n",
    "    # Training Loop for Current Fold\n",
    "    #patience = {model_key: 0 for model_key in ACTIVE_MODELS}\n",
    "    #max_patience = 3\n",
    "    \n",
    "    print(f\"🎯 Fold {fold+1} 다중 모델 학습 시작\")\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n📈 Epoch {epoch+1}/{EPOCHS}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # 에폭별 Dataset 업데이트 (점진적 증강)\n",
    "        trn_dataset.epoch = epoch\n",
    "        val_dataset.epoch = epoch\n",
    "        \n",
    "        # 모든 모델 동시 학습\n",
    "        train_results = train_multi_models_epoch(\n",
    "            trn_loaders, models, optimizers, loss_fns, device,\n",
    "            epoch=epoch, fold=fold+1\n",
    "        )\n",
    "        \n",
    "        # 모든 모델 동시 검증\n",
    "        val_results = validate_multi_models_epoch(\n",
    "            val_loaders, models, loss_fns, device,\n",
    "            epoch=epoch, fold=fold+1,\n",
    "            log_confusion=(epoch == EPOCHS-1)\n",
    "        )\n",
    "        \n",
    "        # 각 모델별 스케줄러 업데이트\n",
    "        for scheduler in schedulers.values():\n",
    "            scheduler.step()\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        # WandB 로깅 및 최고 모델 저장\n",
    "        log_data = {\"epoch\": epoch + 1, \"fold\": fold + 1, \"epoch_time\": epoch_time}\n",
    "        \n",
    "        print(f\"📊 Epoch {epoch+1:2d} 결과:\")\n",
    "        for model_key in ACTIVE_MODELS:\n",
    "            train_res = train_results[model_key]\n",
    "            val_res = val_results[model_key]\n",
    "            current_lr = optimizers[model_key].param_groups[0]['lr']\n",
    "            \n",
    "            log_data.update({\n",
    "                f\"{model_key}/train_loss\": train_res['train_loss'],\n",
    "                f\"{model_key}/train_acc\": train_res['train_acc'],\n",
    "                f\"{model_key}/train_f1\": train_res['train_f1'],\n",
    "                f\"{model_key}/val_loss\": val_res['val_loss'],\n",
    "                f\"{model_key}/val_acc\": val_res['val_acc'],\n",
    "                f\"{model_key}/val_f1\": val_res['val_f1'],\n",
    "                f\"{model_key}/lr\": current_lr,\n",
    "            })\n",
    "            \n",
    "            print(f\"  {model_key:10s}: Train F1={train_res['train_f1']:.4f}, Val F1={val_res['val_f1']:.4f}, LR={current_lr:.2e}\")\n",
    "            \n",
    "            # 최고 성능 모델 저장\n",
    "            if val_res['val_f1'] > best_f1s[model_key]:\n",
    "                best_f1s[model_key] = val_res['val_f1']\n",
    "                best_models[model_key] = copy.deepcopy(models[model_key].state_dict())\n",
    "                #patience[model_key] = 0\n",
    "                \n",
    "                # 모델 저장\n",
    "                model_path = f'best_{model_key}_fold_{fold+1}.pth'\n",
    "                torch.save(best_models[model_key], model_path)\n",
    "                wandb.save(model_path, policy=\"now\")\n",
    "                \n",
    "                # 새로운 최고 성능 로깅\n",
    "                wandb.log({\n",
    "                    f\"best_performance/{model_key}_epoch\": epoch + 1,\n",
    "                    f\"best_performance/{model_key}_val_f1\": best_f1s[model_key],\n",
    "                    f\"best_performance/{model_key}_val_acc\": val_res['val_acc'],\n",
    "                })\n",
    "                \n",
    "                print(f\"    🎉 {model_key} 새로운 최고 성능! F1: {best_f1s[model_key]:.4f}\")\n",
    "            #else:\n",
    "                #patience[model_key] += 1\n",
    "        \n",
    "        # GPU 메모리 사용량 로깅\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory_used = torch.cuda.memory_allocated(0) / 1e9\n",
    "            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            log_data.update({\n",
    "                \"system/gpu_memory_used_gb\": gpu_memory_used,\n",
    "                \"system/gpu_memory_total_gb\": gpu_memory_total,\n",
    "                \"system/gpu_utilization_pct\": (gpu_memory_used / gpu_memory_total) * 100\n",
    "            })\n",
    "        \n",
    "        wandb.log(log_data)\n",
    "        \n",
    "        # Early stopping 체크 (모든 모델이 patience 초과 시)\n",
    "        # if all(p >= max_patience for p in patience.values()) and epoch > EPOCHS // 2:\n",
    "        #     print(f\"⏸️ Early stopping at epoch {epoch+1} (모든 모델 patience 초과)\")\n",
    "        #     wandb.log({\"early_stopping/epoch\": epoch + 1})\n",
    "        #     break\n",
    "    \n",
    "    # Fold 결과 저장\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        fold_result = {\n",
    "            'fold': fold + 1,\n",
    "            'best_val_f1': best_f1s[model_key],\n",
    "            'model_name': MODEL_CONFIGS[model_key]['model_name'],\n",
    "            'epochs_trained': epoch + 1,\n",
    "        }\n",
    "        all_fold_results[model_key].append(fold_result)\n",
    "        all_fold_models[model_key].append(best_models[model_key])\n",
    "    \n",
    "    print(f\"\\n✅ Fold {fold + 1} 완료!\")\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        print(f\"  {model_key:10s}: 최고 F1 = {best_f1s[model_key]:.4f}\")\n",
    "    \n",
    "    # Fold별 요약 로깅\n",
    "    wandb.log({\n",
    "        \"fold_summary/completed\": True,\n",
    "        \"fold_summary/epochs_trained\": epoch + 1,\n",
    "        **{f\"fold_summary/{model_key}_best_f1\": best_f1s[model_key] for model_key in ACTIVE_MODELS}\n",
    "    })\n",
    "    \n",
    "    fold_run.finish()\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del models, optimizers, schedulers, trn_loaders, val_loaders\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold 결과 분석\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🏁 K-FOLD 다중 모델 결과\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    val_f1_scores = [result['best_val_f1'] for result in all_fold_results[model_key]]\n",
    "    mean_f1 = np.mean(val_f1_scores)\n",
    "    std_f1 = np.std(val_f1_scores)\n",
    "    \n",
    "    print(f\"\\n🤖 {model_key.upper()} ({MODEL_CONFIGS[model_key]['model_name']}):\")\n",
    "    print(f\"  📊 평균 CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "    print(f\"  🏆 최고 Fold: {max(val_f1_scores):.4f}\")\n",
    "    print(f\"  📉 최악 Fold: {min(val_f1_scores):.4f}\")\n",
    "    print(f\"  📏 성능 범위: {max(val_f1_scores) - min(val_f1_scores):.4f}\")\n",
    "    \n",
    "    # 메인 run에 모델별 CV 결과 로깅\n",
    "    try:\n",
    "        main_run.log({\n",
    "            f\"cv_results/{model_key}_mean_f1\": mean_f1,\n",
    "            f\"cv_results/{model_key}_std_f1\": std_f1,\n",
    "            f\"cv_results/{model_key}_best_fold_f1\": max(val_f1_scores),\n",
    "            f\"cv_results/{model_key}_worst_fold_f1\": min(val_f1_scores),\n",
    "            f\"cv_results/{model_key}_f1_range\": max(val_f1_scores) - min(val_f1_scores),\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"\\n📊 모델별 성능 비교:\")\n",
    "for fold in range(N_FOLDS):\n",
    "    print(f\"  Fold {fold+1}:\", end=\"\")\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        f1_score = all_fold_results[model_key][fold]['best_val_f1']\n",
    "        print(f\" {model_key}={f1_score:.4f}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앙상블 모델 준비\n",
    "\n",
    "ensemble_models = {model_key: [] for model_key in ACTIVE_MODELS}\n",
    "print(f\"\\n🔧 앙상블 모델 준비 중...\")\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    for i, state_dict in enumerate(all_fold_models[model_key]):\n",
    "        config_detail = MODEL_CONFIGS[model_key]\n",
    "        fold_model = timm.create_model(config_detail['model_name'], pretrained=True, num_classes=17).to(device)\n",
    "        fold_model.load_state_dict(state_dict)\n",
    "        fold_model.eval()\n",
    "        ensemble_models[model_key].append(fold_model)\n",
    "        print(f\"📁 {model_key} Fold {i+1} 모델 로드 완료\")\n",
    "\n",
    "print(f\"\\n🎯 앙상블 구성:\")\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    print(f\"  {model_key}: {len(ensemble_models[model_key])}개 모델\")\n",
    "\n",
    "try:\n",
    "    main_run.log({\n",
    "        \"ensemble/num_model_types\": len(ACTIVE_MODELS),\n",
    "        \"ensemble/models_per_type\": N_FOLDS,\n",
    "        \"ensemble/total_models\": len(ACTIVE_MODELS) * N_FOLDS,\n",
    "        \"ensemble/architectures\": [MODEL_CONFIGS[key]['architecture'] for key in ACTIVE_MODELS]\n",
    "    })\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling 클래스\n",
    "\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self, temperature=1.5):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * temperature)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTA : Multi-Resoulition TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Resolution TTA Setup\n",
    "\n",
    "print(f\"\\n🔄 다중 해상도 TTA (Test Time Augmentation) 설정...\")\n",
    "\n",
    "# 각 모델별 최적화된 TTA 변환 생성\n",
    "multi_res_tta_transforms = {}\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    img_size = MODEL_CONFIGS[model_key]['img_size']\n",
    "    \n",
    "    # 각 모델에 최적화된 TTA 변환들\n",
    "    tta_transforms = [\n",
    "        # 원본\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "        # 90도 회전들\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.Rotate(limit=[90, 90], p=1.0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.Rotate(limit=[180, 180], p=1.0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.Rotate(limit=[-90, -90], p=1.0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "        # 밝기 조정\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "    ]\n",
    "    \n",
    "    multi_res_tta_transforms[model_key] = tta_transforms\n",
    "    print(f\"✅ {model_key} ({img_size}x{img_size}) TTA 변환 {len(tta_transforms)}개 준비 완료\")\n",
    "\n",
    "try:\n",
    "    main_run.log({\n",
    "        \"tta/multi_resolution\": True,\n",
    "        \"tta/transforms_per_model\": {\n",
    "            model_key: len(transforms) for model_key, transforms in multi_res_tta_transforms.items()\n",
    "        },\n",
    "        \"tta/image_sizes\": {\n",
    "            model_key: MODEL_CONFIGS[model_key]['img_size'] for model_key in ACTIVE_MODELS\n",
    "        }\n",
    "    })\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Resolution TTA Dataset 클래스\n",
    "\n",
    "class MultiResTTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, multi_transforms):\n",
    "        \"\"\"\n",
    "        다중 해상도 TTA를 위한 Dataset\n",
    "        multi_transforms: {model_key: [transform1, transform2, ...]} 형태\n",
    "        \"\"\"\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.multi_transforms = multi_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # 모델별, TTA 변형별로 이미지 생성\n",
    "        augmented_images = {}\n",
    "        for model_key, transforms in self.multi_transforms.items():\n",
    "            model_images = []\n",
    "            for transform in transforms:\n",
    "                aug_img = transform(image=img)['image']\n",
    "                model_images.append(aug_img)\n",
    "            augmented_images[model_key] = model_images\n",
    "        \n",
    "        return augmented_images, target\n",
    "\n",
    "# Multi-Resolution TTA Dataset 생성\n",
    "multi_tta_dataset = MultiResTTAImageDataset(\n",
    "    \"/root/home/cv_contest/CV_data/sample_submission.csv\",\n",
    "    \"/root/home/cv_contest/CV_data/test\",\n",
    "    multi_res_tta_transforms\n",
    ")\n",
    "\n",
    "# 각 모델별 최적 배치 크기로 DataLoader 생성\n",
    "multi_tta_loaders = {}\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    batch_size = min(MODEL_CONFIGS[model_key]['batch_size'], 16)  # TTA용으로 배치 크기 조정\n",
    "    \n",
    "    multi_tta_loaders[model_key] = DataLoader(\n",
    "        multi_tta_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 {model_key} TTA DataLoader: 배치 크기 {batch_size}\")\n",
    "\n",
    "print(f\"📊 Multi-Resolution TTA Dataset: {len(multi_tta_dataset)}개 테스트 샘플\")\n",
    "\n",
    "# =============================================================================\n",
    "# 17. Multi-Resolution Ensemble + TTA Inference Function\n",
    "# =============================================================================\n",
    "\n",
    "def multi_resolution_ensemble_tta_inference(ensemble_models, loaders, multi_transforms, confidence_threshold=0.9):\n",
    "    \"\"\"\n",
    "    다중 해상도 앙상블 + TTA 추론 with 상세 WandB 로깅\n",
    "    \"\"\"\n",
    "    # Temperature scaling 초기화\n",
    "    temp_scalings = {model_key: TemperatureScaling().to(device) for model_key in ACTIVE_MODELS}\n",
    "    \n",
    "    # 결과 저장용\n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    model_predictions = {model_key: [] for model_key in ACTIVE_MODELS}\n",
    "    model_confidences = {model_key: [] for model_key in ACTIVE_MODELS}\n",
    "    \n",
    "    print(f\"🚀 다중 해상도 앙상블 TTA 추론 시작...\")\n",
    "    print(f\"📊 모델별 설정:\")\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        config_detail = MODEL_CONFIGS[model_key]\n",
    "        num_folds = len(ensemble_models[model_key])\n",
    "        num_tta = len(multi_transforms[model_key])\n",
    "        total_preds = num_folds * num_tta\n",
    "        print(f\"  🤖 {model_key}: {num_folds}개 모델 × {num_tta}개 TTA = {total_preds}개 예측\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # 모델별 개별 추론 (메모리 효율성을 위해)\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        print(f\"\\n🔍 {model_key.upper()} 모델 추론 중...\")\n",
    "        \n",
    "        config_detail = MODEL_CONFIGS[model_key]\n",
    "        models = ensemble_models[model_key]\n",
    "        loader = multi_tta_loaders[model_key]\n",
    "        temp_scaling = temp_scalings[model_key]\n",
    "        \n",
    "        model_start_time = time.time()\n",
    "        \n",
    "        # 진행상황 로깅을 위한 테이블\n",
    "        progress_table = wandb.Table(columns=[\"Batch\", \"Avg_Confidence\", \"Low_Conf_Count\", \"High_Conf_Count\"])\n",
    "        \n",
    "        for batch_idx, batch_data in enumerate(tqdm(loader, desc=f\"{model_key} TTA\")):\n",
    "            images_dict, _ = batch_data\n",
    "            images_list = images_dict[model_key]  # 현재 모델의 TTA 이미지들\n",
    "            batch_size = images_list[0].size(0)\n",
    "            \n",
    "            # 현재 모델의 앙상블 확률 초기화\n",
    "            model_ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "            \n",
    "            # 각 fold 모델별 예측\n",
    "            for fold_model in models:\n",
    "                fold_model.eval()\n",
    "                with torch.no_grad():\n",
    "                    # 각 TTA 변형별 예측\n",
    "                    for tta_images in images_list:\n",
    "                        tta_images = tta_images.to(device)\n",
    "                        preds = fold_model(tta_images)\n",
    "                        \n",
    "                        # Temperature scaling 적용\n",
    "                        preds = temp_scaling(preds)\n",
    "                        probs = torch.softmax(preds, dim=1)\n",
    "                        \n",
    "                        # 앙상블 확률에 누적\n",
    "                        model_ensemble_probs += probs / (len(models) * len(images_list))\n",
    "            \n",
    "            # 현재 모델의 신뢰도 계산\n",
    "            max_probs = torch.max(model_ensemble_probs, dim=1)[0]\n",
    "            batch_confidences = max_probs.cpu().numpy()\n",
    "            \n",
    "            final_preds = torch.argmax(model_ensemble_probs, dim=1)\n",
    "            \n",
    "            # 모델별 결과 저장\n",
    "            model_predictions[model_key].extend(final_preds.cpu().numpy())\n",
    "            model_confidences[model_key].extend(batch_confidences)\n",
    "            \n",
    "            # 배치별 신뢰도 분석\n",
    "            high_conf_count = np.sum(batch_confidences >= confidence_threshold)\n",
    "            low_conf_count = batch_size - high_conf_count\n",
    "            avg_confidence = np.mean(batch_confidences)\n",
    "            \n",
    "            progress_table.add_data(batch_idx, avg_confidence, low_conf_count, high_conf_count)\n",
    "            \n",
    "            # 배치별 상세 로깅 (20배치마다)\n",
    "            if batch_idx % 20 == 0:\n",
    "                elapsed_time = time.time() - model_start_time\n",
    "                try:\n",
    "                    main_run.log({\n",
    "                        f\"tta_progress/{model_key}_batch\": batch_idx,\n",
    "                        f\"tta_progress/{model_key}_avg_confidence\": avg_confidence,\n",
    "                        f\"tta_progress/{model_key}_high_confidence_ratio\": high_conf_count / batch_size,\n",
    "                        f\"tta_progress/{model_key}_elapsed_time_min\": elapsed_time / 60,\n",
    "                    })\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        model_time = time.time() - model_start_time\n",
    "        model_avg_confidence = np.mean(model_confidences[model_key])\n",
    "        \n",
    "        # 모델별 최종 결과 로깅\n",
    "        try:\n",
    "            main_run.log({\n",
    "                f\"tta_results/{model_key}_time_min\": model_time / 60,\n",
    "                f\"tta_results/{model_key}_avg_confidence\": model_avg_confidence,\n",
    "                f\"tta_results/{model_key}_confidence_std\": np.std(model_confidences[model_key]),\n",
    "                f\"tta_results/{model_key}_high_conf_samples\": np.sum(np.array(model_confidences[model_key]) >= confidence_threshold),\n",
    "                f\"tta_results/{model_key}_progress_table\": progress_table\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print(f\"✅ {model_key} 완료! 소요시간: {model_time/60:.1f}분, 평균 신뢰도: {model_avg_confidence:.4f}\")\n",
    "        \n",
    "        # 메모리 정리\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # =============================================================================\n",
    "    # 모델 간 앙상블 (단순 평균으로 시작)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\n🔗 모델 간 앙상블 수행 중...\")\n",
    "    \n",
    "    for i in range(len(multi_tta_dataset)):\n",
    "        # 각 모델의 예측을 단순 평균\n",
    "        ensemble_pred_probs = []\n",
    "        for model_key in ACTIVE_MODELS:\n",
    "            # 예측을 one-hot으로 변환 후 평균\n",
    "            pred = model_predictions[model_key][i]\n",
    "            confidence = model_confidences[model_key][i]\n",
    "            \n",
    "            # 신뢰도를 고려한 soft voting\n",
    "            prob_vector = np.zeros(17)\n",
    "            prob_vector[pred] = confidence\n",
    "            ensemble_pred_probs.append(prob_vector)\n",
    "        \n",
    "        # 단순 평균\n",
    "        final_prob = np.mean(ensemble_pred_probs, axis=0)\n",
    "        final_pred = np.argmax(final_prob)\n",
    "        final_confidence = np.max(final_prob)\n",
    "        \n",
    "        all_predictions.append(final_pred)\n",
    "        all_confidences.append(final_confidence)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 최종 앙상블 결과 분석 및 로깅\n",
    "    # =============================================================================\n",
    "    \n",
    "    final_avg_confidence = np.mean(all_confidences)\n",
    "    confidence_std = np.std(all_confidences)\n",
    "    high_conf_samples = np.sum(np.array(all_confidences) >= confidence_threshold)\n",
    "    \n",
    "    print(f\"\\n✅ 다중 해상도 앙상블 TTA 완료!\")\n",
    "    print(f\"⏰ 총 소요시간: {total_time/60:.1f}분\")\n",
    "    print(f\"🎯 최종 평균 신뢰도: {final_avg_confidence:.4f} ± {confidence_std:.4f}\")\n",
    "    print(f\"🏆 고신뢰도 샘플: {high_conf_samples}/{len(all_predictions)} ({high_conf_samples/len(all_predictions)*100:.1f}%)\")\n",
    "    \n",
    "    # 모델별 성능 분석\n",
    "    print(f\"\\n📊 모델별 신뢰도 분석:\")\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        model_avg_conf = np.mean(model_confidences[model_key])\n",
    "        model_high_conf = np.sum(np.array(model_confidences[model_key]) >= confidence_threshold)\n",
    "        print(f\"  {model_key:12s}: 평균 {model_avg_conf:.4f}, 고신뢰도 {model_high_conf}/{len(model_confidences[model_key])} ({model_high_conf/len(model_confidences[model_key])*100:.1f}%)\")\n",
    "    \n",
    "    # 최종 결과 로깅\n",
    "    try:\n",
    "        main_run.log({\n",
    "            \"final_ensemble/total_time_min\": total_time / 60,\n",
    "            \"final_ensemble/samples_per_second\": len(all_predictions) / total_time,\n",
    "            \"final_ensemble/final_avg_confidence\": final_avg_confidence,\n",
    "            \"final_ensemble/confidence_std\": confidence_std,\n",
    "            \"final_ensemble/high_confidence_samples\": high_conf_samples,\n",
    "            \"final_ensemble/high_confidence_ratio\": high_conf_samples / len(all_predictions),\n",
    "            \"final_ensemble/total_predictions\": len(all_predictions),\n",
    "            \"final_ensemble/confidence_histogram\": wandb.Histogram(all_confidences),\n",
    "            \"final_ensemble/ensemble_method\": \"simple_average\",\n",
    "            \"final_ensemble/num_model_types\": len(ACTIVE_MODELS),\n",
    "        })\n",
    "        \n",
    "        # 모델별 개별 성능도 로깅\n",
    "        for model_key in ACTIVE_MODELS:\n",
    "            main_run.log({\n",
    "                f\"model_performance/{model_key}_avg_confidence\": np.mean(model_confidences[model_key]),\n",
    "                f\"model_performance/{model_key}_confidence_std\": np.std(model_confidences[model_key]),\n",
    "                f\"model_performance/{model_key}_high_conf_ratio\": np.sum(np.array(model_confidences[model_key]) >= confidence_threshold) / len(model_confidences[model_key])\n",
    "            })\n",
    "        \n",
    "        print(\"📊 최종 앙상블 결과 WandB 로깅 완료!\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ WandB 로깅 중 에러: {e}\")\n",
    "    \n",
    "    return all_predictions, all_confidences, model_predictions, model_confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Resolution Ensemble TTA 실행\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🎯 최종 추론 - 다중 해상도 앙상블 + TTA\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "multi_tta_predictions, multi_confidences, individual_model_preds, individual_model_confs = multi_resolution_ensemble_tta_inference(\n",
    "    ensemble_models=ensemble_models,\n",
    "    loaders=multi_tta_loaders,\n",
    "    multi_transforms=multi_res_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Resolution Results and Submission\n",
    "\n",
    "print(f\"\\n📊 다중 해상도 앙상블 결과 정리 중...\")\n",
    "\n",
    "# 최종 submission 파일 생성\n",
    "multi_pred_df = pd.DataFrame(multi_tta_dataset.df, columns=['ID', 'target'])\n",
    "multi_pred_df['target'] = multi_tta_predictions\n",
    "\n",
    "# ID 순서 확인\n",
    "sample_submission_df = pd.read_csv(\"/root/home/cv_contest/CV_data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == multi_pred_df['ID']).all(), \"❌ ID 순서 불일치!\"\n",
    "\n",
    "# 예측 분포 분석\n",
    "pred_distribution = multi_pred_df['target'].value_counts().sort_index()\n",
    "pred_table = wandb.Table(columns=[\"Class\", \"Count\", \"Percentage\", \"Swin_B_Count\", \"ConvNeXt_Count\"])\n",
    "\n",
    "print(f\"\\n📊 최종 예측 결과 분포 (다중 해상도 앙상블):\")\n",
    "for class_id in range(17):\n",
    "    final_count = pred_distribution.get(class_id, 0)\n",
    "    final_percentage = final_count / len(multi_pred_df) * 100\n",
    "    \n",
    "    # 각 모델별 예측 분포도 확인\n",
    "    swin_count = np.sum(np.array(individual_model_preds['swin_b']) == class_id) if 'swin_b' in individual_model_preds else 0\n",
    "    convnext_count = np.sum(np.array(individual_model_preds['convnext']) == class_id) if 'convnext' in individual_model_preds else 0\n",
    "    \n",
    "    pred_table.add_data(class_id, final_count, final_percentage, swin_count, convnext_count)\n",
    "    print(f\"Class {class_id:2d}: {final_count:4d} ({final_percentage:5.1f}%) [Swin-B: {swin_count}, ConvNeXt: {convnext_count}]\")\n",
    "\n",
    "# 신뢰도 상세 분석\n",
    "confidence_analysis = {}\n",
    "confidence_bins = [0.5, 0.7, 0.8, 0.9, 0.95, 1.0]\n",
    "for i, threshold in enumerate(confidence_bins):\n",
    "    if i == 0:\n",
    "        count = np.sum(np.array(multi_confidences) >= threshold)\n",
    "    else:\n",
    "        prev_threshold = confidence_bins[i-1]\n",
    "        count = np.sum((np.array(multi_confidences) >= prev_threshold) & (np.array(multi_confidences) < threshold))\n",
    "    confidence_analysis[f\"conf_{threshold}\"] = count\n",
    "\n",
    "# 최종 결과 로깅\n",
    "try:\n",
    "    main_run.log({\n",
    "        \"final_results/multi_resolution\": True,\n",
    "        \"final_results/total_predictions\": len(multi_tta_predictions),\n",
    "        \"final_results/unique_classes_predicted\": len(np.unique(multi_tta_predictions)),\n",
    "        \"final_results/prediction_distribution_table\": pred_table,\n",
    "        \"final_results/avg_confidence\": np.mean(multi_confidences),\n",
    "        \"final_results/median_confidence\": np.median(multi_confidences),\n",
    "        \"final_results/min_confidence\": np.min(multi_confidences),\n",
    "        \"final_results/max_confidence\": np.max(multi_confidences),\n",
    "        \"final_results/confidence_distribution\": wandb.Histogram(multi_confidences),\n",
    "        \"final_results/ensemble_type\": \"multi_resolution_simple_average\",\n",
    "        **confidence_analysis\n",
    "    })\n",
    "    \n",
    "    # 예측 분포 바차트\n",
    "    pred_dist_data = [[f\"Class_{i}\", pred_distribution.get(i, 0)] for i in range(17)]\n",
    "    main_run.log({\n",
    "        \"final_results/prediction_distribution_chart\": wandb.plot.bar(\n",
    "            wandb.Table(data=pred_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "            \"Class\", \"Count\", \n",
    "            title=\"Multi-Resolution Ensemble Prediction Distribution\"\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(\"📊 다중 해상도 앙상블 결과 로깅 완료!\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ WandB 로깅 중 에러: {e}\")\n",
    "\n",
    "# 결과 저장\n",
    "output_path = f\"/root/home/cv_contest/results/multiRes_ensemble_{datetime.now().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "multi_pred_df.to_csv(output_path, index=False)\n",
    "\n",
    "# 결과 파일을 WandB 아티팩트로 저장\n",
    "try:\n",
    "    artifact = wandb.Artifact(\n",
    "        name=\"multi_resolution_ensemble_predictions\",\n",
    "        type=\"predictions\",\n",
    "        description=f\"Multi-Resolution Ensemble (Swin-B + ConvNeXt) predictions with {N_FOLDS}-fold CV + TTA\"\n",
    "    )\n",
    "    artifact.add_file(output_path)\n",
    "    main_run.log_artifact(artifact)\n",
    "    print(\"📦 다중 해상도 앙상블 아티팩트 저장 완료!\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 아티팩트 저장 중 에러: {e}\")\n",
    "\n",
    "print(f\"\\n✅ 다중 해상도 앙상블 결과 저장 완료!\")\n",
    "print(f\"📁 파일 위치: {output_path}\")\n",
    "print(f\"📈 총 예측 수: {len(multi_tta_predictions)}\")\n",
    "print(f\"🤖 사용된 모델: {', '.join(ACTIVE_MODELS)}\")\n",
    "print(f\"🔥 사용된 해상도: {', '.join([f'{k}={v}px' for k, v in img_sizes.items()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델별 개별 결과 파일도 저장\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    individual_pred_df = pd.DataFrame(multi_tta_dataset.df, columns=['ID', 'target'])\n",
    "    individual_pred_df['target'] = individual_model_preds[model_key]\n",
    "    \n",
    "    individual_output_path = f\"/root/home/cv_contest/results/{model_key}_individual_{datetime.now().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "    individual_pred_df.to_csv(individual_output_path, index=False)\n",
    "    \n",
    "    # 개별 모델 결과 요약\n",
    "    individual_dist = individual_pred_df['target'].value_counts().sort_index()\n",
    "    individual_avg_conf = np.mean(individual_model_confs[model_key])\n",
    "    \n",
    "    print(f\"📁 {model_key} 개별 결과: {individual_output_path}\")\n",
    "    print(f\"   평균 신뢰도: {individual_avg_conf:.4f}\")\n",
    "    \n",
    "    # WandB에 개별 모델 아티팩트 저장\n",
    "    try:\n",
    "        individual_artifact = wandb.Artifact(\n",
    "            name=f\"{model_key}_individual_predictions\",\n",
    "            type=\"individual_predictions\",\n",
    "            description=f\"{model_key} individual predictions with {N_FOLDS}-fold CV + TTA\"\n",
    "        )\n",
    "        individual_artifact.add_file(individual_output_path)\n",
    "        main_run.log_artifact(individual_artifact)\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ {model_key} 개별 아티팩트 저장 중 에러: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 실험 요약 및 정리\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🏁 다중 해상도 앙상블 실험 완료!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# 전체 실험 요약\n",
    "total_models_trained = len(ACTIVE_MODELS) * N_FOLDS\n",
    "total_tta_transforms = sum(len(transforms) for transforms in multi_res_tta_transforms.values())\n",
    "total_predictions_per_sample = total_models_trained * (total_tta_transforms // len(ACTIVE_MODELS))\n",
    "\n",
    "print(f\"📊 실험 요약:\")\n",
    "print(f\"   🤖 사용된 아키텍처: {len(ACTIVE_MODELS)}개 ({', '.join(ACTIVE_MODELS)})\")\n",
    "print(f\"   📁 총 학습된 모델: {total_models_trained}개 ({N_FOLDS}-Fold CV)\")\n",
    "print(f\"   🔄 TTA 변형: 모델당 평균 {total_tta_transforms // len(ACTIVE_MODELS)}개\")\n",
    "print(f\"   🎯 샘플당 예측 수: {total_predictions_per_sample}개\")\n",
    "print(f\"   📈 테스트 샘플: {len(multi_tta_predictions)}개\")\n",
    "\n",
    "# CV 결과 요약\n",
    "print(f\"\\n📊 Cross-Validation 결과:\")\n",
    "cv_summary_table = wandb.Table(columns=[\"Model\", \"Mean_F1\", \"Std_F1\", \"Best_Fold\", \"Worst_Fold\", \"Architecture\"])\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    val_f1_scores = [result['best_val_f1'] for result in all_fold_results[model_key]]\n",
    "    mean_f1 = np.mean(val_f1_scores)\n",
    "    std_f1 = np.std(val_f1_scores)\n",
    "    best_f1 = max(val_f1_scores)\n",
    "    worst_f1 = min(val_f1_scores)\n",
    "    architecture = MODEL_CONFIGS[model_key]['architecture']\n",
    "    \n",
    "    cv_summary_table.add_data(model_key, mean_f1, std_f1, best_f1, worst_f1, architecture)\n",
    "    print(f\"   {model_key:12s}: {mean_f1:.4f} ± {std_f1:.4f} (범위: {worst_f1:.4f} ~ {best_f1:.4f})\")\n",
    "\n",
    "# 최종 성능 지표\n",
    "final_metrics = {\n",
    "    \"experiment_type\": \"multi_resolution_ensemble\",\n",
    "    \"total_experiment_time_hours\": (time.time() - start_time) / 3600,\n",
    "    \"models_trained\": total_models_trained,\n",
    "    \"cv_folds\": N_FOLDS,\n",
    "    \"tta_transforms_total\": total_tta_transforms,\n",
    "    \"test_samples\": len(multi_tta_predictions),\n",
    "    \"unique_classes_in_prediction\": len(np.unique(multi_tta_predictions)),\n",
    "    \"final_ensemble_confidence\": np.mean(multi_confidences),\n",
    "    \"high_confidence_predictions_ratio\": np.sum(np.array(multi_confidences) >= 0.9) / len(multi_confidences),\n",
    "    \"cv_summary_table\": cv_summary_table\n",
    "}\n",
    "\n",
    "# 최종 WandB 로깅\n",
    "try:\n",
    "    main_run.log(final_metrics)\n",
    "    \n",
    "    # 실험 요약 텍스트\n",
    "    experiment_summary = f\"\"\"\n",
    "# Multi-Resolution Ensemble Experiment Summary\n",
    "\n",
    "## Models Used\n",
    "- **Swin Transformer Base**: {MODEL_CONFIGS['swin_b']['img_size']}px resolution\n",
    "- **ConvNeXt Base**: {MODEL_CONFIGS['convnext']['img_size']}px resolution\n",
    "\n",
    "## Training Strategy\n",
    "- **Cross-Validation**: {N_FOLDS}-Fold Stratified\n",
    "- **Total Models Trained**: {total_models_trained}\n",
    "- **Test Time Augmentation**: {total_tta_transforms // len(ACTIVE_MODELS)} transforms per model\n",
    "\n",
    "## Performance\n",
    "- **Final Ensemble Confidence**: {np.mean(multi_confidences):.4f}\n",
    "- **High Confidence Predictions**: {np.sum(np.array(multi_confidences) >= 0.9)}/{len(multi_confidences)} ({np.sum(np.array(multi_confidences) >= 0.9)/len(multi_confidences)*100:.1f}%)\n",
    "\n",
    "## CV Results\n",
    "{chr(10).join([f\"- **{model_key}**: {np.mean([r['best_val_f1'] for r in all_fold_results[model_key]]):.4f} ± {np.std([r['best_val_f1'] for r in all_fold_results[model_key]]):.4f}\" for model_key in ACTIVE_MODELS])}\n",
    "    \"\"\"\n",
    "    \n",
    "    main_run.summary.update({\n",
    "        \"experiment_summary\": experiment_summary,\n",
    "        \"best_cv_f1\": max([np.mean([r['best_val_f1'] for r in all_fold_results[model_key]]) for model_key in ACTIVE_MODELS]),\n",
    "        \"total_runtime_hours\": (time.time() - start_time) / 3600,\n",
    "        \"final_prediction_file\": output_path,\n",
    "        \"ensemble_method\": \"multi_resolution_average\"\n",
    "    })\n",
    "    \n",
    "    print(\"📊 최종 실험 요약 WandB 로깅 완료!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 최종 로깅 중 에러: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 정리 및 실험 종료\n",
    "\n",
    "# GPU 메모리 정리\n",
    "if torch.cuda.is_available():\n",
    "    for model_key in ensemble_models:\n",
    "        for model in ensemble_models[model_key]:\n",
    "            del model\n",
    "    del ensemble_models\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"🧹 GPU 메모리 정리 완료\")\n",
    "\n",
    "# WandB 실험 종료\n",
    "main_run.finish()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🎉 다중 해상도 앙상블 실험 완료!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"📁 최종 결과 파일: {output_path}\")\n",
    "print(f\"📊 WandB 프로젝트: {PROJECT_NAME}\")\n",
    "print(f\"⏰ 총 실행 시간: {(time.time() - start_time) / 3600:.1f}시간\")\n",
    "print(f\"🏆 최종 앙상블 평균 신뢰도: {np.mean(multi_confidences):.4f}\")\n",
    "print(f\"🎯 고신뢰도 예측 비율: {np.sum(np.array(multi_confidences) >= 0.9)/len(multi_confidences)*100:.1f}%\")\n",
    "\n",
    "# 최종 성공 메시지\n",
    "print(f\"\\n✨ 실험이 성공적으로 완료되었습니다!\")\n",
    "print(f\"📈 결과를 WandB 대시보드에서 확인하세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
