{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* ë°ì´í„° ë¡œë“œë¥¼ ìœ„í•œ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤.\n",
    "* í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# # í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.\n",
    "* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ì†¡ì›í˜¸)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam, AdamW  # AdamW ì¶”ê°€\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, OneCycleLR  # OneCycleLR ì¶”ê°€\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precisionìš©\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "\n",
    "# WandB ê´€ë ¨ import ì¶”ê°€\n",
    "import wandb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1-1. WandB Login and Configuration\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "ğŸš€ íŒ€ì› ì‚¬ìš© ê°€ì´ë“œ:\n",
    "\n",
    "1. WandB ê³„ì • ìƒì„±: https://wandb.ai/signup\n",
    "2. ì´ ì…€ ì‹¤í–‰ ì‹œ ë¡œê·¸ì¸ í”„ë¡¬í”„íŠ¸ê°€ ë‚˜íƒ€ë‚˜ë©´ ê°œì¸ API í‚¤ ì…ë ¥\n",
    "3. EXPERIMENT_NAMEì„ ë‹¤ìŒê³¼ ê°™ì´ ë³€ê²½:\n",
    "   - \"member1-baseline\"\n",
    "   - \"member2-augmentation-test\"  \n",
    "   - \"member3-hyperparameter-tuning\"\n",
    "   ë“±ë“± ê°ì ë‹¤ë¥¸ ì´ë¦„ ì‚¬ìš©\n",
    "\n",
    "4. íŒ€ ëŒ€ì‹œë³´ë“œ URL: [ì—¬ê¸°ì— ë‹¹ì‹ ì˜ í”„ë¡œì íŠ¸ URL ì¶”ê°€]\n",
    "\n",
    "âš ï¸ ì£¼ì˜ì‚¬í•­:\n",
    "- ì ˆëŒ€ API í‚¤ë¥¼ ì½”ë“œì— í•˜ë“œì½”ë”©í•˜ì§€ ë§ˆì„¸ìš”\n",
    "- EXPERIMENT_NAMEë§Œ ë³€ê²½í•˜ê³  PROJECT_NAMEì€ ê·¸ëŒ€ë¡œ ë‘ì„¸ìš”\n",
    "- ê°ì ê°œì¸ ê³„ì •ìœ¼ë¡œ ë¡œê·¸ì¸í•´ì„œ ì‹¤í—˜ì„ ì¶”ê°€í•˜ì„¸ìš”\n",
    "\"\"\"\n",
    "\n",
    "# WandB ë¡œê·¸ì¸ (ê°ì ì‹¤í–‰)\n",
    "try:\n",
    "    if wandb.api.api_key is None:\n",
    "        print(\"WandBì— ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.\")\n",
    "        wandb.login()\n",
    "    else:\n",
    "        print(f\"WandB ë¡œê·¸ì¸ ìƒíƒœ: {wandb.api.viewer()['username']}\")\n",
    "except:\n",
    "    print(\"WandB ë¡œê·¸ì¸ì„ ì§„í–‰í•©ë‹ˆë‹¤...\")\n",
    "    wandb.login()\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ì„¤ì • (ê°ì ìˆ˜ì •í•  ë¶€ë¶„)\n",
    "PROJECT_NAME = \"document-classification-team\"  # ëª¨ë“  íŒ€ì› ë™ì¼\n",
    "ENTITY = None  # ê°ì ê°œì¸ ê³„ì • ì‚¬ìš©\n",
    "EXPERIMENT_NAME = \"swinb-convnext-ensemble\"  # íŒ€ì›ë³„ë¡œ ë³€ê²½ (ì˜ˆ: \"member1-hyperopt\", \"member2-augmentation\")\n",
    "\n",
    "print(f\"í”„ë¡œì íŠ¸: {PROJECT_NAME}\")\n",
    "print(f\"ì‹¤í—˜ëª…: {EXPERIMENT_NAME}\")\n",
    "print(\"íŒ€ì›ë“¤ì€ EXPERIMENT_NAMEì„ ê°ì ë‹¤ë¥´ê²Œ ë³€ê²½í•´ì£¼ì„¸ìš”!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device ë° ê¸°ë³¸ ì„¤ì •\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"ğŸ“± Using device: {device}\")\n",
    "\n",
    "data_path = '/root/home/cv_contest/CV_data/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì¤‘ ëª¨ë¸ ì„¤ì •\n",
    "\n",
    "MODEL_CONFIGS = {\n",
    "    'swin_b': {\n",
    "        'model_name': 'swin_base_patch4_window12_384_in22k',\n",
    "        'img_size': 384,\n",
    "        'batch_size': 16,\n",
    "        'lr': 5e-4,\n",
    "        'architecture': 'Swin Transformer',\n",
    "        'weight_decay': 0.01\n",
    "    },\n",
    "    'convnext': {\n",
    "        'model_name': 'convnext_base_in22k',\n",
    "        'img_size': 224,\n",
    "        'batch_size': 16,\n",
    "        'lr': 3e-4,\n",
    "        'architecture': 'ConvNeXt',\n",
    "        'weight_decay': 0.01\n",
    "    }\n",
    "}\n",
    "\n",
    "# ì‚¬ìš©í•  ëª¨ë¸ë“¤ ì„ íƒ\n",
    "ACTIVE_MODELS = ['swin_b', 'convnext']\n",
    "EPOCHS = 50\n",
    "num_workers = 30\n",
    "N_FOLDS = 5\n",
    "\n",
    "print(f\"ğŸ“Š ì‚¬ìš©í•  ëª¨ë¸: {ACTIVE_MODELS}\")\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    config = MODEL_CONFIGS[model_key]\n",
    "    print(f\"  ğŸ¤– {model_key}: {config['model_name']} ({config['img_size']}x{config['img_size']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Resolution Dataset í´ë˜ìŠ¤\n",
    "\n",
    "class MultiResImageDataset(Dataset):\n",
    "    def __init__(self, data, path, img_sizes, epoch=0, total_epochs=10, is_train=True):\n",
    "        \"\"\"\n",
    "        ë‹¤ì¤‘ í•´ìƒë„ë¥¼ ì§€ì›í•˜ëŠ” Dataset\n",
    "        \"\"\"\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.img_sizes = img_sizes\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation í™•ë¥  ê³„ì‚°\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # ê° í•´ìƒë„ë³„ transform ìƒì„±\n",
    "        self.transforms = {}\n",
    "        for model_key, img_size in img_sizes.items():\n",
    "            # Normal augmentation\n",
    "            normal_aug = A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.OneOf([\n",
    "                    A.Rotate(limit=[90,90], p=1.0),\n",
    "                    A.Rotate(limit=[180,180], p=1.0),\n",
    "                    A.Rotate(limit=[270,270], p=1.0),\n",
    "                ], p=0.6),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "                A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "            \n",
    "            # Hard augmentation\n",
    "            hard_aug = A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.OneOf([\n",
    "                    A.Rotate(limit=[90,90], p=1.0),\n",
    "                    A.Rotate(limit=[180,180], p=1.0),\n",
    "                    A.Rotate(limit=[270,270], p=1.0),\n",
    "                    A.Rotate(limit=[-15,15], p=1.0),\n",
    "                ], p=0.8),\n",
    "                A.OneOf([\n",
    "                    A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                    A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "                ], p=0.95),\n",
    "                A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "                A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "                A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "                A.HorizontalFlip(p=0.5),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ])\n",
    "            \n",
    "            self.transforms[model_key] = {\n",
    "                'normal': normal_aug,\n",
    "                'hard': hard_aug\n",
    "            }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # ê° ëª¨ë¸ë³„ë¡œ ë‹¤ë¥¸ í•´ìƒë„ì˜ ì´ë¯¸ì§€ ìƒì„±\n",
    "        images = {}\n",
    "        for model_key in self.img_sizes.keys():\n",
    "            # ë°°ì¹˜ë³„ ì¦ê°• ì„ íƒ\n",
    "            if self.is_train and random.random() < self.p_hard:\n",
    "                aug_img = self.transforms[model_key]['hard'](image=img)['image']\n",
    "            else:\n",
    "                aug_img = self.transforms[model_key]['normal'](image=img)['image']\n",
    "            images[model_key] = aug_img\n",
    "        \n",
    "        return images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë‹¤ì¤‘ ëª¨ë¸ í•™ìŠµ í•¨ìˆ˜ë“¤\n",
    "\n",
    "def train_multi_models_epoch(loaders, models, optimizers, loss_fns, device, epoch=None, fold=None):\n",
    "    \"\"\"ë‹¤ì¤‘ ëª¨ë¸ì„ ë™ì‹œì— í•™ìŠµí•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    scaler = GradScaler()\n",
    "    \n",
    "    # ëª¨ë“  ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ\n",
    "    for model in models.values():\n",
    "        model.train()\n",
    "    \n",
    "    model_losses = {key: 0 for key in models.keys()}\n",
    "    model_preds = {key: [] for key in models.keys()}\n",
    "    targets_list = []\n",
    "    \n",
    "    # ì²« ë²ˆì§¸ loader ê¸°ì¤€ìœ¼ë¡œ iteration\n",
    "    first_key = list(loaders.keys())[0]\n",
    "    pbar = tqdm(loaders[first_key], desc=f\"Training Epoch {epoch+1 if epoch else '?'}\")\n",
    "    \n",
    "    for batch_idx, batch_data in enumerate(pbar):\n",
    "        images_dict, targets = batch_data\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # ê° ëª¨ë¸ë³„ë¡œ í•™ìŠµ\n",
    "        batch_losses = {}\n",
    "        for model_key in models.keys():\n",
    "            model = models[model_key]\n",
    "            optimizer = optimizers[model_key]\n",
    "            loss_fn = loss_fns[model_key]\n",
    "            \n",
    "            image = images_dict[model_key].to(device)\n",
    "            \n",
    "            # Mixup í™•ë¥  (30% ìœ ì§€)\n",
    "            mixup_applied = False\n",
    "            if random.random() < 0.3:\n",
    "                mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "                with autocast():\n",
    "                    preds = model(mixed_x)\n",
    "                loss = lam * loss_fn(preds.float(), y_a) + (1 - lam) * loss_fn(preds.float(), y_b)\n",
    "                mixup_applied = True\n",
    "            else:\n",
    "                with autocast():\n",
    "                    preds = model(image)\n",
    "                loss = loss_fn(preds.float(), targets)\n",
    "            \n",
    "            # ì—­ì „íŒŒ\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scaler.scale(loss).backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            batch_losses[model_key] = loss.item()\n",
    "            model_losses[model_key] += loss.item()\n",
    "            model_preds[model_key].extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        \n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "        \n",
    "        # ë°°ì¹˜ë³„ ë¡œê¹…\n",
    "        if batch_idx % 100 == 0 and wandb.run is not None:\n",
    "            step = epoch * len(pbar) + batch_idx if epoch is not None else batch_idx\n",
    "            log_data = {f\"fold_{fold}/batch_step\": step}\n",
    "            for model_key, loss_val in batch_losses.items():\n",
    "                log_data[f\"fold_{fold}/{model_key}_batch_loss\"] = loss_val\n",
    "            log_data[f\"fold_{fold}/mixup_applied\"] = int(mixup_applied)\n",
    "            wandb.log(log_data)\n",
    "        \n",
    "        pbar.set_description(f\"Losses: {', '.join([f'{k}: {v:.4f}' for k, v in batch_losses.items()])}\")\n",
    "    \n",
    "    # ê° ëª¨ë¸ë³„ ê²°ê³¼ ê³„ì‚°\n",
    "    results = {}\n",
    "    for model_key in models.keys():\n",
    "        model_losses[model_key] /= len(pbar)\n",
    "        train_acc = accuracy_score(targets_list, model_preds[model_key])\n",
    "        train_f1 = f1_score(targets_list, model_preds[model_key], average='macro')\n",
    "        \n",
    "        results[model_key] = {\n",
    "            \"train_loss\": model_losses[model_key],\n",
    "            \"train_acc\": train_acc,\n",
    "            \"train_f1\": train_f1,\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def validate_multi_models_epoch(loaders, models, loss_fns, device, epoch=None, fold=None, log_confusion=False):\n",
    "    \"\"\"ë‹¤ì¤‘ ëª¨ë¸ì„ ë™ì‹œì— ê²€ì¦í•˜ëŠ” í•¨ìˆ˜\"\"\"\n",
    "    \n",
    "    # ëª¨ë“  ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ\n",
    "    for model in models.values():\n",
    "        model.eval()\n",
    "    \n",
    "    model_losses = {key: 0 for key in models.keys()}\n",
    "    model_preds = {key: [] for key in models.keys()}\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        first_key = list(loaders.keys())[0]\n",
    "        pbar = tqdm(loaders[first_key], desc=f\"Validating Epoch {epoch+1 if epoch else '?'}\")\n",
    "        \n",
    "        for batch_data in pbar:\n",
    "            images_dict, targets = batch_data\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            batch_losses = {}\n",
    "            for model_key in models.keys():\n",
    "                model = models[model_key]\n",
    "                loss_fn = loss_fns[model_key]\n",
    "                \n",
    "                image = images_dict[model_key].to(device)\n",
    "                preds = model(image)\n",
    "                loss = loss_fn(preds, targets)\n",
    "                \n",
    "                batch_losses[model_key] = loss.item()\n",
    "                model_losses[model_key] += loss.item()\n",
    "                model_preds[model_key].extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            \n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "            pbar.set_description(f\"Val Losses: {', '.join([f'{k}: {v:.4f}' for k, v in batch_losses.items()])}\")\n",
    "    \n",
    "    # ê° ëª¨ë¸ë³„ ê²°ê³¼ ê³„ì‚°\n",
    "    results = {}\n",
    "    for model_key in models.keys():\n",
    "        model_losses[model_key] /= len(pbar)\n",
    "        val_acc = accuracy_score(targets_list, model_preds[model_key])\n",
    "        val_f1 = f1_score(targets_list, model_preds[model_key], average='macro')\n",
    "        \n",
    "        # Confusion Matrix ë¡œê¹… (ë§ˆì§€ë§‰ epochì—ë§Œ)\n",
    "        if log_confusion and wandb.run is not None:\n",
    "            try:\n",
    "                wandb.log({\n",
    "                    f\"fold_{fold}/{model_key}_confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                        probs=None,\n",
    "                        y_true=targets_list,\n",
    "                        preds=model_preds[model_key],\n",
    "                        class_names=[f\"Class_{i}\" for i in range(17)]\n",
    "                    )\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ {model_key} Confusion matrix ë¡œê¹… ì‹¤íŒ¨: {e}\")\n",
    "        \n",
    "        results[model_key] = {\n",
    "            \"val_loss\": model_losses[model_key],\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1\": val_f1,\n",
    "        }\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB Config ì„¤ì •\n",
    "\n",
    "config = {\n",
    "    # Multi-Model config\n",
    "    \"ensemble_models\": ACTIVE_MODELS,\n",
    "    \"model_configs\": MODEL_CONFIGS,\n",
    "    \"multi_resolution\": True,\n",
    "    \n",
    "    # Training config\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"device\": str(device),\n",
    "    \n",
    "    # K-Fold config\n",
    "    \"n_folds\": N_FOLDS,\n",
    "    \"seed\": SEED,\n",
    "    \"cv_strategy\": \"StratifiedKFold\",\n",
    "    \n",
    "    # Augmentation & Training techniques\n",
    "    \"mixup_alpha\": 1.0,\n",
    "    \"mixup_prob\": 0.3,\n",
    "    \"label_smoothing\": 0.1,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"mixed_precision\": True,\n",
    "    \n",
    "    # Data\n",
    "    \"data_path\": data_path,\n",
    "    \"train_transforms\": \"Progressive_Hard_Augmentation\",\n",
    "    \"test_transforms\": \"Basic\",\n",
    "}\n",
    "\n",
    "print(\"âœ… í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • ì™„ë£Œ!\")\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    config_detail = MODEL_CONFIGS[model_key]\n",
    "    print(f\"ğŸ¤– {model_key}: {config_detail['model_name']} ({config_detail['img_size']}px, LR={config_detail['lr']})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¡œë“œ ë° í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "train_df = pd.read_csv(\"CV_data/train.csv\")\n",
    "print(f\"ğŸ“Š í•™ìŠµ ë°ì´í„°: {len(train_df)}ê°œ ìƒ˜í”Œ\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "class_counts = train_df['target'].value_counts().sort_index()\n",
    "print(f\"ğŸ“Š í´ë˜ìŠ¤ ë¶„í¬: {dict(class_counts)}\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "total_samples = len(train_df)\n",
    "num_classes = 17\n",
    "class_weights = torch.tensor([\n",
    "    total_samples / (num_classes * class_counts[i]) for i in range(num_classes)\n",
    "], dtype=torch.float32).to(device)\n",
    "\n",
    "# ê°€ì¤‘ì¹˜ ì •ê·œí™”\n",
    "class_weights = class_weights / class_weights.mean()\n",
    "print(f\"ğŸ“Š ì •ê·œí™”ëœ í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ë²”ìœ„: {class_weights.min():.3f} ~ {class_weights.max():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold ê²°ê³¼ ì €ì¥ìš© ë³€ìˆ˜\n",
    "\n",
    "all_fold_results = {model_key: [] for model_key in ACTIVE_MODELS}\n",
    "all_fold_models = {model_key: [] for model_key in ACTIVE_MODELS}\n",
    "\n",
    "# í˜„ì¬ ì‚¬ìš©í•  ì´ë¯¸ì§€ í¬ê¸°ë“¤\n",
    "img_sizes = {model_key: MODEL_CONFIGS[model_key]['img_size'] for model_key in ACTIVE_MODELS}\n",
    "print(f\"ğŸ“Š ì´ë¯¸ì§€ í¬ê¸° ì„¤ì •: {img_sizes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WandB ë©”ì¸ ì‹¤í—˜ ì‹œì‘\n",
    "\n",
    "main_run = wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    entity=ENTITY,\n",
    "    name=f\"{EXPERIMENT_NAME}\",\n",
    "    config=config,\n",
    "    tags=[\"multi-model\", \"swin-convnext\", \"k-fold-cv\", \"ensemble\", \"main-experiment\"],\n",
    "    group=\"multi-model-experiment\",\n",
    "    job_type=\"cross-validation\",\n",
    "    notes=f\"Swin-B + ConvNeXt with {N_FOLDS}-Fold Cross Validation\"\n",
    ")\n",
    "\n",
    "print(f\"ğŸš€ WandB ì‹¤í—˜ ì‹œì‘!\")\n",
    "print(f\"ğŸ“Š ëŒ€ì‹œë³´ë“œ: {main_run.url}\")\n",
    "print(f\"ğŸ“‹ ì‹¤í—˜ëª…: {main_run.name}\")\n",
    "\n",
    "# ë°ì´í„°ì…‹ ì •ë³´ ë¡œê¹…\n",
    "wandb.log({\n",
    "    \"dataset/total_samples\": len(train_df),\n",
    "    \"dataset/num_classes\": 17,\n",
    "    \"dataset/samples_per_fold\": len(train_df) // N_FOLDS,\n",
    "})\n",
    "\n",
    "# í´ë˜ìŠ¤ ë¶„í¬ ì‹œê°í™”\n",
    "class_dist_data = [[f\"Class_{i}\", count] for i, count in enumerate(class_counts)]\n",
    "wandb.log({\n",
    "    \"dataset/class_distribution\": wandb.plot.bar(\n",
    "        wandb.Table(data=class_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "        \"Class\", \"Count\", \n",
    "        title=\"Training Data Class Distribution\"\n",
    "    )\n",
    "})\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ¯ {N_FOLDS}-FOLD MULTI-MODEL CROSS VALIDATION ì‹œì‘\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross Validation Loop\n",
    "\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"ğŸ“ FOLD {fold + 1}/{N_FOLDS} - Multi-Model Training\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # ê° foldë³„ child run ìƒì„±\n",
    "    fold_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        entity=ENTITY,\n",
    "        name=f\"fold-{fold+1}-multi-{datetime.now().strftime('%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"fold\", f\"fold-{fold+1}\", \"multi-model\", \"child-run\"],\n",
    "        group=\"multi-model-experiment\",\n",
    "        job_type=f\"fold-{fold+1}\",\n",
    "        reinit=True\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ“Š Fold {fold+1} Dashboard: {fold_run.url}\")\n",
    "    \n",
    "    # ë°ì´í„° ë¶„í• \n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # Foldë³„ í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸\n",
    "    train_class_dist = train_fold_df['target'].value_counts().sort_index()\n",
    "    val_class_dist = val_fold_df['target'].value_counts().sort_index()\n",
    "    \n",
    "    print(f\"ğŸ“Š Fold {fold+1} í´ë˜ìŠ¤ ë¶„í¬:\")\n",
    "    print(f\"  Train: {len(train_fold_df)}ê°œ ìƒ˜í”Œ\")\n",
    "    print(f\"  Val: {len(val_fold_df)}ê°œ ìƒ˜í”Œ\")\n",
    "    \n",
    "    wandb.log({\n",
    "        \"fold_info/fold_number\": fold + 1,\n",
    "        \"fold_info/train_samples\": len(train_fold_df),\n",
    "        \"fold_info/val_samples\": len(val_fold_df),\n",
    "        \"fold_info/train_ratio\": len(train_fold_df) / len(train_df),\n",
    "        \"fold_info/val_ratio\": len(val_fold_df) / len(train_df),\n",
    "    })\n",
    "    \n",
    "    # ë‹¤ì¤‘ í•´ìƒë„ Dataset ìƒì„±\n",
    "    trn_dataset = MultiResImageDataset(\n",
    "        train_fold_df,\n",
    "        \"/root/home/cv_contest/CV_data/train\",\n",
    "        img_sizes,\n",
    "        epoch=0,\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = MultiResImageDataset(\n",
    "        val_fold_df,\n",
    "        \"/root/home/cv_contest/CV_data/train\",\n",
    "        img_sizes,\n",
    "        epoch=0,\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    # ê° ëª¨ë¸ë³„ DataLoader ìƒì„±\n",
    "    trn_loaders = {}\n",
    "    val_loaders = {}\n",
    "    \n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        batch_size = MODEL_CONFIGS[model_key]['batch_size']\n",
    "        \n",
    "        trn_loaders[model_key] = DataLoader(\n",
    "            trn_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "        \n",
    "        val_loaders[model_key] = DataLoader(\n",
    "            val_dataset,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=num_workers,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    # ê° ëª¨ë¸ ìƒì„±\n",
    "    models = {}\n",
    "    optimizers = {}\n",
    "    schedulers = {}\n",
    "    loss_fns = {}\n",
    "    best_models = {model_key: None for model_key in ACTIVE_MODELS}\n",
    "    best_f1s = {model_key: 0.0 for model_key in ACTIVE_MODELS}\n",
    "    \n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        config_detail = MODEL_CONFIGS[model_key]\n",
    "        \n",
    "        # ëª¨ë¸ ìƒì„±\n",
    "        models[model_key] = timm.create_model(\n",
    "            config_detail['model_name'],\n",
    "            pretrained=True,\n",
    "            num_classes=17\n",
    "        ).to(device)\n",
    "        \n",
    "        # ì˜µí‹°ë§ˆì´ì € ìƒì„±\n",
    "        optimizers[model_key] = AdamW(\n",
    "            models[model_key].parameters(),\n",
    "            lr=config_detail['lr'],\n",
    "            weight_decay=config_detail['weight_decay']\n",
    "        )\n",
    "        \n",
    "        # ìŠ¤ì¼€ì¤„ëŸ¬ ìƒì„±\n",
    "        schedulers[model_key] = CosineAnnealingLR(optimizers[model_key], T_max=EPOCHS)\n",
    "        \n",
    "        # ì†ì‹¤ í•¨ìˆ˜ ìƒì„± (í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ì ìš©)\n",
    "        loss_fns[model_key] = nn.CrossEntropyLoss(\n",
    "            weight=class_weights,\n",
    "            label_smoothing=0.1\n",
    "        )\n",
    "        \n",
    "        model_params = sum(p.numel() for p in models[model_key].parameters())\n",
    "        print(f\"ğŸ¤– {model_key} ëª¨ë¸ ìƒì„±: {config_detail['model_name']} ({model_params:,} parameters)\")\n",
    "    \n",
    "    # Training Loop for Current Fold\n",
    "    #patience = {model_key: 0 for model_key in ACTIVE_MODELS}\n",
    "    #max_patience = 3\n",
    "    \n",
    "    print(f\"ğŸ¯ Fold {fold+1} ë‹¤ì¤‘ ëª¨ë¸ í•™ìŠµ ì‹œì‘\")\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nğŸ“ˆ Epoch {epoch+1}/{EPOCHS}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # ì—í­ë³„ Dataset ì—…ë°ì´íŠ¸ (ì ì§„ì  ì¦ê°•)\n",
    "        trn_dataset.epoch = epoch\n",
    "        val_dataset.epoch = epoch\n",
    "        \n",
    "        # ëª¨ë“  ëª¨ë¸ ë™ì‹œ í•™ìŠµ\n",
    "        train_results = train_multi_models_epoch(\n",
    "            trn_loaders, models, optimizers, loss_fns, device,\n",
    "            epoch=epoch, fold=fold+1\n",
    "        )\n",
    "        \n",
    "        # ëª¨ë“  ëª¨ë¸ ë™ì‹œ ê²€ì¦\n",
    "        val_results = validate_multi_models_epoch(\n",
    "            val_loaders, models, loss_fns, device,\n",
    "            epoch=epoch, fold=fold+1,\n",
    "            log_confusion=(epoch == EPOCHS-1)\n",
    "        )\n",
    "        \n",
    "        # ê° ëª¨ë¸ë³„ ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸\n",
    "        for scheduler in schedulers.values():\n",
    "            scheduler.step()\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        \n",
    "        # WandB ë¡œê¹… ë° ìµœê³  ëª¨ë¸ ì €ì¥\n",
    "        log_data = {\"epoch\": epoch + 1, \"fold\": fold + 1, \"epoch_time\": epoch_time}\n",
    "        \n",
    "        print(f\"ğŸ“Š Epoch {epoch+1:2d} ê²°ê³¼:\")\n",
    "        for model_key in ACTIVE_MODELS:\n",
    "            train_res = train_results[model_key]\n",
    "            val_res = val_results[model_key]\n",
    "            current_lr = optimizers[model_key].param_groups[0]['lr']\n",
    "            \n",
    "            log_data.update({\n",
    "                f\"{model_key}/train_loss\": train_res['train_loss'],\n",
    "                f\"{model_key}/train_acc\": train_res['train_acc'],\n",
    "                f\"{model_key}/train_f1\": train_res['train_f1'],\n",
    "                f\"{model_key}/val_loss\": val_res['val_loss'],\n",
    "                f\"{model_key}/val_acc\": val_res['val_acc'],\n",
    "                f\"{model_key}/val_f1\": val_res['val_f1'],\n",
    "                f\"{model_key}/lr\": current_lr,\n",
    "            })\n",
    "            \n",
    "            print(f\"  {model_key:10s}: Train F1={train_res['train_f1']:.4f}, Val F1={val_res['val_f1']:.4f}, LR={current_lr:.2e}\")\n",
    "            \n",
    "            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n",
    "            if val_res['val_f1'] > best_f1s[model_key]:\n",
    "                best_f1s[model_key] = val_res['val_f1']\n",
    "                best_models[model_key] = copy.deepcopy(models[model_key].state_dict())\n",
    "                #patience[model_key] = 0\n",
    "                \n",
    "                # ëª¨ë¸ ì €ì¥\n",
    "                model_path = f'best_{model_key}_fold_{fold+1}.pth'\n",
    "                torch.save(best_models[model_key], model_path)\n",
    "                wandb.save(model_path, policy=\"now\")\n",
    "                \n",
    "                # ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥ ë¡œê¹…\n",
    "                wandb.log({\n",
    "                    f\"best_performance/{model_key}_epoch\": epoch + 1,\n",
    "                    f\"best_performance/{model_key}_val_f1\": best_f1s[model_key],\n",
    "                    f\"best_performance/{model_key}_val_acc\": val_res['val_acc'],\n",
    "                })\n",
    "                \n",
    "                print(f\"    ğŸ‰ {model_key} ìƒˆë¡œìš´ ìµœê³  ì„±ëŠ¥! F1: {best_f1s[model_key]:.4f}\")\n",
    "            #else:\n",
    "                #patience[model_key] += 1\n",
    "        \n",
    "        # GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë¡œê¹…\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory_used = torch.cuda.memory_allocated(0) / 1e9\n",
    "            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            log_data.update({\n",
    "                \"system/gpu_memory_used_gb\": gpu_memory_used,\n",
    "                \"system/gpu_memory_total_gb\": gpu_memory_total,\n",
    "                \"system/gpu_utilization_pct\": (gpu_memory_used / gpu_memory_total) * 100\n",
    "            })\n",
    "        \n",
    "        wandb.log(log_data)\n",
    "        \n",
    "        # Early stopping ì²´í¬ (ëª¨ë“  ëª¨ë¸ì´ patience ì´ˆê³¼ ì‹œ)\n",
    "        # if all(p >= max_patience for p in patience.values()) and epoch > EPOCHS // 2:\n",
    "        #     print(f\"â¸ï¸ Early stopping at epoch {epoch+1} (ëª¨ë“  ëª¨ë¸ patience ì´ˆê³¼)\")\n",
    "        #     wandb.log({\"early_stopping/epoch\": epoch + 1})\n",
    "        #     break\n",
    "    \n",
    "    # Fold ê²°ê³¼ ì €ì¥\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        fold_result = {\n",
    "            'fold': fold + 1,\n",
    "            'best_val_f1': best_f1s[model_key],\n",
    "            'model_name': MODEL_CONFIGS[model_key]['model_name'],\n",
    "            'epochs_trained': epoch + 1,\n",
    "        }\n",
    "        all_fold_results[model_key].append(fold_result)\n",
    "        all_fold_models[model_key].append(best_models[model_key])\n",
    "    \n",
    "    print(f\"\\nâœ… Fold {fold + 1} ì™„ë£Œ!\")\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        print(f\"  {model_key:10s}: ìµœê³  F1 = {best_f1s[model_key]:.4f}\")\n",
    "    \n",
    "    # Foldë³„ ìš”ì•½ ë¡œê¹…\n",
    "    wandb.log({\n",
    "        \"fold_summary/completed\": True,\n",
    "        \"fold_summary/epochs_trained\": epoch + 1,\n",
    "        **{f\"fold_summary/{model_key}_best_f1\": best_f1s[model_key] for model_key in ACTIVE_MODELS}\n",
    "    })\n",
    "    \n",
    "    fold_run.finish()\n",
    "    \n",
    "    # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "    del models, optimizers, schedulers, trn_loaders, val_loaders\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold ê²°ê³¼ ë¶„ì„\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ K-FOLD ë‹¤ì¤‘ ëª¨ë¸ ê²°ê³¼\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    val_f1_scores = [result['best_val_f1'] for result in all_fold_results[model_key]]\n",
    "    mean_f1 = np.mean(val_f1_scores)\n",
    "    std_f1 = np.std(val_f1_scores)\n",
    "    \n",
    "    print(f\"\\nğŸ¤– {model_key.upper()} ({MODEL_CONFIGS[model_key]['model_name']}):\")\n",
    "    print(f\"  ğŸ“Š í‰ê·  CV F1: {mean_f1:.4f} Â± {std_f1:.4f}\")\n",
    "    print(f\"  ğŸ† ìµœê³  Fold: {max(val_f1_scores):.4f}\")\n",
    "    print(f\"  ğŸ“‰ ìµœì•… Fold: {min(val_f1_scores):.4f}\")\n",
    "    print(f\"  ğŸ“ ì„±ëŠ¥ ë²”ìœ„: {max(val_f1_scores) - min(val_f1_scores):.4f}\")\n",
    "    \n",
    "    # ë©”ì¸ runì— ëª¨ë¸ë³„ CV ê²°ê³¼ ë¡œê¹…\n",
    "    try:\n",
    "        main_run.log({\n",
    "            f\"cv_results/{model_key}_mean_f1\": mean_f1,\n",
    "            f\"cv_results/{model_key}_std_f1\": std_f1,\n",
    "            f\"cv_results/{model_key}_best_fold_f1\": max(val_f1_scores),\n",
    "            f\"cv_results/{model_key}_worst_fold_f1\": min(val_f1_scores),\n",
    "            f\"cv_results/{model_key}_f1_range\": max(val_f1_scores) - min(val_f1_scores),\n",
    "        })\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(\"\\nğŸ“Š ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ:\")\n",
    "for fold in range(N_FOLDS):\n",
    "    print(f\"  Fold {fold+1}:\", end=\"\")\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        f1_score = all_fold_results[model_key][fold]['best_val_f1']\n",
    "        print(f\" {model_key}={f1_score:.4f}\", end=\"\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„\n",
    "\n",
    "ensemble_models = {model_key: [] for model_key in ACTIVE_MODELS}\n",
    "print(f\"\\nğŸ”§ ì•™ìƒë¸” ëª¨ë¸ ì¤€ë¹„ ì¤‘...\")\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    for i, state_dict in enumerate(all_fold_models[model_key]):\n",
    "        config_detail = MODEL_CONFIGS[model_key]\n",
    "        fold_model = timm.create_model(config_detail['model_name'], pretrained=True, num_classes=17).to(device)\n",
    "        fold_model.load_state_dict(state_dict)\n",
    "        fold_model.eval()\n",
    "        ensemble_models[model_key].append(fold_model)\n",
    "        print(f\"ğŸ“ {model_key} Fold {i+1} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n",
    "\n",
    "print(f\"\\nğŸ¯ ì•™ìƒë¸” êµ¬ì„±:\")\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    print(f\"  {model_key}: {len(ensemble_models[model_key])}ê°œ ëª¨ë¸\")\n",
    "\n",
    "try:\n",
    "    main_run.log({\n",
    "        \"ensemble/num_model_types\": len(ACTIVE_MODELS),\n",
    "        \"ensemble/models_per_type\": N_FOLDS,\n",
    "        \"ensemble/total_models\": len(ACTIVE_MODELS) * N_FOLDS,\n",
    "        \"ensemble/architectures\": [MODEL_CONFIGS[key]['architecture'] for key in ACTIVE_MODELS]\n",
    "    })\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling í´ë˜ìŠ¤\n",
    "\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self, temperature=1.5):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * temperature)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTA : Multi-Resoulition TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Resolution TTA Setup\n",
    "\n",
    "print(f\"\\nğŸ”„ ë‹¤ì¤‘ í•´ìƒë„ TTA (Test Time Augmentation) ì„¤ì •...\")\n",
    "\n",
    "# ê° ëª¨ë¸ë³„ ìµœì í™”ëœ TTA ë³€í™˜ ìƒì„±\n",
    "multi_res_tta_transforms = {}\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    img_size = MODEL_CONFIGS[model_key]['img_size']\n",
    "    \n",
    "    # ê° ëª¨ë¸ì— ìµœì í™”ëœ TTA ë³€í™˜ë“¤\n",
    "    tta_transforms = [\n",
    "        # ì›ë³¸\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "        # 90ë„ íšŒì „ë“¤\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.Rotate(limit=[90, 90], p=1.0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.Rotate(limit=[180, 180], p=1.0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.Rotate(limit=[-90, -90], p=1.0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "        # ë°ê¸° ì¡°ì •\n",
    "        A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ]),\n",
    "    ]\n",
    "    \n",
    "    multi_res_tta_transforms[model_key] = tta_transforms\n",
    "    print(f\"âœ… {model_key} ({img_size}x{img_size}) TTA ë³€í™˜ {len(tta_transforms)}ê°œ ì¤€ë¹„ ì™„ë£Œ\")\n",
    "\n",
    "try:\n",
    "    main_run.log({\n",
    "        \"tta/multi_resolution\": True,\n",
    "        \"tta/transforms_per_model\": {\n",
    "            model_key: len(transforms) for model_key, transforms in multi_res_tta_transforms.items()\n",
    "        },\n",
    "        \"tta/image_sizes\": {\n",
    "            model_key: MODEL_CONFIGS[model_key]['img_size'] for model_key in ACTIVE_MODELS\n",
    "        }\n",
    "    })\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Resolution TTA Dataset í´ë˜ìŠ¤\n",
    "\n",
    "class MultiResTTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, multi_transforms):\n",
    "        \"\"\"\n",
    "        ë‹¤ì¤‘ í•´ìƒë„ TTAë¥¼ ìœ„í•œ Dataset\n",
    "        multi_transforms: {model_key: [transform1, transform2, ...]} í˜•íƒœ\n",
    "        \"\"\"\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.multi_transforms = multi_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # ëª¨ë¸ë³„, TTA ë³€í˜•ë³„ë¡œ ì´ë¯¸ì§€ ìƒì„±\n",
    "        augmented_images = {}\n",
    "        for model_key, transforms in self.multi_transforms.items():\n",
    "            model_images = []\n",
    "            for transform in transforms:\n",
    "                aug_img = transform(image=img)['image']\n",
    "                model_images.append(aug_img)\n",
    "            augmented_images[model_key] = model_images\n",
    "        \n",
    "        return augmented_images, target\n",
    "\n",
    "# Multi-Resolution TTA Dataset ìƒì„±\n",
    "multi_tta_dataset = MultiResTTAImageDataset(\n",
    "    \"/root/home/cv_contest/CV_data/sample_submission.csv\",\n",
    "    \"/root/home/cv_contest/CV_data/test\",\n",
    "    multi_res_tta_transforms\n",
    ")\n",
    "\n",
    "# ê° ëª¨ë¸ë³„ ìµœì  ë°°ì¹˜ í¬ê¸°ë¡œ DataLoader ìƒì„±\n",
    "multi_tta_loaders = {}\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    batch_size = min(MODEL_CONFIGS[model_key]['batch_size'], 16)  # TTAìš©ìœ¼ë¡œ ë°°ì¹˜ í¬ê¸° ì¡°ì •\n",
    "    \n",
    "    multi_tta_loaders[model_key] = DataLoader(\n",
    "        multi_tta_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"ğŸ“Š {model_key} TTA DataLoader: ë°°ì¹˜ í¬ê¸° {batch_size}\")\n",
    "\n",
    "print(f\"ğŸ“Š Multi-Resolution TTA Dataset: {len(multi_tta_dataset)}ê°œ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ\")\n",
    "\n",
    "# =============================================================================\n",
    "# 17. Multi-Resolution Ensemble + TTA Inference Function\n",
    "# =============================================================================\n",
    "\n",
    "def multi_resolution_ensemble_tta_inference(ensemble_models, loaders, multi_transforms, confidence_threshold=0.9):\n",
    "    \"\"\"\n",
    "    ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸” + TTA ì¶”ë¡  with ìƒì„¸ WandB ë¡œê¹…\n",
    "    \"\"\"\n",
    "    # Temperature scaling ì´ˆê¸°í™”\n",
    "    temp_scalings = {model_key: TemperatureScaling().to(device) for model_key in ACTIVE_MODELS}\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥ìš©\n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    model_predictions = {model_key: [] for model_key in ACTIVE_MODELS}\n",
    "    model_confidences = {model_key: [] for model_key in ACTIVE_MODELS}\n",
    "    \n",
    "    print(f\"ğŸš€ ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸” TTA ì¶”ë¡  ì‹œì‘...\")\n",
    "    print(f\"ğŸ“Š ëª¨ë¸ë³„ ì„¤ì •:\")\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        config_detail = MODEL_CONFIGS[model_key]\n",
    "        num_folds = len(ensemble_models[model_key])\n",
    "        num_tta = len(multi_transforms[model_key])\n",
    "        total_preds = num_folds * num_tta\n",
    "        print(f\"  ğŸ¤– {model_key}: {num_folds}ê°œ ëª¨ë¸ Ã— {num_tta}ê°œ TTA = {total_preds}ê°œ ì˜ˆì¸¡\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # ëª¨ë¸ë³„ ê°œë³„ ì¶”ë¡  (ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±ì„ ìœ„í•´)\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        print(f\"\\nğŸ” {model_key.upper()} ëª¨ë¸ ì¶”ë¡  ì¤‘...\")\n",
    "        \n",
    "        config_detail = MODEL_CONFIGS[model_key]\n",
    "        models = ensemble_models[model_key]\n",
    "        loader = multi_tta_loaders[model_key]\n",
    "        temp_scaling = temp_scalings[model_key]\n",
    "        \n",
    "        model_start_time = time.time()\n",
    "        \n",
    "        # ì§„í–‰ìƒí™© ë¡œê¹…ì„ ìœ„í•œ í…Œì´ë¸”\n",
    "        progress_table = wandb.Table(columns=[\"Batch\", \"Avg_Confidence\", \"Low_Conf_Count\", \"High_Conf_Count\"])\n",
    "        \n",
    "        for batch_idx, batch_data in enumerate(tqdm(loader, desc=f\"{model_key} TTA\")):\n",
    "            images_dict, _ = batch_data\n",
    "            images_list = images_dict[model_key]  # í˜„ì¬ ëª¨ë¸ì˜ TTA ì´ë¯¸ì§€ë“¤\n",
    "            batch_size = images_list[0].size(0)\n",
    "            \n",
    "            # í˜„ì¬ ëª¨ë¸ì˜ ì•™ìƒë¸” í™•ë¥  ì´ˆê¸°í™”\n",
    "            model_ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "            \n",
    "            # ê° fold ëª¨ë¸ë³„ ì˜ˆì¸¡\n",
    "            for fold_model in models:\n",
    "                fold_model.eval()\n",
    "                with torch.no_grad():\n",
    "                    # ê° TTA ë³€í˜•ë³„ ì˜ˆì¸¡\n",
    "                    for tta_images in images_list:\n",
    "                        tta_images = tta_images.to(device)\n",
    "                        preds = fold_model(tta_images)\n",
    "                        \n",
    "                        # Temperature scaling ì ìš©\n",
    "                        preds = temp_scaling(preds)\n",
    "                        probs = torch.softmax(preds, dim=1)\n",
    "                        \n",
    "                        # ì•™ìƒë¸” í™•ë¥ ì— ëˆ„ì \n",
    "                        model_ensemble_probs += probs / (len(models) * len(images_list))\n",
    "            \n",
    "            # í˜„ì¬ ëª¨ë¸ì˜ ì‹ ë¢°ë„ ê³„ì‚°\n",
    "            max_probs = torch.max(model_ensemble_probs, dim=1)[0]\n",
    "            batch_confidences = max_probs.cpu().numpy()\n",
    "            \n",
    "            final_preds = torch.argmax(model_ensemble_probs, dim=1)\n",
    "            \n",
    "            # ëª¨ë¸ë³„ ê²°ê³¼ ì €ì¥\n",
    "            model_predictions[model_key].extend(final_preds.cpu().numpy())\n",
    "            model_confidences[model_key].extend(batch_confidences)\n",
    "            \n",
    "            # ë°°ì¹˜ë³„ ì‹ ë¢°ë„ ë¶„ì„\n",
    "            high_conf_count = np.sum(batch_confidences >= confidence_threshold)\n",
    "            low_conf_count = batch_size - high_conf_count\n",
    "            avg_confidence = np.mean(batch_confidences)\n",
    "            \n",
    "            progress_table.add_data(batch_idx, avg_confidence, low_conf_count, high_conf_count)\n",
    "            \n",
    "            # ë°°ì¹˜ë³„ ìƒì„¸ ë¡œê¹… (20ë°°ì¹˜ë§ˆë‹¤)\n",
    "            if batch_idx % 20 == 0:\n",
    "                elapsed_time = time.time() - model_start_time\n",
    "                try:\n",
    "                    main_run.log({\n",
    "                        f\"tta_progress/{model_key}_batch\": batch_idx,\n",
    "                        f\"tta_progress/{model_key}_avg_confidence\": avg_confidence,\n",
    "                        f\"tta_progress/{model_key}_high_confidence_ratio\": high_conf_count / batch_size,\n",
    "                        f\"tta_progress/{model_key}_elapsed_time_min\": elapsed_time / 60,\n",
    "                    })\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        model_time = time.time() - model_start_time\n",
    "        model_avg_confidence = np.mean(model_confidences[model_key])\n",
    "        \n",
    "        # ëª¨ë¸ë³„ ìµœì¢… ê²°ê³¼ ë¡œê¹…\n",
    "        try:\n",
    "            main_run.log({\n",
    "                f\"tta_results/{model_key}_time_min\": model_time / 60,\n",
    "                f\"tta_results/{model_key}_avg_confidence\": model_avg_confidence,\n",
    "                f\"tta_results/{model_key}_confidence_std\": np.std(model_confidences[model_key]),\n",
    "                f\"tta_results/{model_key}_high_conf_samples\": np.sum(np.array(model_confidences[model_key]) >= confidence_threshold),\n",
    "                f\"tta_results/{model_key}_progress_table\": progress_table\n",
    "            })\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        print(f\"âœ… {model_key} ì™„ë£Œ! ì†Œìš”ì‹œê°„: {model_time/60:.1f}ë¶„, í‰ê·  ì‹ ë¢°ë„: {model_avg_confidence:.4f}\")\n",
    "        \n",
    "        # ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    # =============================================================================\n",
    "    # ëª¨ë¸ ê°„ ì•™ìƒë¸” (ë‹¨ìˆœ í‰ê· ìœ¼ë¡œ ì‹œì‘)\n",
    "    # =============================================================================\n",
    "    \n",
    "    print(f\"\\nğŸ”— ëª¨ë¸ ê°„ ì•™ìƒë¸” ìˆ˜í–‰ ì¤‘...\")\n",
    "    \n",
    "    for i in range(len(multi_tta_dataset)):\n",
    "        # ê° ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ ë‹¨ìˆœ í‰ê· \n",
    "        ensemble_pred_probs = []\n",
    "        for model_key in ACTIVE_MODELS:\n",
    "            # ì˜ˆì¸¡ì„ one-hotìœ¼ë¡œ ë³€í™˜ í›„ í‰ê· \n",
    "            pred = model_predictions[model_key][i]\n",
    "            confidence = model_confidences[model_key][i]\n",
    "            \n",
    "            # ì‹ ë¢°ë„ë¥¼ ê³ ë ¤í•œ soft voting\n",
    "            prob_vector = np.zeros(17)\n",
    "            prob_vector[pred] = confidence\n",
    "            ensemble_pred_probs.append(prob_vector)\n",
    "        \n",
    "        # ë‹¨ìˆœ í‰ê· \n",
    "        final_prob = np.mean(ensemble_pred_probs, axis=0)\n",
    "        final_pred = np.argmax(final_prob)\n",
    "        final_confidence = np.max(final_prob)\n",
    "        \n",
    "        all_predictions.append(final_pred)\n",
    "        all_confidences.append(final_confidence)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # =============================================================================\n",
    "    # ìµœì¢… ì•™ìƒë¸” ê²°ê³¼ ë¶„ì„ ë° ë¡œê¹…\n",
    "    # =============================================================================\n",
    "    \n",
    "    final_avg_confidence = np.mean(all_confidences)\n",
    "    confidence_std = np.std(all_confidences)\n",
    "    high_conf_samples = np.sum(np.array(all_confidences) >= confidence_threshold)\n",
    "    \n",
    "    print(f\"\\nâœ… ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸” TTA ì™„ë£Œ!\")\n",
    "    print(f\"â° ì´ ì†Œìš”ì‹œê°„: {total_time/60:.1f}ë¶„\")\n",
    "    print(f\"ğŸ¯ ìµœì¢… í‰ê·  ì‹ ë¢°ë„: {final_avg_confidence:.4f} Â± {confidence_std:.4f}\")\n",
    "    print(f\"ğŸ† ê³ ì‹ ë¢°ë„ ìƒ˜í”Œ: {high_conf_samples}/{len(all_predictions)} ({high_conf_samples/len(all_predictions)*100:.1f}%)\")\n",
    "    \n",
    "    # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¶„ì„\n",
    "    print(f\"\\nğŸ“Š ëª¨ë¸ë³„ ì‹ ë¢°ë„ ë¶„ì„:\")\n",
    "    for model_key in ACTIVE_MODELS:\n",
    "        model_avg_conf = np.mean(model_confidences[model_key])\n",
    "        model_high_conf = np.sum(np.array(model_confidences[model_key]) >= confidence_threshold)\n",
    "        print(f\"  {model_key:12s}: í‰ê·  {model_avg_conf:.4f}, ê³ ì‹ ë¢°ë„ {model_high_conf}/{len(model_confidences[model_key])} ({model_high_conf/len(model_confidences[model_key])*100:.1f}%)\")\n",
    "    \n",
    "    # ìµœì¢… ê²°ê³¼ ë¡œê¹…\n",
    "    try:\n",
    "        main_run.log({\n",
    "            \"final_ensemble/total_time_min\": total_time / 60,\n",
    "            \"final_ensemble/samples_per_second\": len(all_predictions) / total_time,\n",
    "            \"final_ensemble/final_avg_confidence\": final_avg_confidence,\n",
    "            \"final_ensemble/confidence_std\": confidence_std,\n",
    "            \"final_ensemble/high_confidence_samples\": high_conf_samples,\n",
    "            \"final_ensemble/high_confidence_ratio\": high_conf_samples / len(all_predictions),\n",
    "            \"final_ensemble/total_predictions\": len(all_predictions),\n",
    "            \"final_ensemble/confidence_histogram\": wandb.Histogram(all_confidences),\n",
    "            \"final_ensemble/ensemble_method\": \"simple_average\",\n",
    "            \"final_ensemble/num_model_types\": len(ACTIVE_MODELS),\n",
    "        })\n",
    "        \n",
    "        # ëª¨ë¸ë³„ ê°œë³„ ì„±ëŠ¥ë„ ë¡œê¹…\n",
    "        for model_key in ACTIVE_MODELS:\n",
    "            main_run.log({\n",
    "                f\"model_performance/{model_key}_avg_confidence\": np.mean(model_confidences[model_key]),\n",
    "                f\"model_performance/{model_key}_confidence_std\": np.std(model_confidences[model_key]),\n",
    "                f\"model_performance/{model_key}_high_conf_ratio\": np.sum(np.array(model_confidences[model_key]) >= confidence_threshold) / len(model_confidences[model_key])\n",
    "            })\n",
    "        \n",
    "        print(\"ğŸ“Š ìµœì¢… ì•™ìƒë¸” ê²°ê³¼ WandB ë¡œê¹… ì™„ë£Œ!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ WandB ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "    \n",
    "    return all_predictions, all_confidences, model_predictions, model_confidences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Resolution Ensemble TTA ì‹¤í–‰\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ¯ ìµœì¢… ì¶”ë¡  - ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸” + TTA\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "multi_tta_predictions, multi_confidences, individual_model_preds, individual_model_confs = multi_resolution_ensemble_tta_inference(\n",
    "    ensemble_models=ensemble_models,\n",
    "    loaders=multi_tta_loaders,\n",
    "    multi_transforms=multi_res_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-Resolution Results and Submission\n",
    "\n",
    "print(f\"\\nğŸ“Š ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸” ê²°ê³¼ ì •ë¦¬ ì¤‘...\")\n",
    "\n",
    "# ìµœì¢… submission íŒŒì¼ ìƒì„±\n",
    "multi_pred_df = pd.DataFrame(multi_tta_dataset.df, columns=['ID', 'target'])\n",
    "multi_pred_df['target'] = multi_tta_predictions\n",
    "\n",
    "# ID ìˆœì„œ í™•ì¸\n",
    "sample_submission_df = pd.read_csv(\"/root/home/cv_contest/CV_data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == multi_pred_df['ID']).all(), \"âŒ ID ìˆœì„œ ë¶ˆì¼ì¹˜!\"\n",
    "\n",
    "# ì˜ˆì¸¡ ë¶„í¬ ë¶„ì„\n",
    "pred_distribution = multi_pred_df['target'].value_counts().sort_index()\n",
    "pred_table = wandb.Table(columns=[\"Class\", \"Count\", \"Percentage\", \"Swin_B_Count\", \"ConvNeXt_Count\"])\n",
    "\n",
    "print(f\"\\nğŸ“Š ìµœì¢… ì˜ˆì¸¡ ê²°ê³¼ ë¶„í¬ (ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸”):\")\n",
    "for class_id in range(17):\n",
    "    final_count = pred_distribution.get(class_id, 0)\n",
    "    final_percentage = final_count / len(multi_pred_df) * 100\n",
    "    \n",
    "    # ê° ëª¨ë¸ë³„ ì˜ˆì¸¡ ë¶„í¬ë„ í™•ì¸\n",
    "    swin_count = np.sum(np.array(individual_model_preds['swin_b']) == class_id) if 'swin_b' in individual_model_preds else 0\n",
    "    convnext_count = np.sum(np.array(individual_model_preds['convnext']) == class_id) if 'convnext' in individual_model_preds else 0\n",
    "    \n",
    "    pred_table.add_data(class_id, final_count, final_percentage, swin_count, convnext_count)\n",
    "    print(f\"Class {class_id:2d}: {final_count:4d} ({final_percentage:5.1f}%) [Swin-B: {swin_count}, ConvNeXt: {convnext_count}]\")\n",
    "\n",
    "# ì‹ ë¢°ë„ ìƒì„¸ ë¶„ì„\n",
    "confidence_analysis = {}\n",
    "confidence_bins = [0.5, 0.7, 0.8, 0.9, 0.95, 1.0]\n",
    "for i, threshold in enumerate(confidence_bins):\n",
    "    if i == 0:\n",
    "        count = np.sum(np.array(multi_confidences) >= threshold)\n",
    "    else:\n",
    "        prev_threshold = confidence_bins[i-1]\n",
    "        count = np.sum((np.array(multi_confidences) >= prev_threshold) & (np.array(multi_confidences) < threshold))\n",
    "    confidence_analysis[f\"conf_{threshold}\"] = count\n",
    "\n",
    "# ìµœì¢… ê²°ê³¼ ë¡œê¹…\n",
    "try:\n",
    "    main_run.log({\n",
    "        \"final_results/multi_resolution\": True,\n",
    "        \"final_results/total_predictions\": len(multi_tta_predictions),\n",
    "        \"final_results/unique_classes_predicted\": len(np.unique(multi_tta_predictions)),\n",
    "        \"final_results/prediction_distribution_table\": pred_table,\n",
    "        \"final_results/avg_confidence\": np.mean(multi_confidences),\n",
    "        \"final_results/median_confidence\": np.median(multi_confidences),\n",
    "        \"final_results/min_confidence\": np.min(multi_confidences),\n",
    "        \"final_results/max_confidence\": np.max(multi_confidences),\n",
    "        \"final_results/confidence_distribution\": wandb.Histogram(multi_confidences),\n",
    "        \"final_results/ensemble_type\": \"multi_resolution_simple_average\",\n",
    "        **confidence_analysis\n",
    "    })\n",
    "    \n",
    "    # ì˜ˆì¸¡ ë¶„í¬ ë°”ì°¨íŠ¸\n",
    "    pred_dist_data = [[f\"Class_{i}\", pred_distribution.get(i, 0)] for i in range(17)]\n",
    "    main_run.log({\n",
    "        \"final_results/prediction_distribution_chart\": wandb.plot.bar(\n",
    "            wandb.Table(data=pred_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "            \"Class\", \"Count\", \n",
    "            title=\"Multi-Resolution Ensemble Prediction Distribution\"\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(\"ğŸ“Š ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸” ê²°ê³¼ ë¡œê¹… ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ WandB ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥\n",
    "output_path = f\"/root/home/cv_contest/results/multiRes_ensemble_{datetime.now().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "multi_pred_df.to_csv(output_path, index=False)\n",
    "\n",
    "# ê²°ê³¼ íŒŒì¼ì„ WandB ì•„í‹°íŒ©íŠ¸ë¡œ ì €ì¥\n",
    "try:\n",
    "    artifact = wandb.Artifact(\n",
    "        name=\"multi_resolution_ensemble_predictions\",\n",
    "        type=\"predictions\",\n",
    "        description=f\"Multi-Resolution Ensemble (Swin-B + ConvNeXt) predictions with {N_FOLDS}-fold CV + TTA\"\n",
    "    )\n",
    "    artifact.add_file(output_path)\n",
    "    main_run.log_artifact(artifact)\n",
    "    print(\"ğŸ“¦ ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸” ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì¤‘ ì—ëŸ¬: {e}\")\n",
    "\n",
    "print(f\"\\nâœ… ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸” ê²°ê³¼ ì €ì¥ ì™„ë£Œ!\")\n",
    "print(f\"ğŸ“ íŒŒì¼ ìœ„ì¹˜: {output_path}\")\n",
    "print(f\"ğŸ“ˆ ì´ ì˜ˆì¸¡ ìˆ˜: {len(multi_tta_predictions)}\")\n",
    "print(f\"ğŸ¤– ì‚¬ìš©ëœ ëª¨ë¸: {', '.join(ACTIVE_MODELS)}\")\n",
    "print(f\"ğŸ”¥ ì‚¬ìš©ëœ í•´ìƒë„: {', '.join([f'{k}={v}px' for k, v in img_sizes.items()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ë³„ ê°œë³„ ê²°ê³¼ íŒŒì¼ë„ ì €ì¥\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    individual_pred_df = pd.DataFrame(multi_tta_dataset.df, columns=['ID', 'target'])\n",
    "    individual_pred_df['target'] = individual_model_preds[model_key]\n",
    "    \n",
    "    individual_output_path = f\"/root/home/cv_contest/results/{model_key}_individual_{datetime.now().strftime('%Y%m%d_%H%M')}.csv\"\n",
    "    individual_pred_df.to_csv(individual_output_path, index=False)\n",
    "    \n",
    "    # ê°œë³„ ëª¨ë¸ ê²°ê³¼ ìš”ì•½\n",
    "    individual_dist = individual_pred_df['target'].value_counts().sort_index()\n",
    "    individual_avg_conf = np.mean(individual_model_confs[model_key])\n",
    "    \n",
    "    print(f\"ğŸ“ {model_key} ê°œë³„ ê²°ê³¼: {individual_output_path}\")\n",
    "    print(f\"   í‰ê·  ì‹ ë¢°ë„: {individual_avg_conf:.4f}\")\n",
    "    \n",
    "    # WandBì— ê°œë³„ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥\n",
    "    try:\n",
    "        individual_artifact = wandb.Artifact(\n",
    "            name=f\"{model_key}_individual_predictions\",\n",
    "            type=\"individual_predictions\",\n",
    "            description=f\"{model_key} individual predictions with {N_FOLDS}-fold CV + TTA\"\n",
    "        )\n",
    "        individual_artifact.add_file(individual_output_path)\n",
    "        main_run.log_artifact(individual_artifact)\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ {model_key} ê°œë³„ ì•„í‹°íŒ©íŠ¸ ì €ì¥ ì¤‘ ì—ëŸ¬: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìµœì¢… ì‹¤í—˜ ìš”ì•½ ë° ì •ë¦¬\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸” ì‹¤í—˜ ì™„ë£Œ!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# ì „ì²´ ì‹¤í—˜ ìš”ì•½\n",
    "total_models_trained = len(ACTIVE_MODELS) * N_FOLDS\n",
    "total_tta_transforms = sum(len(transforms) for transforms in multi_res_tta_transforms.values())\n",
    "total_predictions_per_sample = total_models_trained * (total_tta_transforms // len(ACTIVE_MODELS))\n",
    "\n",
    "print(f\"ğŸ“Š ì‹¤í—˜ ìš”ì•½:\")\n",
    "print(f\"   ğŸ¤– ì‚¬ìš©ëœ ì•„í‚¤í…ì²˜: {len(ACTIVE_MODELS)}ê°œ ({', '.join(ACTIVE_MODELS)})\")\n",
    "print(f\"   ğŸ“ ì´ í•™ìŠµëœ ëª¨ë¸: {total_models_trained}ê°œ ({N_FOLDS}-Fold CV)\")\n",
    "print(f\"   ğŸ”„ TTA ë³€í˜•: ëª¨ë¸ë‹¹ í‰ê·  {total_tta_transforms // len(ACTIVE_MODELS)}ê°œ\")\n",
    "print(f\"   ğŸ¯ ìƒ˜í”Œë‹¹ ì˜ˆì¸¡ ìˆ˜: {total_predictions_per_sample}ê°œ\")\n",
    "print(f\"   ğŸ“ˆ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ: {len(multi_tta_predictions)}ê°œ\")\n",
    "\n",
    "# CV ê²°ê³¼ ìš”ì•½\n",
    "print(f\"\\nğŸ“Š Cross-Validation ê²°ê³¼:\")\n",
    "cv_summary_table = wandb.Table(columns=[\"Model\", \"Mean_F1\", \"Std_F1\", \"Best_Fold\", \"Worst_Fold\", \"Architecture\"])\n",
    "\n",
    "for model_key in ACTIVE_MODELS:\n",
    "    val_f1_scores = [result['best_val_f1'] for result in all_fold_results[model_key]]\n",
    "    mean_f1 = np.mean(val_f1_scores)\n",
    "    std_f1 = np.std(val_f1_scores)\n",
    "    best_f1 = max(val_f1_scores)\n",
    "    worst_f1 = min(val_f1_scores)\n",
    "    architecture = MODEL_CONFIGS[model_key]['architecture']\n",
    "    \n",
    "    cv_summary_table.add_data(model_key, mean_f1, std_f1, best_f1, worst_f1, architecture)\n",
    "    print(f\"   {model_key:12s}: {mean_f1:.4f} Â± {std_f1:.4f} (ë²”ìœ„: {worst_f1:.4f} ~ {best_f1:.4f})\")\n",
    "\n",
    "# ìµœì¢… ì„±ëŠ¥ ì§€í‘œ\n",
    "final_metrics = {\n",
    "    \"experiment_type\": \"multi_resolution_ensemble\",\n",
    "    \"total_experiment_time_hours\": (time.time() - start_time) / 3600,\n",
    "    \"models_trained\": total_models_trained,\n",
    "    \"cv_folds\": N_FOLDS,\n",
    "    \"tta_transforms_total\": total_tta_transforms,\n",
    "    \"test_samples\": len(multi_tta_predictions),\n",
    "    \"unique_classes_in_prediction\": len(np.unique(multi_tta_predictions)),\n",
    "    \"final_ensemble_confidence\": np.mean(multi_confidences),\n",
    "    \"high_confidence_predictions_ratio\": np.sum(np.array(multi_confidences) >= 0.9) / len(multi_confidences),\n",
    "    \"cv_summary_table\": cv_summary_table\n",
    "}\n",
    "\n",
    "# ìµœì¢… WandB ë¡œê¹…\n",
    "try:\n",
    "    main_run.log(final_metrics)\n",
    "    \n",
    "    # ì‹¤í—˜ ìš”ì•½ í…ìŠ¤íŠ¸\n",
    "    experiment_summary = f\"\"\"\n",
    "# Multi-Resolution Ensemble Experiment Summary\n",
    "\n",
    "## Models Used\n",
    "- **Swin Transformer Base**: {MODEL_CONFIGS['swin_b']['img_size']}px resolution\n",
    "- **ConvNeXt Base**: {MODEL_CONFIGS['convnext']['img_size']}px resolution\n",
    "\n",
    "## Training Strategy\n",
    "- **Cross-Validation**: {N_FOLDS}-Fold Stratified\n",
    "- **Total Models Trained**: {total_models_trained}\n",
    "- **Test Time Augmentation**: {total_tta_transforms // len(ACTIVE_MODELS)} transforms per model\n",
    "\n",
    "## Performance\n",
    "- **Final Ensemble Confidence**: {np.mean(multi_confidences):.4f}\n",
    "- **High Confidence Predictions**: {np.sum(np.array(multi_confidences) >= 0.9)}/{len(multi_confidences)} ({np.sum(np.array(multi_confidences) >= 0.9)/len(multi_confidences)*100:.1f}%)\n",
    "\n",
    "## CV Results\n",
    "{chr(10).join([f\"- **{model_key}**: {np.mean([r['best_val_f1'] for r in all_fold_results[model_key]]):.4f} Â± {np.std([r['best_val_f1'] for r in all_fold_results[model_key]]):.4f}\" for model_key in ACTIVE_MODELS])}\n",
    "    \"\"\"\n",
    "    \n",
    "    main_run.summary.update({\n",
    "        \"experiment_summary\": experiment_summary,\n",
    "        \"best_cv_f1\": max([np.mean([r['best_val_f1'] for r in all_fold_results[model_key]]) for model_key in ACTIVE_MODELS]),\n",
    "        \"total_runtime_hours\": (time.time() - start_time) / 3600,\n",
    "        \"final_prediction_file\": output_path,\n",
    "        \"ensemble_method\": \"multi_resolution_average\"\n",
    "    })\n",
    "    \n",
    "    print(\"ğŸ“Š ìµœì¢… ì‹¤í—˜ ìš”ì•½ WandB ë¡œê¹… ì™„ë£Œ!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ ìµœì¢… ë¡œê¹… ì¤‘ ì—ëŸ¬: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ì‹¤í—˜ ì¢…ë£Œ\n",
    "\n",
    "# GPU ë©”ëª¨ë¦¬ ì •ë¦¬\n",
    "if torch.cuda.is_available():\n",
    "    for model_key in ensemble_models:\n",
    "        for model in ensemble_models[model_key]:\n",
    "            del model\n",
    "    del ensemble_models\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"ğŸ§¹ GPU ë©”ëª¨ë¦¬ ì •ë¦¬ ì™„ë£Œ\")\n",
    "\n",
    "# WandB ì‹¤í—˜ ì¢…ë£Œ\n",
    "main_run.finish()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"ğŸ‰ ë‹¤ì¤‘ í•´ìƒë„ ì•™ìƒë¸” ì‹¤í—˜ ì™„ë£Œ!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"ğŸ“ ìµœì¢… ê²°ê³¼ íŒŒì¼: {output_path}\")\n",
    "print(f\"ğŸ“Š WandB í”„ë¡œì íŠ¸: {PROJECT_NAME}\")\n",
    "print(f\"â° ì´ ì‹¤í–‰ ì‹œê°„: {(time.time() - start_time) / 3600:.1f}ì‹œê°„\")\n",
    "print(f\"ğŸ† ìµœì¢… ì•™ìƒë¸” í‰ê·  ì‹ ë¢°ë„: {np.mean(multi_confidences):.4f}\")\n",
    "print(f\"ğŸ¯ ê³ ì‹ ë¢°ë„ ì˜ˆì¸¡ ë¹„ìœ¨: {np.sum(np.array(multi_confidences) >= 0.9)/len(multi_confidences)*100:.1f}%\")\n",
    "\n",
    "# ìµœì¢… ì„±ê³µ ë©”ì‹œì§€\n",
    "print(f\"\\nâœ¨ ì‹¤í—˜ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "print(f\"ğŸ“ˆ ê²°ê³¼ë¥¼ WandB ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
