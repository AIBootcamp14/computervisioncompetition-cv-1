{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "OliaDaX_lwou"
   },
   "source": [
    "# **📄 Document type classification baseline code**\n",
    "> 문서 타입 분류 대회에 오신 여러분 환영합니다! 🎉     \n",
    "> 아래 baseline에서는 ResNet 모델을 로드하여, 모델을 학습 및 예측 파일 생성하는 프로세스에 대해 알아보겠습니다.\n",
    "\n",
    "## Contents\n",
    "- Prepare Environments\n",
    "- Import Library & Define Functions\n",
    "- Hyper-parameters\n",
    "- Load Data\n",
    "- Train Model\n",
    "- Inference & Save File\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n",
    "* 필요한 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# 필요한 라이브러리를 설치합니다.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precision용\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 설정 (시각화용)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다. (Hard Augmentation 포함)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation 확률 계산\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "                A.Rotate(limit=[-15,15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # 배치별 증강 선택\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    scaler = GradScaler()  # Mixed Precision용\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Cutmix/Mixup 적용 (30% 확률)\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        scaler.scale(loss).backward()  # Mixed Precision용\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()  # Mixed Precision용\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation을 위한 함수 추가\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    한 에폭 검증을 수행하는 함수\n",
    "    - model.eval()로 모델을 평가 모드로 전환\n",
    "    - torch.no_grad()로 gradient 계산 비활성화하여 메모리 절약\n",
    "    - 검증 데이터에 대한 loss, accuracy, f1 score 계산\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 전환 (dropout, batchnorm 비활성화)\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():  # gradient 계산 비활성화로 메모리 절약\n",
    "        pbar = tqdm(loader, desc=\"Validating\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)  # 모델 예측\n",
    "            loss = loss_fn(preds, targets)  # 손실 계산\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())  # 예측 클래스 저장\n",
    "            targets_list.extend(targets.detach().cpu().numpy())  # 실제 클래스 저장\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)  # 평균 손실 계산\n",
    "    val_acc = accuracy_score(targets_list, preds_list)  # 정확도 계산\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')  # Macro F1 계산 (대회 평가지표)\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'tf_efficientnetv2_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "model_name = 'swin_base_patch4_window12_384_in22k'\n",
    "\n",
    "# training config\n",
    "img_size = 384\n",
    "LR = 5e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna를 사용한 하이퍼파라미터 튜닝 (선택적 실행)\n",
    "USE_OPTUNA = False  # True로 바꾸면 튜닝 실행\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # 간단한 3-fold CV로 빠른 평가\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf_simple.split(train_df, train_df['target'])):\n",
    "            # 모델 생성\n",
    "            model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "            optimizer = Adam(model.parameters(), lr=lr)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # 간단한 2 epoch 학습\n",
    "            for epoch in range(2):\n",
    "                train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "            \n",
    "            val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "            fold_scores.append(val_ret['val_f1'])\n",
    "        \n",
    "        return np.mean(fold_scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # 최적 파라미터 적용\n",
    "    LR = study.best_params['lr']\n",
    "    BATCH_SIZE = study.best_params['batch_size']\n",
    "    print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "llh5C7ZKoq2S"
   },
   "outputs": [],
   "source": [
    "# # augmentation을 위한 transform 코드\n",
    "# trn_transform = A.Compose([\n",
    "#     # 비율 보존 리사이징 (핵심 개선)\n",
    "#     A.LongestMaxSize(max_size=img_size),\n",
    "#     A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "#                   border_mode=0, value=0),\n",
    "    \n",
    "#     # 문서 특화 회전 (정확한 90도 배수)\n",
    "#     A.OneOf([\n",
    "#         A.Rotate(limit=[90,90], p=1.0),\n",
    "#         A.Rotate(limit=[180,180], p=1.0),\n",
    "#         A.Rotate(limit=[270,270], p=1.0),\n",
    "#     ], p=0.6),\n",
    "    \n",
    "#     # 테스트 특화 강화 증강\n",
    "#     A.OneOf([\n",
    "#         A.MotionBlur(blur_limit=7, p=1.0),\n",
    "#         A.GaussianBlur(blur_limit=7, p=1.0),\n",
    "#     ], p=0.9),\n",
    "    \n",
    "#     A.RandomBrightnessContrast(\n",
    "#         brightness_limit=0.3, \n",
    "#         contrast_limit=0.3, \n",
    "#         p=0.8\n",
    "#     ),\n",
    "#     A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "    \n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "\n",
    "# # test image 변환을 위한 transform 코드\n",
    "# tst_transform = A.Compose([\n",
    "#     A.LongestMaxSize(max_size=img_size),\n",
    "#     A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "#                   border_mode=0, value=0),\n",
    "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "#     ToTensorV2(),\n",
    "# ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 튜닝 (선택적 실행)\n",
    "USE_OPTUNA = False  # True로 바꾸면 튜닝 실행\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    # 위의 objective 함수와 study 코드\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2568: 100%|██████████| 40/40 [00:28<00:00,  1.39it/s]\n",
      "Val Loss: 1.2543: 100%|██████████| 10/10 [00:05<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.0037 | Train F1: 0.3924 | Val Loss: 1.2250 | Val F1: 0.7012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.5098: 100%|██████████| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.9347: 100%|██████████| 10/10 [00:05<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.3746 | Train F1: 0.5983 | Val Loss: 0.9079 | Val F1: 0.8271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4961: 100%|██████████| 40/40 [00:23<00:00,  1.73it/s]\n",
      "Val Loss: 0.8580: 100%|██████████| 10/10 [00:05<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1536 | Train F1: 0.7071 | Val Loss: 0.8506 | Val F1: 0.8710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.0938: 100%|██████████| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.8557: 100%|██████████| 10/10 [00:05<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.0688 | Train F1: 0.7358 | Val Loss: 0.8185 | Val F1: 0.8909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8721: 100%|██████████| 40/40 [00:23<00:00,  1.73it/s]\n",
      "Val Loss: 0.9290: 100%|██████████| 10/10 [00:05<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.9993 | Train F1: 0.7650 | Val Loss: 0.8067 | Val F1: 0.8809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6841: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.7925: 100%|██████████| 10/10 [00:05<00:00,  1.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.9764 | Train F1: 0.7658 | Val Loss: 0.7626 | Val F1: 0.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7461: 100%|██████████| 40/40 [00:23<00:00,  1.73it/s]\n",
      "Val Loss: 0.8077: 100%|██████████| 10/10 [00:05<00:00,  1.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.9320 | Train F1: 0.7911 | Val Loss: 0.7977 | Val F1: 0.8995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7148: 100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Val Loss: 0.7669: 100%|██████████| 10/10 [00:05<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.8693 | Train F1: 0.7889 | Val Loss: 0.7471 | Val F1: 0.9160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6680: 100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Val Loss: 0.7765: 100%|██████████| 10/10 [00:05<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.8322 | Train F1: 0.7679 | Val Loss: 0.7373 | Val F1: 0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.2031: 100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Val Loss: 0.6800: 100%|██████████| 10/10 [00:05<00:00,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.7897 | Train F1: 0.8757 | Val Loss: 0.7122 | Val F1: 0.9433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 Best Validation F1: 0.9433\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7656: 100%|██████████| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 1.2158: 100%|██████████| 10/10 [00:05<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.0549 | Train F1: 0.3884 | Val Loss: 1.2339 | Val F1: 0.6774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4238: 100%|██████████| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.9607: 100%|██████████| 10/10 [00:05<00:00,  1.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.3296 | Train F1: 0.6582 | Val Loss: 0.9992 | Val F1: 0.7915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7661: 100%|██████████| 40/40 [00:24<00:00,  1.61it/s]\n",
      "Val Loss: 0.8482: 100%|██████████| 10/10 [00:05<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1885 | Train F1: 0.6505 | Val Loss: 0.9753 | Val F1: 0.7967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6875: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.7373: 100%|██████████| 10/10 [00:05<00:00,  1.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.1606 | Train F1: 0.7002 | Val Loss: 0.8345 | Val F1: 0.8683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6187: 100%|██████████| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.7280: 100%|██████████| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.9925 | Train F1: 0.7433 | Val Loss: 0.8435 | Val F1: 0.8718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.4668: 100%|██████████| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.7610: 100%|██████████| 10/10 [00:05<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 1.0898 | Train F1: 0.6762 | Val Loss: 0.7824 | Val F1: 0.9005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.0742: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.7390: 100%|██████████| 10/10 [00:05<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.8944 | Train F1: 0.8248 | Val Loss: 0.7706 | Val F1: 0.8967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8145: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.8169: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.9144 | Train F1: 0.7732 | Val Loss: 0.7426 | Val F1: 0.9062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5928: 100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Val Loss: 0.6601: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.8251 | Train F1: 0.8534 | Val Loss: 0.7304 | Val F1: 0.9165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5869: 100%|██████████| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.7006: 100%|██████████| 10/10 [00:05<00:00,  1.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.8354 | Train F1: 0.8665 | Val Loss: 0.7199 | Val F1: 0.9339\n",
      "Fold 2 Best Validation F1: 0.9339\n",
      "\n",
      "==================================================\n",
      "FOLD 3/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8379: 100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Val Loss: 1.0537: 100%|██████████| 10/10 [00:06<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.8609 | Train F1: 0.4330 | Val Loss: 1.1624 | Val F1: 0.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9497: 100%|██████████| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.9336: 100%|██████████| 10/10 [00:05<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.2588 | Train F1: 0.6638 | Val Loss: 0.9955 | Val F1: 0.8115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.0273: 100%|██████████| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.9964: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1731 | Train F1: 0.6881 | Val Loss: 0.9388 | Val F1: 0.8125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7451: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.8878: 100%|██████████| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.0623 | Train F1: 0.8017 | Val Loss: 0.9158 | Val F1: 0.8331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9346: 100%|██████████| 40/40 [00:24<00:00,  1.67it/s]\n",
      "Val Loss: 0.8060: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 1.0380 | Train F1: 0.7860 | Val Loss: 0.8307 | Val F1: 0.8321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0234: 100%|██████████| 40/40 [00:24<00:00,  1.64it/s]\n",
      "Val Loss: 0.8034: 100%|██████████| 10/10 [00:05<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 1.0292 | Train F1: 0.7097 | Val Loss: 0.8051 | Val F1: 0.8755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8418: 100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Val Loss: 0.6771: 100%|██████████| 10/10 [00:05<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.8879 | Train F1: 0.8138 | Val Loss: 0.7435 | Val F1: 0.9152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8403: 100%|██████████| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.7552: 100%|██████████| 10/10 [00:05<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.8695 | Train F1: 0.7996 | Val Loss: 0.7661 | Val F1: 0.8772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1875: 100%|██████████| 40/40 [00:24<00:00,  1.67it/s]\n",
      "Val Loss: 0.6587: 100%|██████████| 10/10 [00:06<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.9242 | Train F1: 0.7836 | Val Loss: 0.7384 | Val F1: 0.9018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7476: 100%|██████████| 40/40 [00:23<00:00,  1.71it/s]\n",
      "Val Loss: 0.7223: 100%|██████████| 10/10 [00:05<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.8906 | Train F1: 0.7861 | Val Loss: 0.7336 | Val F1: 0.9231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 Best Validation F1: 0.9231\n",
      "\n",
      "==================================================\n",
      "FOLD 4/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.8125: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 1.2690: 100%|██████████| 10/10 [00:06<00:00,  1.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.8967 | Train F1: 0.4354 | Val Loss: 1.1877 | Val F1: 0.6869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8281: 100%|██████████| 40/40 [00:25<00:00,  1.59it/s]\n",
      "Val Loss: 0.8655: 100%|██████████| 10/10 [00:05<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.2584 | Train F1: 0.6846 | Val Loss: 0.9315 | Val F1: 0.8163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1738: 100%|██████████| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.7446: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1393 | Train F1: 0.7340 | Val Loss: 0.8615 | Val F1: 0.8682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.0586: 100%|██████████| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 0.7321: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.0290 | Train F1: 0.8045 | Val Loss: 0.8485 | Val F1: 0.8674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6875: 100%|██████████| 40/40 [00:24<00:00,  1.64it/s]\n",
      "Val Loss: 0.7267: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 1.1025 | Train F1: 0.6329 | Val Loss: 0.7986 | Val F1: 0.8726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7959: 100%|██████████| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.7176: 100%|██████████| 10/10 [00:05<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.9432 | Train F1: 0.7542 | Val Loss: 0.7619 | Val F1: 0.8825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6064: 100%|██████████| 40/40 [00:24<00:00,  1.64it/s]\n",
      "Val Loss: 0.7410: 100%|██████████| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.9213 | Train F1: 0.8463 | Val Loss: 0.7527 | Val F1: 0.9099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6216: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.6782: 100%|██████████| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7799 | Train F1: 0.8710 | Val Loss: 0.7419 | Val F1: 0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8149: 100%|██████████| 40/40 [00:23<00:00,  1.70it/s]\n",
      "Val Loss: 0.6772: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.8641 | Train F1: 0.8003 | Val Loss: 0.7257 | Val F1: 0.9232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1309: 100%|██████████| 40/40 [00:24<00:00,  1.66it/s]\n",
      "Val Loss: 0.6831: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.8361 | Train F1: 0.8171 | Val Loss: 0.7205 | Val F1: 0.9385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 4 Best Validation F1: 0.9385\n",
      "\n",
      "==================================================\n",
      "FOLD 5/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4404: 100%|██████████| 40/40 [00:23<00:00,  1.72it/s]\n",
      "Val Loss: 1.1429: 100%|██████████| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.8431 | Train F1: 0.4658 | Val Loss: 1.1814 | Val F1: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1533: 100%|██████████| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.9244: 100%|██████████| 10/10 [00:05<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.2735 | Train F1: 0.6794 | Val Loss: 1.0413 | Val F1: 0.7588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8516: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.8607: 100%|██████████| 10/10 [00:05<00:00,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1440 | Train F1: 0.7158 | Val Loss: 0.9533 | Val F1: 0.8105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7754: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.8276: 100%|██████████| 10/10 [00:05<00:00,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.0708 | Train F1: 0.7348 | Val Loss: 0.9054 | Val F1: 0.8477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6709: 100%|██████████| 40/40 [00:23<00:00,  1.68it/s]\n",
      "Val Loss: 0.7155: 100%|██████████| 10/10 [00:05<00:00,  1.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 1.0822 | Train F1: 0.6902 | Val Loss: 0.7993 | Val F1: 0.8812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7549: 100%|██████████| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.6740: 100%|██████████| 10/10 [00:05<00:00,  1.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.9325 | Train F1: 0.7900 | Val Loss: 0.8064 | Val F1: 0.8766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7256: 100%|██████████| 40/40 [00:23<00:00,  1.67it/s]\n",
      "Val Loss: 0.6516: 100%|██████████| 10/10 [00:06<00:00,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.9858 | Train F1: 0.7210 | Val Loss: 0.7639 | Val F1: 0.8993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6328: 100%|██████████| 40/40 [00:23<00:00,  1.69it/s]\n",
      "Val Loss: 0.6774: 100%|██████████| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.9197 | Train F1: 0.7872 | Val Loss: 0.7469 | Val F1: 0.9215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6069: 100%|██████████| 40/40 [00:24<00:00,  1.65it/s]\n",
      "Val Loss: 0.6574: 100%|██████████| 10/10 [00:05<00:00,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.7990 | Train F1: 0.8924 | Val Loss: 0.7354 | Val F1: 0.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7891: 100%|██████████| 40/40 [00:24<00:00,  1.61it/s]\n",
      "Val Loss: 0.6768: 100%|██████████| 10/10 [00:05<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.8995 | Train F1: 0.8129 | Val Loss: 0.7332 | Val F1: 0.9349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 5 Best Validation F1: 0.9349\n",
      "\n",
      "============================================================\n",
      "K-FOLD CROSS VALIDATION RESULTS\n",
      "============================================================\n",
      "Fold 1: 0.9433\n",
      "Fold 2: 0.9339\n",
      "Fold 3: 0.9231\n",
      "Fold 4: 0.9385\n",
      "Fold 5: 0.9349\n",
      "\n",
      "Mean CV F1: 0.9347 ± 0.0067\n",
      "Best single fold: 0.9433\n"
     ]
    }
   ],
   "source": [
    "# K-Fold 설정\n",
    "N_FOLDS = 5  # 5-fold로 설정 (데이터가 적으므로)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# 클래스별 최소 샘플 보장 확인\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "#     assert len(np.unique(train_df.iloc[val_idx]['target'])) == 17\n",
    "\n",
    "# 전체 학습 데이터 로드\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# K-Fold 결과를 저장할 리스트\n",
    "fold_results = []\n",
    "fold_models = []  # 각 fold의 최고 성능 모델을 저장\n",
    "fold_class_accuracies = [] # 각 fold의 클래스별 정확도 저장\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# LR = best_params['lr']\n",
    "# BATCH_SIZE = best_params['batch_size']\n",
    "\n",
    "# K-Fold Cross Validation 시작\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    current_model = model_name\n",
    "    \n",
    "    # 현재 fold의 train/validation 데이터 분할\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 현재 fold의 Dataset 생성\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=trn_transform\n",
    "        epoch=0,  # 현재 epoch 전달\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=tst_transform  # 검증에는 증강 적용 안함\n",
    "        epoch=0,  # validation은 epoch 관계없음\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False  # validation이므로 hard augmentation 비활성화\n",
    "    )\n",
    "    \n",
    "    # 현재 fold의 DataLoader 생성\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # 모델 초기화 (각 fold마다 새로운 모델)\n",
    "    model = timm.create_model(\n",
    "        current_model,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.1)  # Label Smoothing 적용\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler 추가\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # 현재 fold의 최고 성능 추적\n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # 현재 fold 학습\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # Scheduler step 추가\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # Best 모델 분석\n",
    "            model.eval()\n",
    "            val_preds, val_targets = [], []\n",
    "            with torch.no_grad():\n",
    "                for image, targets in val_loader:\n",
    "                    preds = model(image.to(device)).argmax(dim=1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_targets.extend(targets.numpy())\n",
    "            \n",
    "            # 클래스별 정확도\n",
    "            fold_class_acc = {}\n",
    "            for c in range(17):\n",
    "                mask = np.array(val_targets) == c\n",
    "                if mask.sum() > 0:\n",
    "                    fold_class_acc[c] = (np.array(val_preds)[mask] == c).mean()\n",
    "    \n",
    "    # 현재 fold 결과 저장\n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset)\n",
    "    })\n",
    "    \n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "    fold_class_accuracies.append(fold_class_acc) # 각 fold의 클래스별 정확도 저장\n",
    "\n",
    "# K-Fold 결과 요약\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"K-FOLD CROSS VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(val_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 3 classes:\n",
      "Class 7: 55.0%\n",
      "Class 14: 64.0%\n",
      "Class 3: 71.0%\n"
     ]
    }
   ],
   "source": [
    "# 클래스별 성능 시각화\n",
    "meta_df = pd.read_csv(\"../data/meta.csv\")\n",
    "avg_acc = {c: np.mean([f.get(c,0) for f in fold_class_accuracies]) for c in range(17)}\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "classes = list(avg_acc.keys())\n",
    "accs = [avg_acc[c] * 100 for c in classes]\n",
    "names = [f\"C{c}\" for c in classes]\n",
    "\n",
    "plt.bar(range(17), accs)\n",
    "plt.xticks(range(17), names)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Class-wise Prediction Accuracy')\n",
    "for i, acc in enumerate(accs):\n",
    "    plt.text(i, acc + 1, f'{acc:.1f}%', ha='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Worst 3 classes:\")\n",
    "worst = sorted(avg_acc.items(), key=lambda x: x[1])[:3]\n",
    "for c, acc in worst:\n",
    "    print(f\"Class {c}: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ensemble of all 5 fold models for inference\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "print(f\"Using ensemble of all {len(ensemble_models)} fold models for inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 870,
     "status": "ok",
     "timestamp": 1700315114067,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "FbBgFPsLT-CO"
   },
   "outputs": [],
   "source": [
    "# # load model\n",
    "# model = timm.create_model(\n",
    "#     model_name,\n",
    "#     pretrained=True,\n",
    "#     num_classes=17\n",
    "# ).to(device)\n",
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "# optimizer = Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8778,
     "status": "ok",
     "timestamp": 1700315122843,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "OvIVcSRgUPtS",
    "outputId": "88230bf2-976f-45f6-b3b7-1a2d0ad00548"
   },
   "outputs": [],
   "source": [
    "# for epoch in range(EPOCHS):\n",
    "#     ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)\n",
    "#     ret['epoch'] = epoch\n",
    "\n",
    "#     log = \"\"\n",
    "#     for k, v in ret.items():\n",
    "#       log += f\"{k}: {v:.4f}\\n\"\n",
    "#     print(log)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12776,
     "status": "ok",
     "timestamp": 1700315185336,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "uRYe6jlPU_Om",
    "outputId": "2a08690c-9ffe-418d-8679-eb9280147110"
   },
   "outputs": [],
   "source": [
    "# preds_list = []\n",
    "\n",
    "# model.eval()\n",
    "# for image, _ in tqdm(tst_loader):\n",
    "#     image = image.to(device)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         preds = model(image)\n",
    "#     preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 282,
     "status": "ok",
     "timestamp": 1700315216829,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "aClN7Qi7VZoh"
   },
   "outputs": [],
   "source": [
    "# pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n",
    "# pred_df['target'] = preds_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1700315238836,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "VDBXQqAzVvLY"
   },
   "outputs": [],
   "source": [
    "# sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "# assert (sample_submission_df['ID'] == pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 317,
     "status": "ok",
     "timestamp": 1700315244710,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "ePx2vCELVnuS"
   },
   "outputs": [],
   "source": [
    "# pred_df.to_csv(\"pred.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling 클래스 정의\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_tta_transforms = [\n",
    "    # 원본\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 추론을 위한 Dataset 클래스\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # 여러 transform을 리스트로 받음\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # 모든 transform을 적용한 결과를 리스트로 반환\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA Dataset size: 3140\n"
     ]
    }
   ],
   "source": [
    "# TTA Dataset 생성\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (배치 크기를 줄여서 메모리 절약)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=64,  # TTA는 메모리를 많이 사용하므로 배치 크기 줄임\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_tta_inference(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold 모델 앙상블 + TTA 추론\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # 각 fold 모델별 예측\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # 각 TTA 변형별 예측\n",
    "                for images in images_list:\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ensemble TTA inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 50/50 [13:23<00:00, 16.06s/it]\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 TTA 실행\n",
    "print(\"Starting Ensemble TTA inference...\")\n",
    "tta_predictions = ensemble_tta_inference(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 결과로 submission 파일 생성\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 submission과 동일한 순서인지 확인\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA predictions saved\n",
      "TTA Prediction sample:\n"
     ]
    }
   ],
   "source": [
    "# TTA 결과 저장\n",
    "tta_pred_df.to_csv(\"../submission/choice.csv\", index=False)\n",
    "print(\"TTA predictions saved\")\n",
    "\n",
    "print(\"TTA Prediction sample:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
