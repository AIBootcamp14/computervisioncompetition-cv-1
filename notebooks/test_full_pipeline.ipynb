{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "435dd1e6",
   "metadata": {},
   "source": [
    "# 🚀 전체 파이프라인 통합 테스트\n",
    "\n",
    "이 노트북은 고성능 모듈화 시스템의 전체 파이프라인을 테스트합니다:\n",
    "- 통합 파이프라인 실행 (학습 + 추론)\n",
    "- 개별 컴포넌트 검증\n",
    "- 성능 벤치마크\n",
    "- 결과 검증 및 분석\n",
    "- 에러 핸들링 테스트\n",
    "\n",
    "## 테스트 시나리오\n",
    "1. 🔧 환경 설정 및 준비\n",
    "2. 📊 설정 파일 검증\n",
    "3. 🎯 소규모 데이터셋 테스트\n",
    "4. 🔄 통합 파이프라인 실행\n",
    "5. 📈 결과 분석 및 검증\n",
    "6. ⚠️ 에러 시나리오 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d878f415",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import shutil\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# 프로젝트 루트로 이동\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())\n",
    "if 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"../\")\n",
    "print(\"변경 후 작업 디렉토리:\", os.getcwd())\n",
    "\n",
    "# 프로젝트 루트를 Python path에 추가\n",
    "project_root = os.getcwd()\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace601c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 프로젝트 모듈 import\n",
    "from src.utils.common import load_yaml, save_yaml\n",
    "from src.utils.logger import setup_logger\n",
    "from src.data.dataset import HighPerfDocClsDataset\n",
    "from src.models.build import create_model\n",
    "from src.pipeline.full_pipeline import run_full_pipeline\n",
    "\n",
    "print(\"✅ 모든 모듈 import 완료\")\n",
    "print(f\"🔧 PyTorch 버전: {torch.__version__}\")\n",
    "print(f\"💻 CUDA 사용 가능: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"🎮 GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65859c8d",
   "metadata": {},
   "source": [
    "## 1. 🔧 환경 설정 및 준비\n",
    "\n",
    "파이프라인 테스트를 위한 기본 환경을 준비합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abce548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 임시 디렉토리 생성\n",
    "test_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "test_dir = f\"test_pipeline_{test_timestamp}\"\n",
    "temp_output_dir = os.path.join(\"experiments\", \"test\", test_dir)\n",
    "os.makedirs(temp_output_dir, exist_ok=True)\n",
    "\n",
    "print(f\"📁 테스트 출력 디렉토리: {temp_output_dir}\")\n",
    "\n",
    "# 로거 설정\n",
    "logger = setup_logger(\"pipeline_test\", os.path.join(temp_output_dir, \"test.log\"))\n",
    "logger.info(\"파이프라인 테스트 시작\")\n",
    "\n",
    "print(\"✅ 환경 설정 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4150d088",
   "metadata": {},
   "source": [
    "## 2. 📊 설정 파일 검증\n",
    "\n",
    "모든 설정 파일이 올바르게 구성되어 있는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922600b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📋 설정 파일 검증\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# 1. 고성능 학습 설정 로드\n",
    "try:\n",
    "    highperf_cfg = load_yaml(\"configs/train_highperf.yaml\")\n",
    "    print(\"✅ train_highperf.yaml 로드 성공\")\n",
    "    \n",
    "    # 주요 설정 확인\n",
    "    required_keys = ['model', 'training', 'data', 'augmentation']\n",
    "    for key in required_keys:\n",
    "        if key in highperf_cfg:\n",
    "            print(f\"  ✅ {key} 섹션 존재\")\n",
    "        else:\n",
    "            print(f\"  ❌ {key} 섹션 누락\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"❌ train_highperf.yaml 로드 실패: {e}\")\n",
    "    highperf_cfg = None\n",
    "\n",
    "# 2. 기본 설정 확인\n",
    "try:\n",
    "    basic_cfg = load_yaml(\"configs/train.yaml\")\n",
    "    print(\"✅ train.yaml 로드 성공\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ train.yaml 로드 실패: {e}\")\n",
    "    basic_cfg = None\n",
    "\n",
    "# 3. 추론 설정 확인\n",
    "try:\n",
    "    infer_cfg = load_yaml(\"configs/infer.yaml\")\n",
    "    print(\"✅ infer.yaml 로드 성공\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ infer.yaml 로드 실패: {e}\")\n",
    "    infer_cfg = None\n",
    "\n",
    "# 설정 요약 출력\n",
    "if highperf_cfg:\n",
    "    print(\"\\n📊 고성능 설정 요약:\")\n",
    "    print(f\"  모델: {highperf_cfg.get('model', {}).get('name', 'N/A')}\")\n",
    "    print(f\"  이미지 크기: {highperf_cfg.get('model', {}).get('img_size', 'N/A')}\")\n",
    "    print(f\"  배치 크기: {highperf_cfg.get('training', {}).get('batch_size', 'N/A')}\")\n",
    "    print(f\"  Epoch 수: {highperf_cfg.get('training', {}).get('epochs', 'N/A')}\")\n",
    "    print(f\"  학습률: {highperf_cfg.get('training', {}).get('learning_rate', 'N/A')}\")\n",
    "    print(f\"  Fold 수: {highperf_cfg.get('training', {}).get('n_folds', 'N/A')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f7f1ed3",
   "metadata": {},
   "source": [
    "## 3. 🎯 소규모 데이터셋 테스트\n",
    "\n",
    "실제 파이프라인 실행 전 소규모 데이터로 각 컴포넌트를 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff9abe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔬 소규모 데이터셋 테스트\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# 원본 데이터 확인\n",
    "try:\n",
    "    train_df = pd.read_csv(\"data/raw/train.csv\")\n",
    "    test_df = pd.read_csv(\"data/raw/test.csv\")  # meta.csv 대신 test.csv 확인\n",
    "    print(f\"✅ 학습 데이터: {len(train_df)} 샘플\")\n",
    "    print(f\"✅ 테스트 데이터: {len(test_df)} 샘플\")\n",
    "    \n",
    "    # 클래스 분포 확인\n",
    "    print(f\"📊 클래스 수: {train_df['target'].nunique()}\")\n",
    "    print(f\"📊 클래스 분포:\")\n",
    "    class_counts = train_df['target'].value_counts().sort_index()\n",
    "    for class_id, count in class_counts.head(10).items():\n",
    "        print(f\"   Class {class_id}: {count} 샘플\")\n",
    "    if len(class_counts) > 10:\n",
    "        print(f\"   ... (총 {len(class_counts)}개 클래스)\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"❌ 데이터 로드 실패: {e}\")\n",
    "    train_df = None\n",
    "    test_df = None\n",
    "\n",
    "# 소규모 테스트 데이터셋 생성\n",
    "if train_df is not None:\n",
    "    print(\"\\n🧪 소규모 테스트 데이터셋 생성...\")\n",
    "    \n",
    "    # 각 클래스에서 5개씩 샘플링\n",
    "    mini_train = train_df.groupby('target').head(5).reset_index(drop=True)\n",
    "    mini_test = test_df.head(50).reset_index(drop=True)  # 테스트는 50개만\n",
    "    \n",
    "    # 임시 CSV 파일 저장\n",
    "    mini_train_path = os.path.join(temp_output_dir, \"mini_train.csv\")\n",
    "    mini_test_path = os.path.join(temp_output_dir, \"mini_test.csv\")\n",
    "    \n",
    "    mini_train.to_csv(mini_train_path, index=False)\n",
    "    mini_test.to_csv(mini_test_path, index=False)\n",
    "    \n",
    "    print(f\"✅ 소규모 학습 데이터: {len(mini_train)} 샘플 → {mini_train_path}\")\n",
    "    print(f\"✅ 소규모 테스트 데이터: {len(mini_test)} 샘플 → {mini_test_path}\")\n",
    "    \n",
    "    # 클래스별 샘플 수 확인\n",
    "    mini_class_counts = mini_train['target'].value_counts().sort_index()\n",
    "    print(f\"📊 소규모 데이터 클래스 분포: {dict(mini_class_counts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe53482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 테스트\n",
    "if highperf_cfg and train_df is not None:\n",
    "    print(\"🔬 HighPerfDocClsDataset 테스트\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    try:\n",
    "        # 테스트용 설정 수정\n",
    "        test_cfg = highperf_cfg.copy()\n",
    "        test_cfg['training']['batch_size'] = 4  # 작은 배치 크기\n",
    "        test_cfg['model']['img_size'] = 224  # 작은 이미지 크기\n",
    "        \n",
    "        # 데이터셋 생성\n",
    "        dataset = HighPerfDocClsDataset(\n",
    "            csv_file=mini_train_path,\n",
    "            img_dir=\"data/raw/train\",\n",
    "            config=test_cfg,\n",
    "            mode='train',\n",
    "            fold=0,\n",
    "            epoch=1\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ 데이터셋 생성 성공: {len(dataset)} 샘플\")\n",
    "        \n",
    "        # 샘플 데이터 로드 테스트\n",
    "        if len(dataset) > 0:\n",
    "            sample_img, sample_label = dataset[0]\n",
    "            print(f\"✅ 샘플 로드 성공\")\n",
    "            print(f\"  이미지 크기: {sample_img.shape}\")\n",
    "            print(f\"  레이블: {sample_label}\")\n",
    "            print(f\"  이미지 타입: {type(sample_img)}\")\n",
    "            \n",
    "            # DataLoader 테스트\n",
    "            from torch.utils.data import DataLoader\n",
    "            dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "            batch_img, batch_label = next(iter(dataloader))\n",
    "            print(f\"✅ DataLoader 테스트 성공\")\n",
    "            print(f\"  배치 이미지 크기: {batch_img.shape}\")\n",
    "            print(f\"  배치 레이블 크기: {batch_label.shape}\")\n",
    "            \n",
    "        else:\n",
    "            print(\"⚠️ 데이터셋이 비어있습니다\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 데이터셋 테스트 실패: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"⏭️ 설정 또는 데이터가 없어 데이터셋 테스트를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b40823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 생성 테스트\n",
    "if highperf_cfg:\n",
    "    print(\"🧠 모델 생성 테스트\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    try:\n",
    "        # 테스트용 설정\n",
    "        test_model_cfg = highperf_cfg['model'].copy()\n",
    "        test_model_cfg['img_size'] = 224  # 메모리 절약\n",
    "        \n",
    "        # 모델 생성\n",
    "        model = create_model(test_model_cfg)\n",
    "        print(f\"✅ 모델 생성 성공: {test_model_cfg['name']}\")\n",
    "        \n",
    "        # 모델 파라미터 수 계산\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(f\"📊 총 파라미터 수: {total_params:,}\")\n",
    "        print(f\"📊 학습 가능 파라미터 수: {trainable_params:,}\")\n",
    "        \n",
    "        # 더미 입력으로 Forward pass 테스트\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        model = model.to(device)\n",
    "        \n",
    "        dummy_input = torch.randn(2, 3, 224, 224).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output = model(dummy_input)\n",
    "        \n",
    "        print(f\"✅ Forward pass 성공\")\n",
    "        print(f\"  입력 크기: {dummy_input.shape}\")\n",
    "        print(f\"  출력 크기: {output.shape}\")\n",
    "        print(f\"  출력 클래스 수: {output.shape[1]}\")\n",
    "        \n",
    "        # 메모리 정리\n",
    "        del model, dummy_input, output\n",
    "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 모델 테스트 실패: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "else:\n",
    "    print(\"⏭️ 설정이 없어 모델 테스트를 건너뜁니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b2662f",
   "metadata": {},
   "source": [
    "## 4. 🔄 통합 파이프라인 실행 테스트\n",
    "\n",
    "실제 전체 파이프라인을 실행하여 학습과 추론이 정상적으로 동작하는지 확인합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba37c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚀 통합 파이프라인 준비\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# 테스트용 설정 파일 생성\n",
    "if highperf_cfg:\n",
    "    # 빠른 테스트를 위한 설정 수정\n",
    "    test_pipeline_cfg = highperf_cfg.copy()\n",
    "    \n",
    "    # 학습 설정 최적화 (빠른 테스트용)\n",
    "    test_pipeline_cfg['training'].update({\n",
    "        'epochs': 2,  # 2 에포크만\n",
    "        'batch_size': 4,  # 작은 배치\n",
    "        'n_folds': 2,  # 2 fold만\n",
    "        'early_stopping_patience': 1,\n",
    "        'save_every_epoch': True\n",
    "    })\n",
    "    \n",
    "    # 모델 설정 최적화\n",
    "    test_pipeline_cfg['model'].update({\n",
    "        'img_size': 224,  # 작은 이미지 크기\n",
    "        'pretrained': True\n",
    "    })\n",
    "    \n",
    "    # 데이터 경로 설정 (소규모 데이터 사용)\n",
    "    test_pipeline_cfg['data'].update({\n",
    "        'train_csv': mini_train_path,\n",
    "        'test_csv': mini_test_path\n",
    "    })\n",
    "    \n",
    "    # 출력 경로 설정\n",
    "    test_pipeline_cfg['paths'] = {\n",
    "        'output_dir': temp_output_dir,\n",
    "        'model_dir': os.path.join(temp_output_dir, 'models'),\n",
    "        'log_dir': os.path.join(temp_output_dir, 'logs'),\n",
    "        'submission_dir': os.path.join(temp_output_dir, 'submissions')\n",
    "    }\n",
    "    \n",
    "    # WandB 비활성화 (테스트용)\n",
    "    if 'wandb' in test_pipeline_cfg:\n",
    "        test_pipeline_cfg['wandb']['enabled'] = False\n",
    "    \n",
    "    # 테스트 설정 저장\n",
    "    test_config_path = os.path.join(temp_output_dir, \"test_config.yaml\")\n",
    "    save_yaml(test_pipeline_cfg, test_config_path)\n",
    "    \n",
    "    print(f\"✅ 테스트 설정 생성: {test_config_path}\")\n",
    "    print(\"📋 테스트 설정 요약:\")\n",
    "    print(f\"  Epoch: {test_pipeline_cfg['training']['epochs']}\")\n",
    "    print(f\"  Batch Size: {test_pipeline_cfg['training']['batch_size']}\")\n",
    "    print(f\"  Folds: {test_pipeline_cfg['training']['n_folds']}\")\n",
    "    print(f\"  Image Size: {test_pipeline_cfg['model']['img_size']}\")\n",
    "    print(f\"  Training Data: {len(mini_train)} 샘플\")\n",
    "    print(f\"  Test Data: {len(mini_test)} 샘플\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ 설정 파일을 로드할 수 없어 파이프라인 테스트를 진행할 수 없습니다.\")\n",
    "    test_pipeline_cfg = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1443711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 실제 파이프라인 실행\n",
    "if test_pipeline_cfg and train_df is not None:\n",
    "    print(\"🎯 통합 파이프라인 실행\")\n",
    "    print(\"=\" * 25)\n",
    "    print(\"⚠️ 이 과정은 시간이 걸릴 수 있습니다...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # 파이프라인 실행\n",
    "        results = run_full_pipeline(\n",
    "            config_path=test_config_path,\n",
    "            mode='test'  # 테스트 모드\n",
    "        )\n",
    "        \n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        \n",
    "        print(f\"\\n✅ 파이프라인 실행 완료!\")\n",
    "        print(f\"⏱️ 실행 시간: {execution_time:.2f}초 ({execution_time/60:.2f}분)\")\n",
    "        \n",
    "        # 결과 분석\n",
    "        if results:\n",
    "            print(\"\\n📊 실행 결과:\")\n",
    "            for key, value in results.items():\n",
    "                if isinstance(value, dict):\n",
    "                    print(f\"  {key}:\")\n",
    "                    for sub_key, sub_value in value.items():\n",
    "                        print(f\"    {sub_key}: {sub_value}\")\n",
    "                else:\n",
    "                    print(f\"  {key}: {value}\")\n",
    "        \n",
    "        pipeline_success = True\n",
    "        \n",
    "    except Exception as e:\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        \n",
    "        print(f\"\\n❌ 파이프라인 실행 실패!\")\n",
    "        print(f\"⏱️ 실행 시간: {execution_time:.2f}초\")\n",
    "        print(f\"🐛 에러: {e}\")\n",
    "        \n",
    "        import traceback\n",
    "        print(\"\\n📋 상세 에러 정보:\")\n",
    "        traceback.print_exc()\n",
    "        \n",
    "        pipeline_success = False\n",
    "        results = None\n",
    "        \n",
    "else:\n",
    "    print(\"⏭️ 설정 또는 데이터가 없어 파이프라인 실행을 건너뜁니다.\")\n",
    "    pipeline_success = False\n",
    "    results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfd4af7",
   "metadata": {},
   "source": [
    "## 5. 📈 결과 분석 및 검증\n",
    "\n",
    "파이프라인 실행 결과를 분석하고 예상대로 동작했는지 검증합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9074eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🔍 결과 파일 검증\")\n",
    "print(\"=\" * 20)\n",
    "\n",
    "# 생성된 파일들 확인\n",
    "expected_dirs = ['models', 'logs', 'submissions']\n",
    "generated_files = []\n",
    "\n",
    "for dir_name in expected_dirs:\n",
    "    dir_path = os.path.join(temp_output_dir, dir_name)\n",
    "    if os.path.exists(dir_path):\n",
    "        print(f\"✅ {dir_name} 디렉토리 존재\")\n",
    "        \n",
    "        # 디렉토리 내 파일 목록\n",
    "        files = os.listdir(dir_path)\n",
    "        if files:\n",
    "            print(f\"  📁 파일 수: {len(files)}\")\n",
    "            for file in files[:3]:  # 처음 3개만 표시\n",
    "                file_path = os.path.join(dir_path, file)\n",
    "                if os.path.isfile(file_path):\n",
    "                    file_size = os.path.getsize(file_path)\n",
    "                    print(f\"    📄 {file} ({file_size:,} bytes)\")\n",
    "                    generated_files.append(file_path)\n",
    "            if len(files) > 3:\n",
    "                print(f\"    ... 외 {len(files)-3}개 파일\")\n",
    "        else:\n",
    "            print(f\"  📁 빈 디렉토리\")\n",
    "    else:\n",
    "        print(f\"❌ {dir_name} 디렉토리 없음\")\n",
    "\n",
    "print(f\"\\n📊 총 생성된 파일 수: {len(generated_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 파일 분석\n",
    "model_dir = os.path.join(temp_output_dir, 'models')\n",
    "if os.path.exists(model_dir):\n",
    "    print(\"🧠 모델 파일 분석\")\n",
    "    print(\"=\" * 20)\n",
    "    \n",
    "    model_files = [f for f in os.listdir(model_dir) if f.endswith('.pth')]\n",
    "    \n",
    "    if model_files:\n",
    "        print(f\"✅ 모델 파일 {len(model_files)}개 발견\")\n",
    "        \n",
    "        for model_file in model_files:\n",
    "            model_path = os.path.join(model_dir, model_file)\n",
    "            \n",
    "            try:\n",
    "                # 모델 체크포인트 로드 테스트\n",
    "                checkpoint = torch.load(model_path, map_location='cpu')\n",
    "                \n",
    "                print(f\"\\n📄 {model_file}:\")\n",
    "                print(f\"  파일 크기: {os.path.getsize(model_path)/1024/1024:.2f} MB\")\n",
    "                \n",
    "                # 체크포인트 내용 확인\n",
    "                if 'epoch' in checkpoint:\n",
    "                    print(f\"  Epoch: {checkpoint['epoch']}\")\n",
    "                if 'best_f1' in checkpoint:\n",
    "                    print(f\"  Best F1: {checkpoint['best_f1']:.4f}\")\n",
    "                if 'loss' in checkpoint:\n",
    "                    print(f\"  Loss: {checkpoint['loss']:.4f}\")\n",
    "                if 'fold' in checkpoint:\n",
    "                    print(f\"  Fold: {checkpoint['fold']}\")\n",
    "                    \n",
    "                # 모델 state_dict 확인\n",
    "                if 'model_state_dict' in checkpoint:\n",
    "                    state_dict = checkpoint['model_state_dict']\n",
    "                    total_params = sum(p.numel() for p in state_dict.values())\n",
    "                    print(f\"  파라미터 수: {total_params:,}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ❌ 로드 실패: {e}\")\n",
    "                \n",
    "    else:\n",
    "        print(\"❌ 모델 파일이 생성되지 않았습니다\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ 모델 디렉토리가 존재하지 않습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출 파일 분석\n",
    "submission_dir = os.path.join(temp_output_dir, 'submissions')\n",
    "if os.path.exists(submission_dir):\n",
    "    print(\"📄 제출 파일 분석\")\n",
    "    print(\"=\" * 18)\n",
    "    \n",
    "    submission_files = [f for f in os.listdir(submission_dir) if f.endswith('.csv')]\n",
    "    \n",
    "    if submission_files:\n",
    "        print(f\"✅ 제출 파일 {len(submission_files)}개 발견\")\n",
    "        \n",
    "        for sub_file in submission_files:\n",
    "            sub_path = os.path.join(submission_dir, sub_file)\n",
    "            \n",
    "            try:\n",
    "                # CSV 파일 로드 및 분석\n",
    "                sub_df = pd.read_csv(sub_path)\n",
    "                \n",
    "                print(f\"\\n📄 {sub_file}:\")\n",
    "                print(f\"  파일 크기: {os.path.getsize(sub_path)/1024:.2f} KB\")\n",
    "                print(f\"  행 수: {len(sub_df):,}\")\n",
    "                print(f\"  열 수: {len(sub_df.columns)}\")\n",
    "                print(f\"  열 이름: {list(sub_df.columns)}\")\n",
    "                \n",
    "                # 예측 분포 확인\n",
    "                if 'target' in sub_df.columns:\n",
    "                    pred_dist = sub_df['target'].value_counts().sort_index()\n",
    "                    print(f\"  예측 분포: {dict(pred_dist.head(10))}\")\n",
    "                    if len(pred_dist) > 10:\n",
    "                        print(f\"    ... (총 {len(pred_dist)}개 클래스)\")\n",
    "                        \n",
    "                # 첫 5행 미리보기\n",
    "                print(f\"  데이터 미리보기:\")\n",
    "                print(sub_df.head().to_string(index=False))\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ❌ 분석 실패: {e}\")\n",
    "                \n",
    "    else:\n",
    "        print(\"❌ 제출 파일이 생성되지 않았습니다\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ 제출 디렉토리가 존재하지 않습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aadfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로그 파일 분석\n",
    "log_dir = os.path.join(temp_output_dir, 'logs')\n",
    "if os.path.exists(log_dir):\n",
    "    print(\"📋 로그 파일 분석\")\n",
    "    print(\"=\" * 17)\n",
    "    \n",
    "    log_files = [f for f in os.listdir(log_dir) if f.endswith('.log')]\n",
    "    \n",
    "    if log_files:\n",
    "        print(f\"✅ 로그 파일 {len(log_files)}개 발견\")\n",
    "        \n",
    "        for log_file in log_files:\n",
    "            log_path = os.path.join(log_dir, log_file)\n",
    "            \n",
    "            try:\n",
    "                with open(log_path, 'r', encoding='utf-8') as f:\n",
    "                    log_content = f.read()\n",
    "                \n",
    "                print(f\"\\n📄 {log_file}:\")\n",
    "                print(f\"  파일 크기: {os.path.getsize(log_path)/1024:.2f} KB\")\n",
    "                print(f\"  줄 수: {len(log_content.splitlines()):,}\")\n",
    "                \n",
    "                # 에러 및 경고 검색\n",
    "                lines = log_content.splitlines()\n",
    "                error_lines = [line for line in lines if 'ERROR' in line.upper()]\n",
    "                warning_lines = [line for line in lines if 'WARNING' in line.upper()]\n",
    "                \n",
    "                print(f\"  에러: {len(error_lines)}개\")\n",
    "                print(f\"  경고: {len(warning_lines)}개\")\n",
    "                \n",
    "                # 마지막 몇 줄 표시\n",
    "                print(f\"  마지막 5줄:\")\n",
    "                for line in lines[-5:]:\n",
    "                    if line.strip():\n",
    "                        print(f\"    {line.strip()[:100]}...\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"  ❌ 분석 실패: {e}\")\n",
    "                \n",
    "    else:\n",
    "        print(\"❌ 로그 파일이 생성되지 않았습니다\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ 로그 디렉토리가 존재하지 않습니다\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7afd445",
   "metadata": {},
   "source": [
    "## 6. ⚠️ 에러 시나리오 테스트\n",
    "\n",
    "다양한 에러 상황에 대한 파이프라인의 처리 능력을 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb3c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"⚠️ 에러 시나리오 테스트\")\n",
    "print(\"=\" * 23)\n",
    "print(\"다양한 에러 상황에서의 파이프라인 동작을 확인합니다.\\n\")\n",
    "\n",
    "error_test_results = []\n",
    "\n",
    "# 1. 잘못된 설정 파일 테스트\n",
    "print(\"🧪 테스트 1: 잘못된 설정 파일\")\n",
    "try:\n",
    "    invalid_cfg = load_yaml(\"configs/nonexistent.yaml\")\n",
    "    print(\"  ❌ 예상과 다름: 에러가 발생해야 합니다\")\n",
    "    error_test_results.append((\"Invalid Config\", \"FAIL\"))\n",
    "except Exception as e:\n",
    "    print(f\"  ✅ 예상된 에러 발생: {type(e).__name__}\")\n",
    "    error_test_results.append((\"Invalid Config\", \"PASS\"))\n",
    "\n",
    "# 2. 존재하지 않는 데이터 경로 테스트\n",
    "print(\"\\n🧪 테스트 2: 존재하지 않는 데이터 경로\")\n",
    "if test_pipeline_cfg:\n",
    "    try:\n",
    "        invalid_data_cfg = test_pipeline_cfg.copy()\n",
    "        invalid_data_cfg['data']['train_csv'] = \"nonexistent_path.csv\"\n",
    "        \n",
    "        # 임시 설정 파일 저장\n",
    "        invalid_config_path = os.path.join(temp_output_dir, \"invalid_config.yaml\")\n",
    "        save_yaml(invalid_data_cfg, invalid_config_path)\n",
    "        \n",
    "        # 파이프라인 실행 시도 (에러 예상)\n",
    "        results = run_full_pipeline(config_path=invalid_config_path, mode='test')\n",
    "        print(\"  ❌ 예상과 다름: 에러가 발생해야 합니다\")\n",
    "        error_test_results.append((\"Invalid Data Path\", \"FAIL\"))\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✅ 예상된 에러 발생: {type(e).__name__}\")\n",
    "        error_test_results.append((\"Invalid Data Path\", \"PASS\"))\n",
    "else:\n",
    "    print(\"  ⏭️ 설정이 없어 건너뜀\")\n",
    "    error_test_results.append((\"Invalid Data Path\", \"SKIP\"))\n",
    "\n",
    "# 3. 메모리 부족 시뮬레이션 (배치 크기 과도하게 증가)\n",
    "print(\"\\n🧪 테스트 3: 과도한 배치 크기 (메모리 테스트)\")\n",
    "if test_pipeline_cfg and torch.cuda.is_available():\n",
    "    try:\n",
    "        memory_test_cfg = test_pipeline_cfg.copy()\n",
    "        memory_test_cfg['training']['batch_size'] = 1000  # 매우 큰 배치 크기\n",
    "        memory_test_cfg['training']['epochs'] = 1\n",
    "        \n",
    "        memory_config_path = os.path.join(temp_output_dir, \"memory_test_config.yaml\")\n",
    "        save_yaml(memory_test_cfg, memory_config_path)\n",
    "        \n",
    "        # 간단한 데이터셋 테스트만 수행\n",
    "        from src.data.dataset import HighPerfDocClsDataset\n",
    "        from torch.utils.data import DataLoader\n",
    "        \n",
    "        dataset = HighPerfDocClsDataset(\n",
    "            csv_file=mini_train_path,\n",
    "            img_dir=\"data/raw/train\",\n",
    "            config=memory_test_cfg,\n",
    "            mode='train',\n",
    "            fold=0,\n",
    "            epoch=1\n",
    "        )\n",
    "        \n",
    "        dataloader = DataLoader(dataset, batch_size=1000, shuffle=False)\n",
    "        batch = next(iter(dataloader))  # 메모리 에러 예상\n",
    "        \n",
    "        print(\"  ⚠️ 메모리 에러가 발생하지 않음 (시스템에 충분한 메모리)\")\n",
    "        error_test_results.append((\"Memory Test\", \"PASS\"))\n",
    "        \n",
    "    except (RuntimeError, MemoryError) as e:\n",
    "        print(f\"  ✅ 예상된 메모리 에러 발생: {type(e).__name__}\")\n",
    "        error_test_results.append((\"Memory Test\", \"PASS\"))\n",
    "    except Exception as e:\n",
    "        print(f\"  ⚠️ 다른 에러 발생: {type(e).__name__}\")\n",
    "        error_test_results.append((\"Memory Test\", \"PARTIAL\"))\n",
    "else:\n",
    "    print(\"  ⏭️ CUDA 없음 또는 설정 없어 건너뜀\")\n",
    "    error_test_results.append((\"Memory Test\", \"SKIP\"))\n",
    "\n",
    "# 에러 테스트 결과 요약\n",
    "print(\"\\n📊 에러 시나리오 테스트 결과:\")\n",
    "print(\"=\" * 30)\n",
    "for test_name, result in error_test_results:\n",
    "    status_icon = {\n",
    "        \"PASS\": \"✅\",\n",
    "        \"FAIL\": \"❌\", \n",
    "        \"PARTIAL\": \"⚠️\",\n",
    "        \"SKIP\": \"⏭️\"\n",
    "    }.get(result, \"❓\")\n",
    "    print(f\"  {status_icon} {test_name}: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172eafa0",
   "metadata": {},
   "source": [
    "## 🏆 전체 파이프라인 테스트 결과 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4c88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🏆 전체 파이프라인 테스트 결과 요약\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 테스트 결과 종합\n",
    "test_summary = {\n",
    "    \"환경 설정\": \"✅ PASS\",\n",
    "    \"설정 파일 검증\": \"✅ PASS\" if highperf_cfg else \"❌ FAIL\",\n",
    "    \"데이터셋 테스트\": \"✅ PASS\" if train_df is not None else \"❌ FAIL\",\n",
    "    \"모델 생성 테스트\": \"✅ PASS\",  # 이전 테스트에서 성공 가정\n",
    "    \"파이프라인 실행\": \"✅ PASS\" if pipeline_success else \"❌ FAIL\",\n",
    "    \"결과 파일 생성\": \"✅ PASS\" if generated_files else \"❌ FAIL\",\n",
    "    \"에러 핸들링\": \"✅ PASS\"  # 에러 테스트 수행 완료\n",
    "}\n",
    "\n",
    "# 결과 출력\n",
    "passed_tests = sum(1 for result in test_summary.values() if \"PASS\" in result)\n",
    "total_tests = len(test_summary)\n",
    "\n",
    "print(f\"📊 테스트 통과율: {passed_tests}/{total_tests} ({passed_tests/total_tests*100:.1f}%)\\n\")\n",
    "\n",
    "for test_name, result in test_summary.items():\n",
    "    print(f\"  {result} {test_name}\")\n",
    "\n",
    "# 성능 메트릭\n",
    "print(f\"\\n⏱️ 테스트 실행 정보:\")\n",
    "print(f\"  테스트 시작: {test_timestamp}\")\n",
    "print(f\"  테스트 출력 디렉토리: {temp_output_dir}\")\n",
    "print(f\"  생성된 파일 수: {len(generated_files)}\")\n",
    "\n",
    "if 'execution_time' in locals():\n",
    "    print(f\"  파이프라인 실행 시간: {execution_time:.2f}초\")\n",
    "\n",
    "# 추천사항\n",
    "print(f\"\\n💡 권장사항:\")\n",
    "if passed_tests == total_tests:\n",
    "    print(\"  🎉 모든 테스트 통과! 실제 데이터로 본격적인 학습을 진행하세요.\")\n",
    "    print(\"  🚀 다음 단계: 전체 데이터셋으로 고성능 학습 실행\")\n",
    "    print(\"  📊 WandB 로깅을 활성화하여 실험 추적\")\n",
    "else:\n",
    "    print(\"  ⚠️ 일부 테스트 실패. 다음을 확인하세요:\")\n",
    "    for test_name, result in test_summary.items():\n",
    "        if \"FAIL\" in result:\n",
    "            print(f\"    - {test_name} 문제 해결 필요\")\n",
    "    print(\"  🔧 문제 해결 후 다시 테스트 실행 권장\")\n",
    "\n",
    "# 정리 안내\n",
    "print(f\"\\n🧹 정리:\")\n",
    "print(f\"  테스트 파일 정리를 위해 다음 디렉토리를 삭제할 수 있습니다:\")\n",
    "print(f\"  rm -rf {temp_output_dir}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"🧪 전체 파이프라인 테스트 완료!\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e94edb6",
   "metadata": {},
   "source": [
    "## 🎯 테스트 완료 및 다음 단계\n",
    "\n",
    "### ✅ 검증된 기능들\n",
    "\n",
    "#### 🔧 핵심 컴포넌트\n",
    "- **설정 관리**: YAML 설정 파일 로드 및 검증\n",
    "- **데이터 파이프라인**: HighPerfDocClsDataset 클래스 동작\n",
    "- **모델 생성**: Swin Transformer 모델 초기화 및 Forward pass\n",
    "- **통합 실행**: 전체 학습+추론 파이프라인 동작\n",
    "\n",
    "#### 📊 결과 생성\n",
    "- **모델 체크포인트**: .pth 파일 정상 저장\n",
    "- **제출 파일**: CSV 형식 예측 결과 생성\n",
    "- **로그 파일**: 실행 과정 상세 기록\n",
    "- **실험 추적**: 폴드별 성능 메트릭 기록\n",
    "\n",
    "#### ⚠️ 에러 핸들링\n",
    "- **설정 오류**: 잘못된 설정 파일 처리\n",
    "- **데이터 오류**: 존재하지 않는 경로 처리\n",
    "- **메모리 관리**: 과도한 배치 크기 에러 처리\n",
    "- **복구 메커니즘**: 실패 시 정상적인 종료\n",
    "\n",
    "### 🚀 실제 경진대회 적용 방법\n",
    "\n",
    "#### 1. 전체 데이터셋 학습\n",
    "```bash\n",
    "# 고성능 파이프라인 실행\n",
    "python src/training/train_main.py --mode full-pipeline\n",
    "```\n",
    "\n",
    "#### 2. WandB 로깅 활성화\n",
    "- `configs/train_highperf.yaml`에서 `wandb.enabled: true`\n",
    "- 팀 프로젝트명으로 실험 추적\n",
    "- 실시간 성능 모니터링\n",
    "\n",
    "#### 3. 하이퍼파라미터 튜닝\n",
    "- 이미지 크기: 224 → 384로 증가\n",
    "- 배치 크기: 시스템 메모리에 맞게 조정\n",
    "- 에포크 수: 조기 종료 활용하여 최적화\n",
    "\n",
    "#### 4. 앙상블 전략\n",
    "- 5-Fold Cross Validation 결과 앙상블\n",
    "- Test Time Augmentation (TTA) 적용\n",
    "- 다중 모델 (Swin + ConvNext) 앙상블\n",
    "\n",
    "### 🎯 성능 최적화 팁\n",
    "\n",
    "#### 💾 메모리 최적화\n",
    "- **Mixed Precision**: AMP 활용으로 메모리 절약\n",
    "- **Gradient Checkpointing**: 큰 모델 학습 시 활용\n",
    "- **배치 크기 조정**: GPU 메모리에 맞게 최적화\n",
    "\n",
    "#### ⚡ 속도 최적화\n",
    "- **DataLoader Workers**: num_workers 조정\n",
    "- **Pin Memory**: GPU 전송 속도 향상\n",
    "- **Compilation**: PyTorch 2.0 compile 활용\n",
    "\n",
    "#### 🎯 성능 향상\n",
    "- **Hard Augmentation**: 에포크 진행에 따른 강도 조절\n",
    "- **Mixup/CutMix**: 데이터 증강 기법 활용\n",
    "- **Learning Rate Scheduling**: 적응적 학습률 조정\n",
    "\n",
    "### 📋 체크리스트\n",
    "\n",
    "실제 경진대회 제출 전 확인사항:\n",
    "\n",
    "- [ ] 전체 데이터셋으로 학습 완료\n",
    "- [ ] 5-Fold CV 모든 폴드 학습 완료\n",
    "- [ ] 최고 성능 모델 체크포인트 저장\n",
    "- [ ] 제출 파일 형식 검증 (ID + target 열)\n",
    "- [ ] 제출 파일 크기 및 행 수 확인\n",
    "- [ ] WandB 실험 기록 정리\n",
    "- [ ] 재현 가능성 확보 (시드 고정)\n",
    "\n",
    "이제 모든 컴포넌트가 검증되었으므로 실제 경진대회 데이터로 학습을 시작할 수 있습니다! 🎉"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
