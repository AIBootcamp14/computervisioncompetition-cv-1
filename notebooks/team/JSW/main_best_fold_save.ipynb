{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* Îç∞Ïù¥ÌÑ∞ Î°úÎìúÎ•º ÏúÑÌïú Íµ¨Í∏Ä ÎìúÎùºÏù¥Î∏åÎ•º ÎßàÏö¥Ìä∏Ìï©ÎãàÎã§.\n",
    "* ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÑ§ÏπòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# # ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º ÏÑ§ÏπòÌï©ÎãàÎã§.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna\n",
    "# !apt install -y libgl1-mesa-glx\n",
    "# !pip install albumentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* ÌïôÏäµ Î∞è Ï∂îÎ°†Ïóê ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º Î°úÎìúÌï©ÎãàÎã§.\n",
    "* ÌïôÏäµ Î∞è Ï∂îÎ°†Ïóê ÌïÑÏöîÌïú Ìï®ÏàòÏôÄ ÌÅ¥ÎûòÏä§Î•º Ï†ïÏùòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed PrecisionÏö©\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# ÌïúÍ∏Ä Ìè∞Ìä∏ ÏÑ§Ï†ï (ÏãúÍ∞ÅÌôîÏö©)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ÌòÑÏû¨ ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN\n",
      "‚úÖ GPU ÏÇ¨Ïö© Í∞ÄÎä•: NVIDIA GeForce RTX 4090\n",
      "‚úÖ ÎÇòÎàîÍ≥†Îîï Ìè∞Ìä∏ Î°úÎìú ÏÑ±Í≥µ\n",
      "üìù ÎÖ∏Ìä∏Î∂Å ÏûëÏóÖ ÏãúÏûë: main_best_fold_save\n",
      "üìù Î°úÍ∑∏ ÎîîÎ†âÌÜ†Î¶¨: notebooks/team/JSW/main_best_fold_save/20250912_043001\n",
      "‚úÖ ÌôòÍ≤Ω ÏÑ§Ï†ï Î∞è Î°úÍ±∞ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\n"
     ]
    }
   ],
   "source": [
    "# [1] ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏ ÎîîÎ†âÌÜ†Î¶¨ Ïù¥Îèô Î∞è ÌôòÍ≤Ω ÏÑ§Ï†ï\n",
    "import os\n",
    "os.chdir(\"../../../\")  # ÌîÑÎ°úÏ†ùÌä∏ Î£®Ìä∏Î°ú Ïù¥Îèô\n",
    "print(\"ÌòÑÏû¨ ÏûëÏóÖ ÎîîÎ†âÌÜ†Î¶¨:\", os.getcwd())\n",
    "\n",
    "# GPU Ï≤¥ÌÅ¨\n",
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(f'‚úÖ GPU ÏÇ¨Ïö© Í∞ÄÎä•: {torch.cuda.get_device_name(0)}')\n",
    "else:\n",
    "    print('‚ö†Ô∏è GPU ÏÇ¨Ïö© Î∂àÍ∞Ä, CPUÎ°ú Ïã§ÌñâÎê©ÎãàÎã§')\n",
    "\n",
    "# Í≤ΩÍ≥† ÏñµÏ†ú ÏÑ§Ï†ï\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ÌïúÍ∏Ä Ìè∞Ìä∏ Ï†ÅÏö© Î∞è ÏãúÍ∞ÅÌôî ÌôòÍ≤Ω ÏÑ§Ï†ï\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# ÎÇòÎàîÍ≥†Îîï Ìè∞Ìä∏ Í≤ΩÎ°ú Î∞è ÏÑ§Ï†ï\n",
    "font_path = './font/NanumGothic.ttf'\n",
    "fontprop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# Ìè∞Ìä∏ Îì±Î°ù Î∞è ÏÑ§Ï†ï (ÌïúÍ∏Ä ÌÖçÏä§Ìä∏ ÌëúÏãúÎ•º ÏúÑÌï®)\n",
    "fe = fm.FontEntry(fname=font_path, name='NanumGothic')\n",
    "fm.fontManager.ttflist.insert(0, fe)\n",
    "plt.rcParams['font.family'] = 'NanumGothic'      # Í∏∞Î≥∏ Ìè∞Ìä∏Î•º ÎÇòÎàîÍ≥†ÎîïÏúºÎ°ú ÏÑ§Ï†ï\n",
    "plt.rcParams['font.size'] = 10                   # Í∏∞Î≥∏ Í∏ÄÏûê ÌÅ¨Í∏∞ ÏÑ§Ï†ï\n",
    "plt.rcParams['axes.unicode_minus'] = False       # ÎßàÏù¥ÎÑàÏä§ Í∏∞Ìò∏ Íπ®Ïßê Î∞©ÏßÄ\n",
    "\n",
    "# Í∏ÄÏûê Í≤πÏπ® Î∞©ÏßÄÎ•º ÏúÑÌïú Î†àÏù¥ÏïÑÏõÉ ÏÑ§Ï†ï\n",
    "plt.rcParams['figure.autolayout'] = True         # ÏûêÎèô Î†àÏù¥ÏïÑÏõÉ Ï°∞Ï†ï\n",
    "plt.rcParams['axes.titlepad'] = 20               # Ï†úÎ™©Í≥º Ï∂ï ÏÇ¨Ïù¥ Ïó¨Î∞±\n",
    "\n",
    "# Ìè∞Ìä∏ Î°úÎìú ÌôïÏù∏\n",
    "try:\n",
    "    test_font = fm.FontProperties(fname=font_path)\n",
    "    print(\"‚úÖ ÎÇòÎàîÍ≥†Îîï Ìè∞Ìä∏ Î°úÎìú ÏÑ±Í≥µ\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Ìè∞Ìä∏ Î°úÎìú Ïã§Ìå®: {e}\")\n",
    "\n",
    "# ÎÖ∏Ìä∏Î∂Å Î°úÍ±∞ ÏÉùÏÑ±\n",
    "from src.logging.notebook_logger import create_notebook_logger\n",
    "\n",
    "logger = create_notebook_logger(\n",
    "    base_log_dir=\"team\",\n",
    "    folder_name=\"JSW\",\n",
    "    file_name=\"main_best_fold_save\"\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ÌôòÍ≤Ω ÏÑ§Ï†ï Î∞è Î°úÍ±∞ Ï¥àÍ∏∞Ìôî ÏôÑÎ£å\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏãúÎìúÎ•º Í≥†Ï†ïÌï©ÎãàÎã§.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ÏÖã ÌÅ¥ÎûòÏä§Î•º Ï†ïÏùòÌï©ÎãàÎã§. (Hard Augmentation Ìè¨Ìï®)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation ÌôïÎ•† Í≥ÑÏÇ∞\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "                A.Rotate(limit=[-15,15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # Î∞∞ÏπòÎ≥Ñ Ï¶ùÍ∞ï ÏÑ†ÌÉù\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch ÌïôÏäµÏùÑ ÏúÑÌïú Ìï®ÏàòÏûÖÎãàÎã§.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    scaler = GradScaler()  # Mixed PrecisionÏö©\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Cutmix/Mixup Ï†ÅÏö© (30% ÌôïÎ•†)\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        scaler.scale(loss).backward()  # Mixed PrecisionÏö©\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()  # Mixed PrecisionÏö©\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validationÏùÑ ÏúÑÌïú Ìï®Ïàò Ï∂îÍ∞Ä\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    Ìïú ÏóêÌè≠ Í≤ÄÏ¶ùÏùÑ ÏàòÌñâÌïòÎäî Ìï®Ïàò\n",
    "    - model.eval()Î°ú Î™®Îç∏ÏùÑ ÌèâÍ∞Ä Î™®ÎìúÎ°ú Ï†ÑÌôò\n",
    "    - torch.no_grad()Î°ú gradient Í≥ÑÏÇ∞ ÎπÑÌôúÏÑ±ÌôîÌïòÏó¨ Î©îÎ™®Î¶¨ Ï†àÏïΩ\n",
    "    - Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞Ïóê ÎåÄÌïú loss, accuracy, f1 score Í≥ÑÏÇ∞\n",
    "    \"\"\"\n",
    "    model.eval()  # Î™®Îç∏ÏùÑ ÌèâÍ∞Ä Î™®ÎìúÎ°ú Ï†ÑÌôò (dropout, batchnorm ÎπÑÌôúÏÑ±Ìôî)\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():  # gradient Í≥ÑÏÇ∞ ÎπÑÌôúÏÑ±ÌôîÎ°ú Î©îÎ™®Î¶¨ Ï†àÏïΩ\n",
    "        pbar = tqdm(loader, desc=\"Validating\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)  # Î™®Îç∏ ÏòàÏ∏°\n",
    "            loss = loss_fn(preds, targets)  # ÏÜêÏã§ Í≥ÑÏÇ∞\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())  # ÏòàÏ∏° ÌÅ¥ÎûòÏä§ Ï†ÄÏû•\n",
    "            targets_list.extend(targets.detach().cpu().numpy())  # Ïã§Ï†ú ÌÅ¥ÎûòÏä§ Ï†ÄÏû•\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)  # ÌèâÍ∑† ÏÜêÏã§ Í≥ÑÏÇ∞\n",
    "    val_acc = accuracy_score(targets_list, preds_list)  # Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')  # Macro F1 Í≥ÑÏÇ∞ (ÎåÄÌöå ÌèâÍ∞ÄÏßÄÌëú)\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* ÌïôÏäµ Î∞è Ï∂îÎ°†Ïóê ÌïÑÏöîÌïú ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞Îì§ÏùÑ Ï†ïÏùòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = './data/raw/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'tf_efficientnetv2_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "# model_name = 'swin_base_patch4_window12_384_in22k'\n",
    "model_name = 'convnext_base_384_in22ft1k'\n",
    "# model_name = 'convnextv2_base.fcmae_ft_in22k_in1k_384'\n",
    "# model_name = 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k' # openclip\n",
    "# model_name = 'vit_base_patch16_384.augreg_in1k' # augreg\n",
    "# model_name = 'eva02_enormous_patch14_plus_clip_224.laion2b_s9b_b144k' # eva-02 Î©ÄÌã∞Î™®Îã¨\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 ÌÖåÏä§Ìä∏Ïö©\n",
    "# model_name = 'vit_base_patch14_reg4_dinov2.lvd142m' # dinov2 reg4\n",
    "\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 ÌÖåÏä§Ìä∏Ïö©\n",
    "\n",
    "# training config\n",
    "img_size = 512\n",
    "LR = 2e-4\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "num_workers = 8\n",
    "EMA = True  # Exponential Moving Average ÏÇ¨Ïö© Ïó¨Î∂Ä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OptunaÎ•º ÏÇ¨Ïö©Ìïú ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ ÌäúÎãù (ÏÑ†ÌÉùÏ†Å Ïã§Ìñâ)\n",
    "USE_OPTUNA = False  # TrueÎ°ú Î∞îÍæ∏Î©¥ ÌäúÎãù Ïã§Ìñâ\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # Í∞ÑÎã®Ìïú 3-fold CVÎ°ú Îπ†Î•∏ ÌèâÍ∞Ä\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf_simple.split(train_df, train_df['target'])):\n",
    "            # Î™®Îç∏ ÏÉùÏÑ±\n",
    "            model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "            optimizer = Adam(model.parameters(), lr=lr)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # Í∞ÑÎã®Ìïú 2 epoch ÌïôÏäµ\n",
    "            for epoch in range(2):\n",
    "                train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "            \n",
    "            val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "            fold_scores.append(val_ret['val_f1'])\n",
    "        \n",
    "        return np.mean(fold_scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # ÏµúÏ†Å ÌååÎùºÎØ∏ÌÑ∞ Ï†ÅÏö©\n",
    "    LR = study.best_params['lr']\n",
    "    BATCH_SIZE = study.best_params['batch_size']\n",
    "    print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* ÌïôÏäµ, ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ÏÖãÍ≥º Î°úÎçîÎ•º Ï†ïÏùòÌï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna ÌäúÎãù (ÏÑ†ÌÉùÏ†Å Ïã§Ìñâ)\n",
    "USE_OPTUNA = False  # TrueÎ°ú Î∞îÍæ∏Î©¥ ÌäúÎãù Ïã§Ìñâ\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    # ÏúÑÏùò objective Ìï®ÏàòÏôÄ study ÏΩîÎìú\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ï†ÑÏ≤¥ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Î°úÎìú (Í≤ΩÎ°ú ÏàòÏ†ï)\n",
    "train_df = pd.read_csv(\"data/raw/train.csv\")\n",
    "\n",
    "# K-Fold Í≤∞Í≥ºÎ•º Ï†ÄÏû•Ìï† Î¶¨Ïä§Ìä∏\n",
    "fold_results = []\n",
    "fold_models = []  # Í∞Å foldÏùò ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏ÏùÑ Ï†ÄÏû•\n",
    "fold_class_accuracies = [] # Í∞Å foldÏùò ÌÅ¥ÎûòÏä§Î≥Ñ Ï†ïÌôïÎèÑ Ï†ÄÏû•\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# K-Fold Cross Validation ÏãúÏûë\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    current_model = model_name\n",
    "    \n",
    "    # ÌòÑÏû¨ foldÏùò train/validation Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # ÌòÑÏû¨ foldÏùò Dataset ÏÉùÏÑ± (Í≤ΩÎ°ú ÏàòÏ†ï)\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"data/raw/train\",  # Í≤ΩÎ°ú ÏàòÏ†ï\n",
    "        epoch=0,  # ÌòÑÏû¨ epoch Ï†ÑÎã¨\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"data/raw/train\",  # Í≤ΩÎ°ú ÏàòÏ†ï\n",
    "        epoch=0,  # validationÏùÄ epoch Í¥ÄÍ≥ÑÏóÜÏùå\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False  # validationÏù¥ÎØÄÎ°ú hard augmentation ÎπÑÌôúÏÑ±Ìôî\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7412: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:21<00:00,  5.94it/s]\n",
      "Val Loss: 0.8423: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:03<00:00,  8.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.6760 | Train F1: 0.4697 | Val Loss: 0.7412 | Val F1: 0.8457 | LR: 2.00e-04 | Time: 24.9s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.8457 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7139: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.89it/s]\n",
      "Val Loss: 0.7645: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.9505 | Train F1: 0.6909 | Val Loss: 0.6452 | Val F1: 0.8383 | LR: 2.00e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0547: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.02it/s]\n",
      "Val Loss: 0.6771: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8082 | Train F1: 0.7326 | Val Loss: 0.5882 | Val F1: 0.8591 | LR: 2.00e-04 | Time: 15.0s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.8591 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6646: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.96it/s]\n",
      "Val Loss: 0.4858: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8843 | Train F1: 0.7438 | Val Loss: 0.5954 | Val F1: 0.8991 | LR: 1.99e-04 | Time: 15.0s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.8991 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7158: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.83it/s]\n",
      "Val Loss: 0.5691: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7922 | Train F1: 0.7523 | Val Loss: 0.5293 | Val F1: 0.8937 | LR: 1.99e-04 | Time: 15.2s\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3696: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.90it/s]\n",
      "Val Loss: 0.4840: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7495 | Train F1: 0.7784 | Val Loss: 0.5426 | Val F1: 0.9167 | LR: 1.98e-04 | Time: 15.1s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9167 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7798: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.82it/s]\n",
      "Val Loss: 0.9979: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.6938 | Train F1: 0.8205 | Val Loss: 0.5586 | Val F1: 0.9133 | LR: 1.98e-04 | Time: 15.2s\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4170: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3412: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.6325 | Train F1: 0.8562 | Val Loss: 0.5235 | Val F1: 0.9272 | LR: 1.97e-04 | Time: 15.1s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9272 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0322: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.83it/s]\n",
      "Val Loss: 0.3618: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6396 | Train F1: 0.8265 | Val Loss: 0.5173 | Val F1: 0.9455 | LR: 1.96e-04 | Time: 15.2s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9455 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3330: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3402: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6472 | Train F1: 0.8160 | Val Loss: 0.4898 | Val F1: 0.9368 | LR: 1.95e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8574: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.82it/s]\n",
      "Val Loss: 0.3354: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6181 | Train F1: 0.8385 | Val Loss: 0.4220 | Val F1: 0.9656 | LR: 1.94e-04 | Time: 15.3s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9656 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6826: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.94it/s]\n",
      "Val Loss: 0.4778: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6516 | Train F1: 0.8197 | Val Loss: 0.5542 | Val F1: 0.9180 | LR: 1.93e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3296: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.81it/s]\n",
      "Val Loss: 0.3803: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.5970 | Train F1: 0.8491 | Val Loss: 0.4540 | Val F1: 0.9554 | LR: 1.92e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6025: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3421: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.5687 | Train F1: 0.8674 | Val Loss: 0.4573 | Val F1: 0.9510 | LR: 1.90e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0068: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:13<00:00,  9.69it/s]\n",
      "Val Loss: 0.3352: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.5835 | Train F1: 0.8312 | Val Loss: 0.4845 | Val F1: 0.9474 | LR: 1.89e-04 | Time: 15.4s\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3403: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.4947: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.5825 | Train F1: 0.8586 | Val Loss: 0.4503 | Val F1: 0.9532 | LR: 1.88e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4673: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.94it/s]\n",
      "Val Loss: 0.3287: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.5772 | Train F1: 0.8986 | Val Loss: 0.4439 | Val F1: 0.9551 | LR: 1.86e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3252: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.92it/s]\n",
      "Val Loss: 0.3257: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5779 | Train F1: 0.8448 | Val Loss: 0.4922 | Val F1: 0.9347 | LR: 1.84e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3242: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.00it/s]\n",
      "Val Loss: 0.3257: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5301 | Train F1: 0.8653 | Val Loss: 0.4355 | Val F1: 0.9692 | LR: 1.83e-04 | Time: 15.0s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9692 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3247: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.92it/s]\n",
      "Val Loss: 0.3289: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5476 | Train F1: 0.8765 | Val Loss: 0.4499 | Val F1: 0.9634 | LR: 1.81e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5215: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.06it/s]\n",
      "Val Loss: 0.4093: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5790 | Train F1: 0.8378 | Val Loss: 0.4228 | Val F1: 0.9709 | LR: 1.79e-04 | Time: 14.9s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9709 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3806: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.94it/s]\n",
      "Val Loss: 0.3235: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5634 | Train F1: 0.8603 | Val Loss: 0.4255 | Val F1: 0.9594 | LR: 1.77e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3264: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.98it/s]\n",
      "Val Loss: 0.3213: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.6163 | Train F1: 0.8355 | Val Loss: 0.4871 | Val F1: 0.9574 | LR: 1.75e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1387: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.87it/s]\n",
      "Val Loss: 0.3230: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5927 | Train F1: 0.8169 | Val Loss: 0.4631 | Val F1: 0.9572 | LR: 1.73e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4932: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.97it/s]\n",
      "Val Loss: 0.5952: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5762 | Train F1: 0.8758 | Val Loss: 0.5114 | Val F1: 0.9453 | LR: 1.71e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3413: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.92it/s]\n",
      "Val Loss: 0.3233: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.5778 | Train F1: 0.8569 | Val Loss: 0.4192 | Val F1: 0.9702 | LR: 1.68e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5293: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.04it/s]\n",
      "Val Loss: 0.3222: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.6060 | Train F1: 0.8439 | Val Loss: 0.4804 | Val F1: 0.9498 | LR: 1.66e-04 | Time: 14.9s\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9883: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.81it/s]\n",
      "Val Loss: 0.3335: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5845 | Train F1: 0.8677 | Val Loss: 0.4635 | Val F1: 0.9595 | LR: 1.64e-04 | Time: 15.2s\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3235: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.83it/s]\n",
      "Val Loss: 0.3338: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5612 | Train F1: 0.8750 | Val Loss: 0.4628 | Val F1: 0.9583 | LR: 1.61e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1504: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.80it/s]\n",
      "Val Loss: 0.3224: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5759 | Train F1: 0.8524 | Val Loss: 0.4714 | Val F1: 0.9614 | LR: 1.59e-04 | Time: 15.2s\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3230: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.02it/s]\n",
      "Val Loss: 0.3227: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5206 | Train F1: 0.8881 | Val Loss: 0.4308 | Val F1: 0.9673 | LR: 1.56e-04 | Time: 14.9s\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3213: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.81it/s]\n",
      "Val Loss: 0.3212: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.5497 | Train F1: 0.8640 | Val Loss: 0.4383 | Val F1: 0.9718 | LR: 1.54e-04 | Time: 15.2s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9718 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3220: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.03it/s]\n",
      "Val Loss: 0.3225: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 0.5782 | Train F1: 0.8525 | Val Loss: 0.4607 | Val F1: 0.9514 | LR: 1.51e-04 | Time: 14.9s\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3213: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.86it/s]\n",
      "Val Loss: 0.3213: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 0.5652 | Train F1: 0.8631 | Val Loss: 0.4753 | Val F1: 0.9554 | LR: 1.48e-04 | Time: 15.2s\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3240: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.96it/s]\n",
      "Val Loss: 0.3222: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 0.5667 | Train F1: 0.8754 | Val Loss: 0.4401 | Val F1: 0.9655 | LR: 1.45e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.81it/s]\n",
      "Val Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 0.5697 | Train F1: 0.8454 | Val Loss: 0.4410 | Val F1: 0.9617 | LR: 1.43e-04 | Time: 15.2s\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9307: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3218: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 0.5448 | Train F1: 0.8673 | Val Loss: 0.4390 | Val F1: 0.9693 | LR: 1.40e-04 | Time: 14.9s\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6104: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.89it/s]\n",
      "Val Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 0.5880 | Train F1: 0.8272 | Val Loss: 0.4390 | Val F1: 0.9667 | LR: 1.37e-04 | Time: 15.2s\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.00it/s]\n",
      "Val Loss: 0.3244: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 0.4780 | Train F1: 0.8943 | Val Loss: 0.4346 | Val F1: 0.9697 | LR: 1.34e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3210: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.5440 | Train F1: 0.8469 | Val Loss: 0.4568 | Val F1: 0.9593 | LR: 1.31e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9355: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3207: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 0.5103 | Train F1: 0.8974 | Val Loss: 0.4510 | Val F1: 0.9688 | LR: 1.28e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3217: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 0.4996 | Train F1: 0.8801 | Val Loss: 0.4339 | Val F1: 0.9735 | LR: 1.25e-04 | Time: 15.0s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9735 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5132: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.98it/s]\n",
      "Val Loss: 0.3219: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 14.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 0.5211 | Train F1: 0.8627 | Val Loss: 0.4647 | Val F1: 0.9615 | LR: 1.22e-04 | Time: 14.9s\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3245: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.87it/s]\n",
      "Val Loss: 0.3207: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 0.5207 | Train F1: 0.8659 | Val Loss: 0.4269 | Val F1: 0.9746 | LR: 1.19e-04 | Time: 15.2s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9746 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3225: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.01it/s]\n",
      "Val Loss: 0.3211: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 0.5185 | Train F1: 0.8400 | Val Loss: 0.4618 | Val F1: 0.9597 | LR: 1.16e-04 | Time: 14.9s\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3268: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 0.5476 | Train F1: 0.8779 | Val Loss: 0.4475 | Val F1: 0.9703 | LR: 1.13e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1299: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.90it/s]\n",
      "Val Loss: 0.3213: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 0.5295 | Train F1: 0.8843 | Val Loss: 0.4856 | Val F1: 0.9588 | LR: 1.09e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.02it/s]\n",
      "Val Loss: 0.3213: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 0.5024 | Train F1: 0.8971 | Val Loss: 0.4463 | Val F1: 0.9654 | LR: 1.06e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9717: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.84it/s]\n",
      "Val Loss: 0.3205: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 0.5705 | Train F1: 0.8386 | Val Loss: 0.4419 | Val F1: 0.9701 | LR: 1.03e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6006: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.01it/s]\n",
      "Val Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 0.4923 | Train F1: 0.8713 | Val Loss: 0.4426 | Val F1: 0.9680 | LR: 1.00e-04 | Time: 14.9s\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9482: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.81it/s]\n",
      "Val Loss: 0.3210: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Train Loss: 0.5113 | Train F1: 0.8814 | Val Loss: 0.4724 | Val F1: 0.9709 | LR: 9.69e-05 | Time: 15.2s\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4751: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3209: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 0.4996 | Train F1: 0.8833 | Val Loss: 0.4411 | Val F1: 0.9674 | LR: 9.37e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8193: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.85it/s]\n",
      "Val Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Train Loss: 0.4883 | Train F1: 0.8361 | Val Loss: 0.4537 | Val F1: 0.9665 | LR: 9.06e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 14.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Train Loss: 0.5157 | Train F1: 0.8513 | Val Loss: 0.4794 | Val F1: 0.9612 | LR: 8.75e-05 | Time: 14.9s\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.88it/s]\n",
      "Val Loss: 0.3216: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Train Loss: 0.5481 | Train F1: 0.8779 | Val Loss: 0.4571 | Val F1: 0.9673 | LR: 8.44e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3213: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.98it/s]\n",
      "Val Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Train Loss: 0.5104 | Train F1: 0.8824 | Val Loss: 0.4643 | Val F1: 0.9672 | LR: 8.13e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.90it/s]\n",
      "Val Loss: 0.3209: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Train Loss: 0.4762 | Train F1: 0.8549 | Val Loss: 0.4456 | Val F1: 0.9721 | LR: 7.82e-05 | Time: 15.2s\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Train Loss: 0.5033 | Train F1: 0.8897 | Val Loss: 0.4508 | Val F1: 0.9724 | LR: 7.51e-05 | Time: 14.9s\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9131: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.72it/s]\n",
      "Val Loss: 0.3219: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Train Loss: 0.5241 | Train F1: 0.8720 | Val Loss: 0.4424 | Val F1: 0.9718 | LR: 7.21e-05 | Time: 15.4s\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.94it/s]\n",
      "Val Loss: 0.3205: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Train Loss: 0.5265 | Train F1: 0.8554 | Val Loss: 0.4675 | Val F1: 0.9707 | LR: 6.91e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.98it/s]\n",
      "Val Loss: 0.3205: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 | Train Loss: 0.4896 | Train F1: 0.8709 | Val Loss: 0.4587 | Val F1: 0.9673 | LR: 6.61e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.89it/s]\n",
      "Val Loss: 0.3205: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Train Loss: 0.5297 | Train F1: 0.8500 | Val Loss: 0.4352 | Val F1: 0.9733 | LR: 6.32e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9512: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.01it/s]\n",
      "Val Loss: 0.3204: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 | Train Loss: 0.5126 | Train F1: 0.8553 | Val Loss: 0.4605 | Val F1: 0.9647 | LR: 6.03e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.86it/s]\n",
      "Val Loss: 0.3207: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Train Loss: 0.4863 | Train F1: 0.8713 | Val Loss: 0.4432 | Val F1: 0.9727 | LR: 5.74e-05 | Time: 15.2s\n",
      "\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.03it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 | Train Loss: 0.4716 | Train F1: 0.9064 | Val Loss: 0.4595 | Val F1: 0.9690 | LR: 5.46e-05 | Time: 14.9s\n",
      "\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.82it/s]\n",
      "Val Loss: 0.3204: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Train Loss: 0.4993 | Train F1: 0.8742 | Val Loss: 0.4387 | Val F1: 0.9699 | LR: 5.18e-05 | Time: 15.2s\n",
      "\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 | Train Loss: 0.5199 | Train F1: 0.8648 | Val Loss: 0.4410 | Val F1: 0.9742 | LR: 4.91e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.76it/s]\n",
      "Val Loss: 0.3205: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 | Train Loss: 0.4760 | Train F1: 0.8690 | Val Loss: 0.4447 | Val F1: 0.9698 | LR: 4.64e-05 | Time: 15.3s\n",
      "\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7710: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.00it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 | Train Loss: 0.5181 | Train F1: 0.8819 | Val Loss: 0.4398 | Val F1: 0.9699 | LR: 4.38e-05 | Time: 14.9s\n",
      "\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.88it/s]\n",
      "Val Loss: 0.3205: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 | Train Loss: 0.5600 | Train F1: 0.8367 | Val Loss: 0.4544 | Val F1: 0.9704 | LR: 4.12e-05 | Time: 15.2s\n",
      "\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0059: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.98it/s]\n",
      "Val Loss: 0.3204: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Train Loss: 0.4775 | Train F1: 0.8718 | Val Loss: 0.4529 | Val F1: 0.9670 | LR: 3.87e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6631: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.87it/s]\n",
      "Val Loss: 0.3204: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 | Train Loss: 0.4970 | Train F1: 0.8580 | Val Loss: 0.4629 | Val F1: 0.9670 | LR: 3.63e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4409: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.95it/s]\n",
      "Val Loss: 0.3204: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Train Loss: 0.4896 | Train F1: 0.8723 | Val Loss: 0.4480 | Val F1: 0.9703 | LR: 3.39e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6543: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.76it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 | Train Loss: 0.4907 | Train F1: 0.8720 | Val Loss: 0.4565 | Val F1: 0.9670 | LR: 3.15e-05 | Time: 15.3s\n",
      "\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.94it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Train Loss: 0.5189 | Train F1: 0.8753 | Val Loss: 0.4548 | Val F1: 0.9699 | LR: 2.93e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.96it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train Loss: 0.5216 | Train F1: 0.7942 | Val Loss: 0.4813 | Val F1: 0.9637 | LR: 2.71e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0781: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.92it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 | Train Loss: 0.4945 | Train F1: 0.8939 | Val Loss: 0.4684 | Val F1: 0.9644 | LR: 2.50e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.07it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 | Train Loss: 0.5031 | Train F1: 0.8271 | Val Loss: 0.4653 | Val F1: 0.9670 | LR: 2.29e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.88it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 | Train Loss: 0.4659 | Train F1: 0.8988 | Val Loss: 0.4658 | Val F1: 0.9641 | LR: 2.10e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5381: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.03it/s]\n",
      "Val Loss: 0.3204: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 | Train Loss: 0.5356 | Train F1: 0.8322 | Val Loss: 0.4735 | Val F1: 0.9622 | LR: 1.91e-05 | Time: 14.9s\n",
      "\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.88it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 | Train Loss: 0.4964 | Train F1: 0.8861 | Val Loss: 0.4565 | Val F1: 0.9673 | LR: 1.73e-05 | Time: 15.1s\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.01it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 | Train Loss: 0.4871 | Train F1: 0.8777 | Val Loss: 0.4649 | Val F1: 0.9665 | LR: 1.56e-05 | Time: 14.9s\n",
      "\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.83it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 | Train Loss: 0.5082 | Train F1: 0.8589 | Val Loss: 0.4551 | Val F1: 0.9674 | LR: 1.39e-05 | Time: 15.2s\n",
      "\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6855: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.97it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 | Train Loss: 0.5370 | Train F1: 0.8514 | Val Loss: 0.4634 | Val F1: 0.9670 | LR: 1.24e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.87it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 | Train Loss: 0.4922 | Train F1: 0.8616 | Val Loss: 0.4412 | Val F1: 0.9693 | LR: 1.09e-05 | Time: 15.2s\n",
      "\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.00it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 | Train Loss: 0.4686 | Train F1: 0.8999 | Val Loss: 0.4487 | Val F1: 0.9734 | LR: 9.52e-06 | Time: 14.9s\n",
      "\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.85it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 | Train Loss: 0.5041 | Train F1: 0.8801 | Val Loss: 0.4589 | Val F1: 0.9673 | LR: 8.22e-06 | Time: 15.1s\n",
      "\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.96it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 | Train Loss: 0.4892 | Train F1: 0.8679 | Val Loss: 0.4633 | Val F1: 0.9645 | LR: 7.02e-06 | Time: 15.0s\n",
      "\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.75it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 | Train Loss: 0.4866 | Train F1: 0.8865 | Val Loss: 0.4746 | Val F1: 0.9669 | LR: 5.91e-06 | Time: 15.3s\n",
      "\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.98it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 | Train Loss: 0.4757 | Train F1: 0.8715 | Val Loss: 0.4525 | Val F1: 0.9672 | LR: 4.89e-06 | Time: 15.0s\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9126: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.89it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 | Train Loss: 0.5018 | Train F1: 0.8424 | Val Loss: 0.4462 | Val F1: 0.9701 | LR: 3.97e-06 | Time: 15.1s\n",
      "\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.91it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 | Train Loss: 0.5029 | Train F1: 0.8540 | Val Loss: 0.4623 | Val F1: 0.9643 | LR: 3.14e-06 | Time: 15.1s\n",
      "\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.96it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 | Train Loss: 0.4710 | Train F1: 0.9132 | Val Loss: 0.4687 | Val F1: 0.9670 | LR: 2.41e-06 | Time: 15.0s\n",
      "\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 | Train Loss: 0.5168 | Train F1: 0.9050 | Val Loss: 0.4616 | Val F1: 0.9703 | LR: 1.77e-06 | Time: 15.0s\n",
      "\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8950: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 | Train Loss: 0.5029 | Train F1: 0.8719 | Val Loss: 0.4573 | Val F1: 0.9672 | LR: 1.23e-06 | Time: 15.1s\n",
      "\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9556: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.89it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 | Train Loss: 0.4536 | Train F1: 0.9112 | Val Loss: 0.4680 | Val F1: 0.9642 | LR: 7.89e-07 | Time: 15.1s\n",
      "\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.00it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 | Train Loss: 0.4502 | Train F1: 0.8985 | Val Loss: 0.4504 | Val F1: 0.9699 | LR: 4.44e-07 | Time: 14.9s\n",
      "\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6650: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.87it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 | Train Loss: 0.4687 | Train F1: 0.8741 | Val Loss: 0.4407 | Val F1: 0.9724 | LR: 1.97e-07 | Time: 15.2s\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.01it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.5278 | Train F1: 0.8404 | Val Loss: 0.4629 | Val F1: 0.9672 | LR: 4.93e-08 | Time: 14.9s\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.89it/s]\n",
      "Val Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Train Loss: 0.4786 | Train F1: 0.8835 | Val Loss: 0.4641 | Val F1: 0.9644 | LR: 0.00e+00 | Time: 15.1s\n",
      "\n",
      "Fold 1 ÏôÑÎ£å!\n",
      "ÏµúÍ≥† Validation F1: 0.9746\n",
      "ÌïôÏäµÎêú ÏóêÌè≠: 100/100\n",
      "Î™®Îç∏ Ï†ÄÏû• ÏúÑÏπò: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2695: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.85it/s]\n",
      "Val Loss: 1.0553: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.7206 | Train F1: 0.4433 | Val Loss: 0.8488 | Val F1: 0.7556 | LR: 2.00e-04 | Time: 15.2s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.7556 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3638: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.78it/s]\n",
      "Val Loss: 1.4616: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.9865 | Train F1: 0.7016 | Val Loss: 0.7066 | Val F1: 0.8109 | LR: 2.00e-04 | Time: 15.3s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.8109 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7944: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.79it/s]\n",
      "Val Loss: 0.4968: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8668 | Train F1: 0.7338 | Val Loss: 0.5258 | Val F1: 0.9064 | LR: 2.00e-04 | Time: 15.3s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9064 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9878: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.79it/s]\n",
      "Val Loss: 0.5459: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8012 | Train F1: 0.7420 | Val Loss: 0.5280 | Val F1: 0.9039 | LR: 1.99e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8174: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.03it/s]\n",
      "Val Loss: 0.3519: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7279 | Train F1: 0.8325 | Val Loss: 0.5761 | Val F1: 0.8645 | LR: 1.99e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3728: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.78it/s]\n",
      "Val Loss: 0.4064: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7422 | Train F1: 0.8154 | Val Loss: 0.4705 | Val F1: 0.9456 | LR: 1.98e-04 | Time: 15.3s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9456 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4055: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.02it/s]\n",
      "Val Loss: 0.5093: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.6691 | Train F1: 0.8510 | Val Loss: 0.4836 | Val F1: 0.9333 | LR: 1.98e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4202: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.80it/s]\n",
      "Val Loss: 0.6881: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7364 | Train F1: 0.7827 | Val Loss: 0.5022 | Val F1: 0.9202 | LR: 1.97e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0137: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.01it/s]\n",
      "Val Loss: 0.3543: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6996 | Train F1: 0.8314 | Val Loss: 0.4969 | Val F1: 0.9357 | LR: 1.96e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8071: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.75it/s]\n",
      "Val Loss: 0.3688: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6414 | Train F1: 0.8281 | Val Loss: 0.4918 | Val F1: 0.9384 | LR: 1.95e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7388: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3494: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6971 | Train F1: 0.7848 | Val Loss: 0.5436 | Val F1: 0.9251 | LR: 1.94e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3416: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.76it/s]\n",
      "Val Loss: 0.3938: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.5931 | Train F1: 0.8418 | Val Loss: 0.5012 | Val F1: 0.9118 | LR: 1.93e-04 | Time: 15.4s\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5010: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3357: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6558 | Train F1: 0.8478 | Val Loss: 0.4430 | Val F1: 0.9521 | LR: 1.92e-04 | Time: 15.0s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9521 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3274: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.77it/s]\n",
      "Val Loss: 0.3382: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6393 | Train F1: 0.8254 | Val Loss: 0.5073 | Val F1: 0.9440 | LR: 1.90e-04 | Time: 15.4s\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7168: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.98it/s]\n",
      "Val Loss: 0.4263: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6167 | Train F1: 0.8743 | Val Loss: 0.5044 | Val F1: 0.9405 | LR: 1.89e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3423: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.81it/s]\n",
      "Val Loss: 0.8725: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.6417 | Train F1: 0.8066 | Val Loss: 0.5098 | Val F1: 0.9276 | LR: 1.88e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5684: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.77it/s]\n",
      "Val Loss: 0.3911: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6384 | Train F1: 0.8157 | Val Loss: 0.4583 | Val F1: 0.9509 | LR: 1.86e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3330: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.79it/s]\n",
      "Val Loss: 0.3306: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5697 | Train F1: 0.8481 | Val Loss: 0.4338 | Val F1: 0.9622 | LR: 1.84e-04 | Time: 15.3s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9622 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3235: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.00it/s]\n",
      "Val Loss: 0.3849: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5510 | Train F1: 0.8591 | Val Loss: 0.4380 | Val F1: 0.9624 | LR: 1.83e-04 | Time: 15.0s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9624 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3281: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.77it/s]\n",
      "Val Loss: 0.3322: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5501 | Train F1: 0.8547 | Val Loss: 0.4415 | Val F1: 0.9608 | LR: 1.81e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7793: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.00it/s]\n",
      "Val Loss: 0.3269: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5718 | Train F1: 0.8692 | Val Loss: 0.5082 | Val F1: 0.9216 | LR: 1.79e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3242: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.84it/s]\n",
      "Val Loss: 0.3237: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5384 | Train F1: 0.8925 | Val Loss: 0.4402 | Val F1: 0.9664 | LR: 1.77e-04 | Time: 15.3s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9664 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3389: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.95it/s]\n",
      "Val Loss: 0.3462: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5602 | Train F1: 0.8326 | Val Loss: 0.4374 | Val F1: 0.9520 | LR: 1.75e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3315: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.82it/s]\n",
      "Val Loss: 0.3352: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5504 | Train F1: 0.8637 | Val Loss: 0.4173 | Val F1: 0.9575 | LR: 1.73e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8818: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.95it/s]\n",
      "Val Loss: 0.3252: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5940 | Train F1: 0.8410 | Val Loss: 0.4206 | Val F1: 0.9702 | LR: 1.71e-04 | Time: 15.1s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9702 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5635: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.81it/s]\n",
      "Val Loss: 0.3275: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.6308 | Train F1: 0.7787 | Val Loss: 0.4723 | Val F1: 0.9581 | LR: 1.68e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4941: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.95it/s]\n",
      "Val Loss: 0.5127: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5969 | Train F1: 0.8253 | Val Loss: 0.4795 | Val F1: 0.9505 | LR: 1.66e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1475: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.84it/s]\n",
      "Val Loss: 0.3259: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5674 | Train F1: 0.8552 | Val Loss: 0.4307 | Val F1: 0.9621 | LR: 1.64e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3234: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5644 | Train F1: 0.8327 | Val Loss: 0.4203 | Val F1: 0.9690 | LR: 1.61e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3247: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.83it/s]\n",
      "Val Loss: 0.3216: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5431 | Train F1: 0.8848 | Val Loss: 0.4013 | Val F1: 0.9791 | LR: 1.59e-04 | Time: 15.2s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9791 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5142: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3253: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5672 | Train F1: 0.8785 | Val Loss: 0.4546 | Val F1: 0.9548 | LR: 1.56e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9043: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:13<00:00,  9.66it/s]\n",
      "Val Loss: 0.3304: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.5605 | Train F1: 0.8567 | Val Loss: 0.4131 | Val F1: 0.9749 | LR: 1.54e-04 | Time: 15.5s\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.97it/s]\n",
      "Val Loss: 0.3211: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 0.5067 | Train F1: 0.8944 | Val Loss: 0.4069 | Val F1: 0.9732 | LR: 1.51e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.83it/s]\n",
      "Val Loss: 0.3219: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 0.5594 | Train F1: 0.8537 | Val Loss: 0.4090 | Val F1: 0.9703 | LR: 1.48e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3230: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.95it/s]\n",
      "Val Loss: 0.3242: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 0.5827 | Train F1: 0.8777 | Val Loss: 0.4243 | Val F1: 0.9661 | LR: 1.45e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.89it/s]\n",
      "Val Loss: 0.3207: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 12.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 0.5512 | Train F1: 0.8643 | Val Loss: 0.4355 | Val F1: 0.9622 | LR: 1.43e-04 | Time: 15.2s\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5947: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.91it/s]\n",
      "Val Loss: 0.3212: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 0.5732 | Train F1: 0.8493 | Val Loss: 0.3854 | Val F1: 0.9836 | LR: 1.40e-04 | Time: 15.1s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9836 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3613: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.86it/s]\n",
      "Val Loss: 0.3211: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 12.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 0.5503 | Train F1: 0.8418 | Val Loss: 0.4297 | Val F1: 0.9655 | LR: 1.37e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.90it/s]\n",
      "Val Loss: 0.3229: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 0.5127 | Train F1: 0.8784 | Val Loss: 0.3971 | Val F1: 0.9804 | LR: 1.34e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3403: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3234: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.5401 | Train F1: 0.8812 | Val Loss: 0.4179 | Val F1: 0.9731 | LR: 1.31e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3228: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.95it/s]\n",
      "Val Loss: 0.3230: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 0.5076 | Train F1: 0.8937 | Val Loss: 0.4213 | Val F1: 0.9699 | LR: 1.28e-04 | Time: 15.0s\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.95it/s]\n",
      "Val Loss: 0.3210: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 12.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 0.5092 | Train F1: 0.8824 | Val Loss: 0.3895 | Val F1: 0.9839 | LR: 1.25e-04 | Time: 15.2s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9839 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3237: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.91it/s]\n",
      "Val Loss: 0.3319: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 0.5510 | Train F1: 0.8527 | Val Loss: 0.4330 | Val F1: 0.9565 | LR: 1.22e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7490: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00, 10.02it/s]\n",
      "Val Loss: 0.3285: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 12.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 0.5745 | Train F1: 0.8530 | Val Loss: 0.4425 | Val F1: 0.9687 | LR: 1.19e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3225: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.86it/s]\n",
      "Val Loss: 0.3211: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 0.5014 | Train F1: 0.8647 | Val Loss: 0.3782 | Val F1: 0.9848 | LR: 1.16e-04 | Time: 15.2s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9848 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7373: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.79it/s]\n",
      "Val Loss: 0.3210: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 12.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 0.5902 | Train F1: 0.8550 | Val Loss: 0.4108 | Val F1: 0.9728 | LR: 1.13e-04 | Time: 15.4s\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.86it/s]\n",
      "Val Loss: 0.3235: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 0.5141 | Train F1: 0.8908 | Val Loss: 0.4191 | Val F1: 0.9731 | LR: 1.09e-04 | Time: 15.2s\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3300: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 12.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 0.5017 | Train F1: 0.8827 | Val Loss: 0.4026 | Val F1: 0.9696 | LR: 1.06e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.81it/s]\n",
      "Val Loss: 0.3209: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 0.5047 | Train F1: 0.8683 | Val Loss: 0.3982 | Val F1: 0.9810 | LR: 1.03e-04 | Time: 15.3s\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.98it/s]\n",
      "Val Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 0.4906 | Train F1: 0.8992 | Val Loss: 0.4124 | Val F1: 0.9731 | LR: 1.00e-04 | Time: 15.1s\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.78it/s]\n",
      "Val Loss: 0.3207: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Train Loss: 0.5170 | Train F1: 0.8995 | Val Loss: 0.3993 | Val F1: 0.9808 | LR: 9.69e-05 | Time: 15.3s\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9468: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.99it/s]\n",
      "Val Loss: 0.3205: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 0.5378 | Train F1: 0.8581 | Val Loss: 0.4755 | Val F1: 0.9560 | LR: 9.37e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1172: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.79it/s]\n",
      "Val Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Train Loss: 0.5793 | Train F1: 0.7915 | Val Loss: 0.3887 | Val F1: 0.9803 | LR: 9.06e-05 | Time: 15.3s\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4917: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.95it/s]\n",
      "Val Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Train Loss: 0.5535 | Train F1: 0.8600 | Val Loss: 0.3951 | Val F1: 0.9759 | LR: 8.75e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7578: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.80it/s]\n",
      "Val Loss: 0.3208: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Train Loss: 0.5115 | Train F1: 0.8340 | Val Loss: 0.3869 | Val F1: 0.9838 | LR: 8.44e-05 | Time: 15.3s\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.93it/s]\n",
      "Val Loss: 0.3212: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Train Loss: 0.4975 | Train F1: 0.8641 | Val Loss: 0.3856 | Val F1: 0.9867 | LR: 8.13e-05 | Time: 15.1s\n",
      "ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: 0.9867 - Î™®Îç∏ Ï†ÄÏû•: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.79it/s]\n",
      "Val Loss: 0.3210: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Train Loss: 0.5318 | Train F1: 0.8684 | Val Loss: 0.4166 | Val F1: 0.9686 | LR: 7.82e-05 | Time: 15.3s\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.96it/s]\n",
      "Val Loss: 0.3215: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Train Loss: 0.4922 | Train F1: 0.8899 | Val Loss: 0.4070 | Val F1: 0.9808 | LR: 7.51e-05 | Time: 15.0s\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.85it/s]\n",
      "Val Loss: 0.3205: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 12.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Train Loss: 0.5342 | Train F1: 0.8367 | Val Loss: 0.3849 | Val F1: 0.9796 | LR: 7.21e-05 | Time: 15.3s\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 126/126 [00:12<00:00,  9.87it/s]\n",
      "Val Loss: 0.3209: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 32/32 [00:02<00:00, 13.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Train Loss: 0.5207 | Train F1: 0.8434 | Val Loss: 0.3883 | Val F1: 0.9812 | LR: 6.91e-05 | Time: 15.2s\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3237:  22%|‚ñà‚ñà‚ñè       | 28/126 [00:03<00:11,  8.80it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 87\u001b[0m\n\u001b[1;32m     84\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# Training\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m train_ret \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrn_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# Validation\u001b[39;00m\n\u001b[1;32m     90\u001b[0m val_ret \u001b[38;5;241m=\u001b[39m validate_one_epoch(val_loader, model, loss_fn, device)\n",
      "Cell \u001b[0;32mIn[6], line 27\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(loader, model, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     25\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Mixed PrecisionÏö©\u001b[39;00m\n\u001b[1;32m     26\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m; scaler\u001b[38;5;241m.\u001b[39mupdate()  \u001b[38;5;66;03m# Mixed PrecisionÏö©\u001b[39;00m\n\u001b[1;32m     29\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     30\u001b[0m preds_list\u001b[38;5;241m.\u001b[39mextend(preds\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/torch/amp/grad_scaler.py:457\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munscale_(optimizer)\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    455\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 457\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(v\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/torch/amp/grad_scaler.py:351\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_maybe_opt_step\u001b[39m(\n\u001b[1;32m    344\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    345\u001b[0m     optimizer: torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mOptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    350\u001b[0m     retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 351\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    352\u001b[0m         retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m retval\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# K-Fold ÏÑ§Ï†ï\n",
    "N_FOLDS = 5  # 5-foldÎ°ú ÏÑ§Ï†ï (Îç∞Ïù¥ÌÑ∞Í∞Ä Ï†ÅÏúºÎØÄÎ°ú)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# Ï†ÑÏ≤¥ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "train_df = pd.read_csv(\"./data/raw/train.csv\")\n",
    "\n",
    "# K-Fold Í≤∞Í≥ºÎ•º Ï†ÄÏû•Ìï† Î¶¨Ïä§Ìä∏\n",
    "fold_results = []\n",
    "fold_models = []  # Í∞Å foldÏùò ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏ÏùÑ Ï†ÄÏû•\n",
    "fold_class_accuracies = [] # Í∞Å foldÏùò ÌÅ¥ÎûòÏä§Î≥Ñ Ï†ïÌôïÎèÑ Ï†ÄÏû•\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# K-Fold Cross Validation ÏãúÏûë\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    current_model = model_name\n",
    "    \n",
    "    # ÌòÑÏû¨ foldÏùò train/validation Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # ÌòÑÏû¨ foldÏùò Dataset ÏÉùÏÑ±\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"./data/raw/train\",\n",
    "        epoch=0,  # ÌòÑÏû¨ epoch Ï†ÑÎã¨\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"./data/raw/train\",\n",
    "        epoch=0,  # validationÏùÄ epoch Í¥ÄÍ≥ÑÏóÜÏùå\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False  # validationÏù¥ÎØÄÎ°ú hard augmentation ÎπÑÌôúÏÑ±Ìôî\n",
    "    )\n",
    "    \n",
    "    # ÌòÑÏû¨ foldÏùò DataLoader ÏÉùÏÑ±\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # Î™®Îç∏ Ï¥àÍ∏∞Ìôî (Í∞Å foldÎßàÎã§ ÏÉàÎ°úÏö¥ Î™®Îç∏)\n",
    "    model = timm.create_model(\n",
    "        current_model,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)  # Label Smoothing Ï†ÅÏö©\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler Ï∂îÍ∞Ä\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # ÌòÑÏû¨ foldÏùò ÏµúÍ≥† ÏÑ±Îä• Ï∂îÏ†Å\n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # ÌòÑÏû¨ fold ÌïôÏäµ\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training\n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # Scheduler step Ï∂îÍ∞Ä\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f} | \"\n",
    "              f\"LR: {current_lr:.2e} | \"\n",
    "              f\"Time: {epoch_time:.1f}s\")\n",
    "        \n",
    "        # ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏ Ï†ÄÏû•\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏ÏùÑ ÌååÏùºÎ°ú Ï†ÄÏû•\n",
    "            model_path = f'BH_512_base_best_model_fold_{fold+1}.pth'\n",
    "            torch.save(best_model, model_path)\n",
    "            print(f\"ÏÉàÎ°úÏö¥ ÏµúÍ≥† ÏÑ±Îä•! F1: {best_val_f1:.4f} - Î™®Îç∏ Ï†ÄÏû•: {model_path}\")\n",
    "            \n",
    "            # Best Î™®Îç∏Î°ú ÌÅ¥ÎûòÏä§Î≥Ñ Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞\n",
    "            model.eval()\n",
    "            val_preds, val_targets = [], []\n",
    "            with torch.no_grad():\n",
    "                for image, targets in val_loader:\n",
    "                    preds = model(image.to(device)).argmax(dim=1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_targets.extend(targets.numpy())\n",
    "            \n",
    "            # ÌÅ¥ÎûòÏä§Î≥Ñ Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞\n",
    "            fold_class_acc = {}\n",
    "            for c in range(17):\n",
    "                mask = np.array(val_targets) == c\n",
    "                if mask.sum() > 0:\n",
    "                    fold_class_acc[c] = (np.array(val_preds)[mask] == c).mean()\n",
    "\n",
    "    # ÌòÑÏû¨ fold Í≤∞Í≥º Ï†ÄÏû•\n",
    "    fold_result = {\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'final_train_f1': train_ret['train_f1'],\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset),\n",
    "        'epochs_trained': EPOCHS,\n",
    "        'model_path': f'./notebooks/team/JSW/models/BH_512_base_best_model_fold_{fold+1}.pth'\n",
    "    }\n",
    "    \n",
    "    fold_results.append(fold_result)\n",
    "    fold_models.append(best_model)\n",
    "    fold_class_accuracies.append(fold_class_acc)\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} ÏôÑÎ£å!\")\n",
    "    print(f\"ÏµúÍ≥† Validation F1: {best_val_f1:.4f}\")\n",
    "    print(f\"ÌïôÏäµÎêú ÏóêÌè≠: {EPOCHS}/{EPOCHS}\")\n",
    "    print(f\"Î™®Îç∏ Ï†ÄÏû• ÏúÑÏπò: ./notebooks/team/JSW/models/BH_512_base_best_model_fold_{fold+1}.pth\")\n",
    "    \n",
    "    # Î©îÎ™®Î¶¨ Ï†ïÎ¶¨\n",
    "    del model, optimizer, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# K-Fold Í≤∞Í≥º ÏöîÏïΩ\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"K-FOLD CROSS VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: F1={result['best_val_f1']:.4f} \"\n",
    "          f\"(epochs: {result['epochs_trained']}) \"\n",
    "          f\"- {result['model_path']}\")\n",
    "\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} ¬± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(val_f1_scores):.4f}\")\n",
    "\n",
    "# Ï†ÄÏû•Îêú Î™®Îç∏ ÌååÏùº Î¶¨Ïä§Ìä∏ Ï∂úÎ†•\n",
    "print(f\"\\nÏ†ÄÏû•Îêú Î™®Îç∏ ÌååÏùºÎì§:\")\n",
    "for i in range(N_FOLDS):\n",
    "    model_file = f'./notebooks/team/JSW/models/BH_512_base_best_model_fold_{i+1}.pth'\n",
    "    if os.path.exists(model_file):\n",
    "        print(f\"  ‚úì {model_file}\")\n",
    "    else:\n",
    "        print(f\"  ‚úó {model_file} (ÏóÜÏùå)\")\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§Î≥Ñ ÌèâÍ∑† Ï†ïÌôïÎèÑ Í≥ÑÏÇ∞\n",
    "if fold_class_accuracies:\n",
    "    print(f\"\\nÌÅ¥ÎûòÏä§Î≥Ñ ÌèâÍ∑† Ï†ïÌôïÎèÑ (Ï†ÑÏ≤¥ fold):\")\n",
    "    for class_id in range(17):\n",
    "        class_accs = []\n",
    "        for fold_acc in fold_class_accuracies:\n",
    "            if class_id in fold_acc:\n",
    "                class_accs.append(fold_acc[class_id])\n",
    "        \n",
    "        if class_accs:\n",
    "            mean_acc = np.mean(class_accs)\n",
    "            std_acc = np.std(class_accs)\n",
    "            print(f\"  Class {class_id:2d}: {mean_acc:.3f} ¬± {std_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K-Fold ÏÑ§Ï†ï\n",
    "# N_FOLDS = 5  # 5-foldÎ°ú ÏÑ§Ï†ï (Îç∞Ïù¥ÌÑ∞Í∞Ä Ï†ÅÏúºÎØÄÎ°ú)\n",
    "# skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# # ÌÅ¥ÎûòÏä§Î≥Ñ ÏµúÏÜå ÏÉòÌîå Î≥¥Ïû• ÌôïÏù∏\n",
    "# # for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "# #     assert len(np.unique(train_df.iloc[val_idx]['target'])) == 17\n",
    "\n",
    "# # Ï†ÑÏ≤¥ ÌïôÏäµ Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "# train_df = pd.read_csv(\"./data/raw/train.csv\")\n",
    "\n",
    "# # K-Fold Í≤∞Í≥ºÎ•º Ï†ÄÏû•Ìï† Î¶¨Ïä§Ìä∏\n",
    "# fold_results = []\n",
    "# fold_models = []  # Í∞Å foldÏùò ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏ÏùÑ Ï†ÄÏû•\n",
    "# fold_class_accuracies = [] # Í∞Å foldÏùò ÌÅ¥ÎûòÏä§Î≥Ñ Ï†ïÌôïÎèÑ Ï†ÄÏû•\n",
    "\n",
    "# print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# # LR = best_params['lr']\n",
    "# # BATCH_SIZE = best_params['batch_size']\n",
    "\n",
    "# # K-Fold Cross Validation ÏãúÏûë\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "#     print(f\"\\n{'='*50}\")\n",
    "#     print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "#     print(f\"{'='*50}\")\n",
    "    \n",
    "#     current_model = model_name\n",
    "    \n",
    "#     # ÌòÑÏû¨ foldÏùò train/validation Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "#     train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "#     val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "#     # ÌòÑÏû¨ foldÏùò Dataset ÏÉùÏÑ±\n",
    "#     trn_dataset = ImageDataset(\n",
    "#         train_fold_df,\n",
    "#         \"./data/raw/train/\",\n",
    "#         # transform=trn_transform\n",
    "#         epoch=0,  # ÌòÑÏû¨ epoch Ï†ÑÎã¨\n",
    "#         total_epochs=EPOCHS,\n",
    "#         is_train=True\n",
    "#     )\n",
    "    \n",
    "#     val_dataset = ImageDataset(\n",
    "#         val_fold_df,\n",
    "#         \"./data/raw/train/\",\n",
    "#         # transform=tst_transform  # Í≤ÄÏ¶ùÏóêÎäî Ï¶ùÍ∞ï Ï†ÅÏö© ÏïàÌï®\n",
    "#         epoch=0,  # validationÏùÄ epoch Í¥ÄÍ≥ÑÏóÜÏùå\n",
    "#         total_epochs=EPOCHS,\n",
    "#         is_train=False  # validationÏù¥ÎØÄÎ°ú hard augmentation ÎπÑÌôúÏÑ±Ìôî\n",
    "#     )\n",
    "    \n",
    "#     # ÌòÑÏû¨ foldÏùò DataLoader ÏÉùÏÑ±\n",
    "#     trn_loader = DataLoader(\n",
    "#         trn_dataset,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         shuffle=True,\n",
    "#         num_workers=num_workers,\n",
    "#         pin_memory=True,\n",
    "#         drop_last=False\n",
    "#     )\n",
    "    \n",
    "#     val_loader = DataLoader(\n",
    "#         val_dataset,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         shuffle=False,\n",
    "#         num_workers=num_workers,\n",
    "#         pin_memory=True\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "#     # Î™®Îç∏ Ï¥àÍ∏∞Ìôî (Í∞Å foldÎßàÎã§ ÏÉàÎ°úÏö¥ Î™®Îç∏)\n",
    "#     model = timm.create_model(\n",
    "#         current_model,\n",
    "#         pretrained=True,\n",
    "#         num_classes=17\n",
    "#     ).to(device)\n",
    "    \n",
    "#     loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)  # Label Smoothing Ï†ÅÏö©\n",
    "#     optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "#     # Learning Rate Scheduler Ï∂îÍ∞Ä\n",
    "#     scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "#     # ÌòÑÏû¨ foldÏùò ÏµúÍ≥† ÏÑ±Îä• Ï∂îÏ†Å\n",
    "#     best_val_f1 = 0.0\n",
    "#     best_model = None\n",
    "    \n",
    "#     # ÌòÑÏû¨ fold ÌïôÏäµ\n",
    "#     for epoch in range(EPOCHS):\n",
    "#         # Training\n",
    "#         train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "#         # Validation\n",
    "#         val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "#         # Scheduler step Ï∂îÍ∞Ä\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         print(f\"Epoch {epoch+1:2d} | \"\n",
    "#               f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "#               f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "#               f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "#               f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "#         # ÏµúÍ≥† ÏÑ±Îä• Î™®Îç∏ Ï†ÄÏû•\n",
    "#         if val_ret['val_f1'] > best_val_f1:\n",
    "#             best_val_f1 = val_ret['val_f1']\n",
    "#             best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "#             # Best Î™®Îç∏ Î∂ÑÏÑù\n",
    "#             model.eval()\n",
    "#             val_preds, val_targets = [], []\n",
    "#             with torch.no_grad():\n",
    "#                 for image, targets in val_loader:\n",
    "#                     preds = model(image.to(device)).argmax(dim=1)\n",
    "#                     val_preds.extend(preds.cpu().numpy())\n",
    "#                     val_targets.extend(targets.numpy())\n",
    "            \n",
    "#             # ÌÅ¥ÎûòÏä§Î≥Ñ Ï†ïÌôïÎèÑ\n",
    "#             fold_class_acc = {}\n",
    "#             for c in range(17):\n",
    "#                 mask = np.array(val_targets) == c\n",
    "#                 if mask.sum() > 0:\n",
    "#                     fold_class_acc[c] = (np.array(val_preds)[mask] == c).mean()\n",
    "    \n",
    "#     # ÌòÑÏû¨ fold Í≤∞Í≥º Ï†ÄÏû•\n",
    "#     fold_results.append({\n",
    "#         'fold': fold + 1,\n",
    "#         'best_val_f1': best_val_f1,\n",
    "#         'train_samples': len(trn_dataset),\n",
    "#         'val_samples': len(val_dataset)\n",
    "#     })\n",
    "    \n",
    "#     fold_models.append(best_model)\n",
    "    \n",
    "#     print(f\"Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "#     fold_class_accuracies.append(fold_class_acc) # Í∞Å foldÏùò ÌÅ¥ÎûòÏä§Î≥Ñ Ï†ïÌôïÎèÑ Ï†ÄÏû•\n",
    "\n",
    "# # K-Fold Í≤∞Í≥º ÏöîÏïΩ\n",
    "# print(f\"\\n{'='*60}\")\n",
    "# print(\"K-FOLD CROSS VALIDATION RESULTS\")\n",
    "# print(f\"{'='*60}\")\n",
    "\n",
    "# val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "# mean_f1 = np.mean(val_f1_scores)\n",
    "# std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "# for result in fold_results:\n",
    "#     print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "# print(f\"\\nMean CV F1: {mean_f1:.4f} ¬± {std_f1:.4f}\")\n",
    "# print(f\"Best single fold: {max(val_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌÅ¥ÎûòÏä§Î≥Ñ ÏÑ±Îä• ÏãúÍ∞ÅÌôî\n",
    "meta_df = pd.read_csv(\"./data/raw/meta.csv\")\n",
    "avg_acc = {c: np.mean([f.get(c,0) for f in fold_class_accuracies]) for c in range(17)}\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "classes = list(avg_acc.keys())\n",
    "accs = [avg_acc[c] * 100 for c in classes]\n",
    "names = [f\"C{c}\" for c in classes]\n",
    "\n",
    "plt.bar(range(17), accs)\n",
    "plt.xticks(range(17), names)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Class-wise Prediction Accuracy')\n",
    "for i, acc in enumerate(accs):\n",
    "    plt.text(i, acc + 1, f'{acc:.1f}%', ha='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Worst 3 classes:\")\n",
    "worst = sorted(avg_acc.items(), key=lambda x: x[1])[:3]\n",
    "for c, acc in worst:\n",
    "    print(f\"Class {c}: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
    "# os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# # fold_models Ï†ÄÏû• (ÌòÑÏû¨ Î©îÎ™®Î¶¨Ïóê ÏûàÎã§Î©¥ Î∞îÎ°ú Ïã§Ìñâ Í∞ÄÎä•)\n",
    "# print(\"Saving fold models...\")\n",
    "# for i, state_dict in enumerate(fold_models):\n",
    "#     save_path = f'models/fold_{i+1}_best.pth'\n",
    "#     torch.save(state_dict, save_path)  # Í∑∏ÎÉ• ÏßÅÏ†ë Ï†ÄÏû•\n",
    "#     print(f\"‚úì Fold {i+1} model saved to {save_path}\")\n",
    "\n",
    "# print(f\"All {len(fold_models)} fold models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Î™®Îç∏ Ï†ÄÏû• - ÌòÑÏû¨ ÏÉÅÌÉú Í∑∏ÎåÄÎ°ú Ï†ÄÏû•\n",
    "# def save_models():\n",
    "#     \"\"\"ÌïôÏäµÌïú Î™®Îç∏Îì§ÏùÑ Ï†ÄÏû•\"\"\"\n",
    "    \n",
    "#     # Ï†ÄÏû• ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±\n",
    "#     save_dir = \"models\"\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "#     timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "#     print(\"üö® Î™®Îç∏ Ï†ÄÏû• ÏãúÏûë...\")\n",
    "    \n",
    "#     # Í∞Å foldÎ≥Ñ Î™®Îç∏ Ï†ÄÏû• (fold_models Î¶¨Ïä§Ìä∏Í∞Ä ÏûàÎã§Í≥† Í∞ÄÏ†ï)\n",
    "#     try:\n",
    "#         for fold in range(5):  # 5-foldÎùºÍ≥† Í∞ÄÏ†ï\n",
    "#             model_path = f\"{save_dir}/fold_{fold}_model_{timestamp}.pth\"\n",
    "            \n",
    "#             # fold_models[fold]Í∞Ä Ï°¥Ïû¨ÌïúÎã§Î©¥ Ï†ÄÏû•\n",
    "#             if 'fold_models' in globals() and len(fold_models) > fold:\n",
    "#                 torch.save({\n",
    "#                     'model_state_dict': fold_models[fold].state_dict(),\n",
    "#                     'fold': fold,\n",
    "#                     'timestamp': timestamp,\n",
    "#                     'epoch': 'unknown',  # ÏóêÌè¨ÌÅ¨ Ï†ïÎ≥¥ Î™®Î•¥Î©¥ unknown\n",
    "#                 }, model_path)\n",
    "#                 print(f\"‚úÖ Fold {fold} Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {model_path}\")\n",
    "            \n",
    "#             # ÎòêÎäî best_models Î¶¨Ïä§Ìä∏Í∞Ä ÏûàÎã§Î©¥\n",
    "#             elif 'best_models' in globals() and len(best_models) > fold:\n",
    "#                 torch.save({\n",
    "#                     'model_state_dict': best_models[fold].state_dict(),\n",
    "#                     'fold': fold,\n",
    "#                     'timestamp': timestamp,\n",
    "#                     'epoch': 'unknown',\n",
    "#                 }, model_path)\n",
    "#                 print(f\"‚úÖ Fold {fold} best Î™®Îç∏ Ï†ÄÏû• ÏôÑÎ£å: {model_path}\")\n",
    "                \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå FoldÎ≥Ñ Ï†ÄÏû• Ïã§Ìå®: {e}\")\n",
    "    \n",
    "#     # Ï†ÑÏ≤¥ Î≥ÄÏàò ÏÉÅÌÉú Ï†ÄÏû• (ÌòπÏãú Î™®Î•¥ÎãàÍπå)\n",
    "#     try:\n",
    "#         state_path = f\"{save_dir}/full_state_{timestamp}.pth\"\n",
    "        \n",
    "#         # ÌòÑÏû¨ Í∏ÄÎ°úÎ≤å Î≥ÄÏàòÏóêÏÑú Î™®Îç∏ Í¥ÄÎ†® Í∞ùÏ≤¥Îì§ Ï∞æÏïÑÏÑú Ï†ÄÏû•\n",
    "#         save_dict = {}\n",
    "        \n",
    "#         # Í∞ÄÎä•Ìïú Î™®Îç∏ Î≥ÄÏàòÎ™ÖÎì§ Ï≤¥ÌÅ¨\n",
    "#         possible_model_vars = ['model', 'models', 'fold_models', 'best_models', \n",
    "#                               'tta_models', 'ensemble_models']\n",
    "        \n",
    "#         for var_name in possible_model_vars:\n",
    "#             if var_name in globals():\n",
    "#                 save_dict[var_name] = globals()[var_name]\n",
    "#                 print(f\"‚úÖ {var_name} Î≥ÄÏàò Ìè¨Ìï®Îê®\")\n",
    "        \n",
    "#         if save_dict:\n",
    "#             torch.save(save_dict, state_path)\n",
    "#             print(f\"‚úÖ Ï†ÑÏ≤¥ ÏÉÅÌÉú Ï†ÄÏû• ÏôÑÎ£å: {state_path}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Ï†ÑÏ≤¥ ÏÉÅÌÉú Ï†ÄÏû• Ïã§Ìå®: {e}\")\n",
    "    \n",
    "#     print(f\"üéâ Ï†ÄÏû• ÏôÑÎ£å! Ï†ÄÏû• ÏúÑÏπò: {save_dir}/\")\n",
    "#     print(f\"üìÅ ÌååÏùº Î™©Î°ù:\")\n",
    "#     for file in os.listdir(save_dir):\n",
    "#         print(f\"   - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ïò§Îãµ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Î∞è ÏãúÍ∞ÅÌôî\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "\n",
    "# def analyze_wrong_predictions(model, val_loader, device, num_samples=20):\n",
    "#     \"\"\"Ïò§Îãµ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù Î∞è ÏãúÍ∞ÅÌôî\"\"\"\n",
    "#     model.eval()\n",
    "#     wrong_predictions = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, targets in val_loader:\n",
    "#             images, targets = images.to(device), targets.to(device)\n",
    "#             outputs = model(images)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "#             # Ïò§ÎãµÏù∏ ÏÉòÌîåÎì§ Ï∞æÍ∏∞\n",
    "#             wrong_mask = (preds != targets)\n",
    "#             wrong_indices = torch.where(wrong_mask)[0]\n",
    "            \n",
    "#             for idx in wrong_indices:\n",
    "#                 wrong_predictions.append({\n",
    "#                     'image': images[idx].cpu(),\n",
    "#                     'true_class': targets[idx].cpu().item(),\n",
    "#                     'pred_class': preds[idx].cpu().item(),\n",
    "#                     'confidence': torch.softmax(outputs[idx], 0).max().cpu().item()\n",
    "#                 })\n",
    "                \n",
    "#                 if len(wrong_predictions) >= num_samples:\n",
    "#                     break\n",
    "            \n",
    "#             if len(wrong_predictions) >= num_samples:\n",
    "#                 break\n",
    "    \n",
    "#     return wrong_predictions\n",
    "\n",
    "# def visualize_wrong_predictions(wrong_predictions, class_names, rows=4, cols=5):\n",
    "#     \"\"\"Ïò§Îãµ Îç∞Ïù¥ÌÑ∞ ÏãúÍ∞ÅÌôî\"\"\"\n",
    "#     fig, axes = plt.subplots(rows, cols, figsize=(20, 16))\n",
    "#     axes = axes.flatten()\n",
    "    \n",
    "#     for i, wrong_pred in enumerate(wrong_predictions[:rows*cols]):\n",
    "#         if i >= len(axes):\n",
    "#             break\n",
    "            \n",
    "#         # Ïù¥ÎØ∏ÏßÄ Ï†ÑÏ≤òÎ¶¨ (Ï†ïÍ∑úÌôî Ìï¥Ï†ú)\n",
    "#         img = wrong_pred['image'].permute(1, 2, 0)\n",
    "#         img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "#         img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "#         axes[i].imshow(img)\n",
    "#         axes[i].set_title(f\"True: {wrong_pred['true_class']} | \"\n",
    "#                          f\"Pred: {wrong_pred['pred_class']}\\n\"\n",
    "#                          f\"Conf: {wrong_pred['confidence']:.3f}\", \n",
    "#                          fontsize=10)\n",
    "#         axes[i].axis('off')\n",
    "    \n",
    "#     # Îπà subplot Ï†úÍ±∞\n",
    "#     for i in range(len(wrong_predictions), len(axes)):\n",
    "#         axes[i].remove()\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('wrong_predictions_analysis.png', dpi=300, bbox_inches='tight')\n",
    "#     plt.show()\n",
    "\n",
    "# def print_wrong_class_summary(wrong_predictions):\n",
    "#     \"\"\"Ïò§Îãµ ÌÅ¥ÎûòÏä§ ÏöîÏïΩ Ï∂úÎ†•\"\"\"\n",
    "#     from collections import Counter\n",
    "    \n",
    "#     true_classes = [wp['true_class'] for wp in wrong_predictions]\n",
    "#     pred_classes = [wp['pred_class'] for wp in wrong_predictions]\n",
    "    \n",
    "#     print(\"=== Ïò§Îãµ Î∂ÑÏÑù ÏöîÏïΩ ===\")\n",
    "#     print(\"Ïã§Ï†ú ÌÅ¥ÎûòÏä§Î≥Ñ Ïò§Îãµ ÎπàÎèÑ:\")\n",
    "#     true_counter = Counter(true_classes)\n",
    "#     for class_id, count in sorted(true_counter.items()):\n",
    "#         print(f\"  ÌÅ¥ÎûòÏä§ {class_id}: {count}Í∞ú Ïò§Îãµ\")\n",
    "    \n",
    "#     print(\"\\nÏòàÏ∏° ÌÅ¥ÎûòÏä§Î≥Ñ Ïò§Îãµ ÎπàÎèÑ:\")\n",
    "#     pred_counter = Counter(pred_classes)\n",
    "#     for class_id, count in sorted(pred_counter.items()):\n",
    "#         print(f\"  ÌÅ¥ÎûòÏä§ {class_id}Î°ú Ïò§ÏòàÏ∏°: {count}Í∞ú\")\n",
    "    \n",
    "#     print(f\"\\nÏ¥ù Î∂ÑÏÑùÎêú Ïò§Îãµ Ïàò: {len(wrong_predictions)}Í∞ú\")\n",
    "\n",
    "# # Ïã§Ìñâ ÏΩîÎìú\n",
    "# print(\"Ïò§Îãµ Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù ÏãúÏûë...\")\n",
    "\n",
    "# # ÌòÑÏû¨ best Î™®Îç∏Î°ú Ïò§Îãµ Î∂ÑÏÑù (Fold 1 Í∏∞Ï§Ä)\n",
    "# wrong_preds = analyze_wrong_predictions(best_model, val_loader, device, num_samples=20)\n",
    "\n",
    "# # Ïò§Îãµ ÏöîÏïΩ Ï∂úÎ†•\n",
    "# print_wrong_class_summary(wrong_preds)\n",
    "\n",
    "# # Ïò§Îãµ Ïù¥ÎØ∏ÏßÄ ÏãúÍ∞ÅÌôî\n",
    "# visualize_wrong_predictions(wrong_preds, class_names=None, rows=4, cols=5)\n",
    "\n",
    "# print(\"Ïò§Îãµ Î∂ÑÏÑù ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# üìä K-Fold Í≤∞Í≥º Î∂ÑÏÑù (Îã®Ïùº Î™®Îç∏ Î≤ÑÏ†Ñ)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üèÅ K-FOLD Í≤∞Í≥º ÏÉÅÏÑ∏ Î∂ÑÏÑù\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Ï†ÑÏ≤¥ ÏÑ±Îä• ÏöîÏïΩ\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "print(f\"\\nü§ñ Î™®Îç∏: {model_name}\")\n",
    "print(f\"üìä ÌèâÍ∑† CV F1: {mean_f1:.4f} ¬± {std_f1:.4f}\")\n",
    "print(f\"üèÜ ÏµúÍ≥† Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\"üìâ ÏµúÏïÖ Fold: {min(val_f1_scores):.4f}\")\n",
    "print(f\"üìè ÏÑ±Îä• Î≤îÏúÑ: {max(val_f1_scores) - min(val_f1_scores):.4f}\")\n",
    "\n",
    "# FoldÎ≥Ñ ÏÉÅÏÑ∏ ÏÑ±Îä•\n",
    "print(f\"\\nüìã FoldÎ≥Ñ ÏÉÅÏÑ∏ Í≤∞Í≥º:\")\n",
    "print(f\"{'üìÅ Fold':<8} {'üéØ Val F1':<10} {'üìà Train F1':<11} {'üë• Train':<8} {'‚úÖ Val':<7}\")\n",
    "print(\"‚îÄ\" * 50)\n",
    "\n",
    "for result in fold_results:\n",
    "   print(f\"   {result['fold']:<5} \"\n",
    "         f\"   {result['best_val_f1']:<8.4f} \"\n",
    "         f\"   {result['final_train_f1']:<9.4f} \"\n",
    "         f\"   {result['train_samples']:<6} \"\n",
    "         f\"   {result['val_samples']:<5}\")\n",
    "\n",
    "# ÏÑ±Îä• ÏàúÏúÑ\n",
    "sorted_results = sorted(fold_results, key=lambda x: x['best_val_f1'], reverse=True)\n",
    "print(f\"\\nüèÖ ÏÑ±Îä• ÏàúÏúÑ:\")\n",
    "medals = [\"ü•á\", \"ü•à\", \"ü•â\", \"üèÖ\", \"üèÖ\"]\n",
    "for i, result in enumerate(sorted_results):\n",
    "   medal = medals[i] if i < len(medals) else \"üìç\"\n",
    "   print(f\"{medal} {i+1}ÏúÑ: Fold {result['fold']} - F1: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "# ÌÅ¥ÎûòÏä§Î≥Ñ ÏÑ±Îä• Î∂ÑÏÑù\n",
    "if fold_class_accuracies:\n",
    "   print(f\"\\nüéØ ÌÅ¥ÎûòÏä§Î≥Ñ ÏÑ±Îä• Î∂ÑÏÑù:\")\n",
    "   print(f\"{'üìä Class':<9} {'üìà ÌèâÍ∑†':<8} {'üìè ÌëúÏ§ÄÌé∏Ï∞®':<9} {'üèÜ ÏµúÍ≥†':<7} {'üìâ ÏµúÏïÖ':<7}\")\n",
    "   print(\"‚îÄ\" * 45)\n",
    "   \n",
    "   class_performance = []\n",
    "   for class_id in range(17):\n",
    "       class_accs = []\n",
    "       for fold_acc in fold_class_accuracies:\n",
    "           if class_id in fold_acc:\n",
    "               class_accs.append(fold_acc[class_id])\n",
    "       \n",
    "       if class_accs:\n",
    "           mean_acc = np.mean(class_accs)\n",
    "           std_acc = np.std(class_accs)\n",
    "           max_acc = max(class_accs)\n",
    "           min_acc = min(class_accs)\n",
    "           \n",
    "           class_performance.append({\n",
    "               'class_id': class_id,\n",
    "               'mean_acc': mean_acc,\n",
    "               'std_acc': std_acc,\n",
    "               'max_acc': max_acc,\n",
    "               'min_acc': min_acc\n",
    "           })\n",
    "           \n",
    "           print(f\"   {class_id:<5} \"\n",
    "                 f\"   {mean_acc:<6.3f} \"\n",
    "                 f\"   {std_acc:<7.3f} \"\n",
    "                 f\"   {max_acc:<5.3f} \"\n",
    "                 f\"   {min_acc:<5.3f}\")\n",
    "   \n",
    "   # Ïñ¥Î†§Ïö¥ ÌÅ¥ÎûòÏä§ TOP 3\n",
    "   worst_classes = sorted(class_performance, key=lambda x: x['mean_acc'])[:3]\n",
    "   print(f\"\\nüî¥ Í∞ÄÏû• Ïñ¥Î†§Ïö¥ ÌÅ¥ÎûòÏä§ TOP 3:\")\n",
    "   for i, cls in enumerate(worst_classes, 1):\n",
    "       print(f\"   {i}. Class {cls['class_id']}: {cls['mean_acc']:.3f} Ï†ïÌôïÎèÑ\")\n",
    "   \n",
    "   # Ïâ¨Ïö¥ ÌÅ¥ÎûòÏä§ TOP 3\n",
    "   best_classes = sorted(class_performance, key=lambda x: x['mean_acc'], reverse=True)[:3]\n",
    "   print(f\"\\nüü¢ Í∞ÄÏû• Ïâ¨Ïö¥ ÌÅ¥ÎûòÏä§ TOP 3:\")\n",
    "   for i, cls in enumerate(best_classes, 1):\n",
    "       print(f\"   {i}. Class {cls['class_id']}: {cls['mean_acc']:.3f} Ï†ïÌôïÎèÑ\")\n",
    "\n",
    "# ÏÑ±Îä• ÏùºÍ¥ÄÏÑ± Î∂ÑÏÑù\n",
    "cv_coefficient = std_f1 / mean_f1 if mean_f1 > 0 else 0\n",
    "print(f\"\\n‚öñÔ∏è ÏÑ±Îä• ÏùºÍ¥ÄÏÑ± Î∂ÑÏÑù:\")\n",
    "print(f\"üìä Î≥ÄÎèôÍ≥ÑÏàò (CV): {cv_coefficient:.3f}\")\n",
    "\n",
    "if cv_coefficient < 0.05:\n",
    "   consistency_emoji = \"üü¢\"\n",
    "   consistency_text = \"Îß§Ïö∞ ÏùºÍ¥ÄÏ†ÅÏù∏ ÏÑ±Îä•\"\n",
    "elif cv_coefficient < 0.1:\n",
    "   consistency_emoji = \"üîµ\"\n",
    "   consistency_text = \"ÏùºÍ¥ÄÏ†ÅÏù∏ ÏÑ±Îä•\"\n",
    "elif cv_coefficient < 0.15:\n",
    "   consistency_emoji = \"üü°\"\n",
    "   consistency_text = \"Î≥¥ÌÜµ ÏàòÏ§ÄÏùò ÏùºÍ¥ÄÏÑ±\"\n",
    "else:\n",
    "   consistency_emoji = \"üî¥\"\n",
    "   consistency_text = \"ÏÑ±Îä• Î≥ÄÎèôÏù¥ ÌÅº\"\n",
    "\n",
    "print(f\"{consistency_emoji} {consistency_text}\")\n",
    "\n",
    "# Ï∂îÍ∞Ä ÌÜµÍ≥Ñ\n",
    "overfit_count = sum(1 for result in fold_results \n",
    "                  if result['final_train_f1'] - result['best_val_f1'] > 0.05)\n",
    "\n",
    "print(f\"\\nüìà ÌïôÏäµ ÏÉÅÌÉú Î∂ÑÏÑù:\")\n",
    "print(f\"üéØ Í≥ºÏ†ÅÌï© ÏùòÏã¨ Fold: {overfit_count}/{len(fold_results)}Í∞ú\")\n",
    "if overfit_count > 0:\n",
    "   print(f\"   üí° Train-Val F1 Ï∞®Ïù¥Í∞Ä 0.05 Ïù¥ÏÉÅÏù∏ fold Ïàò\")\n",
    "\n",
    "print(f\"\\n‚úÖ ÌïôÏäµ ÏôÑÎ£å! Ï¥ù {len(fold_results)}Í∞ú fold Î™®Îç∏ Ï†ÄÏû•Îê®\")\n",
    "print(f\"üìÅ Ï†ÄÏû•Îêú Î™®Îç∏ ÌååÏùº:\")\n",
    "for i, result in enumerate(fold_results, 1):\n",
    "   print(f\"   üìÑ {result['model_path']}\")\n",
    "\n",
    "print(f\"\\nüéâ K-Fold Cross Validation Î∂ÑÏÑù ÏôÑÎ£å!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-Fold ÏïôÏÉÅÎ∏î Î™®Îç∏ Ï§ÄÎπÑ\n",
    "ensemble_models = []\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "print(f\"Using ensemble of all {len(ensemble_models)} fold models for inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* Î™®Îç∏ÏùÑ Î°úÎìúÌïòÍ≥†, ÌïôÏäµÏùÑ ÏßÑÌñâÌï©ÎãàÎã§."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* ÌÖåÏä§Ìä∏ Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌïú Ï∂îÎ°†ÏùÑ ÏßÑÌñâÌïòÍ≥†, Í≤∞Í≥º ÌååÏùºÏùÑ Ï†ÄÏû•Ìï©ÎãàÎã§."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling ÌÅ¥ÎûòÏä§ Ï†ïÏùò\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_tta_transforms = [\n",
    "    # ÏõêÎ≥∏\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90ÎèÑ ÌöåÏ†ÑÎì§\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # Î∞ùÍ∏∞ Í∞úÏÑ†\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA Dataset ÏÉùÏÑ± (Í≤ΩÎ°ú ÏàòÏ†ï)\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"data/raw/sample_submission.csv\",  # Í≤ΩÎ°ú ÏàòÏ†ï\n",
    "    \"data/raw/test\",  # Í≤ΩÎ°ú ÏàòÏ†ï\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (Î∞∞Ïπò ÌÅ¨Í∏∞Î•º Ï§ÑÏó¨ÏÑú Î©îÎ™®Î¶¨ Ï†àÏïΩ)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=16,  # TTAÎäî Î©îÎ™®Î¶¨Î•º ÎßéÏù¥ ÏÇ¨Ïö©ÌïòÎØÄÎ°ú Î∞∞Ïπò ÌÅ¨Í∏∞ Ï§ÑÏûÑ\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")\n",
    "\n",
    "# Î°úÍ±∞Ïóê Îç∞Ïù¥ÌÑ∞ÏÖã Ï†ïÎ≥¥ Ï†ÄÏû•\n",
    "logger.write(f\"TTA Dataset ÏÉùÏÑ± ÏôÑÎ£å: {len(tta_dataset)}Í∞ú ÏÉòÌîå\")\n",
    "logger.write(f\"TTA Î≥ÄÌòï Ïàò: {len(essential_tta_transforms)}Í∞ÄÏßÄ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA Dataset ÏÉùÏÑ±\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"./data/raw/sample_submission.csv\",\n",
    "    \"./data/raw/test\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (Î∞∞Ïπò ÌÅ¨Í∏∞Î•º Ï§ÑÏó¨ÏÑú Î©îÎ™®Î¶¨ Ï†àÏïΩ)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=16,  # TTAÎäî Î©îÎ™®Î¶¨Î•º ÎßéÏù¥ ÏÇ¨Ïö©ÌïòÎØÄÎ°ú Î∞∞Ïπò ÌÅ¨Í∏∞ Ï§ÑÏûÑ\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_tta_inference(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold Î™®Îç∏ ÏïôÏÉÅÎ∏î + TTA Ï∂îÎ°†\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # Í∞Å fold Î™®Îç∏Î≥Ñ ÏòàÏ∏°\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # Í∞Å TTA Î≥ÄÌòïÎ≥Ñ ÏòàÏ∏°\n",
    "                for images in images_list:\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÏïôÏÉÅÎ∏î TTA Ïã§Ìñâ\n",
    "print(\"Starting Ensemble TTA inference...\")\n",
    "tta_predictions = ensemble_tta_inference(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA Í≤∞Í≥ºÎ°ú submission ÌååÏùº ÏÉùÏÑ±\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA Í≤∞Í≥º Ï†ÄÏû• (Î°úÍ±∞ Ïó∞Îèô)\n",
    "# Í∏∞Ï°¥ submissionÍ≥º ÎèôÏùºÌïú ÏàúÏÑúÏù∏ÏßÄ ÌôïÏù∏\n",
    "sample_submission_df = pd.read_csv(\"./data/raw/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()\n",
    "\n",
    "# Í≤∞Í≥º ÌååÏùº Ï†ÄÏû•\n",
    "output_path = f\"./notebooks/team/JSW/submissions/JSW_convnext_base_TTA_{logger.timestamp}.csv\"\n",
    "os.makedirs(\"./notebooks/team/JSW/submissions\", exist_ok=True)\n",
    "tta_pred_df.to_csv(output_path, index=False)\n",
    "\n",
    "# Î°úÍ±∞Ïóê Í≤∞Í≥º Ï†ÄÏû•\n",
    "logger.save_dataframe(tta_pred_df.head(10), 'prediction_sample', 'ÏòàÏ∏° Í≤∞Í≥º ÏÉòÌîå')\n",
    "logger.save_test_result('final_results', {\n",
    "    'model_name': model_name,\n",
    "    'cv_f1_mean': np.mean([result['best_val_f1'] for result in fold_results]) if fold_results else 0,\n",
    "    'total_test_samples': len(tta_pred_df),\n",
    "    'output_file': output_path,\n",
    "    'tta_transforms': len(essential_tta_transforms),\n",
    "    'fold_count': len(fold_models) if fold_models else N_FOLDS\n",
    "})\n",
    "\n",
    "print(f\"TTA predictions saved to: {output_path}\")\n",
    "print(\"TTA Prediction sample:\")\n",
    "\n",
    "# ÏµúÏ¢Ö Î°úÍ±∞ ÏôÑÎ£å\n",
    "logger.finalize_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA Í≤∞Í≥º Ï†ÄÏû•\n",
    "tta_pred_df.to_csv(\"/root/home/cv_contest/results/BH_512_base_TTA.csv\", index=False)\n",
    "print(\"TTA predictions saved\")\n",
    "\n",
    "print(\"TTA Prediction sample:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(ÏÜ°ÏõêÌò∏)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [],
   "source": [
    "tta_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cv_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
