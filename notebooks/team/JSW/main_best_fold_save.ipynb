{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n",
    "* 필요한 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# # 필요한 라이브러리를 설치합니다.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna\n",
    "# !apt install -y libgl1-mesa-glx\n",
    "# !pip install albumentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precision용\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# 한글 폰트 설정 (시각화용)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# 데이터셋 클래스를 정의합니다. (Hard Augmentation 포함)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation 확률 계산\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "                A.Rotate(limit=[-15,15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # 배치별 증강 선택\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    scaler = GradScaler()  # Mixed Precision용\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Cutmix/Mixup 적용 (30% 확률)\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        scaler.scale(loss).backward()  # Mixed Precision용\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()  # Mixed Precision용\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation을 위한 함수 추가\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    한 에폭 검증을 수행하는 함수\n",
    "    - model.eval()로 모델을 평가 모드로 전환\n",
    "    - torch.no_grad()로 gradient 계산 비활성화하여 메모리 절약\n",
    "    - 검증 데이터에 대한 loss, accuracy, f1 score 계산\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 전환 (dropout, batchnorm 비활성화)\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():  # gradient 계산 비활성화로 메모리 절약\n",
    "        pbar = tqdm(loader, desc=\"Validating\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)  # 모델 예측\n",
    "            loss = loss_fn(preds, targets)  # 손실 계산\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())  # 예측 클래스 저장\n",
    "            targets_list.extend(targets.detach().cpu().numpy())  # 실제 클래스 저장\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)  # 평균 손실 계산\n",
    "    val_acc = accuracy_score(targets_list, preds_list)  # 정확도 계산\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')  # Macro F1 계산 (대회 평가지표)\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'tf_efficientnetv2_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "# model_name = 'swin_base_patch4_window12_384_in22k'\n",
    "model_name = 'convnext_base_384_in22ft1k'\n",
    "# model_name = 'convnextv2_base.fcmae_ft_in22k_in1k_384'\n",
    "# model_name = 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k' # openclip\n",
    "# model_name = 'vit_base_patch16_384.augreg_in1k' # augreg\n",
    "# model_name = 'eva02_enormous_patch14_plus_clip_224.laion2b_s9b_b144k' # eva-02 멀티모달\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 테스트용\n",
    "# model_name = 'vit_base_patch14_reg4_dinov2.lvd142m' # dinov2 reg4\n",
    "\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 테스트용\n",
    "\n",
    "# training config\n",
    "img_size = 512\n",
    "LR = 2e-4\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "num_workers = 8\n",
    "EMA = True  # Exponential Moving Average 사용 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna를 사용한 하이퍼파라미터 튜닝 (선택적 실행)\n",
    "USE_OPTUNA = False  # True로 바꾸면 튜닝 실행\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # 간단한 3-fold CV로 빠른 평가\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf_simple.split(train_df, train_df['target'])):\n",
    "            # 모델 생성\n",
    "            model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "            optimizer = Adam(model.parameters(), lr=lr)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # 간단한 2 epoch 학습\n",
    "            for epoch in range(2):\n",
    "                train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "            \n",
    "            val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "            fold_scores.append(val_ret['val_f1'])\n",
    "        \n",
    "        return np.mean(fold_scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # 최적 파라미터 적용\n",
    "    LR = study.best_params['lr']\n",
    "    BATCH_SIZE = study.best_params['batch_size']\n",
    "    print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 튜닝 (선택적 실행)\n",
    "USE_OPTUNA = False  # True로 바꾸면 튜닝 실행\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    # 위의 objective 함수와 study 코드\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2959: 100%|██████████| 126/126 [01:05<00:00,  1.92it/s]\n",
      "Val Loss: 1.4162: 100%|██████████| 32/32 [00:16<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.7730 | Train F1: 0.4472 | Val Loss: 0.8851 | Val F1: 0.8036 | LR: 2.00e-04 | Time: 82.1s\n",
      "새로운 최고 성능! F1: 0.8036 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5146: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.8446: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.0022 | Train F1: 0.7014 | Val Loss: 0.7424 | Val F1: 0.8336 | LR: 2.00e-04 | Time: 27.1s\n",
      "새로운 최고 성능! F1: 0.8336 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6030: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.5585: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8768 | Train F1: 0.7228 | Val Loss: 0.6196 | Val F1: 0.8811 | LR: 2.00e-04 | Time: 27.3s\n",
      "새로운 최고 성능! F1: 0.8811 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5410: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.5857: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8156 | Train F1: 0.7902 | Val Loss: 0.5282 | Val F1: 0.8956 | LR: 1.99e-04 | Time: 27.7s\n",
      "새로운 최고 성능! F1: 0.8956 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4937: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.6976: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7618 | Train F1: 0.7853 | Val Loss: 0.5681 | Val F1: 0.8720 | LR: 1.99e-04 | Time: 28.2s\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4829: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.3719: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.6963 | Train F1: 0.7996 | Val Loss: 0.4939 | Val F1: 0.9064 | LR: 1.98e-04 | Time: 28.0s\n",
      "새로운 최고 성능! F1: 0.9064 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7651: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.4411: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.6368 | Train F1: 0.8466 | Val Loss: 0.5073 | Val F1: 0.9300 | LR: 1.98e-04 | Time: 27.2s\n",
      "새로운 최고 성능! F1: 0.9300 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0625: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.4537: 100%|██████████| 32/32 [00:04<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.6256 | Train F1: 0.8682 | Val Loss: 0.5234 | Val F1: 0.9352 | LR: 1.97e-04 | Time: 27.0s\n",
      "새로운 최고 성능! F1: 0.9352 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9697: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.5636: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6626 | Train F1: 0.8130 | Val Loss: 0.4926 | Val F1: 0.9294 | LR: 1.96e-04 | Time: 27.5s\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3774: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.5162: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6671 | Train F1: 0.8249 | Val Loss: 0.4718 | Val F1: 0.9419 | LR: 1.95e-04 | Time: 27.7s\n",
      "새로운 최고 성능! F1: 0.9419 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0527: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.5594: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6239 | Train F1: 0.8390 | Val Loss: 0.4640 | Val F1: 0.9530 | LR: 1.94e-04 | Time: 28.0s\n",
      "새로운 최고 성능! F1: 0.9530 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5986: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.5949: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6164 | Train F1: 0.8288 | Val Loss: 0.4659 | Val F1: 0.9407 | LR: 1.93e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3347: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.4730: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.5730 | Train F1: 0.8592 | Val Loss: 0.4844 | Val F1: 0.9517 | LR: 1.92e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9741: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3759: 100%|██████████| 32/32 [00:04<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.5733 | Train F1: 0.8679 | Val Loss: 0.4482 | Val F1: 0.9642 | LR: 1.90e-04 | Time: 27.1s\n",
      "새로운 최고 성능! F1: 0.9642 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3496: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.7520: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.5970 | Train F1: 0.8255 | Val Loss: 0.4791 | Val F1: 0.9435 | LR: 1.89e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3391: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3285: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.5454 | Train F1: 0.8795 | Val Loss: 0.5120 | Val F1: 0.9474 | LR: 1.88e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3340: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.9515: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6179 | Train F1: 0.8824 | Val Loss: 0.5238 | Val F1: 0.9285 | LR: 1.86e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3245: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3751: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5814 | Train F1: 0.8410 | Val Loss: 0.4506 | Val F1: 0.9620 | LR: 1.84e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3303: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3252: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5250 | Train F1: 0.8705 | Val Loss: 0.4604 | Val F1: 0.9654 | LR: 1.83e-04 | Time: 27.3s\n",
      "새로운 최고 성능! F1: 0.9654 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3240: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3290: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5523 | Train F1: 0.8736 | Val Loss: 0.4424 | Val F1: 0.9682 | LR: 1.81e-04 | Time: 27.1s\n",
      "새로운 최고 성능! F1: 0.9682 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3770: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3242: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.6016 | Train F1: 0.8361 | Val Loss: 0.5388 | Val F1: 0.9228 | LR: 1.79e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3230: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 1.1065: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5804 | Train F1: 0.8787 | Val Loss: 0.5501 | Val F1: 0.9255 | LR: 1.77e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3372: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3361: 100%|██████████| 32/32 [00:04<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.6208 | Train F1: 0.8344 | Val Loss: 0.4379 | Val F1: 0.9626 | LR: 1.75e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1611: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3264: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5583 | Train F1: 0.8407 | Val Loss: 0.4402 | Val F1: 0.9646 | LR: 1.73e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5381: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3236: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5633 | Train F1: 0.8668 | Val Loss: 0.4263 | Val F1: 0.9626 | LR: 1.71e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3264: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3309: 100%|██████████| 32/32 [00:04<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.5523 | Train F1: 0.8700 | Val Loss: 0.4487 | Val F1: 0.9568 | LR: 1.68e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5127: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.5677: 100%|██████████| 32/32 [00:04<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5675 | Train F1: 0.8468 | Val Loss: 0.4395 | Val F1: 0.9647 | LR: 1.66e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5952: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.7408: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5522 | Train F1: 0.8699 | Val Loss: 0.4338 | Val F1: 0.9686 | LR: 1.64e-04 | Time: 27.5s\n",
      "새로운 최고 성능! F1: 0.9686 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3227: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5123 | Train F1: 0.8848 | Val Loss: 0.4736 | Val F1: 0.9485 | LR: 1.61e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9614: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3288: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5408 | Train F1: 0.8687 | Val Loss: 0.4600 | Val F1: 0.9612 | LR: 1.59e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.7350: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5234 | Train F1: 0.8962 | Val Loss: 0.4865 | Val F1: 0.9497 | LR: 1.56e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3271: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3238: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.5767 | Train F1: 0.8665 | Val Loss: 0.4604 | Val F1: 0.9600 | LR: 1.54e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3235: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3246: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 0.5897 | Train F1: 0.8441 | Val Loss: 0.5136 | Val F1: 0.9502 | LR: 1.51e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3232: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3833: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 0.5613 | Train F1: 0.8544 | Val Loss: 0.4785 | Val F1: 0.9542 | LR: 1.48e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3240: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3227: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 0.5894 | Train F1: 0.8743 | Val Loss: 0.4667 | Val F1: 0.9619 | LR: 1.45e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4526: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3215: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 0.5711 | Train F1: 0.8313 | Val Loss: 0.4606 | Val F1: 0.9690 | LR: 1.43e-04 | Time: 28.0s\n",
      "새로운 최고 성능! F1: 0.9690 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1328: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 1.7053: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 0.5240 | Train F1: 0.8712 | Val Loss: 0.5706 | Val F1: 0.9366 | LR: 1.40e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3216: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 0.6054 | Train F1: 0.8173 | Val Loss: 0.4305 | Val F1: 0.9655 | LR: 1.37e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3230: 100%|██████████| 32/32 [00:04<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 0.4885 | Train F1: 0.8855 | Val Loss: 0.4262 | Val F1: 0.9670 | LR: 1.34e-04 | Time: 27.0s\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3289: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.5587 | Train F1: 0.8413 | Val Loss: 0.4815 | Val F1: 0.9535 | LR: 1.31e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8613: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 0.5215 | Train F1: 0.8974 | Val Loss: 0.4315 | Val F1: 0.9690 | LR: 1.28e-04 | Time: 27.5s\n",
      "새로운 최고 성능! F1: 0.9690 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3333: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3219: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 0.5043 | Train F1: 0.8735 | Val Loss: 0.4935 | Val F1: 0.9530 | LR: 1.25e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4219: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 1.5189: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 0.5148 | Train F1: 0.8746 | Val Loss: 0.4993 | Val F1: 0.9511 | LR: 1.22e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 0.4806 | Train F1: 0.8826 | Val Loss: 0.4552 | Val F1: 0.9630 | LR: 1.19e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3296: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3215: 100%|██████████| 32/32 [00:04<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 0.5199 | Train F1: 0.8495 | Val Loss: 0.4561 | Val F1: 0.9639 | LR: 1.16e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3217: 100%|██████████| 32/32 [00:04<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 0.5329 | Train F1: 0.8821 | Val Loss: 0.4443 | Val F1: 0.9699 | LR: 1.13e-04 | Time: 27.1s\n",
      "새로운 최고 성능! F1: 0.9699 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1543: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 0.5189 | Train F1: 0.8905 | Val Loss: 0.4494 | Val F1: 0.9669 | LR: 1.09e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3245: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 0.5152 | Train F1: 0.8886 | Val Loss: 0.4433 | Val F1: 0.9697 | LR: 1.06e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9810: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 0.6023 | Train F1: 0.8241 | Val Loss: 0.4407 | Val F1: 0.9658 | LR: 1.03e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9512: 100%|██████████| 126/126 [00:23<00:00,  5.39it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 0.4862 | Train F1: 0.8867 | Val Loss: 0.4432 | Val F1: 0.9683 | LR: 1.00e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3691: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3212: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Train Loss: 0.5228 | Train F1: 0.8794 | Val Loss: 0.4437 | Val F1: 0.9637 | LR: 9.69e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 0.4953 | Train F1: 0.8824 | Val Loss: 0.4417 | Val F1: 0.9714 | LR: 9.37e-05 | Time: 27.1s\n",
      "새로운 최고 성능! F1: 0.9714 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3213: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Train Loss: 0.4963 | Train F1: 0.8334 | Val Loss: 0.4576 | Val F1: 0.9623 | LR: 9.06e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Train Loss: 0.5376 | Train F1: 0.8576 | Val Loss: 0.4697 | Val F1: 0.9628 | LR: 8.75e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Train Loss: 0.5453 | Train F1: 0.8805 | Val Loss: 0.4407 | Val F1: 0.9682 | LR: 8.44e-05 | Time: 28.0s\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Train Loss: 0.4881 | Train F1: 0.8838 | Val Loss: 0.4421 | Val F1: 0.9688 | LR: 8.13e-05 | Time: 28.2s\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3250: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Train Loss: 0.4692 | Train F1: 0.8608 | Val Loss: 0.4586 | Val F1: 0.9571 | LR: 7.82e-05 | Time: 28.0s\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3235: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3222: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Train Loss: 0.4920 | Train F1: 0.8873 | Val Loss: 0.5051 | Val F1: 0.9564 | LR: 7.51e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8496: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Train Loss: 0.5521 | Train F1: 0.8670 | Val Loss: 0.4453 | Val F1: 0.9655 | LR: 7.21e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Train Loss: 0.5069 | Train F1: 0.8484 | Val Loss: 0.4293 | Val F1: 0.9685 | LR: 6.91e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 | Train Loss: 0.4877 | Train F1: 0.8681 | Val Loss: 0.4390 | Val F1: 0.9690 | LR: 6.61e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Train Loss: 0.5244 | Train F1: 0.8610 | Val Loss: 0.4215 | Val F1: 0.9766 | LR: 6.32e-05 | Time: 27.6s\n",
      "새로운 최고 성능! F1: 0.9766 - 모델 저장: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2959: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 | Train Loss: 0.5233 | Train F1: 0.8527 | Val Loss: 0.4224 | Val F1: 0.9639 | LR: 6.03e-05 | Time: 28.0s\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Train Loss: 0.4901 | Train F1: 0.8762 | Val Loss: 0.4435 | Val F1: 0.9717 | LR: 5.74e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 | Train Loss: 0.4824 | Train F1: 0.9016 | Val Loss: 0.4556 | Val F1: 0.9690 | LR: 5.46e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Train Loss: 0.4913 | Train F1: 0.8713 | Val Loss: 0.4414 | Val F1: 0.9715 | LR: 5.18e-05 | Time: 27.0s\n",
      "\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 | Train Loss: 0.5075 | Train F1: 0.8649 | Val Loss: 0.4399 | Val F1: 0.9735 | LR: 4.91e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 | Train Loss: 0.4778 | Train F1: 0.8697 | Val Loss: 0.4476 | Val F1: 0.9653 | LR: 4.64e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5889: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 | Train Loss: 0.5053 | Train F1: 0.8668 | Val Loss: 0.4349 | Val F1: 0.9684 | LR: 4.38e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 | Train Loss: 0.5385 | Train F1: 0.8472 | Val Loss: 0.4507 | Val F1: 0.9643 | LR: 4.12e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6025: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Train Loss: 0.4862 | Train F1: 0.8626 | Val Loss: 0.4444 | Val F1: 0.9655 | LR: 3.87e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 | Train Loss: 0.5211 | Train F1: 0.8469 | Val Loss: 0.4393 | Val F1: 0.9711 | LR: 3.63e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4792: 100%|██████████| 126/126 [00:22<00:00,  5.64it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Train Loss: 0.4969 | Train F1: 0.8825 | Val Loss: 0.4417 | Val F1: 0.9651 | LR: 3.39e-05 | Time: 27.0s\n",
      "\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6689: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 | Train Loss: 0.4933 | Train F1: 0.8860 | Val Loss: 0.4591 | Val F1: 0.9624 | LR: 3.15e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Train Loss: 0.4961 | Train F1: 0.8689 | Val Loss: 0.4358 | Val F1: 0.9683 | LR: 2.93e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train Loss: 0.5301 | Train F1: 0.7935 | Val Loss: 0.4306 | Val F1: 0.9698 | LR: 2.71e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8535: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 | Train Loss: 0.4828 | Train F1: 0.8963 | Val Loss: 0.4485 | Val F1: 0.9690 | LR: 2.50e-05 | Time: 28.0s\n",
      "\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 | Train Loss: 0.5084 | Train F1: 0.8199 | Val Loss: 0.4695 | Val F1: 0.9633 | LR: 2.29e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3262: 100%|██████████| 32/32 [00:04<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 | Train Loss: 0.4987 | Train F1: 0.8857 | Val Loss: 0.4463 | Val F1: 0.9655 | LR: 2.10e-05 | Time: 26.9s\n",
      "\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9883: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 | Train Loss: 0.5507 | Train F1: 0.8270 | Val Loss: 0.4434 | Val F1: 0.9683 | LR: 1.91e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 | Train Loss: 0.5007 | Train F1: 0.8902 | Val Loss: 0.4166 | Val F1: 0.9718 | LR: 1.73e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 | Train Loss: 0.4873 | Train F1: 0.8801 | Val Loss: 0.4167 | Val F1: 0.9746 | LR: 1.56e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 | Train Loss: 0.4853 | Train F1: 0.8645 | Val Loss: 0.4488 | Val F1: 0.9682 | LR: 1.39e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9185: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 | Train Loss: 0.5312 | Train F1: 0.8538 | Val Loss: 0.4384 | Val F1: 0.9698 | LR: 1.24e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8574: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 | Train Loss: 0.5078 | Train F1: 0.8720 | Val Loss: 0.4729 | Val F1: 0.9628 | LR: 1.09e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 | Train Loss: 0.4752 | Train F1: 0.8994 | Val Loss: 0.4468 | Val F1: 0.9652 | LR: 9.52e-06 | Time: 27.0s\n",
      "\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2266: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 | Train Loss: 0.4956 | Train F1: 0.8893 | Val Loss: 0.4297 | Val F1: 0.9711 | LR: 8.22e-06 | Time: 27.1s\n",
      "\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3248: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 | Train Loss: 0.4759 | Train F1: 0.8773 | Val Loss: 0.4344 | Val F1: 0.9717 | LR: 7.02e-06 | Time: 27.3s\n",
      "\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 | Train Loss: 0.4776 | Train F1: 0.8815 | Val Loss: 0.4440 | Val F1: 0.9682 | LR: 5.91e-06 | Time: 27.7s\n",
      "\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 | Train Loss: 0.4747 | Train F1: 0.8648 | Val Loss: 0.4442 | Val F1: 0.9654 | LR: 4.89e-06 | Time: 27.9s\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9561: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 | Train Loss: 0.5329 | Train F1: 0.8250 | Val Loss: 0.4556 | Val F1: 0.9659 | LR: 3.97e-06 | Time: 27.9s\n",
      "\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 | Train Loss: 0.4964 | Train F1: 0.8429 | Val Loss: 0.4441 | Val F1: 0.9711 | LR: 3.14e-06 | Time: 27.4s\n",
      "\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.64it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 | Train Loss: 0.4724 | Train F1: 0.9125 | Val Loss: 0.4535 | Val F1: 0.9642 | LR: 2.41e-06 | Time: 26.9s\n",
      "\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.64it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 | Train Loss: 0.5034 | Train F1: 0.9147 | Val Loss: 0.4277 | Val F1: 0.9709 | LR: 1.77e-06 | Time: 26.9s\n",
      "\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7295: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 | Train Loss: 0.4968 | Train F1: 0.8533 | Val Loss: 0.4326 | Val F1: 0.9731 | LR: 1.23e-06 | Time: 27.4s\n",
      "\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7861: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 | Train Loss: 0.4406 | Train F1: 0.9203 | Val Loss: 0.4486 | Val F1: 0.9655 | LR: 7.89e-07 | Time: 27.6s\n",
      "\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 | Train Loss: 0.4357 | Train F1: 0.9069 | Val Loss: 0.4325 | Val F1: 0.9711 | LR: 4.44e-07 | Time: 27.9s\n",
      "\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 | Train Loss: 0.4684 | Train F1: 0.8806 | Val Loss: 0.4471 | Val F1: 0.9683 | LR: 1.97e-07 | Time: 27.7s\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.4966 | Train F1: 0.8486 | Val Loss: 0.4379 | Val F1: 0.9711 | LR: 4.93e-08 | Time: 27.2s\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.64it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Train Loss: 0.4685 | Train F1: 0.8897 | Val Loss: 0.4208 | Val F1: 0.9766 | LR: 0.00e+00 | Time: 27.0s\n",
      "\n",
      "Fold 1 완료!\n",
      "최고 Validation F1: 0.9766\n",
      "학습된 에폭: 100/100\n",
      "모델 저장 위치: BH_512_base_best_model_fold_1.pth\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1348: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.5611: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.6588 | Train F1: 0.4477 | Val Loss: 0.8833 | Val F1: 0.7513 | LR: 2.00e-04 | Time: 27.3s\n",
      "새로운 최고 성능! F1: 0.7513 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5684: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.7814: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.9842 | Train F1: 0.6954 | Val Loss: 0.6472 | Val F1: 0.8505 | LR: 2.00e-04 | Time: 27.7s\n",
      "새로운 최고 성능! F1: 0.8505 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5146: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.6054: 100%|██████████| 32/32 [00:04<00:00,  6.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8708 | Train F1: 0.7506 | Val Loss: 0.5926 | Val F1: 0.8479 | LR: 2.00e-04 | Time: 28.2s\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3826: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.9161: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8001 | Train F1: 0.7363 | Val Loss: 0.5835 | Val F1: 0.8668 | LR: 1.99e-04 | Time: 28.1s\n",
      "새로운 최고 성능! F1: 0.8668 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3667: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.9205: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7035 | Train F1: 0.8290 | Val Loss: 0.5894 | Val F1: 0.8723 | LR: 1.99e-04 | Time: 27.5s\n",
      "새로운 최고 성능! F1: 0.8723 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3967: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.8359: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7652 | Train F1: 0.7924 | Val Loss: 0.5583 | Val F1: 0.8904 | LR: 1.98e-04 | Time: 27.2s\n",
      "새로운 최고 성능! F1: 0.8904 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3306: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3346: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.6695 | Train F1: 0.8368 | Val Loss: 0.5395 | Val F1: 0.9025 | LR: 1.98e-04 | Time: 27.4s\n",
      "새로운 최고 성능! F1: 0.9025 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5654: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3333: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7373 | Train F1: 0.7805 | Val Loss: 0.5478 | Val F1: 0.9202 | LR: 1.97e-04 | Time: 27.9s\n",
      "새로운 최고 성능! F1: 0.9202 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4297: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.7469: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.7762 | Train F1: 0.8124 | Val Loss: 0.5310 | Val F1: 0.9092 | LR: 1.96e-04 | Time: 28.2s\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4585: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.5119: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6613 | Train F1: 0.8304 | Val Loss: 0.4891 | Val F1: 0.9348 | LR: 1.95e-04 | Time: 27.9s\n",
      "새로운 최고 성능! F1: 0.9348 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3252: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3610: 100%|██████████| 32/32 [00:04<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.7054 | Train F1: 0.7748 | Val Loss: 0.4861 | Val F1: 0.9431 | LR: 1.94e-04 | Time: 27.2s\n",
      "새로운 최고 성능! F1: 0.9431 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6631: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.6062: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6025 | Train F1: 0.8403 | Val Loss: 0.5232 | Val F1: 0.9302 | LR: 1.93e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7637: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3606: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6427 | Train F1: 0.8486 | Val Loss: 0.4855 | Val F1: 0.9443 | LR: 1.92e-04 | Time: 27.4s\n",
      "새로운 최고 성능! F1: 0.9443 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5396: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3304: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6366 | Train F1: 0.8278 | Val Loss: 0.5238 | Val F1: 0.9364 | LR: 1.90e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7168: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3337: 100%|██████████| 32/32 [00:04<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.5855 | Train F1: 0.8813 | Val Loss: 0.4596 | Val F1: 0.9413 | LR: 1.89e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3298: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.3783: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.5891 | Train F1: 0.8185 | Val Loss: 0.5088 | Val F1: 0.9471 | LR: 1.88e-04 | Time: 28.0s\n",
      "새로운 최고 성능! F1: 0.9471 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5723: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.5516: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6215 | Train F1: 0.8063 | Val Loss: 0.4745 | Val F1: 0.9505 | LR: 1.86e-04 | Time: 27.4s\n",
      "새로운 최고 성능! F1: 0.9505 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5830: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3399: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5696 | Train F1: 0.8482 | Val Loss: 0.4583 | Val F1: 0.9534 | LR: 1.84e-04 | Time: 27.5s\n",
      "새로운 최고 성능! F1: 0.9534 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3276: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3937: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5387 | Train F1: 0.8714 | Val Loss: 0.4778 | Val F1: 0.9481 | LR: 1.83e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6162: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3337: 100%|██████████| 32/32 [00:04<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5853 | Train F1: 0.8490 | Val Loss: 0.5578 | Val F1: 0.9294 | LR: 1.81e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6606: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.3566: 100%|██████████| 32/32 [00:04<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5535 | Train F1: 0.8731 | Val Loss: 0.4720 | Val F1: 0.9445 | LR: 1.79e-04 | Time: 28.2s\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3269: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3360: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5389 | Train F1: 0.8836 | Val Loss: 0.4583 | Val F1: 0.9523 | LR: 1.77e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3245: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3505: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5644 | Train F1: 0.8351 | Val Loss: 0.5516 | Val F1: 0.9364 | LR: 1.75e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3374: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3445: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5647 | Train F1: 0.8485 | Val Loss: 0.4916 | Val F1: 0.9522 | LR: 1.73e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3809: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3344: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5976 | Train F1: 0.8469 | Val Loss: 0.5513 | Val F1: 0.9289 | LR: 1.71e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8296: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3241: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.6329 | Train F1: 0.7901 | Val Loss: 0.4537 | Val F1: 0.9617 | LR: 1.68e-04 | Time: 27.6s\n",
      "새로운 최고 성능! F1: 0.9617 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4751: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3225: 100%|██████████| 32/32 [00:04<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5526 | Train F1: 0.8492 | Val Loss: 0.4610 | Val F1: 0.9524 | LR: 1.66e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3125: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.3296: 100%|██████████| 32/32 [00:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5401 | Train F1: 0.8720 | Val Loss: 0.4517 | Val F1: 0.9612 | LR: 1.64e-04 | Time: 28.2s\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3245: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3244: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5455 | Train F1: 0.8378 | Val Loss: 0.4558 | Val F1: 0.9500 | LR: 1.61e-04 | Time: 27.5s\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3394: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3230: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5205 | Train F1: 0.8856 | Val Loss: 0.4756 | Val F1: 0.9550 | LR: 1.59e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3244: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5184 | Train F1: 0.8986 | Val Loss: 0.4891 | Val F1: 0.9443 | LR: 1.56e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9492: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3215: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.5407 | Train F1: 0.8608 | Val Loss: 0.4433 | Val F1: 0.9670 | LR: 1.54e-04 | Time: 27.6s\n",
      "새로운 최고 성능! F1: 0.9670 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3350: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3256: 100%|██████████| 32/32 [00:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 0.5047 | Train F1: 0.8858 | Val Loss: 0.4377 | Val F1: 0.9572 | LR: 1.51e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3225: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3227: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 0.5526 | Train F1: 0.8539 | Val Loss: 0.4695 | Val F1: 0.9506 | LR: 1.48e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3220: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.3276: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 0.5638 | Train F1: 0.8761 | Val Loss: 0.4485 | Val F1: 0.9657 | LR: 1.45e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3235: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3244: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 0.5377 | Train F1: 0.8693 | Val Loss: 0.4220 | Val F1: 0.9620 | LR: 1.43e-04 | Time: 27.5s\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8950: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3220: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 0.5442 | Train F1: 0.8518 | Val Loss: 0.4318 | Val F1: 0.9609 | LR: 1.40e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3237: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3231: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 0.5572 | Train F1: 0.8467 | Val Loss: 0.4898 | Val F1: 0.9484 | LR: 1.37e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3228: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3218: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 0.5294 | Train F1: 0.8639 | Val Loss: 0.4458 | Val F1: 0.9675 | LR: 1.34e-04 | Time: 27.5s\n",
      "새로운 최고 성능! F1: 0.9675 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3213: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.5148 | Train F1: 0.8831 | Val Loss: 0.4478 | Val F1: 0.9643 | LR: 1.31e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.3251: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 0.5035 | Train F1: 0.8948 | Val Loss: 0.4384 | Val F1: 0.9598 | LR: 1.28e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3228: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3439: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 0.5240 | Train F1: 0.8654 | Val Loss: 0.5260 | Val F1: 0.9483 | LR: 1.25e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.4465: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 0.5141 | Train F1: 0.8645 | Val Loss: 0.4566 | Val F1: 0.9589 | LR: 1.22e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3220: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3217: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 0.5162 | Train F1: 0.8680 | Val Loss: 0.4042 | Val F1: 0.9756 | LR: 1.19e-04 | Time: 27.1s\n",
      "새로운 최고 성능! F1: 0.9756 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3217: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 0.5005 | Train F1: 0.8693 | Val Loss: 0.5101 | Val F1: 0.9549 | LR: 1.16e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3213: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 0.5493 | Train F1: 0.8589 | Val Loss: 0.4237 | Val F1: 0.9695 | LR: 1.13e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3214: 100%|██████████| 32/32 [00:04<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 0.4772 | Train F1: 0.9110 | Val Loss: 0.4640 | Val F1: 0.9603 | LR: 1.09e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3259: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.3228: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 0.5325 | Train F1: 0.8632 | Val Loss: 0.4394 | Val F1: 0.9669 | LR: 1.06e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3408: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3250: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 0.4654 | Train F1: 0.8812 | Val Loss: 0.4633 | Val F1: 0.9594 | LR: 1.03e-04 | Time: 27.5s\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3999: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3213: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 0.4735 | Train F1: 0.9197 | Val Loss: 0.4271 | Val F1: 0.9688 | LR: 1.00e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4272: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3221: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Train Loss: 0.5302 | Train F1: 0.8923 | Val Loss: 0.4406 | Val F1: 0.9625 | LR: 9.69e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9263: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3229: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 0.5273 | Train F1: 0.8702 | Val Loss: 0.4583 | Val F1: 0.9676 | LR: 9.37e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9170: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3234: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Train Loss: 0.5583 | Train F1: 0.8004 | Val Loss: 0.4377 | Val F1: 0.9640 | LR: 9.06e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3369: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Train Loss: 0.5699 | Train F1: 0.8569 | Val Loss: 0.4316 | Val F1: 0.9668 | LR: 8.75e-05 | Time: 28.1s\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9126: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.3212: 100%|██████████| 32/32 [00:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Train Loss: 0.5312 | Train F1: 0.8383 | Val Loss: 0.4697 | Val F1: 0.9618 | LR: 8.44e-05 | Time: 28.2s\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3219: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Train Loss: 0.4875 | Train F1: 0.8725 | Val Loss: 0.4526 | Val F1: 0.9658 | LR: 8.13e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Train Loss: 0.5079 | Train F1: 0.8763 | Val Loss: 0.4205 | Val F1: 0.9737 | LR: 7.82e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Train Loss: 0.4864 | Train F1: 0.8902 | Val Loss: 0.4309 | Val F1: 0.9703 | LR: 7.51e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3213: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Train Loss: 0.5333 | Train F1: 0.8421 | Val Loss: 0.4255 | Val F1: 0.9718 | LR: 7.21e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Train Loss: 0.5068 | Train F1: 0.8540 | Val Loss: 0.4421 | Val F1: 0.9667 | LR: 6.91e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3217: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 | Train Loss: 0.5314 | Train F1: 0.8860 | Val Loss: 0.4063 | Val F1: 0.9782 | LR: 6.61e-05 | Time: 28.0s\n",
      "새로운 최고 성능! F1: 0.9782 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Train Loss: 0.4855 | Train F1: 0.8645 | Val Loss: 0.4221 | Val F1: 0.9740 | LR: 6.32e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 | Train Loss: 0.5414 | Train F1: 0.8844 | Val Loss: 0.4563 | Val F1: 0.9617 | LR: 6.03e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Train Loss: 0.4833 | Train F1: 0.8940 | Val Loss: 0.4669 | Val F1: 0.9590 | LR: 5.74e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 | Train Loss: 0.5068 | Train F1: 0.8645 | Val Loss: 0.4420 | Val F1: 0.9650 | LR: 5.46e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Train Loss: 0.4819 | Train F1: 0.8678 | Val Loss: 0.4327 | Val F1: 0.9706 | LR: 5.18e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7041: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3219: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 | Train Loss: 0.5015 | Train F1: 0.8512 | Val Loss: 0.4130 | Val F1: 0.9783 | LR: 4.91e-05 | Time: 27.9s\n",
      "새로운 최고 성능! F1: 0.9783 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7559: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.3283: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 | Train Loss: 0.5305 | Train F1: 0.8225 | Val Loss: 0.4332 | Val F1: 0.9691 | LR: 4.64e-05 | Time: 28.1s\n",
      "\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 | Train Loss: 0.5149 | Train F1: 0.8446 | Val Loss: 0.4438 | Val F1: 0.9691 | LR: 4.38e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 | Train Loss: 0.5157 | Train F1: 0.8707 | Val Loss: 0.4323 | Val F1: 0.9695 | LR: 4.12e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0596: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Train Loss: 0.5302 | Train F1: 0.8607 | Val Loss: 0.4110 | Val F1: 0.9737 | LR: 3.87e-05 | Time: 27.0s\n",
      "\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 | Train Loss: 0.4925 | Train F1: 0.8562 | Val Loss: 0.4286 | Val F1: 0.9688 | LR: 3.63e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Train Loss: 0.5196 | Train F1: 0.8895 | Val Loss: 0.4509 | Val F1: 0.9695 | LR: 3.39e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 | Train Loss: 0.4606 | Train F1: 0.8713 | Val Loss: 0.4499 | Val F1: 0.9631 | LR: 3.15e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3591: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Train Loss: 0.4820 | Train F1: 0.9061 | Val Loss: 0.4105 | Val F1: 0.9737 | LR: 2.93e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train Loss: 0.4702 | Train F1: 0.8747 | Val Loss: 0.4217 | Val F1: 0.9777 | LR: 2.71e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7070: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 | Train Loss: 0.5186 | Train F1: 0.8591 | Val Loss: 0.4682 | Val F1: 0.9604 | LR: 2.50e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.64it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 | Train Loss: 0.5142 | Train F1: 0.8713 | Val Loss: 0.4391 | Val F1: 0.9657 | LR: 2.29e-05 | Time: 27.0s\n",
      "\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0547: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 | Train Loss: 0.4680 | Train F1: 0.8998 | Val Loss: 0.4547 | Val F1: 0.9722 | LR: 2.10e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3408: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 | Train Loss: 0.5273 | Train F1: 0.8356 | Val Loss: 0.4210 | Val F1: 0.9722 | LR: 1.91e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1152: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 | Train Loss: 0.4917 | Train F1: 0.8367 | Val Loss: 0.4454 | Val F1: 0.9667 | LR: 1.73e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 | Train Loss: 0.4781 | Train F1: 0.8448 | Val Loss: 0.4162 | Val F1: 0.9718 | LR: 1.56e-05 | Time: 28.1s\n",
      "\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 | Train Loss: 0.5436 | Train F1: 0.8270 | Val Loss: 0.4143 | Val F1: 0.9753 | LR: 1.39e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 | Train Loss: 0.5172 | Train F1: 0.8280 | Val Loss: 0.4291 | Val F1: 0.9754 | LR: 1.24e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 | Train Loss: 0.4649 | Train F1: 0.8823 | Val Loss: 0.4423 | Val F1: 0.9720 | LR: 1.09e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 | Train Loss: 0.5084 | Train F1: 0.8540 | Val Loss: 0.4131 | Val F1: 0.9724 | LR: 9.52e-06 | Time: 27.3s\n",
      "\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 | Train Loss: 0.4726 | Train F1: 0.8996 | Val Loss: 0.4291 | Val F1: 0.9745 | LR: 8.22e-06 | Time: 27.8s\n",
      "\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7744: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 | Train Loss: 0.5310 | Train F1: 0.8655 | Val Loss: 0.4028 | Val F1: 0.9839 | LR: 7.02e-06 | Time: 28.0s\n",
      "새로운 최고 성능! F1: 0.9839 - 모델 저장: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 | Train Loss: 0.4934 | Train F1: 0.8822 | Val Loss: 0.4515 | Val F1: 0.9612 | LR: 5.91e-06 | Time: 27.7s\n",
      "\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4150: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 | Train Loss: 0.5101 | Train F1: 0.8765 | Val Loss: 0.4253 | Val F1: 0.9779 | LR: 4.89e-06 | Time: 27.3s\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5952: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 | Train Loss: 0.5041 | Train F1: 0.8585 | Val Loss: 0.4215 | Val F1: 0.9723 | LR: 3.97e-06 | Time: 27.1s\n",
      "\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7598: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 | Train Loss: 0.5245 | Train F1: 0.8681 | Val Loss: 0.4332 | Val F1: 0.9691 | LR: 3.14e-06 | Time: 27.2s\n",
      "\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5498: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 | Train Loss: 0.5331 | Train F1: 0.8224 | Val Loss: 0.4408 | Val F1: 0.9695 | LR: 2.41e-06 | Time: 27.5s\n",
      "\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.3212: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 | Train Loss: 0.4933 | Train F1: 0.8417 | Val Loss: 0.4191 | Val F1: 0.9708 | LR: 1.77e-06 | Time: 27.8s\n",
      "\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 | Train Loss: 0.4758 | Train F1: 0.8606 | Val Loss: 0.4396 | Val F1: 0.9724 | LR: 1.23e-06 | Time: 28.0s\n",
      "\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9473: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 | Train Loss: 0.4918 | Train F1: 0.8739 | Val Loss: 0.4381 | Val F1: 0.9695 | LR: 7.89e-07 | Time: 27.5s\n",
      "\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 | Train Loss: 0.4656 | Train F1: 0.8964 | Val Loss: 0.4273 | Val F1: 0.9722 | LR: 4.44e-07 | Time: 27.2s\n",
      "\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 | Train Loss: 0.4872 | Train F1: 0.8674 | Val Loss: 0.4136 | Val F1: 0.9724 | LR: 1.97e-07 | Time: 27.0s\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1016: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.4825 | Train F1: 0.9123 | Val Loss: 0.4449 | Val F1: 0.9695 | LR: 4.93e-08 | Time: 27.2s\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Train Loss: 0.4886 | Train F1: 0.8874 | Val Loss: 0.4289 | Val F1: 0.9708 | LR: 0.00e+00 | Time: 27.6s\n",
      "\n",
      "Fold 2 완료!\n",
      "최고 Validation F1: 0.9839\n",
      "학습된 에폭: 100/100\n",
      "모델 저장 위치: BH_512_base_best_model_fold_2.pth\n",
      "\n",
      "==================================================\n",
      "FOLD 3/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1084: 100%|██████████| 126/126 [00:23<00:00,  5.39it/s]\n",
      "Val Loss: 0.3837: 100%|██████████| 32/32 [00:04<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.6653 | Train F1: 0.4894 | Val Loss: 0.8163 | Val F1: 0.7945 | LR: 2.00e-04 | Time: 28.2s\n",
      "새로운 최고 성능! F1: 0.7945 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7930: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.3454: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.9202 | Train F1: 0.7263 | Val Loss: 0.6805 | Val F1: 0.8193 | LR: 2.00e-04 | Time: 28.1s\n",
      "새로운 최고 성능! F1: 0.8193 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9365: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3716: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.9450 | Train F1: 0.7348 | Val Loss: 0.6353 | Val F1: 0.8370 | LR: 2.00e-04 | Time: 27.4s\n",
      "새로운 최고 성능! F1: 0.8370 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3682: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3332: 100%|██████████| 32/32 [00:04<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.7316 | Train F1: 0.8219 | Val Loss: 0.6180 | Val F1: 0.8513 | LR: 1.99e-04 | Time: 27.1s\n",
      "새로운 최고 성능! F1: 0.8513 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5713: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3330: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7605 | Train F1: 0.8044 | Val Loss: 0.5575 | Val F1: 0.8754 | LR: 1.99e-04 | Time: 27.4s\n",
      "새로운 최고 성능! F1: 0.8754 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7603: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3781: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7317 | Train F1: 0.8025 | Val Loss: 0.5226 | Val F1: 0.9076 | LR: 1.98e-04 | Time: 27.8s\n",
      "새로운 최고 성능! F1: 0.9076 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3481: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.3292: 100%|██████████| 32/32 [00:04<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7033 | Train F1: 0.8129 | Val Loss: 0.4888 | Val F1: 0.9214 | LR: 1.98e-04 | Time: 28.1s\n",
      "새로운 최고 성능! F1: 0.9214 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4546: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3291: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.6365 | Train F1: 0.8667 | Val Loss: 0.5672 | Val F1: 0.8909 | LR: 1.97e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3308: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3289: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6708 | Train F1: 0.8480 | Val Loss: 0.4870 | Val F1: 0.9345 | LR: 1.96e-04 | Time: 27.5s\n",
      "새로운 최고 성능! F1: 0.9345 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3774: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3343: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6739 | Train F1: 0.8437 | Val Loss: 0.4624 | Val F1: 0.9448 | LR: 1.95e-04 | Time: 27.2s\n",
      "새로운 최고 성능! F1: 0.9448 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3699: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3271: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.5652 | Train F1: 0.8468 | Val Loss: 0.4375 | Val F1: 0.9458 | LR: 1.94e-04 | Time: 27.3s\n",
      "새로운 최고 성능! F1: 0.9458 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3499: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3243: 100%|██████████| 32/32 [00:04<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6442 | Train F1: 0.8424 | Val Loss: 0.4821 | Val F1: 0.9425 | LR: 1.93e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3467: 100%|██████████| 126/126 [00:23<00:00,  5.39it/s]\n",
      "Val Loss: 0.3292: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.5910 | Train F1: 0.8612 | Val Loss: 0.4239 | Val F1: 0.9561 | LR: 1.92e-04 | Time: 28.2s\n",
      "새로운 최고 성능! F1: 0.9561 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0977: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3255: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6430 | Train F1: 0.8239 | Val Loss: 0.4251 | Val F1: 0.9453 | LR: 1.90e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3552: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3217: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6063 | Train F1: 0.8245 | Val Loss: 0.4558 | Val F1: 0.9408 | LR: 1.89e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7310: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3277: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.5886 | Train F1: 0.8646 | Val Loss: 0.4704 | Val F1: 0.9534 | LR: 1.88e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3350: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3264: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6465 | Train F1: 0.8412 | Val Loss: 0.5613 | Val F1: 0.9111 | LR: 1.86e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3477: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3247: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6681 | Train F1: 0.7715 | Val Loss: 0.4376 | Val F1: 0.9598 | LR: 1.84e-04 | Time: 27.6s\n",
      "새로운 최고 성능! F1: 0.9598 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3066: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3233: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.6251 | Train F1: 0.8617 | Val Loss: 0.4447 | Val F1: 0.9569 | LR: 1.83e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3289: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3234: 100%|██████████| 32/32 [00:04<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5596 | Train F1: 0.8343 | Val Loss: 0.4184 | Val F1: 0.9700 | LR: 1.81e-04 | Time: 28.1s\n",
      "새로운 최고 성능! F1: 0.9700 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3252: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3243: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5298 | Train F1: 0.8744 | Val Loss: 0.4291 | Val F1: 0.9461 | LR: 1.79e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3271: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3268: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5724 | Train F1: 0.8548 | Val Loss: 0.5883 | Val F1: 0.9165 | LR: 1.77e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8818: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3219: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.6049 | Train F1: 0.8231 | Val Loss: 0.4298 | Val F1: 0.9508 | LR: 1.75e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8662: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3223: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5856 | Train F1: 0.8040 | Val Loss: 0.3913 | Val F1: 0.9750 | LR: 1.73e-04 | Time: 27.5s\n",
      "새로운 최고 성능! F1: 0.9750 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3237: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3211: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5568 | Train F1: 0.8589 | Val Loss: 0.4802 | Val F1: 0.9469 | LR: 1.71e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3606: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3241: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.6052 | Train F1: 0.8339 | Val Loss: 0.5103 | Val F1: 0.9487 | LR: 1.68e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3486: 100%|██████████| 126/126 [00:23<00:00,  5.39it/s]\n",
      "Val Loss: 0.3231: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5543 | Train F1: 0.8646 | Val Loss: 0.4109 | Val F1: 0.9560 | LR: 1.66e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4802: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3241: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5255 | Train F1: 0.8841 | Val Loss: 0.4248 | Val F1: 0.9680 | LR: 1.64e-04 | Time: 27.5s\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8677: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3241: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.6110 | Train F1: 0.7953 | Val Loss: 0.3835 | Val F1: 0.9777 | LR: 1.61e-04 | Time: 27.1s\n",
      "새로운 최고 성능! F1: 0.9777 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3569: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5298 | Train F1: 0.8627 | Val Loss: 0.4203 | Val F1: 0.9593 | LR: 1.59e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4385: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3217: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5621 | Train F1: 0.8499 | Val Loss: 0.4241 | Val F1: 0.9622 | LR: 1.56e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3242: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.3239: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.6189 | Train F1: 0.8578 | Val Loss: 0.3792 | Val F1: 0.9761 | LR: 1.54e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 0.5403 | Train F1: 0.8839 | Val Loss: 0.4584 | Val F1: 0.9615 | LR: 1.51e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3271: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3222: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 0.6027 | Train F1: 0.8149 | Val Loss: 0.4281 | Val F1: 0.9671 | LR: 1.48e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3252: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3222: 100%|██████████| 32/32 [00:04<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 0.5452 | Train F1: 0.8418 | Val Loss: 0.5185 | Val F1: 0.9540 | LR: 1.45e-04 | Time: 27.0s\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3219: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 0.5468 | Train F1: 0.8629 | Val Loss: 0.3668 | Val F1: 0.9882 | LR: 1.43e-04 | Time: 27.1s\n",
      "새로운 최고 성능! F1: 0.9882 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3350: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3247: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 0.6101 | Train F1: 0.8347 | Val Loss: 0.4779 | Val F1: 0.9465 | LR: 1.40e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3213: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 0.5372 | Train F1: 0.8765 | Val Loss: 0.3748 | Val F1: 0.9809 | LR: 1.37e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9688: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 0.5449 | Train F1: 0.8791 | Val Loss: 0.3969 | Val F1: 0.9679 | LR: 1.34e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6494: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3211: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.5508 | Train F1: 0.8513 | Val Loss: 0.4248 | Val F1: 0.9716 | LR: 1.31e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3235: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 0.5661 | Train F1: 0.8597 | Val Loss: 0.3856 | Val F1: 0.9809 | LR: 1.28e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 0.5353 | Train F1: 0.8620 | Val Loss: 0.4229 | Val F1: 0.9701 | LR: 1.25e-04 | Time: 27.0s\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9360: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 0.5348 | Train F1: 0.8769 | Val Loss: 0.3900 | Val F1: 0.9823 | LR: 1.22e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3486: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 0.5794 | Train F1: 0.8461 | Val Loss: 0.4231 | Val F1: 0.9720 | LR: 1.19e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 0.5187 | Train F1: 0.8711 | Val Loss: 0.3814 | Val F1: 0.9808 | LR: 1.16e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 0.4600 | Train F1: 0.9063 | Val Loss: 0.4022 | Val F1: 0.9763 | LR: 1.13e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4282: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3314: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 0.5330 | Train F1: 0.8599 | Val Loss: 0.3952 | Val F1: 0.9798 | LR: 1.09e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3240: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3233: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 0.5729 | Train F1: 0.8295 | Val Loss: 0.4011 | Val F1: 0.9751 | LR: 1.06e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 0.5517 | Train F1: 0.8123 | Val Loss: 0.3884 | Val F1: 0.9761 | LR: 1.03e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 0.5305 | Train F1: 0.8536 | Val Loss: 0.3539 | Val F1: 0.9882 | LR: 1.00e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3286: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Train Loss: 0.4873 | Train F1: 0.8754 | Val Loss: 0.4200 | Val F1: 0.9679 | LR: 9.69e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 0.5244 | Train F1: 0.8714 | Val Loss: 0.3906 | Val F1: 0.9809 | LR: 9.37e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Train Loss: 0.5627 | Train F1: 0.8504 | Val Loss: 0.4021 | Val F1: 0.9760 | LR: 9.06e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Train Loss: 0.5236 | Train F1: 0.8688 | Val Loss: 0.4501 | Val F1: 0.9632 | LR: 8.75e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Train Loss: 0.4878 | Train F1: 0.8952 | Val Loss: 0.3988 | Val F1: 0.9790 | LR: 8.44e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Train Loss: 0.5026 | Train F1: 0.8428 | Val Loss: 0.3747 | Val F1: 0.9809 | LR: 8.13e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Train Loss: 0.4995 | Train F1: 0.8893 | Val Loss: 0.4378 | Val F1: 0.9670 | LR: 7.82e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9204: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3211: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Train Loss: 0.5570 | Train F1: 0.8410 | Val Loss: 0.4131 | Val F1: 0.9759 | LR: 7.51e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Train Loss: 0.5147 | Train F1: 0.8889 | Val Loss: 0.4075 | Val F1: 0.9822 | LR: 7.21e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Train Loss: 0.5200 | Train F1: 0.8382 | Val Loss: 0.3959 | Val F1: 0.9853 | LR: 6.91e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 | Train Loss: 0.4987 | Train F1: 0.8585 | Val Loss: 0.3909 | Val F1: 0.9808 | LR: 6.61e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3213: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Train Loss: 0.5580 | Train F1: 0.8574 | Val Loss: 0.4361 | Val F1: 0.9670 | LR: 6.32e-05 | Time: 27.0s\n",
      "\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 | Train Loss: 0.4741 | Train F1: 0.8924 | Val Loss: 0.3993 | Val F1: 0.9778 | LR: 6.03e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Train Loss: 0.4827 | Train F1: 0.8703 | Val Loss: 0.4001 | Val F1: 0.9822 | LR: 5.74e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0811: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 | Train Loss: 0.5355 | Train F1: 0.8601 | Val Loss: 0.3760 | Val F1: 0.9882 | LR: 5.46e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Train Loss: 0.5267 | Train F1: 0.8742 | Val Loss: 0.4044 | Val F1: 0.9750 | LR: 5.18e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 | Train Loss: 0.4869 | Train F1: 0.8523 | Val Loss: 0.3950 | Val F1: 0.9761 | LR: 4.91e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8159: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 | Train Loss: 0.5100 | Train F1: 0.8496 | Val Loss: 0.4023 | Val F1: 0.9809 | LR: 4.64e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 | Train Loss: 0.5273 | Train F1: 0.8586 | Val Loss: 0.3869 | Val F1: 0.9853 | LR: 4.38e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 | Train Loss: 0.5094 | Train F1: 0.8924 | Val Loss: 0.3745 | Val F1: 0.9868 | LR: 4.12e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Train Loss: 0.5892 | Train F1: 0.8214 | Val Loss: 0.3551 | Val F1: 0.9867 | LR: 3.87e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4688: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 | Train Loss: 0.5020 | Train F1: 0.8769 | Val Loss: 0.3655 | Val F1: 0.9912 | LR: 3.63e-05 | Time: 28.0s\n",
      "새로운 최고 성능! F1: 0.9912 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Train Loss: 0.5269 | Train F1: 0.8414 | Val Loss: 0.4105 | Val F1: 0.9780 | LR: 3.39e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6641: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 | Train Loss: 0.5141 | Train F1: 0.8494 | Val Loss: 0.3708 | Val F1: 0.9882 | LR: 3.15e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Train Loss: 0.4915 | Train F1: 0.8666 | Val Loss: 0.3500 | Val F1: 0.9941 | LR: 2.93e-05 | Time: 27.1s\n",
      "새로운 최고 성능! F1: 0.9941 - 모델 저장: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train Loss: 0.5144 | Train F1: 0.8465 | Val Loss: 0.3995 | Val F1: 0.9853 | LR: 2.71e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 | Train Loss: 0.4458 | Train F1: 0.8997 | Val Loss: 0.3833 | Val F1: 0.9882 | LR: 2.50e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 | Train Loss: 0.5044 | Train F1: 0.8518 | Val Loss: 0.3572 | Val F1: 0.9897 | LR: 2.29e-05 | Time: 28.0s\n",
      "\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 | Train Loss: 0.4302 | Train F1: 0.8670 | Val Loss: 0.3832 | Val F1: 0.9867 | LR: 2.10e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7451: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 | Train Loss: 0.5267 | Train F1: 0.8330 | Val Loss: 0.3756 | Val F1: 0.9838 | LR: 1.91e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 | Train Loss: 0.4801 | Train F1: 0.8879 | Val Loss: 0.3902 | Val F1: 0.9759 | LR: 1.73e-05 | Time: 27.0s\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 | Train Loss: 0.5075 | Train F1: 0.8859 | Val Loss: 0.4011 | Val F1: 0.9809 | LR: 1.56e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 | Train Loss: 0.5217 | Train F1: 0.8228 | Val Loss: 0.3701 | Val F1: 0.9882 | LR: 1.39e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 | Train Loss: 0.4632 | Train F1: 0.8884 | Val Loss: 0.3694 | Val F1: 0.9882 | LR: 1.24e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 | Train Loss: 0.4660 | Train F1: 0.9089 | Val Loss: 0.3541 | Val F1: 0.9941 | LR: 1.09e-05 | Time: 28.0s\n",
      "\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 | Train Loss: 0.5249 | Train F1: 0.8424 | Val Loss: 0.3808 | Val F1: 0.9853 | LR: 9.52e-06 | Time: 27.5s\n",
      "\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5674: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 | Train Loss: 0.5243 | Train F1: 0.8977 | Val Loss: 0.3719 | Val F1: 0.9882 | LR: 8.22e-06 | Time: 27.2s\n",
      "\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4634: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 | Train Loss: 0.5026 | Train F1: 0.8688 | Val Loss: 0.4069 | Val F1: 0.9778 | LR: 7.02e-06 | Time: 27.2s\n",
      "\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 | Train Loss: 0.4348 | Train F1: 0.9497 | Val Loss: 0.3915 | Val F1: 0.9853 | LR: 5.91e-06 | Time: 27.3s\n",
      "\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 | Train Loss: 0.4551 | Train F1: 0.8888 | Val Loss: 0.3665 | Val F1: 0.9882 | LR: 4.89e-06 | Time: 27.8s\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 | Train Loss: 0.4568 | Train F1: 0.8844 | Val Loss: 0.3650 | Val F1: 0.9853 | LR: 3.97e-06 | Time: 28.1s\n",
      "\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 | Train Loss: 0.4636 | Train F1: 0.8931 | Val Loss: 0.3728 | Val F1: 0.9837 | LR: 3.14e-06 | Time: 28.1s\n",
      "\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 | Train Loss: 0.4956 | Train F1: 0.8869 | Val Loss: 0.3463 | Val F1: 0.9897 | LR: 2.41e-06 | Time: 27.5s\n",
      "\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 | Train Loss: 0.4647 | Train F1: 0.8827 | Val Loss: 0.3684 | Val F1: 0.9852 | LR: 1.77e-06 | Time: 27.3s\n",
      "\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8633: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 | Train Loss: 0.4948 | Train F1: 0.8820 | Val Loss: 0.3660 | Val F1: 0.9853 | LR: 1.23e-06 | Time: 27.2s\n",
      "\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9580: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 | Train Loss: 0.4940 | Train F1: 0.8483 | Val Loss: 0.3564 | Val F1: 0.9866 | LR: 7.89e-07 | Time: 27.5s\n",
      "\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6211: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 | Train Loss: 0.5486 | Train F1: 0.8406 | Val Loss: 0.3595 | Val F1: 0.9912 | LR: 4.44e-07 | Time: 28.0s\n",
      "\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 | Train Loss: 0.5042 | Train F1: 0.8610 | Val Loss: 0.4088 | Val F1: 0.9774 | LR: 1.97e-07 | Time: 28.1s\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1719: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3202: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.5360 | Train F1: 0.8469 | Val Loss: 0.3694 | Val F1: 0.9838 | LR: 4.93e-08 | Time: 28.0s\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9951: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3202: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Train Loss: 0.5338 | Train F1: 0.8542 | Val Loss: 0.3621 | Val F1: 0.9912 | LR: 0.00e+00 | Time: 27.5s\n",
      "\n",
      "Fold 3 완료!\n",
      "최고 Validation F1: 0.9941\n",
      "학습된 에폭: 100/100\n",
      "모델 저장 위치: BH_512_base_best_model_fold_3.pth\n",
      "\n",
      "==================================================\n",
      "FOLD 4/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7183: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.6487: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.5928 | Train F1: 0.4959 | Val Loss: 0.8745 | Val F1: 0.7281 | LR: 2.00e-04 | Time: 27.4s\n",
      "새로운 최고 성능! F1: 0.7281 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4187: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.4150: 100%|██████████| 32/32 [00:04<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.9338 | Train F1: 0.7324 | Val Loss: 0.6398 | Val F1: 0.8323 | LR: 2.00e-04 | Time: 27.8s\n",
      "새로운 최고 성능! F1: 0.8323 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8438: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.8129: 100%|██████████| 32/32 [00:04<00:00,  6.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8814 | Train F1: 0.7609 | Val Loss: 0.6629 | Val F1: 0.8268 | LR: 2.00e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7314: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.5136: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.7820 | Train F1: 0.7557 | Val Loss: 0.6516 | Val F1: 0.8462 | LR: 1.99e-04 | Time: 28.1s\n",
      "새로운 최고 성능! F1: 0.8462 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4707: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.6240: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7719 | Train F1: 0.8008 | Val Loss: 0.5598 | Val F1: 0.8689 | LR: 1.99e-04 | Time: 27.4s\n",
      "새로운 최고 성능! F1: 0.8689 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5811: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.5565: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.6762 | Train F1: 0.8599 | Val Loss: 0.5602 | Val F1: 0.8759 | LR: 1.98e-04 | Time: 27.5s\n",
      "새로운 최고 성능! F1: 0.8759 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6104: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3388: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7934 | Train F1: 0.7967 | Val Loss: 0.5262 | Val F1: 0.9162 | LR: 1.98e-04 | Time: 27.6s\n",
      "새로운 최고 성능! F1: 0.9162 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5176: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.5669: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7219 | Train F1: 0.8014 | Val Loss: 0.5414 | Val F1: 0.9160 | LR: 1.97e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5508: 100%|██████████| 126/126 [00:23<00:00,  5.37it/s]\n",
      "Val Loss: 0.3612: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.7019 | Train F1: 0.8095 | Val Loss: 0.4877 | Val F1: 0.9537 | LR: 1.96e-04 | Time: 28.3s\n",
      "새로운 최고 성능! F1: 0.9537 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7480: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3626: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6586 | Train F1: 0.8198 | Val Loss: 0.6053 | Val F1: 0.8764 | LR: 1.95e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3818: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3777: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6691 | Train F1: 0.8209 | Val Loss: 0.5023 | Val F1: 0.9295 | LR: 1.94e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6113: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3879: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6400 | Train F1: 0.8477 | Val Loss: 0.4913 | Val F1: 0.9511 | LR: 1.93e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3276: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3460: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6166 | Train F1: 0.8512 | Val Loss: 0.5008 | Val F1: 0.9210 | LR: 1.92e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3245: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3261: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6112 | Train F1: 0.8641 | Val Loss: 0.4728 | Val F1: 0.9411 | LR: 1.90e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3271: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.5981: 100%|██████████| 32/32 [00:04<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6005 | Train F1: 0.8424 | Val Loss: 0.4888 | Val F1: 0.9368 | LR: 1.89e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3262: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3768: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.6085 | Train F1: 0.7982 | Val Loss: 0.4310 | Val F1: 0.9614 | LR: 1.88e-04 | Time: 27.9s\n",
      "새로운 최고 성능! F1: 0.9614 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3308: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3484: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.5636 | Train F1: 0.8571 | Val Loss: 0.4946 | Val F1: 0.9384 | LR: 1.86e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7041: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3263: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5436 | Train F1: 0.8833 | Val Loss: 0.4391 | Val F1: 0.9617 | LR: 1.84e-04 | Time: 27.0s\n",
      "새로운 최고 성능! F1: 0.9617 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3523: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3292: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5435 | Train F1: 0.8709 | Val Loss: 0.4361 | Val F1: 0.9671 | LR: 1.83e-04 | Time: 27.2s\n",
      "새로운 최고 성능! F1: 0.9671 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5176: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3447: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.6428 | Train F1: 0.8100 | Val Loss: 0.4713 | Val F1: 0.9499 | LR: 1.81e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3278: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5717 | Train F1: 0.8338 | Val Loss: 0.4407 | Val F1: 0.9592 | LR: 1.79e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7246: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3269: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.6141 | Train F1: 0.8530 | Val Loss: 0.4347 | Val F1: 0.9553 | LR: 1.77e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6475: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3385: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5718 | Train F1: 0.8663 | Val Loss: 0.4750 | Val F1: 0.9458 | LR: 1.75e-04 | Time: 27.5s\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3267: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3256: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.6085 | Train F1: 0.8130 | Val Loss: 0.4996 | Val F1: 0.9411 | LR: 1.73e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3308: 100%|██████████| 126/126 [00:22<00:00,  5.64it/s]\n",
      "Val Loss: 0.4209: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5896 | Train F1: 0.8341 | Val Loss: 0.4874 | Val F1: 0.9365 | LR: 1.71e-04 | Time: 27.0s\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1768: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3645: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.5944 | Train F1: 0.8822 | Val Loss: 0.5880 | Val F1: 0.9167 | LR: 1.68e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9048: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3285: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5942 | Train F1: 0.8252 | Val Loss: 0.4590 | Val F1: 0.9469 | LR: 1.66e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3311: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3348: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5688 | Train F1: 0.8385 | Val Loss: 0.4129 | Val F1: 0.9621 | LR: 1.64e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3386: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5300 | Train F1: 0.8531 | Val Loss: 0.4840 | Val F1: 0.9547 | LR: 1.61e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3254: 100%|██████████| 32/32 [00:04<00:00,  6.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5071 | Train F1: 0.9130 | Val Loss: 0.4423 | Val F1: 0.9628 | LR: 1.59e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8936: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3240: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5318 | Train F1: 0.8642 | Val Loss: 0.4550 | Val F1: 0.9606 | LR: 1.56e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5273: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3236: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.5332 | Train F1: 0.8808 | Val Loss: 0.4133 | Val F1: 0.9745 | LR: 1.54e-04 | Time: 27.2s\n",
      "새로운 최고 성능! F1: 0.9745 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3281: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3266: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 0.5008 | Train F1: 0.8888 | Val Loss: 0.4267 | Val F1: 0.9704 | LR: 1.51e-04 | Time: 27.5s\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.3399: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 0.5544 | Train F1: 0.8148 | Val Loss: 0.3960 | Val F1: 0.9770 | LR: 1.48e-04 | Time: 27.9s\n",
      "새로운 최고 성능! F1: 0.9770 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.3244: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 0.4986 | Train F1: 0.8558 | Val Loss: 0.3955 | Val F1: 0.9818 | LR: 1.45e-04 | Time: 28.0s\n",
      "새로운 최고 성능! F1: 0.9818 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3213: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3230: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 0.5589 | Train F1: 0.8583 | Val Loss: 0.4270 | Val F1: 0.9725 | LR: 1.43e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7012: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3242: 100%|██████████| 32/32 [00:04<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 0.5544 | Train F1: 0.8474 | Val Loss: 0.3942 | Val F1: 0.9816 | LR: 1.40e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4082: 100%|██████████| 126/126 [00:22<00:00,  5.63it/s]\n",
      "Val Loss: 0.3275: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 0.5528 | Train F1: 0.8398 | Val Loss: 0.4368 | Val F1: 0.9665 | LR: 1.37e-04 | Time: 27.1s\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3215: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 0.5061 | Train F1: 0.8554 | Val Loss: 0.4197 | Val F1: 0.9695 | LR: 1.34e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3215: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.5090 | Train F1: 0.8718 | Val Loss: 0.3966 | Val F1: 0.9724 | LR: 1.31e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3220: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.3220: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 0.5071 | Train F1: 0.9035 | Val Loss: 0.4360 | Val F1: 0.9616 | LR: 1.28e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3213: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 0.5670 | Train F1: 0.8297 | Val Loss: 0.4149 | Val F1: 0.9649 | LR: 1.25e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3352: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 0.5207 | Train F1: 0.8770 | Val Loss: 0.4649 | Val F1: 0.9623 | LR: 1.22e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5386: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3217: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 0.5423 | Train F1: 0.8405 | Val Loss: 0.4286 | Val F1: 0.9695 | LR: 1.19e-04 | Time: 27.2s\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 0.5316 | Train F1: 0.8345 | Val Loss: 0.4394 | Val F1: 0.9748 | LR: 1.16e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 0.4785 | Train F1: 0.9135 | Val Loss: 0.4207 | Val F1: 0.9728 | LR: 1.13e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3220: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3244: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 0.5557 | Train F1: 0.8315 | Val Loss: 0.4224 | Val F1: 0.9649 | LR: 1.09e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1523: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 0.5172 | Train F1: 0.8623 | Val Loss: 0.4022 | Val F1: 0.9773 | LR: 1.06e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 0.5459 | Train F1: 0.8362 | Val Loss: 0.4156 | Val F1: 0.9672 | LR: 1.03e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 0.4834 | Train F1: 0.8648 | Val Loss: 0.4005 | Val F1: 0.9743 | LR: 1.00e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3289: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Train Loss: 0.4696 | Train F1: 0.9122 | Val Loss: 0.4216 | Val F1: 0.9770 | LR: 9.69e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 0.4958 | Train F1: 0.8886 | Val Loss: 0.4276 | Val F1: 0.9729 | LR: 9.37e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Train Loss: 0.5141 | Train F1: 0.8556 | Val Loss: 0.4211 | Val F1: 0.9778 | LR: 9.06e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Train Loss: 0.5062 | Train F1: 0.8698 | Val Loss: 0.4119 | Val F1: 0.9777 | LR: 8.75e-05 | Time: 28.1s\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Train Loss: 0.5183 | Train F1: 0.8509 | Val Loss: 0.4024 | Val F1: 0.9743 | LR: 8.44e-05 | Time: 28.0s\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0010: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Train Loss: 0.4919 | Train F1: 0.9043 | Val Loss: 0.4227 | Val F1: 0.9712 | LR: 8.13e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3237: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Train Loss: 0.5391 | Train F1: 0.8434 | Val Loss: 0.4274 | Val F1: 0.9683 | LR: 7.82e-05 | Time: 27.2s\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3257: 100%|██████████| 126/126 [00:22<00:00,  5.59it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Train Loss: 0.5096 | Train F1: 0.8438 | Val Loss: 0.4024 | Val F1: 0.9753 | LR: 7.51e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3235: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3211: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Train Loss: 0.5539 | Train F1: 0.8303 | Val Loss: 0.4208 | Val F1: 0.9714 | LR: 7.21e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2451: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Train Loss: 0.5016 | Train F1: 0.8625 | Val Loss: 0.4417 | Val F1: 0.9639 | LR: 6.91e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 | Train Loss: 0.5127 | Train F1: 0.8308 | Val Loss: 0.4531 | Val F1: 0.9708 | LR: 6.61e-05 | Time: 28.2s\n",
      "\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Train Loss: 0.4940 | Train F1: 0.8936 | Val Loss: 0.4056 | Val F1: 0.9778 | LR: 6.32e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9346: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 | Train Loss: 0.5404 | Train F1: 0.8451 | Val Loss: 0.4279 | Val F1: 0.9679 | LR: 6.03e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3650: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Train Loss: 0.4984 | Train F1: 0.8549 | Val Loss: 0.4210 | Val F1: 0.9777 | LR: 5.74e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 | Train Loss: 0.4902 | Train F1: 0.8869 | Val Loss: 0.4352 | Val F1: 0.9652 | LR: 5.46e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9009: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Train Loss: 0.5106 | Train F1: 0.8756 | Val Loss: 0.4142 | Val F1: 0.9677 | LR: 5.18e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8452: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 | Train Loss: 0.5254 | Train F1: 0.8397 | Val Loss: 0.4122 | Val F1: 0.9773 | LR: 4.91e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 | Train Loss: 0.4805 | Train F1: 0.8835 | Val Loss: 0.4448 | Val F1: 0.9713 | LR: 4.64e-05 | Time: 28.1s\n",
      "\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3457: 100%|██████████| 126/126 [00:23<00:00,  5.37it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 | Train Loss: 0.5425 | Train F1: 0.8523 | Val Loss: 0.3965 | Val F1: 0.9799 | LR: 4.38e-05 | Time: 28.3s\n",
      "\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 | Train Loss: 0.4924 | Train F1: 0.8691 | Val Loss: 0.3884 | Val F1: 0.9837 | LR: 4.12e-05 | Time: 27.8s\n",
      "새로운 최고 성능! F1: 0.9837 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1104: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Train Loss: 0.4507 | Train F1: 0.8937 | Val Loss: 0.4177 | Val F1: 0.9794 | LR: 3.87e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 | Train Loss: 0.5355 | Train F1: 0.8312 | Val Loss: 0.4059 | Val F1: 0.9778 | LR: 3.63e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Train Loss: 0.4975 | Train F1: 0.8603 | Val Loss: 0.3920 | Val F1: 0.9832 | LR: 3.39e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 | Train Loss: 0.5123 | Train F1: 0.8714 | Val Loss: 0.3849 | Val F1: 0.9809 | LR: 3.15e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8828: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Train Loss: 0.4930 | Train F1: 0.8536 | Val Loss: 0.3987 | Val F1: 0.9798 | LR: 2.93e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.39it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train Loss: 0.5257 | Train F1: 0.8420 | Val Loss: 0.4180 | Val F1: 0.9788 | LR: 2.71e-05 | Time: 28.3s\n",
      "\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4863: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 | Train Loss: 0.4622 | Train F1: 0.8831 | Val Loss: 0.3853 | Val F1: 0.9838 | LR: 2.50e-05 | Time: 27.8s\n",
      "새로운 최고 성능! F1: 0.9838 - 모델 저장: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 | Train Loss: 0.4850 | Train F1: 0.8713 | Val Loss: 0.4024 | Val F1: 0.9799 | LR: 2.29e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 | Train Loss: 0.4601 | Train F1: 0.8863 | Val Loss: 0.4203 | Val F1: 0.9743 | LR: 2.10e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7041: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3211: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 | Train Loss: 0.4762 | Train F1: 0.8574 | Val Loss: 0.3934 | Val F1: 0.9802 | LR: 1.91e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 | Train Loss: 0.5015 | Train F1: 0.8466 | Val Loss: 0.3896 | Val F1: 0.9837 | LR: 1.73e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8369: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 | Train Loss: 0.4919 | Train F1: 0.8860 | Val Loss: 0.4047 | Val F1: 0.9769 | LR: 1.56e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.39it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 | Train Loss: 0.5056 | Train F1: 0.8965 | Val Loss: 0.3891 | Val F1: 0.9802 | LR: 1.39e-05 | Time: 28.1s\n",
      "\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 | Train Loss: 0.4948 | Train F1: 0.8743 | Val Loss: 0.4189 | Val F1: 0.9695 | LR: 1.24e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4663: 100%|██████████| 126/126 [00:22<00:00,  5.62it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 | Train Loss: 0.4639 | Train F1: 0.8952 | Val Loss: 0.3823 | Val F1: 0.9832 | LR: 1.09e-05 | Time: 27.1s\n",
      "\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4443: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 | Train Loss: 0.4854 | Train F1: 0.8587 | Val Loss: 0.3845 | Val F1: 0.9778 | LR: 9.52e-06 | Time: 27.1s\n",
      "\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 | Train Loss: 0.5104 | Train F1: 0.8322 | Val Loss: 0.4278 | Val F1: 0.9743 | LR: 8.22e-06 | Time: 27.5s\n",
      "\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 | Train Loss: 0.5088 | Train F1: 0.8695 | Val Loss: 0.4052 | Val F1: 0.9814 | LR: 7.02e-06 | Time: 27.8s\n",
      "\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 | Train Loss: 0.4790 | Train F1: 0.8834 | Val Loss: 0.4204 | Val F1: 0.9706 | LR: 5.91e-06 | Time: 28.0s\n",
      "\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5303: 100%|██████████| 126/126 [00:23<00:00,  5.37it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 | Train Loss: 0.4904 | Train F1: 0.8618 | Val Loss: 0.4079 | Val F1: 0.9802 | LR: 4.89e-06 | Time: 28.3s\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 | Train Loss: 0.4898 | Train F1: 0.8637 | Val Loss: 0.3894 | Val F1: 0.9802 | LR: 3.97e-06 | Time: 27.8s\n",
      "\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 | Train Loss: 0.4738 | Train F1: 0.8495 | Val Loss: 0.4169 | Val F1: 0.9710 | LR: 3.14e-06 | Time: 27.6s\n",
      "\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 | Train Loss: 0.5167 | Train F1: 0.8608 | Val Loss: 0.4186 | Val F1: 0.9808 | LR: 2.41e-06 | Time: 27.6s\n",
      "\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6025: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 | Train Loss: 0.4666 | Train F1: 0.8980 | Val Loss: 0.4280 | Val F1: 0.9743 | LR: 1.77e-06 | Time: 27.5s\n",
      "\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5566: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 | Train Loss: 0.4699 | Train F1: 0.9041 | Val Loss: 0.4211 | Val F1: 0.9743 | LR: 1.23e-06 | Time: 27.6s\n",
      "\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 | Train Loss: 0.4939 | Train F1: 0.8521 | Val Loss: 0.4123 | Val F1: 0.9739 | LR: 7.89e-07 | Time: 27.9s\n",
      "\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5127: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 | Train Loss: 0.5056 | Train F1: 0.8357 | Val Loss: 0.4183 | Val F1: 0.9739 | LR: 4.44e-07 | Time: 28.0s\n",
      "\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7832: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 | Train Loss: 0.4995 | Train F1: 0.8528 | Val Loss: 0.4084 | Val F1: 0.9802 | LR: 1.97e-07 | Time: 27.9s\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.5176 | Train F1: 0.8307 | Val Loss: 0.4395 | Val F1: 0.9671 | LR: 4.93e-08 | Time: 27.4s\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4673: 100%|██████████| 126/126 [00:22<00:00,  5.61it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Train Loss: 0.4738 | Train F1: 0.9039 | Val Loss: 0.4197 | Val F1: 0.9693 | LR: 0.00e+00 | Time: 27.2s\n",
      "\n",
      "Fold 4 완료!\n",
      "최고 Validation F1: 0.9838\n",
      "학습된 에폭: 100/100\n",
      "모델 저장 위치: BH_512_base_best_model_fold_4.pth\n",
      "\n",
      "==================================================\n",
      "FOLD 5/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5913: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.7271: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.8178 | Train F1: 0.4589 | Val Loss: 0.9236 | Val F1: 0.7416 | LR: 2.00e-04 | Time: 27.5s\n",
      "새로운 최고 성능! F1: 0.7416 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8159: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 1.1097: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.0694 | Train F1: 0.6819 | Val Loss: 0.6619 | Val F1: 0.8683 | LR: 2.00e-04 | Time: 27.8s\n",
      "새로운 최고 성능! F1: 0.8683 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3372: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.5519: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8755 | Train F1: 0.7485 | Val Loss: 0.5803 | Val F1: 0.8667 | LR: 2.00e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4341: 100%|██████████| 126/126 [00:23<00:00,  5.36it/s]\n",
      "Val Loss: 0.9749: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.7184 | Train F1: 0.8031 | Val Loss: 0.6404 | Val F1: 0.8593 | LR: 1.99e-04 | Time: 28.4s\n",
      "\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5898: 100%|██████████| 126/126 [00:23<00:00,  5.37it/s]\n",
      "Val Loss: 0.3764: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7849 | Train F1: 0.7992 | Val Loss: 0.5366 | Val F1: 0.8847 | LR: 1.99e-04 | Time: 28.3s\n",
      "새로운 최고 성능! F1: 0.8847 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6914: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.4977: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7423 | Train F1: 0.7925 | Val Loss: 0.5185 | Val F1: 0.9140 | LR: 1.98e-04 | Time: 27.7s\n",
      "새로운 최고 성능! F1: 0.9140 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4614: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3972: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7356 | Train F1: 0.8066 | Val Loss: 0.5191 | Val F1: 0.9189 | LR: 1.98e-04 | Time: 27.3s\n",
      "새로운 최고 성능! F1: 0.9189 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 8/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5918: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.5440: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7468 | Train F1: 0.7532 | Val Loss: 0.4999 | Val F1: 0.9206 | LR: 1.97e-04 | Time: 27.6s\n",
      "새로운 최고 성능! F1: 0.9206 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6143: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.5047: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6834 | Train F1: 0.8115 | Val Loss: 0.5444 | Val F1: 0.9180 | LR: 1.96e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3965: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.5840: 100%|██████████| 32/32 [00:04<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6596 | Train F1: 0.8446 | Val Loss: 0.5198 | Val F1: 0.9354 | LR: 1.95e-04 | Time: 28.1s\n",
      "새로운 최고 성능! F1: 0.9354 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3379: 100%|██████████| 126/126 [00:23<00:00,  5.35it/s]\n",
      "Val Loss: 0.3555: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6130 | Train F1: 0.8567 | Val Loss: 0.5745 | Val F1: 0.9155 | LR: 1.94e-04 | Time: 28.4s\n",
      "\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4736: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 1.0871: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6515 | Train F1: 0.8294 | Val Loss: 0.5332 | Val F1: 0.9286 | LR: 1.93e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3860: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3403: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6351 | Train F1: 0.8277 | Val Loss: 0.4922 | Val F1: 0.9518 | LR: 1.92e-04 | Time: 27.6s\n",
      "새로운 최고 성능! F1: 0.9518 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 14/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1816: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.5960: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.5904 | Train F1: 0.8451 | Val Loss: 0.4813 | Val F1: 0.9442 | LR: 1.90e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 15/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3328: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.6267: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.5948 | Train F1: 0.8594 | Val Loss: 0.4574 | Val F1: 0.9559 | LR: 1.89e-04 | Time: 27.4s\n",
      "새로운 최고 성능! F1: 0.9559 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 16/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3479: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3852: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.5702 | Train F1: 0.8723 | Val Loss: 0.4733 | Val F1: 0.9566 | LR: 1.88e-04 | Time: 27.6s\n",
      "새로운 최고 성능! F1: 0.9566 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 17/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5654: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.4474: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6528 | Train F1: 0.8061 | Val Loss: 0.4998 | Val F1: 0.9538 | LR: 1.86e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 18/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3250: 100%|██████████| 126/126 [00:23<00:00,  5.35it/s]\n",
      "Val Loss: 0.6813: 100%|██████████| 32/32 [00:04<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5391 | Train F1: 0.8484 | Val Loss: 0.5024 | Val F1: 0.9395 | LR: 1.84e-04 | Time: 28.4s\n",
      "\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3274: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.3411: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.6230 | Train F1: 0.8258 | Val Loss: 0.4401 | Val F1: 0.9633 | LR: 1.83e-04 | Time: 28.1s\n",
      "새로운 최고 성능! F1: 0.9633 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 20/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9478: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3341: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5652 | Train F1: 0.8658 | Val Loss: 0.4325 | Val F1: 0.9634 | LR: 1.81e-04 | Time: 27.7s\n",
      "새로운 최고 성능! F1: 0.9634 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8926: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3319: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5810 | Train F1: 0.8253 | Val Loss: 0.4699 | Val F1: 0.9435 | LR: 1.79e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 22/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3213: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3866: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5362 | Train F1: 0.8493 | Val Loss: 0.4774 | Val F1: 0.9573 | LR: 1.77e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 23/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0000: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3498: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5482 | Train F1: 0.8832 | Val Loss: 0.5394 | Val F1: 0.9371 | LR: 1.75e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 24/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3225: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.4000: 100%|██████████| 32/32 [00:04<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5773 | Train F1: 0.8537 | Val Loss: 0.4456 | Val F1: 0.9695 | LR: 1.73e-04 | Time: 28.1s\n",
      "새로운 최고 성능! F1: 0.9695 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 25/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3228: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.3320: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5774 | Train F1: 0.8425 | Val Loss: 0.4356 | Val F1: 0.9691 | LR: 1.71e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 26/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8340: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3231: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.5310 | Train F1: 0.8931 | Val Loss: 0.4382 | Val F1: 0.9626 | LR: 1.68e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 27/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2988: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.5819: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5538 | Train F1: 0.8777 | Val Loss: 0.5084 | Val F1: 0.9326 | LR: 1.66e-04 | Time: 27.5s\n",
      "\n",
      "Epoch 28/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3250: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3525: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5752 | Train F1: 0.8551 | Val Loss: 0.4747 | Val F1: 0.9517 | LR: 1.64e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 29/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3350: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3609: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5754 | Train F1: 0.8546 | Val Loss: 0.4965 | Val F1: 0.9402 | LR: 1.61e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 30/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3264: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3261: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5559 | Train F1: 0.8764 | Val Loss: 0.4495 | Val F1: 0.9689 | LR: 1.59e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 31/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3237: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5186 | Train F1: 0.8841 | Val Loss: 0.4611 | Val F1: 0.9638 | LR: 1.56e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 32/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9277: 100%|██████████| 126/126 [00:23<00:00,  5.37it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.5613 | Train F1: 0.8811 | Val Loss: 0.4472 | Val F1: 0.9690 | LR: 1.54e-04 | Time: 28.4s\n",
      "\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7642: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.3213: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33 | Train Loss: 0.5315 | Train F1: 0.8637 | Val Loss: 0.4408 | Val F1: 0.9673 | LR: 1.51e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 34/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7305: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3220: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34 | Train Loss: 0.5513 | Train F1: 0.8867 | Val Loss: 0.4511 | Val F1: 0.9576 | LR: 1.48e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 35/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5122: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3214: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35 | Train Loss: 0.5305 | Train F1: 0.8791 | Val Loss: 0.4477 | Val F1: 0.9689 | LR: 1.45e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 36/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36 | Train Loss: 0.5501 | Train F1: 0.8522 | Val Loss: 0.4349 | Val F1: 0.9620 | LR: 1.43e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8262: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 0.3217: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37 | Train Loss: 0.5084 | Train F1: 0.8860 | Val Loss: 0.4551 | Val F1: 0.9655 | LR: 1.40e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5649: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38 | Train Loss: 0.5187 | Train F1: 0.8741 | Val Loss: 0.4113 | Val F1: 0.9723 | LR: 1.37e-04 | Time: 27.9s\n",
      "새로운 최고 성능! F1: 0.9723 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3213: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39 | Train Loss: 0.5520 | Train F1: 0.8560 | Val Loss: 0.4411 | Val F1: 0.9689 | LR: 1.34e-04 | Time: 28.1s\n",
      "\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3230: 100%|██████████| 126/126 [00:23<00:00,  5.32it/s]\n",
      "Val Loss: 0.3226: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40 | Train Loss: 0.5626 | Train F1: 0.8375 | Val Loss: 0.4378 | Val F1: 0.9688 | LR: 1.31e-04 | Time: 28.5s\n",
      "\n",
      "Epoch 41/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6494: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.8517: 100%|██████████| 32/32 [00:04<00:00,  6.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41 | Train Loss: 0.5128 | Train F1: 0.8799 | Val Loss: 0.4426 | Val F1: 0.9666 | LR: 1.28e-04 | Time: 27.9s\n",
      "\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1191: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3305: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42 | Train Loss: 0.5387 | Train F1: 0.8518 | Val Loss: 0.4472 | Val F1: 0.9635 | LR: 1.25e-04 | Time: 27.6s\n",
      "\n",
      "Epoch 43/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0752: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 1.1073: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43 | Train Loss: 0.5690 | Train F1: 0.8488 | Val Loss: 0.4489 | Val F1: 0.9633 | LR: 1.22e-04 | Time: 27.4s\n",
      "\n",
      "Epoch 44/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3254: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3213: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44 | Train Loss: 0.5456 | Train F1: 0.8687 | Val Loss: 0.4720 | Val F1: 0.9581 | LR: 1.19e-04 | Time: 27.5s\n",
      "\n",
      "Epoch 45/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.4638: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45 | Train Loss: 0.5278 | Train F1: 0.8654 | Val Loss: 0.4839 | Val F1: 0.9460 | LR: 1.16e-04 | Time: 27.8s\n",
      "\n",
      "Epoch 46/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3369: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3213: 100%|██████████| 32/32 [00:04<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46 | Train Loss: 0.5118 | Train F1: 0.8727 | Val Loss: 0.4306 | Val F1: 0.9634 | LR: 1.13e-04 | Time: 28.0s\n",
      "\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5200: 100%|██████████| 126/126 [00:23<00:00,  5.35it/s]\n",
      "Val Loss: 0.3220: 100%|██████████| 32/32 [00:04<00:00,  6.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47 | Train Loss: 0.5139 | Train F1: 0.8862 | Val Loss: 0.4296 | Val F1: 0.9721 | LR: 1.09e-04 | Time: 28.5s\n",
      "\n",
      "Epoch 48/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:23<00:00,  5.38it/s]\n",
      "Val Loss: 0.4417: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48 | Train Loss: 0.5440 | Train F1: 0.8561 | Val Loss: 0.4740 | Val F1: 0.9604 | LR: 1.06e-04 | Time: 28.3s\n",
      "\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8975: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3416: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 | Train Loss: 0.5532 | Train F1: 0.8556 | Val Loss: 0.4612 | Val F1: 0.9650 | LR: 1.03e-04 | Time: 27.7s\n",
      "\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 1.4060: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50 | Train Loss: 0.5102 | Train F1: 0.8507 | Val Loss: 0.5037 | Val F1: 0.9588 | LR: 1.00e-04 | Time: 27.3s\n",
      "\n",
      "Epoch 51/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|██████████| 126/126 [00:22<00:00,  5.60it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51 | Train Loss: 0.4835 | Train F1: 0.8795 | Val Loss: 0.4456 | Val F1: 0.9684 | LR: 9.69e-05 | Time: 27.3s\n",
      "\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3086: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52 | Train Loss: 0.5430 | Train F1: 0.8504 | Val Loss: 0.4627 | Val F1: 0.9578 | LR: 9.37e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 53/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.3231: 100%|██████████| 32/32 [00:04<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53 | Train Loss: 0.5135 | Train F1: 0.8755 | Val Loss: 0.4542 | Val F1: 0.9572 | LR: 9.06e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 54/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54 | Train Loss: 0.5244 | Train F1: 0.8501 | Val Loss: 0.4557 | Val F1: 0.9607 | LR: 8.75e-05 | Time: 28.2s\n",
      "\n",
      "Epoch 55/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1523: 100%|██████████| 126/126 [00:23<00:00,  5.34it/s]\n",
      "Val Loss: 1.4255: 100%|██████████| 32/32 [00:04<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55 | Train Loss: 0.5474 | Train F1: 0.8339 | Val Loss: 0.5029 | Val F1: 0.9602 | LR: 8.44e-05 | Time: 28.5s\n",
      "\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.38it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56 | Train Loss: 0.5411 | Train F1: 0.8650 | Val Loss: 0.4617 | Val F1: 0.9609 | LR: 8.13e-05 | Time: 28.2s\n",
      "\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3206: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57 | Train Loss: 0.4728 | Train F1: 0.8918 | Val Loss: 0.4805 | Val F1: 0.9577 | LR: 7.82e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9775: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58 | Train Loss: 0.5592 | Train F1: 0.8466 | Val Loss: 0.4515 | Val F1: 0.9677 | LR: 7.51e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 59/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3245: 100%|██████████| 32/32 [00:04<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59 | Train Loss: 0.5363 | Train F1: 0.8687 | Val Loss: 0.4631 | Val F1: 0.9625 | LR: 7.21e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 60/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60 | Train Loss: 0.5039 | Train F1: 0.8568 | Val Loss: 0.4670 | Val F1: 0.9571 | LR: 6.91e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.40it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61 | Train Loss: 0.5561 | Train F1: 0.8284 | Val Loss: 0.4595 | Val F1: 0.9598 | LR: 6.61e-05 | Time: 28.1s\n",
      "\n",
      "Epoch 62/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3555: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62 | Train Loss: 0.5107 | Train F1: 0.8419 | Val Loss: 0.4469 | Val F1: 0.9656 | LR: 6.32e-05 | Time: 28.3s\n",
      "\n",
      "Epoch 63/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7471: 100%|██████████| 126/126 [00:23<00:00,  5.33it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63 | Train Loss: 0.4605 | Train F1: 0.9065 | Val Loss: 0.4565 | Val F1: 0.9644 | LR: 6.03e-05 | Time: 28.6s\n",
      "\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64 | Train Loss: 0.5094 | Train F1: 0.8883 | Val Loss: 0.4560 | Val F1: 0.9621 | LR: 5.74e-05 | Time: 28.1s\n",
      "\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65 | Train Loss: 0.5486 | Train F1: 0.8097 | Val Loss: 0.4923 | Val F1: 0.9535 | LR: 5.46e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66 | Train Loss: 0.4964 | Train F1: 0.8827 | Val Loss: 0.4971 | Val F1: 0.9605 | LR: 5.18e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 67/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67 | Train Loss: 0.4922 | Train F1: 0.8542 | Val Loss: 0.4537 | Val F1: 0.9605 | LR: 4.91e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 68/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0352: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68 | Train Loss: 0.4973 | Train F1: 0.8620 | Val Loss: 0.4889 | Val F1: 0.9577 | LR: 4.64e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5815: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69 | Train Loss: 0.4802 | Train F1: 0.8631 | Val Loss: 0.4522 | Val F1: 0.9637 | LR: 4.38e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9053: 100%|██████████| 126/126 [00:23<00:00,  5.39it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70 | Train Loss: 0.5247 | Train F1: 0.8432 | Val Loss: 0.4809 | Val F1: 0.9633 | LR: 4.12e-05 | Time: 28.2s\n",
      "\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9160: 100%|██████████| 126/126 [00:23<00:00,  5.35it/s]\n",
      "Val Loss: 0.3208: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71 | Train Loss: 0.4905 | Train F1: 0.8810 | Val Loss: 0.4895 | Val F1: 0.9581 | LR: 3.87e-05 | Time: 28.4s\n",
      "\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72 | Train Loss: 0.4808 | Train F1: 0.8711 | Val Loss: 0.5023 | Val F1: 0.9535 | LR: 3.63e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 73/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3227: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73 | Train Loss: 0.5113 | Train F1: 0.8473 | Val Loss: 0.4837 | Val F1: 0.9569 | LR: 3.39e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 74/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74 | Train Loss: 0.5616 | Train F1: 0.8073 | Val Loss: 0.4601 | Val F1: 0.9584 | LR: 3.15e-05 | Time: 27.5s\n",
      "\n",
      "Epoch 75/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5708: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75 | Train Loss: 0.5244 | Train F1: 0.8541 | Val Loss: 0.4257 | Val F1: 0.9721 | LR: 2.93e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76 | Train Loss: 0.4809 | Train F1: 0.9015 | Val Loss: 0.4794 | Val F1: 0.9564 | LR: 2.71e-05 | Time: 27.8s\n",
      "\n",
      "Epoch 77/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77 | Train Loss: 0.4775 | Train F1: 0.8938 | Val Loss: 0.4340 | Val F1: 0.9677 | LR: 2.50e-05 | Time: 28.1s\n",
      "\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.33it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78 | Train Loss: 0.4899 | Train F1: 0.8695 | Val Loss: 0.4702 | Val F1: 0.9591 | LR: 2.29e-05 | Time: 28.5s\n",
      "\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3225: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79 | Train Loss: 0.5002 | Train F1: 0.8726 | Val Loss: 0.4750 | Val F1: 0.9600 | LR: 2.10e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 80/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3216: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80 | Train Loss: 0.5098 | Train F1: 0.8210 | Val Loss: 0.4371 | Val F1: 0.9641 | LR: 1.91e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 81/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:22<00:00,  5.55it/s]\n",
      "Val Loss: 0.3232: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81 | Train Loss: 0.5069 | Train F1: 0.8818 | Val Loss: 0.4422 | Val F1: 0.9722 | LR: 1.73e-05 | Time: 27.4s\n",
      "\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.53it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82 | Train Loss: 0.4949 | Train F1: 0.8687 | Val Loss: 0.4567 | Val F1: 0.9658 | LR: 1.56e-05 | Time: 27.6s\n",
      "\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83 | Train Loss: 0.5276 | Train F1: 0.8715 | Val Loss: 0.4919 | Val F1: 0.9549 | LR: 1.39e-05 | Time: 27.7s\n",
      "\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84 | Train Loss: 0.4865 | Train F1: 0.8550 | Val Loss: 0.4662 | Val F1: 0.9688 | LR: 1.24e-05 | Time: 27.9s\n",
      "\n",
      "Epoch 85/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.42it/s]\n",
      "Val Loss: 0.3204: 100%|██████████| 32/32 [00:04<00:00,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85 | Train Loss: 0.4740 | Train F1: 0.9135 | Val Loss: 0.5039 | Val F1: 0.9574 | LR: 1.09e-05 | Time: 28.1s\n",
      "\n",
      "Epoch 86/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7397: 100%|██████████| 126/126 [00:23<00:00,  5.43it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86 | Train Loss: 0.5281 | Train F1: 0.8504 | Val Loss: 0.4804 | Val F1: 0.9596 | LR: 9.52e-06 | Time: 28.0s\n",
      "\n",
      "Epoch 87/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8936: 100%|██████████| 126/126 [00:22<00:00,  5.54it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87 | Train Loss: 0.4605 | Train F1: 0.8708 | Val Loss: 0.5090 | Val F1: 0.9587 | LR: 8.22e-06 | Time: 27.5s\n",
      "\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9004: 100%|██████████| 126/126 [00:22<00:00,  5.58it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88 | Train Loss: 0.5033 | Train F1: 0.8776 | Val Loss: 0.4256 | Val F1: 0.9763 | LR: 7.02e-06 | Time: 27.3s\n",
      "새로운 최고 성능! F1: 0.9763 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 89/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3211: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89 | Train Loss: 0.4810 | Train F1: 0.8669 | Val Loss: 0.4947 | Val F1: 0.9559 | LR: 5.91e-06 | Time: 27.6s\n",
      "\n",
      "Epoch 90/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1904: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90 | Train Loss: 0.5038 | Train F1: 0.8822 | Val Loss: 0.4789 | Val F1: 0.9609 | LR: 4.89e-06 | Time: 27.7s\n",
      "\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91 | Train Loss: 0.4899 | Train F1: 0.8757 | Val Loss: 0.4729 | Val F1: 0.9635 | LR: 3.97e-06 | Time: 27.9s\n",
      "\n",
      "Epoch 92/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6348: 100%|██████████| 126/126 [00:23<00:00,  5.41it/s]\n",
      "Val Loss: 0.3205: 100%|██████████| 32/32 [00:04<00:00,  6.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92 | Train Loss: 0.5211 | Train F1: 0.8658 | Val Loss: 0.4783 | Val F1: 0.9568 | LR: 3.14e-06 | Time: 28.2s\n",
      "\n",
      "Epoch 93/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8486: 100%|██████████| 126/126 [00:23<00:00,  5.39it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93 | Train Loss: 0.4989 | Train F1: 0.8724 | Val Loss: 0.4075 | Val F1: 0.9793 | LR: 2.41e-06 | Time: 28.2s\n",
      "새로운 최고 성능! F1: 0.9793 - 모델 저장: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Epoch 94/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6470: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94 | Train Loss: 0.4730 | Train F1: 0.8641 | Val Loss: 0.4660 | Val F1: 0.9559 | LR: 1.77e-06 | Time: 27.6s\n",
      "\n",
      "Epoch 95/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:22<00:00,  5.57it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95 | Train Loss: 0.4722 | Train F1: 0.8540 | Val Loss: 0.4569 | Val F1: 0.9648 | LR: 1.23e-06 | Time: 27.3s\n",
      "\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8320: 100%|██████████| 126/126 [00:22<00:00,  5.56it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96 | Train Loss: 0.5177 | Train F1: 0.8122 | Val Loss: 0.4317 | Val F1: 0.9737 | LR: 7.89e-07 | Time: 27.4s\n",
      "\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8857: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97 | Train Loss: 0.5349 | Train F1: 0.7975 | Val Loss: 0.4844 | Val F1: 0.9611 | LR: 4.44e-07 | Time: 27.6s\n",
      "\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3201: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98 | Train Loss: 0.4825 | Train F1: 0.8945 | Val Loss: 0.4681 | Val F1: 0.9648 | LR: 1.97e-07 | Time: 27.8s\n",
      "\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99 | Train Loss: 0.4885 | Train F1: 0.8911 | Val Loss: 0.4651 | Val F1: 0.9534 | LR: 4.93e-08 | Time: 28.1s\n",
      "\n",
      "Epoch 100/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3203: 100%|██████████| 126/126 [00:23<00:00,  5.38it/s]\n",
      "Val Loss: 0.3203: 100%|██████████| 32/32 [00:04<00:00,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100 | Train Loss: 0.4761 | Train F1: 0.8910 | Val Loss: 0.4560 | Val F1: 0.9592 | LR: 0.00e+00 | Time: 28.3s\n",
      "\n",
      "Fold 5 완료!\n",
      "최고 Validation F1: 0.9793\n",
      "학습된 에폭: 100/100\n",
      "모델 저장 위치: BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "============================================================\n",
      "K-FOLD CROSS VALIDATION RESULTS\n",
      "============================================================\n",
      "Fold 1: F1=0.9766 (epochs: 100) - BH_512_base_best_model_fold_1.pth\n",
      "Fold 2: F1=0.9839 (epochs: 100) - BH_512_base_best_model_fold_2.pth\n",
      "Fold 3: F1=0.9941 (epochs: 100) - BH_512_base_best_model_fold_3.pth\n",
      "Fold 4: F1=0.9838 (epochs: 100) - BH_512_base_best_model_fold_4.pth\n",
      "Fold 5: F1=0.9793 (epochs: 100) - BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "Mean CV F1: 0.9835 ± 0.0060\n",
      "Best single fold: 0.9941\n",
      "\n",
      "저장된 모델 파일들:\n",
      "  ✓ BH_512_base_best_model_fold_1.pth\n",
      "  ✓ BH_512_base_best_model_fold_2.pth\n",
      "  ✓ BH_512_base_best_model_fold_3.pth\n",
      "  ✓ BH_512_base_best_model_fold_4.pth\n",
      "  ✓ BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "클래스별 평균 정확도 (전체 fold):\n",
      "  Class  0: 1.000 ± 0.000\n",
      "  Class  1: 1.000 ± 0.000\n",
      "  Class  2: 1.000 ± 0.000\n",
      "  Class  3: 0.870 ± 0.068\n",
      "  Class  4: 0.950 ± 0.055\n",
      "  Class  5: 1.000 ± 0.000\n",
      "  Class  6: 0.990 ± 0.020\n",
      "  Class  7: 0.930 ± 0.040\n",
      "  Class  8: 1.000 ± 0.000\n",
      "  Class  9: 1.000 ± 0.000\n",
      "  Class 10: 0.990 ± 0.020\n",
      "  Class 11: 0.980 ± 0.024\n",
      "  Class 12: 1.000 ± 0.000\n",
      "  Class 13: 1.000 ± 0.000\n",
      "  Class 14: 0.840 ± 0.080\n",
      "  Class 15: 1.000 ± 0.000\n",
      "  Class 16: 1.000 ± 0.000\n"
     ]
    }
   ],
   "source": [
    "# K-Fold 설정\n",
    "N_FOLDS = 5  # 5-fold로 설정 (데이터가 적으므로)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# 전체 학습 데이터 로드\n",
    "train_df = pd.read_csv(\"/root/home/cv_contest/CV_data/train.csv\")\n",
    "\n",
    "# K-Fold 결과를 저장할 리스트\n",
    "fold_results = []\n",
    "fold_models = []  # 각 fold의 최고 성능 모델을 저장\n",
    "fold_class_accuracies = [] # 각 fold의 클래스별 정확도 저장\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# K-Fold Cross Validation 시작\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    current_model = model_name\n",
    "    \n",
    "    # 현재 fold의 train/validation 데이터 분할\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 현재 fold의 Dataset 생성\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"/root/home/cv_contest/CV_data/train\",\n",
    "        epoch=0,  # 현재 epoch 전달\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"/root/home/cv_contest/CV_data/train\",\n",
    "        epoch=0,  # validation은 epoch 관계없음\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False  # validation이므로 hard augmentation 비활성화\n",
    "    )\n",
    "    \n",
    "    # 현재 fold의 DataLoader 생성\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # 모델 초기화 (각 fold마다 새로운 모델)\n",
    "    model = timm.create_model(\n",
    "        current_model,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)  # Label Smoothing 적용\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler 추가\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # 현재 fold의 최고 성능 추적\n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # 현재 fold 학습\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training\n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # Scheduler step 추가\n",
    "        scheduler.step()\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f} | \"\n",
    "              f\"LR: {current_lr:.2e} | \"\n",
    "              f\"Time: {epoch_time:.1f}s\")\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # 최고 성능 모델을 파일로 저장\n",
    "            model_path = f'BH_512_base_best_model_fold_{fold+1}.pth'\n",
    "            torch.save(best_model, model_path)\n",
    "            print(f\"새로운 최고 성능! F1: {best_val_f1:.4f} - 모델 저장: {model_path}\")\n",
    "            \n",
    "            # Best 모델로 클래스별 정확도 계산\n",
    "            model.eval()\n",
    "            val_preds, val_targets = [], []\n",
    "            with torch.no_grad():\n",
    "                for image, targets in val_loader:\n",
    "                    preds = model(image.to(device)).argmax(dim=1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_targets.extend(targets.numpy())\n",
    "            \n",
    "            # 클래스별 정확도 계산\n",
    "            fold_class_acc = {}\n",
    "            for c in range(17):\n",
    "                mask = np.array(val_targets) == c\n",
    "                if mask.sum() > 0:\n",
    "                    fold_class_acc[c] = (np.array(val_preds)[mask] == c).mean()\n",
    "\n",
    "    # 현재 fold 결과 저장\n",
    "    fold_result = {\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'final_train_f1': train_ret['train_f1'],\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset),\n",
    "        'epochs_trained': EPOCHS,\n",
    "        'model_path': f'BH_512_base_best_model_fold_{fold+1}.pth'\n",
    "    }\n",
    "    \n",
    "    fold_results.append(fold_result)\n",
    "    fold_models.append(best_model)\n",
    "    fold_class_accuracies.append(fold_class_acc)\n",
    "    \n",
    "    print(f\"\\nFold {fold + 1} 완료!\")\n",
    "    print(f\"최고 Validation F1: {best_val_f1:.4f}\")\n",
    "    print(f\"학습된 에폭: {EPOCHS}/{EPOCHS}\")\n",
    "    print(f\"모델 저장 위치: BH_512_base_best_model_fold_{fold+1}.pth\")\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del model, optimizer, scheduler\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# K-Fold 결과 요약\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"K-FOLD CROSS VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: F1={result['best_val_f1']:.4f} \"\n",
    "          f\"(epochs: {result['epochs_trained']}) \"\n",
    "          f\"- {result['model_path']}\")\n",
    "\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(val_f1_scores):.4f}\")\n",
    "\n",
    "# 저장된 모델 파일 리스트 출력\n",
    "print(f\"\\n저장된 모델 파일들:\")\n",
    "for i in range(N_FOLDS):\n",
    "    model_file = f'BH_512_base_best_model_fold_{i+1}.pth'\n",
    "    if os.path.exists(model_file):\n",
    "        print(f\"  ✓ {model_file}\")\n",
    "    else:\n",
    "        print(f\"  ✗ {model_file} (없음)\")\n",
    "\n",
    "# 클래스별 평균 정확도 계산\n",
    "if fold_class_accuracies:\n",
    "    print(f\"\\n클래스별 평균 정확도 (전체 fold):\")\n",
    "    for class_id in range(17):\n",
    "        class_accs = []\n",
    "        for fold_acc in fold_class_accuracies:\n",
    "            if class_id in fold_acc:\n",
    "                class_accs.append(fold_acc[class_id])\n",
    "        \n",
    "        if class_accs:\n",
    "            mean_acc = np.mean(class_accs)\n",
    "            std_acc = np.std(class_accs)\n",
    "            print(f\"  Class {class_id:2d}: {mean_acc:.3f} ± {std_acc:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # K-Fold 설정\n",
    "# N_FOLDS = 5  # 5-fold로 설정 (데이터가 적으므로)\n",
    "# skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# # 클래스별 최소 샘플 보장 확인\n",
    "# # for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "# #     assert len(np.unique(train_df.iloc[val_idx]['target'])) == 17\n",
    "\n",
    "# # 전체 학습 데이터 로드\n",
    "# train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# # K-Fold 결과를 저장할 리스트\n",
    "# fold_results = []\n",
    "# fold_models = []  # 각 fold의 최고 성능 모델을 저장\n",
    "# fold_class_accuracies = [] # 각 fold의 클래스별 정확도 저장\n",
    "\n",
    "# print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# # LR = best_params['lr']\n",
    "# # BATCH_SIZE = best_params['batch_size']\n",
    "\n",
    "# # K-Fold Cross Validation 시작\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "#     print(f\"\\n{'='*50}\")\n",
    "#     print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "#     print(f\"{'='*50}\")\n",
    "    \n",
    "#     current_model = model_name\n",
    "    \n",
    "#     # 현재 fold의 train/validation 데이터 분할\n",
    "#     train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "#     val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "#     # 현재 fold의 Dataset 생성\n",
    "#     trn_dataset = ImageDataset(\n",
    "#         train_fold_df,\n",
    "#         \"../data/train/\",\n",
    "#         # transform=trn_transform\n",
    "#         epoch=0,  # 현재 epoch 전달\n",
    "#         total_epochs=EPOCHS,\n",
    "#         is_train=True\n",
    "#     )\n",
    "    \n",
    "#     val_dataset = ImageDataset(\n",
    "#         val_fold_df,\n",
    "#         \"../data/train/\",\n",
    "#         # transform=tst_transform  # 검증에는 증강 적용 안함\n",
    "#         epoch=0,  # validation은 epoch 관계없음\n",
    "#         total_epochs=EPOCHS,\n",
    "#         is_train=False  # validation이므로 hard augmentation 비활성화\n",
    "#     )\n",
    "    \n",
    "#     # 현재 fold의 DataLoader 생성\n",
    "#     trn_loader = DataLoader(\n",
    "#         trn_dataset,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         shuffle=True,\n",
    "#         num_workers=num_workers,\n",
    "#         pin_memory=True,\n",
    "#         drop_last=False\n",
    "#     )\n",
    "    \n",
    "#     val_loader = DataLoader(\n",
    "#         val_dataset,\n",
    "#         batch_size=BATCH_SIZE,\n",
    "#         shuffle=False,\n",
    "#         num_workers=num_workers,\n",
    "#         pin_memory=True\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "#     # 모델 초기화 (각 fold마다 새로운 모델)\n",
    "#     model = timm.create_model(\n",
    "#         current_model,\n",
    "#         pretrained=True,\n",
    "#         num_classes=17\n",
    "#     ).to(device)\n",
    "    \n",
    "#     loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)  # Label Smoothing 적용\n",
    "#     optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "#     # Learning Rate Scheduler 추가\n",
    "#     scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "#     # 현재 fold의 최고 성능 추적\n",
    "#     best_val_f1 = 0.0\n",
    "#     best_model = None\n",
    "    \n",
    "#     # 현재 fold 학습\n",
    "#     for epoch in range(EPOCHS):\n",
    "#         # Training\n",
    "#         train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "#         # Validation\n",
    "#         val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "#         # Scheduler step 추가\n",
    "#         scheduler.step()\n",
    "        \n",
    "#         print(f\"Epoch {epoch+1:2d} | \"\n",
    "#               f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "#               f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "#               f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "#               f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "#         # 최고 성능 모델 저장\n",
    "#         if val_ret['val_f1'] > best_val_f1:\n",
    "#             best_val_f1 = val_ret['val_f1']\n",
    "#             best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "#             # Best 모델 분석\n",
    "#             model.eval()\n",
    "#             val_preds, val_targets = [], []\n",
    "#             with torch.no_grad():\n",
    "#                 for image, targets in val_loader:\n",
    "#                     preds = model(image.to(device)).argmax(dim=1)\n",
    "#                     val_preds.extend(preds.cpu().numpy())\n",
    "#                     val_targets.extend(targets.numpy())\n",
    "            \n",
    "#             # 클래스별 정확도\n",
    "#             fold_class_acc = {}\n",
    "#             for c in range(17):\n",
    "#                 mask = np.array(val_targets) == c\n",
    "#                 if mask.sum() > 0:\n",
    "#                     fold_class_acc[c] = (np.array(val_preds)[mask] == c).mean()\n",
    "    \n",
    "#     # 현재 fold 결과 저장\n",
    "#     fold_results.append({\n",
    "#         'fold': fold + 1,\n",
    "#         'best_val_f1': best_val_f1,\n",
    "#         'train_samples': len(trn_dataset),\n",
    "#         'val_samples': len(val_dataset)\n",
    "#     })\n",
    "    \n",
    "#     fold_models.append(best_model)\n",
    "    \n",
    "#     print(f\"Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "#     fold_class_accuracies.append(fold_class_acc) # 각 fold의 클래스별 정확도 저장\n",
    "\n",
    "# # K-Fold 결과 요약\n",
    "# print(f\"\\n{'='*60}\")\n",
    "# print(\"K-FOLD CROSS VALIDATION RESULTS\")\n",
    "# print(f\"{'='*60}\")\n",
    "\n",
    "# val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "# mean_f1 = np.mean(val_f1_scores)\n",
    "# std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "# for result in fold_results:\n",
    "#     print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "# print(f\"\\nMean CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "# print(f\"Best single fold: {max(val_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 3 classes:\n",
      "Class 14: 84.0%\n",
      "Class 3: 87.0%\n",
      "Class 7: 93.0%\n"
     ]
    }
   ],
   "source": [
    "# 클래스별 성능 시각화\n",
    "meta_df = pd.read_csv(\"/root/home/cv_contest/CV_data/meta.csv\")\n",
    "avg_acc = {c: np.mean([f.get(c,0) for f in fold_class_accuracies]) for c in range(17)}\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "classes = list(avg_acc.keys())\n",
    "accs = [avg_acc[c] * 100 for c in classes]\n",
    "names = [f\"C{c}\" for c in classes]\n",
    "\n",
    "plt.bar(range(17), accs)\n",
    "plt.xticks(range(17), names)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Class-wise Prediction Accuracy')\n",
    "for i, acc in enumerate(accs):\n",
    "    plt.text(i, acc + 1, f'{acc:.1f}%', ha='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Worst 3 classes:\")\n",
    "worst = sorted(avg_acc.items(), key=lambda x: x[1])[:3]\n",
    "for c, acc in worst:\n",
    "    print(f\"Class {c}: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 디렉토리 생성\n",
    "# os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# # fold_models 저장 (현재 메모리에 있다면 바로 실행 가능)\n",
    "# print(\"Saving fold models...\")\n",
    "# for i, state_dict in enumerate(fold_models):\n",
    "#     save_path = f'models/fold_{i+1}_best.pth'\n",
    "#     torch.save(state_dict, save_path)  # 그냥 직접 저장\n",
    "#     print(f\"✓ Fold {i+1} model saved to {save_path}\")\n",
    "\n",
    "# print(f\"All {len(fold_models)} fold models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 모델 저장 - 현재 상태 그대로 저장\n",
    "# def save_models():\n",
    "#     \"\"\"학습한 모델들을 저장\"\"\"\n",
    "    \n",
    "#     # 저장 디렉토리 생성\n",
    "#     save_dir = \"models\"\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "#     timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "#     print(\"🚨 모델 저장 시작...\")\n",
    "    \n",
    "#     # 각 fold별 모델 저장 (fold_models 리스트가 있다고 가정)\n",
    "#     try:\n",
    "#         for fold in range(5):  # 5-fold라고 가정\n",
    "#             model_path = f\"{save_dir}/fold_{fold}_model_{timestamp}.pth\"\n",
    "            \n",
    "#             # fold_models[fold]가 존재한다면 저장\n",
    "#             if 'fold_models' in globals() and len(fold_models) > fold:\n",
    "#                 torch.save({\n",
    "#                     'model_state_dict': fold_models[fold].state_dict(),\n",
    "#                     'fold': fold,\n",
    "#                     'timestamp': timestamp,\n",
    "#                     'epoch': 'unknown',  # 에포크 정보 모르면 unknown\n",
    "#                 }, model_path)\n",
    "#                 print(f\"✅ Fold {fold} 모델 저장 완료: {model_path}\")\n",
    "            \n",
    "#             # 또는 best_models 리스트가 있다면\n",
    "#             elif 'best_models' in globals() and len(best_models) > fold:\n",
    "#                 torch.save({\n",
    "#                     'model_state_dict': best_models[fold].state_dict(),\n",
    "#                     'fold': fold,\n",
    "#                     'timestamp': timestamp,\n",
    "#                     'epoch': 'unknown',\n",
    "#                 }, model_path)\n",
    "#                 print(f\"✅ Fold {fold} best 모델 저장 완료: {model_path}\")\n",
    "                \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ Fold별 저장 실패: {e}\")\n",
    "    \n",
    "#     # 전체 변수 상태 저장 (혹시 모르니까)\n",
    "#     try:\n",
    "#         state_path = f\"{save_dir}/full_state_{timestamp}.pth\"\n",
    "        \n",
    "#         # 현재 글로벌 변수에서 모델 관련 객체들 찾아서 저장\n",
    "#         save_dict = {}\n",
    "        \n",
    "#         # 가능한 모델 변수명들 체크\n",
    "#         possible_model_vars = ['model', 'models', 'fold_models', 'best_models', \n",
    "#                               'tta_models', 'ensemble_models']\n",
    "        \n",
    "#         for var_name in possible_model_vars:\n",
    "#             if var_name in globals():\n",
    "#                 save_dict[var_name] = globals()[var_name]\n",
    "#                 print(f\"✅ {var_name} 변수 포함됨\")\n",
    "        \n",
    "#         if save_dict:\n",
    "#             torch.save(save_dict, state_path)\n",
    "#             print(f\"✅ 전체 상태 저장 완료: {state_path}\")\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"❌ 전체 상태 저장 실패: {e}\")\n",
    "    \n",
    "#     print(f\"🎉 저장 완료! 저장 위치: {save_dir}/\")\n",
    "#     print(f\"📁 파일 목록:\")\n",
    "#     for file in os.listdir(save_dir):\n",
    "#         print(f\"   - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 오답 데이터 분석 및 시각화\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "# import numpy as np\n",
    "\n",
    "# def analyze_wrong_predictions(model, val_loader, device, num_samples=20):\n",
    "#     \"\"\"오답 데이터 분석 및 시각화\"\"\"\n",
    "#     model.eval()\n",
    "#     wrong_predictions = []\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, targets in val_loader:\n",
    "#             images, targets = images.to(device), targets.to(device)\n",
    "#             outputs = model(images)\n",
    "#             _, preds = torch.max(outputs, 1)\n",
    "            \n",
    "#             # 오답인 샘플들 찾기\n",
    "#             wrong_mask = (preds != targets)\n",
    "#             wrong_indices = torch.where(wrong_mask)[0]\n",
    "            \n",
    "#             for idx in wrong_indices:\n",
    "#                 wrong_predictions.append({\n",
    "#                     'image': images[idx].cpu(),\n",
    "#                     'true_class': targets[idx].cpu().item(),\n",
    "#                     'pred_class': preds[idx].cpu().item(),\n",
    "#                     'confidence': torch.softmax(outputs[idx], 0).max().cpu().item()\n",
    "#                 })\n",
    "                \n",
    "#                 if len(wrong_predictions) >= num_samples:\n",
    "#                     break\n",
    "            \n",
    "#             if len(wrong_predictions) >= num_samples:\n",
    "#                 break\n",
    "    \n",
    "#     return wrong_predictions\n",
    "\n",
    "# def visualize_wrong_predictions(wrong_predictions, class_names, rows=4, cols=5):\n",
    "#     \"\"\"오답 데이터 시각화\"\"\"\n",
    "#     fig, axes = plt.subplots(rows, cols, figsize=(20, 16))\n",
    "#     axes = axes.flatten()\n",
    "    \n",
    "#     for i, wrong_pred in enumerate(wrong_predictions[:rows*cols]):\n",
    "#         if i >= len(axes):\n",
    "#             break\n",
    "            \n",
    "#         # 이미지 전처리 (정규화 해제)\n",
    "#         img = wrong_pred['image'].permute(1, 2, 0)\n",
    "#         img = img * torch.tensor([0.229, 0.224, 0.225]) + torch.tensor([0.485, 0.456, 0.406])\n",
    "#         img = torch.clamp(img, 0, 1)\n",
    "        \n",
    "#         axes[i].imshow(img)\n",
    "#         axes[i].set_title(f\"True: {wrong_pred['true_class']} | \"\n",
    "#                          f\"Pred: {wrong_pred['pred_class']}\\n\"\n",
    "#                          f\"Conf: {wrong_pred['confidence']:.3f}\", \n",
    "#                          fontsize=10)\n",
    "#         axes[i].axis('off')\n",
    "    \n",
    "#     # 빈 subplot 제거\n",
    "#     for i in range(len(wrong_predictions), len(axes)):\n",
    "#         axes[i].remove()\n",
    "    \n",
    "#     plt.tight_layout()\n",
    "#     plt.savefig('wrong_predictions_analysis.png', dpi=300, bbox_inches='tight')\n",
    "#     plt.show()\n",
    "\n",
    "# def print_wrong_class_summary(wrong_predictions):\n",
    "#     \"\"\"오답 클래스 요약 출력\"\"\"\n",
    "#     from collections import Counter\n",
    "    \n",
    "#     true_classes = [wp['true_class'] for wp in wrong_predictions]\n",
    "#     pred_classes = [wp['pred_class'] for wp in wrong_predictions]\n",
    "    \n",
    "#     print(\"=== 오답 분석 요약 ===\")\n",
    "#     print(\"실제 클래스별 오답 빈도:\")\n",
    "#     true_counter = Counter(true_classes)\n",
    "#     for class_id, count in sorted(true_counter.items()):\n",
    "#         print(f\"  클래스 {class_id}: {count}개 오답\")\n",
    "    \n",
    "#     print(\"\\n예측 클래스별 오답 빈도:\")\n",
    "#     pred_counter = Counter(pred_classes)\n",
    "#     for class_id, count in sorted(pred_counter.items()):\n",
    "#         print(f\"  클래스 {class_id}로 오예측: {count}개\")\n",
    "    \n",
    "#     print(f\"\\n총 분석된 오답 수: {len(wrong_predictions)}개\")\n",
    "\n",
    "# # 실행 코드\n",
    "# print(\"오답 데이터 분석 시작...\")\n",
    "\n",
    "# # 현재 best 모델로 오답 분석 (Fold 1 기준)\n",
    "# wrong_preds = analyze_wrong_predictions(best_model, val_loader, device, num_samples=20)\n",
    "\n",
    "# # 오답 요약 출력\n",
    "# print_wrong_class_summary(wrong_preds)\n",
    "\n",
    "# # 오답 이미지 시각화\n",
    "# visualize_wrong_predictions(wrong_preds, class_names=None, rows=4, cols=5)\n",
    "\n",
    "# print(\"오답 분석 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🏁 K-FOLD ConvNeXt 강화 시스템 결과\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ACTIVE_MODELS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🏁 K-FOLD ConvNeXt 강화 시스템 결과\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_key \u001b[38;5;129;01min\u001b[39;00m \u001b[43mACTIVE_MODELS\u001b[49m:\n\u001b[1;32m     10\u001b[0m     val_f1_scores \u001b[38;5;241m=\u001b[39m [result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_val_f1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m all_fold_results[model_key]]\n\u001b[1;32m     11\u001b[0m     mean_f1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(val_f1_scores)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ACTIVE_MODELS' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🏁 K-FOLD 결과 상세 분석\n",
      "============================================================\n",
      "\n",
      "🤖 모델: convnext_base_384_in22ft1k\n",
      "📊 평균 CV F1: 0.9835 ± 0.0060\n",
      "🏆 최고 Fold: 0.9941\n",
      "📉 최악 Fold: 0.9766\n",
      "📏 성능 범위: 0.0176\n",
      "\n",
      "📋 Fold별 상세 결과:\n",
      "📁 Fold   🎯 Val F1   📈 Train F1  👥 Train  ✅ Val  \n",
      "──────────────────────────────────────────────────\n",
      "   1        0.9766      0.8897       1256      314  \n",
      "   2        0.9839      0.8874       1256      314  \n",
      "   3        0.9941      0.8542       1256      314  \n",
      "   4        0.9838      0.9039       1256      314  \n",
      "   5        0.9793      0.8910       1256      314  \n",
      "\n",
      "🏅 성능 순위:\n",
      "🥇 1위: Fold 3 - F1: 0.9941\n",
      "🥈 2위: Fold 2 - F1: 0.9839\n",
      "🥉 3위: Fold 4 - F1: 0.9838\n",
      "🏅 4위: Fold 5 - F1: 0.9793\n",
      "🏅 5위: Fold 1 - F1: 0.9766\n",
      "\n",
      "🎯 클래스별 성능 분석:\n",
      "📊 Class   📈 평균     📏 표준편차    🏆 최고    📉 최악   \n",
      "─────────────────────────────────────────────\n",
      "   0        1.000     0.000      1.000    1.000\n",
      "   1        1.000     0.000      1.000    1.000\n",
      "   2        1.000     0.000      1.000    1.000\n",
      "   3        0.870     0.068      0.950    0.750\n",
      "   4        0.950     0.055      1.000    0.850\n",
      "   5        1.000     0.000      1.000    1.000\n",
      "   6        0.990     0.020      1.000    0.950\n",
      "   7        0.930     0.040      1.000    0.900\n",
      "   8        1.000     0.000      1.000    1.000\n",
      "   9        1.000     0.000      1.000    1.000\n",
      "   10       0.990     0.020      1.000    0.950\n",
      "   11       0.980     0.024      1.000    0.950\n",
      "   12       1.000     0.000      1.000    1.000\n",
      "   13       1.000     0.000      1.000    1.000\n",
      "   14       0.840     0.080      0.900    0.700\n",
      "   15       1.000     0.000      1.000    1.000\n",
      "   16       1.000     0.000      1.000    1.000\n",
      "\n",
      "🔴 가장 어려운 클래스 TOP 3:\n",
      "   1. Class 14: 0.840 정확도\n",
      "   2. Class 3: 0.870 정확도\n",
      "   3. Class 7: 0.930 정확도\n",
      "\n",
      "🟢 가장 쉬운 클래스 TOP 3:\n",
      "   1. Class 0: 1.000 정확도\n",
      "   2. Class 1: 1.000 정확도\n",
      "   3. Class 2: 1.000 정확도\n",
      "\n",
      "⚖️ 성능 일관성 분석:\n",
      "📊 변동계수 (CV): 0.006\n",
      "🟢 매우 일관적인 성능\n",
      "\n",
      "📈 학습 상태 분석:\n",
      "🎯 과적합 의심 Fold: 0/5개\n",
      "\n",
      "✅ 학습 완료! 총 5개 fold 모델 저장됨\n",
      "📁 저장된 모델 파일:\n",
      "   📄 BH_512_base_best_model_fold_1.pth\n",
      "   📄 BH_512_base_best_model_fold_2.pth\n",
      "   📄 BH_512_base_best_model_fold_3.pth\n",
      "   📄 BH_512_base_best_model_fold_4.pth\n",
      "   📄 BH_512_base_best_model_fold_5.pth\n",
      "\n",
      "🎉 K-Fold Cross Validation 분석 완료!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 📊 K-Fold 결과 분석 (단일 모델 버전)\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"🏁 K-FOLD 결과 상세 분석\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# 전체 성능 요약\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "print(f\"\\n🤖 모델: {model_name}\")\n",
    "print(f\"📊 평균 CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"🏆 최고 Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\"📉 최악 Fold: {min(val_f1_scores):.4f}\")\n",
    "print(f\"📏 성능 범위: {max(val_f1_scores) - min(val_f1_scores):.4f}\")\n",
    "\n",
    "# Fold별 상세 성능\n",
    "print(f\"\\n📋 Fold별 상세 결과:\")\n",
    "print(f\"{'📁 Fold':<8} {'🎯 Val F1':<10} {'📈 Train F1':<11} {'👥 Train':<8} {'✅ Val':<7}\")\n",
    "print(\"─\" * 50)\n",
    "\n",
    "for result in fold_results:\n",
    "   print(f\"   {result['fold']:<5} \"\n",
    "         f\"   {result['best_val_f1']:<8.4f} \"\n",
    "         f\"   {result['final_train_f1']:<9.4f} \"\n",
    "         f\"   {result['train_samples']:<6} \"\n",
    "         f\"   {result['val_samples']:<5}\")\n",
    "\n",
    "# 성능 순위\n",
    "sorted_results = sorted(fold_results, key=lambda x: x['best_val_f1'], reverse=True)\n",
    "print(f\"\\n🏅 성능 순위:\")\n",
    "medals = [\"🥇\", \"🥈\", \"🥉\", \"🏅\", \"🏅\"]\n",
    "for i, result in enumerate(sorted_results):\n",
    "   medal = medals[i] if i < len(medals) else \"📍\"\n",
    "   print(f\"{medal} {i+1}위: Fold {result['fold']} - F1: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "# 클래스별 성능 분석\n",
    "if fold_class_accuracies:\n",
    "   print(f\"\\n🎯 클래스별 성능 분석:\")\n",
    "   print(f\"{'📊 Class':<9} {'📈 평균':<8} {'📏 표준편차':<9} {'🏆 최고':<7} {'📉 최악':<7}\")\n",
    "   print(\"─\" * 45)\n",
    "   \n",
    "   class_performance = []\n",
    "   for class_id in range(17):\n",
    "       class_accs = []\n",
    "       for fold_acc in fold_class_accuracies:\n",
    "           if class_id in fold_acc:\n",
    "               class_accs.append(fold_acc[class_id])\n",
    "       \n",
    "       if class_accs:\n",
    "           mean_acc = np.mean(class_accs)\n",
    "           std_acc = np.std(class_accs)\n",
    "           max_acc = max(class_accs)\n",
    "           min_acc = min(class_accs)\n",
    "           \n",
    "           class_performance.append({\n",
    "               'class_id': class_id,\n",
    "               'mean_acc': mean_acc,\n",
    "               'std_acc': std_acc,\n",
    "               'max_acc': max_acc,\n",
    "               'min_acc': min_acc\n",
    "           })\n",
    "           \n",
    "           print(f\"   {class_id:<5} \"\n",
    "                 f\"   {mean_acc:<6.3f} \"\n",
    "                 f\"   {std_acc:<7.3f} \"\n",
    "                 f\"   {max_acc:<5.3f} \"\n",
    "                 f\"   {min_acc:<5.3f}\")\n",
    "   \n",
    "   # 어려운 클래스 TOP 3\n",
    "   worst_classes = sorted(class_performance, key=lambda x: x['mean_acc'])[:3]\n",
    "   print(f\"\\n🔴 가장 어려운 클래스 TOP 3:\")\n",
    "   for i, cls in enumerate(worst_classes, 1):\n",
    "       print(f\"   {i}. Class {cls['class_id']}: {cls['mean_acc']:.3f} 정확도\")\n",
    "   \n",
    "   # 쉬운 클래스 TOP 3\n",
    "   best_classes = sorted(class_performance, key=lambda x: x['mean_acc'], reverse=True)[:3]\n",
    "   print(f\"\\n🟢 가장 쉬운 클래스 TOP 3:\")\n",
    "   for i, cls in enumerate(best_classes, 1):\n",
    "       print(f\"   {i}. Class {cls['class_id']}: {cls['mean_acc']:.3f} 정확도\")\n",
    "\n",
    "# 성능 일관성 분석\n",
    "cv_coefficient = std_f1 / mean_f1 if mean_f1 > 0 else 0\n",
    "print(f\"\\n⚖️ 성능 일관성 분석:\")\n",
    "print(f\"📊 변동계수 (CV): {cv_coefficient:.3f}\")\n",
    "\n",
    "if cv_coefficient < 0.05:\n",
    "   consistency_emoji = \"🟢\"\n",
    "   consistency_text = \"매우 일관적인 성능\"\n",
    "elif cv_coefficient < 0.1:\n",
    "   consistency_emoji = \"🔵\"\n",
    "   consistency_text = \"일관적인 성능\"\n",
    "elif cv_coefficient < 0.15:\n",
    "   consistency_emoji = \"🟡\"\n",
    "   consistency_text = \"보통 수준의 일관성\"\n",
    "else:\n",
    "   consistency_emoji = \"🔴\"\n",
    "   consistency_text = \"성능 변동이 큼\"\n",
    "\n",
    "print(f\"{consistency_emoji} {consistency_text}\")\n",
    "\n",
    "# 추가 통계\n",
    "overfit_count = sum(1 for result in fold_results \n",
    "                  if result['final_train_f1'] - result['best_val_f1'] > 0.05)\n",
    "\n",
    "print(f\"\\n📈 학습 상태 분석:\")\n",
    "print(f\"🎯 과적합 의심 Fold: {overfit_count}/{len(fold_results)}개\")\n",
    "if overfit_count > 0:\n",
    "   print(f\"   💡 Train-Val F1 차이가 0.05 이상인 fold 수\")\n",
    "\n",
    "print(f\"\\n✅ 학습 완료! 총 {len(fold_results)}개 fold 모델 저장됨\")\n",
    "print(f\"📁 저장된 모델 파일:\")\n",
    "for i, result in enumerate(fold_results, 1):\n",
    "   print(f\"   📄 {result['model_path']}\")\n",
    "\n",
    "print(f\"\\n🎉 K-Fold Cross Validation 분석 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ensemble of all 5 fold models for inference\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "print(f\"Using ensemble of all {len(ensemble_models)} fold models for inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling 클래스 정의\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_tta_transforms = [\n",
    "    # 원본\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 추론을 위한 Dataset 클래스\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # 여러 transform을 리스트로 받음\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # 모든 transform을 적용한 결과를 리스트로 반환\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA Dataset size: 3140\n"
     ]
    }
   ],
   "source": [
    "# TTA Dataset 생성\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"/root/home/cv_contest/CV_data/sample_submission.csv\",\n",
    "    \"/root/home/cv_contest/CV_data/test\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (배치 크기를 줄여서 메모리 절약)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=16,  # TTA는 메모리를 많이 사용하므로 배치 크기 줄임\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_tta_inference(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold 모델 앙상블 + TTA 추론\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # 각 fold 모델별 예측\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # 각 TTA 변형별 예측\n",
    "                for images in images_list:\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ensemble TTA inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 197/197 [17:24<00:00,  5.30s/it]\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 TTA 실행\n",
    "print(\"Starting Ensemble TTA inference...\")\n",
    "tta_predictions = ensemble_tta_inference(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 결과로 submission 파일 생성\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 submission과 동일한 순서인지 확인\n",
    "sample_submission_df = pd.read_csv(\"/root/home/cv_contest/CV_data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA predictions saved\n",
      "TTA Prediction sample:\n"
     ]
    }
   ],
   "source": [
    "# TTA 결과 저장\n",
    "tta_pred_df.to_csv(\"/root/home/cv_contest/results/BH_512_base_TTA.csv\", index=False)\n",
    "print(\"TTA predictions saved\")\n",
    "\n",
    "print(\"TTA Prediction sample:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
