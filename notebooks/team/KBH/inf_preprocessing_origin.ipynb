{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n",
    "* 필요한 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# # 필요한 라이브러리를 설치합니다.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna\n",
    "# !apt install -y libgl1-mesa-glx\n",
    "# !pip install albumentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precision용\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# 한글 폰트 설정 (시각화용)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'tf_efficientnetv2_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "# model_name = 'swin_base_patch4_window12_384_in22k'\n",
    "model_name = 'convnext_large_384_in22ft1k'\n",
    "# model_name = 'convnextv2_base.fcmae_ft_in22k_in1k_384'\n",
    "# model_name = 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k' # openclip\n",
    "# model_name = 'vit_base_patch16_384.augreg_in1k' # augreg\n",
    "# model_name = 'eva02_enormous_patch14_plus_clip_224.laion2b_s9b_b144k' # eva-02 멀티모달\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 테스트용\n",
    "# model_name = 'vit_base_patch14_reg4_dinov2.lvd142m' # dinov2 reg4\n",
    "\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 테스트용\n",
    "\n",
    "# training config\n",
    "img_size = 512\n",
    "LR = 2e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 16\n",
    "num_workers = 8\n",
    "EMA = True  # Exponential Moving Average 사용 여부"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold 적용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fold 1 model loaded from models/fold_1_best.pth\n",
      "✓ Fold 2 model loaded from models/fold_2_best.pth\n",
      "✓ Fold 3 model loaded from models/fold_3_best.pth\n",
      "✓ Fold 4 model loaded from models/fold_4_best.pth\n",
      "✓ Fold 5 model loaded from models/fold_5_best.pth\n",
      "Using ensemble of all 5 fold models for inference\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "for i in range(5):  # fold 개수만큼\n",
    "    fold_model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)  # pretrained=False로 변경\n",
    "    \n",
    "    # fold별 저장된 파일 로드\n",
    "    checkpoint = torch.load(f'models/fold_{i+1}_best.pth')  # fold별 파일 경로\n",
    "    fold_model.load_state_dict(checkpoint)\n",
    "    fold_model.eval()\n",
    "    \n",
    "    ensemble_models.append(fold_model)\n",
    "    print(f\"✓ Fold {i+1} model loaded from models/fold_{i+1}_best.pth\")\n",
    "\n",
    "print(f\"Using ensemble of all {len(ensemble_models)} fold models for inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling 클래스 정의\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 함수 추가 완료!\n"
     ]
    }
   ],
   "source": [
    "def get_classification_confidence(image_path, model):\n",
    "    \"\"\"분류 모델 신뢰도 기반 품질 측정\"\"\"\n",
    "    try:\n",
    "        # 이미지 로드 및 전처리\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return 0.0\n",
    "        \n",
    "        # RGB 변환\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # 모델 입력용 transform 적용\n",
    "        transform = A.Compose([\n",
    "            A.LongestMaxSize(max_size=512),\n",
    "            A.PadIfNeeded(min_height=512, min_width=512, border_mode=0, value=0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # 이미지 전처리 및 배치 차원 추가\n",
    "        processed = transform(image=img_rgb)['image'].unsqueeze(0).to(device)\n",
    "        \n",
    "        # 모델 예측 (첫 번째 앙상블 모델 사용)\n",
    "        with torch.no_grad():\n",
    "            logits = ensemble_models[0](processed)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            confidence = torch.max(probs).item()\n",
    "        \n",
    "        return confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"신뢰도 측정 실패 ({image_path}): {e}\")\n",
    "        return 0.0\n",
    "\n",
    "# 문서 특화 적응형 전처리 함수\n",
    "def adaptive_preprocessing(image_path, quality_threshold=0.99):\n",
    "    \"\"\"문서 이미지 전문가 워크플로우 기반 전처리\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return None, 0.0, 0.0\n",
    "        \n",
    "        # 분류 신뢰도 기반 품질 측정\n",
    "        original_confidence = get_classification_confidence(image_path, ensemble_models[0])\n",
    "        \n",
    "        # 신뢰도가 높으면 전처리 스킵\n",
    "        if original_confidence > quality_threshold:\n",
    "        # if False: # 모든 이미지에 대해 전처리 시도\n",
    "            return img, original_confidence, original_confidence\n",
    "        \n",
    "        # 1) 품질 진단\n",
    "        processed_img = img.copy()\n",
    "        gray = cv2.cvtColor(processed_img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        g_std = gray.std()  # 대비\n",
    "        lap_var = cv2.Laplacian(gray, cv2.CV_64F).var()  # 블러\n",
    "        mean_bright = gray.mean()  # 밝기\n",
    "        \n",
    "        # 스큐 각도 측정\n",
    "        edges = cv2.Canny(gray, 50, 150)\n",
    "        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)\n",
    "        skew_angle = 0\n",
    "        if lines is not None and len(lines) > 5:\n",
    "            angles = []\n",
    "            for line in lines[:20]:\n",
    "                if len(line[0]) >= 2:\n",
    "                    rho, theta = line[0]\n",
    "                    angle = theta * 180 / np.pi - 90\n",
    "                    if abs(angle) < 45:\n",
    "                        angles.append(angle)\n",
    "            if angles:\n",
    "                skew_angle = abs(np.median(angles))\n",
    "        \n",
    "        # 2) 라우팅 결정\n",
    "        needs_deskew = skew_angle >= 8\n",
    "        low_contrast = g_std < 35\n",
    "        is_blurry = 50 <= lap_var < 150\n",
    "        very_blurry = lap_var < 50\n",
    "        too_bright = mean_bright > 180\n",
    "        has_noise = lap_var < 100\n",
    "        \n",
    "        # 3) 프리셋 선택\n",
    "        if very_blurry and too_bright and has_noise:\n",
    "            preset = \"HEAVY\"\n",
    "        elif needs_deskew or skew_angle >= 5:\n",
    "            preset = \"MEDIUM\"  \n",
    "        else:\n",
    "            preset = \"LIGHT\"\n",
    "        \n",
    "        # 4) 전처리 적용\n",
    "        \n",
    "        # 단계 0: 플립 감지 및 보정\n",
    "        flipped = cv2.flip(processed_img, 1)\n",
    "        gray_current = cv2.cvtColor(processed_img, cv2.COLOR_BGR2GRAY)\n",
    "        gray_flipped = cv2.cvtColor(flipped, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        def get_text_density(image):\n",
    "            binary = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "                                         cv2.THRESH_BINARY, 15, 10)\n",
    "            return np.sum(binary == 0) / binary.size\n",
    "        \n",
    "        original_density = get_text_density(gray_current)\n",
    "        flipped_density = get_text_density(gray_flipped)\n",
    "        \n",
    "        if flipped_density > original_density * 1.1:\n",
    "            processed_img = flipped\n",
    "        \n",
    "        # 단계 1: Deskew (필요시)\n",
    "        if needs_deskew and preset in [\"MEDIUM\", \"HEAVY\"]:\n",
    "            h, w = processed_img.shape[:2]\n",
    "            center = (w//2, h//2)\n",
    "            \n",
    "            valid_angles = []\n",
    "            if lines is not None:\n",
    "                for line in lines[:10]:\n",
    "                    if len(line[0]) >= 2:\n",
    "                        rho, theta = line[0]\n",
    "                        angle = theta * 180 / np.pi - 90\n",
    "                        if abs(angle) < 15:\n",
    "                            valid_angles.append(angle)\n",
    "            \n",
    "            if len(valid_angles) > 0:\n",
    "                rotation_angle = np.median(valid_angles)\n",
    "                if abs(rotation_angle) >= 3:\n",
    "                    M = cv2.getRotationMatrix2D(center, rotation_angle, 1.0)\n",
    "                    processed_img = cv2.warpAffine(processed_img, M, (w, h), \n",
    "                                                 borderMode=cv2.BORDER_CONSTANT, \n",
    "                                                 borderValue=(255, 255, 255))\n",
    "        \n",
    "        # 단계 2: 밝기 조정 (HEAVY만)\n",
    "        if too_bright and preset == \"HEAVY\":\n",
    "            processed_img = np.power(processed_img/255.0, 0.92) * 255\n",
    "            processed_img = processed_img.astype(np.uint8)\n",
    "        \n",
    "        # 단계 3: NLM 노이즈 제거 (HEAVY만)\n",
    "        if has_noise and preset == \"HEAVY\":\n",
    "            processed_img = cv2.fastNlMeansDenoisingColored(processed_img, None, 3, 3, 7, 21)\n",
    "        \n",
    "        # 단계 4: CLAHE (저대비인 경우)\n",
    "        if low_contrast:\n",
    "            lab = cv2.cvtColor(processed_img, cv2.COLOR_BGR2LAB)\n",
    "            l_channel = lab[:, :, 0]\n",
    "            clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "            l_channel = clahe.apply(l_channel)\n",
    "            lab[:, :, 0] = l_channel\n",
    "            processed_img = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "        \n",
    "        # 단계 5: Unsharp (블러인 경우)\n",
    "        if is_blurry or very_blurry:\n",
    "            gray = cv2.cvtColor(processed_img, cv2.COLOR_BGR2GRAY)\n",
    "            gaussian = cv2.GaussianBlur(gray, (0, 0), 1.0)\n",
    "            unsharp = cv2.addWeighted(gray, 1.4, gaussian, -0.4, 0)\n",
    "            unsharp = np.clip(unsharp, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            hsv = cv2.cvtColor(processed_img, cv2.COLOR_BGR2HSV)\n",
    "            hsv[:, :, 2] = unsharp\n",
    "            processed_img = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "        \n",
    "        # 품질 검사\n",
    "        temp_path = image_path.replace('.jpg', '_temp_processed.jpg')\n",
    "        cv2.imwrite(temp_path, processed_img)\n",
    "        processed_confidence = get_classification_confidence(temp_path, ensemble_models[0])\n",
    "        os.remove(temp_path)\n",
    "\n",
    "        if processed_confidence < original_confidence * 0.8:\n",
    "            return img, original_confidence, original_confidence\n",
    "\n",
    "        return processed_img, original_confidence, processed_confidence\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"전처리 실패 ({image_path}): {e}\")\n",
    "        img = cv2.imread(image_path)\n",
    "        original_confidence = 0.5 if img is not None else 0.0\n",
    "        return img, original_confidence, original_confidence\n",
    "\n",
    "def assess_image_quality(image_path):\n",
    "    \"\"\"이미지 품질을 0-1 점수로 평가\"\"\"\n",
    "    try:\n",
    "        img = cv2.imread(image_path)\n",
    "        if img is None:\n",
    "            return 0.0\n",
    "            \n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # 블러 측정\n",
    "        blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "        blur_normalized = min(blur_score / 1000.0, 1.0)\n",
    "        \n",
    "        # 대비 측정\n",
    "        contrast_score = gray.std()\n",
    "        contrast_normalized = min(contrast_score / 80.0, 1.0)\n",
    "        \n",
    "        # 밝기 분포 측정\n",
    "        hist = cv2.calcHist([gray], [0], None, [256], [0, 256])\n",
    "        hist = hist.flatten()\n",
    "        hist = hist[hist > 0]\n",
    "        if len(hist) > 1:\n",
    "            prob = hist / hist.sum()\n",
    "            brightness_score = -np.sum(prob * np.log2(prob + 1e-8))\n",
    "            brightness_normalized = brightness_score / 8.0\n",
    "        else:\n",
    "            brightness_normalized = 0.0\n",
    "            \n",
    "        quality_score = (\n",
    "            0.5 * blur_normalized +\n",
    "            0.3 * contrast_normalized +\n",
    "            0.2 * brightness_normalized\n",
    "        )\n",
    "        \n",
    "        return min(quality_score, 1.0)\n",
    "        \n",
    "    except Exception as e:\n",
    "        return 0.0\n",
    "\n",
    "print(\"전처리 함수 추가 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_tta_transforms = [\n",
    "    # 원본\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 추론을 위한 Dataset 클래스\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # 여러 transform을 리스트로 받음\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        #img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "\n",
    "        # 적응형 전처리 적용 (오염도 높은 이미지만 자동 선별)\n",
    "        processed_img, original_confidence, processed_confidence = adaptive_preprocessing(img_path)\n",
    "\n",
    "        # 전처리 적용 여부 판단\n",
    "        preprocessing_applied = abs(processed_confidence - original_confidence) > 0.001\n",
    "\n",
    "        # 통계 수집\n",
    "        collect_preprocessing_stats(original_confidence, processed_confidence, preprocessing_applied)\n",
    "        \n",
    "        if processed_img is not None:\n",
    "            # OpenCV BGR을 RGB로 변환\n",
    "            img = cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            # 전처리 실패 시 원본 사용\n",
    "            img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # 모든 transform을 적용한 결과를 리스트로 반환\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA Dataset size: 3140\n"
     ]
    }
   ],
   "source": [
    "# TTA Dataset 생성\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (배치 크기를 줄여서 메모리 절약)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=64,  # TTA는 메모리를 많이 사용하므로 배치 크기 줄임\n",
    "    shuffle=False,\n",
    "    # num_workers=num_workers,\n",
    "    num_workers=0,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 제출용\n",
    "def ensemble_tta_inference(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold 모델 앙상블 + TTA 추론\"\"\"\n",
    "    temp_scaling = TemperatureScaling().to(device)  # Temperature Scaling 추가\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        \n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "                \n",
    "        # 각 fold 모델별 예측\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # 각 TTA 변형별 예측\n",
    "                for images in images_list:\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    \n",
    "                    # Temperature Scaling 적용\n",
    "                    scaled_preds = temp_scaling(preds)\n",
    "                    probs = torch.softmax(scaled_preds, dim=1)\n",
    "                    \n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실험용 단일 추론 함수 추가 완료!\n"
     ]
    }
   ],
   "source": [
    "# 실험용: 단일 모델 TTA 추론 (5배 빠름)\n",
    "def single_model_tta_inference(model, loader, transforms):\n",
    "    \"\"\"단일 모델 TTA 추론 - 실험용\"\"\"\n",
    "    temp_scaling = TemperatureScaling().to(device)\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Single TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        tta_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # 단일 모델로 TTA\n",
    "        with torch.no_grad():\n",
    "            for images in images_list:\n",
    "                images = images.to(device)\n",
    "                preds = model(images)\n",
    "                \n",
    "                # Temperature Scaling 적용\n",
    "                scaled_preds = temp_scaling(preds)\n",
    "                probs = torch.softmax(scaled_preds, dim=1)\n",
    "                \n",
    "                tta_probs += probs / len(images_list)\n",
    "        \n",
    "        final_preds = torch.argmax(tta_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions\n",
    "\n",
    "print(\"실험용 단일 추론 함수 추가 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 통계 수집용 글로벌 변수 초기화\n",
    "preprocessing_stats = {\n",
    "    'total_images': 0,\n",
    "    'preprocessing_applied': 0,\n",
    "    'preprocessing_skipped': 0,\n",
    "    'quality_improvements': [],\n",
    "    'quality_degradations': []\n",
    "}\n",
    "\n",
    "def collect_preprocessing_stats(original_confidence, processed_confidence, applied):\n",
    "    \"\"\"전처리 통계 수집\"\"\"\n",
    "    global preprocessing_stats\n",
    "    preprocessing_stats['total_images'] += 1\n",
    "    \n",
    "    # 디버깅용 출력 (첫 5개만)\n",
    "    if preprocessing_stats['total_images'] <= 5:\n",
    "        print(f\"Debug: 이미지 {preprocessing_stats['total_images']} 처리됨, 적용: {applied}\")\n",
    "    \n",
    "    if applied:\n",
    "        preprocessing_stats['preprocessing_applied'] += 1\n",
    "        quality_change = processed_confidence - original_confidence\n",
    "        if quality_change > 0:\n",
    "            preprocessing_stats['quality_improvements'].append(quality_change)\n",
    "        else:\n",
    "            preprocessing_stats['quality_degradations'].append(quality_change)\n",
    "    else:\n",
    "        preprocessing_stats['preprocessing_skipped'] += 1\n",
    "\n",
    "def print_preprocessing_stats():\n",
    "    \"\"\"전처리 통계 출력\"\"\"\n",
    "    stats = preprocessing_stats\n",
    "    total = stats['total_images']\n",
    "    applied = stats['preprocessing_applied']\n",
    "    skipped = stats['preprocessing_skipped']\n",
    "    \n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"전처리 통계 분석\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"총 이미지 수: {total}개\")\n",
    "    \n",
    "    # ZeroDivisionError 방지\n",
    "    if total > 0:\n",
    "        print(f\"전처리 적용: {applied}개 ({applied/total*100:.1f}%)\")\n",
    "        print(f\"전처리 스킵: {skipped}개 ({skipped/total*100:.1f}%)\")\n",
    "    else:\n",
    "        print(\"전처리 적용: 0개 (0.0%)\")\n",
    "        print(\"전처리 스킵: 0개 (0.0%)\")\n",
    "        print(\"⚠️ 통계 수집이 작동하지 않았습니다.\")\n",
    "        return\n",
    "    \n",
    "    if stats['quality_improvements']:\n",
    "        avg_improvement = np.mean(stats['quality_improvements'])\n",
    "        print(f\"품질 개선 평균: +{avg_improvement:.3f}\")\n",
    "        print(f\"품질 개선 건수: {len(stats['quality_improvements'])}개\")\n",
    "    \n",
    "    if stats['quality_degradations']:\n",
    "        avg_degradation = np.mean(stats['quality_degradations'])\n",
    "        print(f\"품질 악화 평균: {avg_degradation:.3f}\")\n",
    "        print(f\"품질 악화 건수: {len(stats['quality_degradations'])}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 기반 F1 비교 함수 수정 완료!\n"
     ]
    }
   ],
   "source": [
    "# GT 기반 전처리 효과 검증 함수 - 수정 버전\n",
    "class CleanTTAImageDataset(Dataset):\n",
    "    \"\"\"전처리 없는 순수한 TTA Dataset\"\"\"\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img_path = os.path.join(self.path, name)\n",
    "        \n",
    "        # 전처리 없이 원본 이미지만 로드\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        # 모든 transform을 적용한 결과를 리스트로 반환\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target\n",
    "\n",
    "def evaluate_preprocessing_effect():\n",
    "    \"\"\"selected_images_500.csv GT로 전처리 전후 F1 스코어 비교 - 수정 버전\"\"\"\n",
    "    \n",
    "    global preprocessing_stats\n",
    "    preprocessing_stats = {\n",
    "        'total_images': 0,\n",
    "        'preprocessing_applied': 0,\n",
    "        'preprocessing_skipped': 0,\n",
    "        'quality_improvements': [],\n",
    "        'quality_degradations': []\n",
    "    }\n",
    "    \n",
    "    # GT 파일 로드\n",
    "    gt_file = \"../data/selected_images_500.csv\"\n",
    "    try:\n",
    "        gt_df = pd.read_csv(gt_file)\n",
    "        gt_df = gt_df.rename(columns={'predicted_class': 'true_label'})\n",
    "        print(f\"GT 데이터 로드 완료: {len(gt_df)}개 이미지\")\n",
    "    except:\n",
    "        print(\"selected_images_500.csv 파일을 찾을 수 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 라벨링된 데이터만 필터링\n",
    "    if 'true_label' in gt_df.columns:\n",
    "        labeled_df = gt_df.dropna(subset=['true_label'])\n",
    "        print(f\"라벨링된 데이터: {len(labeled_df)}개\")\n",
    "    else:\n",
    "        print(\"true_label 컬럼이 없습니다. GT 파일 형식을 확인하세요.\")\n",
    "        return\n",
    "    \n",
    "    gt_files = labeled_df['filename'].tolist()\n",
    "    gt_labels = labeled_df['true_label'].astype(int).tolist()\n",
    "    \n",
    "    # 1) 전처리 OFF 추론 (CleanTTAImageDataset 사용)\n",
    "    print(\"\\n1단계: 전처리 없는 추론 (CleanTTAImageDataset)...\")\n",
    "    clean_dataset = CleanTTAImageDataset(\n",
    "        labeled_df[['filename', 'true_label']].rename(columns={'true_label': 'target'}),\n",
    "        \"../data/test/\",\n",
    "        essential_tta_transforms\n",
    "    )\n",
    "    \n",
    "    # clean_loader = DataLoader(clean_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    clean_loader = DataLoader(clean_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    \n",
    "    single_model = ensemble_models[0]\n",
    "    clean_preds = single_model_tta_inference(single_model, clean_loader, essential_tta_transforms)\n",
    "    \n",
    "    # 2) 전처리 ON 추론 (기존 TTAImageDataset 사용)  \n",
    "    print(\"2단계: 전처리 적용된 추론 (TTAImageDataset)...\")\n",
    "    preprocessed_dataset = TTAImageDataset(\n",
    "        labeled_df[['filename', 'true_label']].rename(columns={'true_label': 'target'}),\n",
    "        \"../data/test/\",\n",
    "        essential_tta_transforms\n",
    "    )\n",
    "    \n",
    "    # preprocessed_loader = DataLoader(preprocessed_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    preprocessed_loader = DataLoader(preprocessed_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    preprocessed_preds = single_model_tta_inference(single_model, preprocessed_loader, essential_tta_transforms)\n",
    "    \n",
    "    # 3) F1 스코어 계산\n",
    "    from sklearn.metrics import f1_score, classification_report\n",
    "    \n",
    "    f1_clean = f1_score(gt_labels, clean_preds, average='macro')\n",
    "    f1_preprocessed = f1_score(gt_labels, preprocessed_preds, average='macro')\n",
    "    f1_improvement = f1_preprocessed - f1_clean\n",
    "    \n",
    "    # 4) 결과 출력\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"전처리 효과 검증 결과 (수정 버전)\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"GT 데이터 수: {len(gt_labels)}개\")\n",
    "    print(f\"전처리 전 F1 (Clean): {f1_clean:.4f}\")\n",
    "    print(f\"전처리 후 F1 (Processed): {f1_preprocessed:.4f}\")\n",
    "    print(f\"F1 개선: {f1_improvement:+.4f} ({f1_improvement/f1_clean*100:+.1f}%)\")\n",
    "    \n",
    "    if f1_improvement > 0.01:\n",
    "        print(\"✅ 전처리 효과 확인! 제출용 앙상블 모드 실행 권장\")\n",
    "    elif f1_improvement > 0.005:\n",
    "        print(\"📊 미미한 개선. 추가 검토 필요\")\n",
    "    else:\n",
    "        print(\"❌ 전처리 효과 미미. 설정 재검토 필요\")\n",
    "    \n",
    "    # 5) 상세 분석\n",
    "    unique_labels = sorted(set(gt_labels) | set(clean_preds) | set(preprocessed_preds))\n",
    "    target_names = [f\"Class_{i}\" for i in unique_labels]\n",
    "\n",
    "    print(\"\\n전처리 전 (Clean Dataset):\")\n",
    "    print(classification_report(gt_labels, clean_preds, labels=unique_labels, target_names=target_names, digits=3))\n",
    "    print(\"\\n전처리 후 (Preprocessed Dataset):\")\n",
    "    print(classification_report(gt_labels, preprocessed_preds, labels=unique_labels, target_names=target_names, digits=3))\n",
    "    \n",
    "    # 전처리 통계 출력\n",
    "    print_preprocessing_stats()\n",
    "    \n",
    "    return {\n",
    "        'f1_clean': f1_clean,\n",
    "        'f1_preprocessed': f1_preprocessed, \n",
    "        'improvement': f1_improvement,\n",
    "        'gt_count': len(gt_labels)\n",
    "    }\n",
    "\n",
    "print(\"GT 기반 F1 비교 함수 수정 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# 실험 모드 설정 (실험용 vs 제출용)\n",
    "# ===========================================\n",
    "EXPERIMENT_MODE = True  # True: 단일모델, False: 5-fold 앙상블\n",
    "\n",
    "if EXPERIMENT_MODE:\n",
    "    print(\"🧪 실험 모드: 단일 모델 TTA 추론 (빠름)\")\n",
    "    # 첫 번째 모델만 사용\n",
    "    single_model = ensemble_models[0]\n",
    "    tta_predictions = single_model_tta_inference(\n",
    "        model=single_model,\n",
    "        loader=tta_loader, \n",
    "        transforms=essential_tta_transforms\n",
    "    )\n",
    "else:\n",
    "    print(\"🚀 제출 모드: 5-Fold 앙상블 TTA 추론 (정확함)\")\n",
    "    tta_predictions = ensemble_tta_inference(\n",
    "        models=ensemble_models, \n",
    "        loader=tta_loader, \n",
    "        transforms=essential_tta_transforms,\n",
    "        confidence_threshold=0.9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT 데이터 로드 완료: 500개 이미지\n",
      "라벨링된 데이터: 500개\n",
      "\n",
      "1단계: 전처리 없는 추론 (CleanTTAImageDataset)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Single TTA: 100%|██████████| 16/16 [01:15<00:00,  4.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2단계: 전처리 적용된 추론 (TTAImageDataset)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Single TTA:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug: 이미지 1 처리됨, 적용: True\n",
      "Debug: 이미지 2 처리됨, 적용: True\n",
      "Debug: 이미지 3 처리됨, 적용: False\n",
      "Debug: 이미지 4 처리됨, 적용: True\n",
      "Debug: 이미지 5 처리됨, 적용: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Single TTA: 100%|██████████| 16/16 [01:55<00:00,  7.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "전처리 효과 검증 결과 (수정 버전)\n",
      "==================================================\n",
      "GT 데이터 수: 500개\n",
      "전처리 전 F1 (Clean): 0.6796\n",
      "전처리 후 F1 (Processed): 0.5458\n",
      "F1 개선: -0.1338 (-19.7%)\n",
      "❌ 전처리 효과 미미. 설정 재검토 필요\n",
      "\n",
      "전처리 전 (Clean Dataset):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class_3      0.686     0.901     0.779       121\n",
      "     Class_4      0.985     0.832     0.902       161\n",
      "     Class_7      0.838     0.763     0.799       169\n",
      "    Class_10      0.000     0.000     0.000         0\n",
      "    Class_13      0.000     0.000     0.000         0\n",
      "    Class_14      0.918     0.918     0.918        49\n",
      "\n",
      "   micro avg      0.834     0.834     0.834       500\n",
      "   macro avg      0.571     0.569     0.566       500\n",
      "weighted avg      0.856     0.834     0.839       500\n",
      "\n",
      "\n",
      "전처리 후 (Preprocessed Dataset):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Class_3      0.671     0.893     0.766       121\n",
      "     Class_4      0.925     0.845     0.883       161\n",
      "     Class_7      0.845     0.710     0.772       169\n",
      "    Class_10      0.000     0.000     0.000         0\n",
      "    Class_13      0.000     0.000     0.000         0\n",
      "    Class_14      0.872     0.837     0.854        49\n",
      "\n",
      "    accuracy                          0.810       500\n",
      "   macro avg      0.552     0.547     0.546       500\n",
      "weighted avg      0.831     0.810     0.814       500\n",
      "\n",
      "\n",
      "==================================================\n",
      "전처리 통계 분석\n",
      "==================================================\n",
      "총 이미지 수: 500개\n",
      "전처리 적용: 259개 (51.8%)\n",
      "전처리 스킵: 241개 (48.2%)\n",
      "품질 개선 평균: +0.074\n",
      "품질 개선 건수: 114개\n",
      "품질 악화 평균: -0.028\n",
      "품질 악화 건수: 145개\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = evaluate_preprocessing_effect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 결과로 submission 파일 생성\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 submission과 동일한 순서인지 확인\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA predictions saved\n",
      "TTA Prediction sample:\n"
     ]
    }
   ],
   "source": [
    "# TTA 결과 저장\n",
    "tta_pred_df.to_csv(\"../submission/choice.csv\", index=False)\n",
    "print(\"TTA predictions saved\")\n",
    "\n",
    "print(\"TTA Prediction sample:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
