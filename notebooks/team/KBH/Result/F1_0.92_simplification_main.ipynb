{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV 문서분류 경진대회 - ConvNeXt Base 384 (간결화 버전)\n",
    "## 5-Fold Cross Validation + Ensemble TTA\n",
    "\n",
    "**성능 목표**: CV F1 0.95+ 유지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 한글 폰트 설정 (시각화용)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 설정 및 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model: convnext_base_384_in22ft1k\n"
     ]
    }
   ],
   "source": [
    "# 설정 통합\n",
    "CONFIG = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'data_path': '../data/',\n",
    "    'model_name': 'convnext_base_384_in22ft1k',\n",
    "    'img_size': 384,\n",
    "    'lr': 2e-4,\n",
    "    'epochs': 20,\n",
    "    'batch_size': 32,\n",
    "    'num_workers': 32,\n",
    "    'n_folds': 5,\n",
    "    'label_smoothing': 0.05\n",
    "}\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Model: {CONFIG['model_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    \"\"\"Mixup 데이터 증강\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"적응형 Hard Augmentation 지원 데이터셋\"\"\"\n",
    "    def __init__(self, data, path, total_epochs=10, is_train=True):\n",
    "        self.df = pd.read_csv(data).values if isinstance(data, str) else data.values\n",
    "        self.path = path\n",
    "        self.is_train = is_train\n",
    "        self.total_epochs = total_epochs\n",
    "        self.current_epoch = 0  # 현재 에포크 추적\n",
    "        \n",
    "        self._update_transforms()\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        \"\"\"에포크 업데이트 메서드\"\"\"\n",
    "        self.current_epoch = epoch\n",
    "        self._update_transforms()\n",
    "    \n",
    "    def _update_transforms(self):\n",
    "        \"\"\"에포크에 따른 증강 변환 업데이트\"\"\"\n",
    "        # Hard augmentation 확률 계산\n",
    "        p_hard = 0.2 + 0.3 * (self.current_epoch / self.total_epochs) if self.is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "            A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "            A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "                A.Rotate(limit=[-15,15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        self.p_hard = p_hard\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert(\"RGB\"))\n",
    "        \n",
    "        # 증강 선택\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습 및 검증 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    \"\"\"한 에포크 학습\"\"\"\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    total_loss, preds_list, targets_list = 0, [], []\n",
    "\n",
    "    for image, targets in tqdm(loader, desc=\"Training\"):\n",
    "        image, targets = image.to(device), targets.to(device)\n",
    "        \n",
    "        # Mixup 적용 (30% 확률)\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): \n",
    "                preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": total_loss / len(loader),\n",
    "        \"train_acc\": accuracy_score(targets_list, preds_list),\n",
    "        \"train_f1\": f1_score(targets_list, preds_list, average='macro'),\n",
    "    }\n",
    "\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    \"\"\"한 에포크 검증\"\"\"\n",
    "    model.eval()\n",
    "    total_loss, n_samples, preds_list, targets_list = 0.0, 0, [], []\n",
    "    \n",
    "    use_amp = torch.cuda.is_available()\n",
    "\n",
    "    # no_grad 대신 inference_mode: 내부 그래프/메모리 더 공격적으로 해제 → 속도/메모리 이점\n",
    "    with torch.inference_mode():\n",
    "        for images, targets in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            # non_blocking=True로 H2D 전송 최적화 (pin_memory=True와 궁합)\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            # 검증에서도 autocast: 연산량/메모리 감소, 정확도엔 영향 없음(CE는 FP32 누수 없이 OK)\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                logits = model(images)\n",
    "                loss = loss_fn(logits, targets)\n",
    "\n",
    "            # 평균 loss를 위해 배치 크기만큼 가중 합\n",
    "            bsz = images.size(0)\n",
    "            total_loss += loss.item() * bsz\n",
    "            n_samples += bsz\n",
    "\n",
    "            # 예측 및 정답 수집 (후단에서 F1/ACC 계산)\n",
    "            preds_list.extend(logits.argmax(dim=1).detach().cpu().tolist())\n",
    "            targets_list.extend(targets.detach().cpu().tolist())\n",
    "\n",
    "    avg_loss = total_loss / max(1, n_samples)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1  = f1_score(targets_list, preds_list, average=\"macro\")\n",
    "\n",
    "    return {\"val_loss\": avg_loss, \"val_acc\": val_acc, \"val_f1\": val_f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 40/40 [00:29<00:00,  1.33it/s]\n",
      "                                                           \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 65\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_folds\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-Fold Cross Validation...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m fold, (train_idx, val_idx) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(skf\u001b[38;5;241m.\u001b[39msplit(train_df, train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m])):\n\u001b[0;32m---> 65\u001b[0m     best_f1, best_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_single_fold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m     fold_results\u001b[38;5;241m.\u001b[39mappend(best_f1)\n\u001b[1;32m     67\u001b[0m     fold_models\u001b[38;5;241m.\u001b[39mappend(best_model)\n",
      "Cell \u001b[0;32mIn[6], line 42\u001b[0m, in \u001b[0;36mtrain_single_fold\u001b[0;34m(fold, train_idx, val_idx, train_df)\u001b[0m\n\u001b[1;32m     38\u001b[0m val_ret \u001b[38;5;241m=\u001b[39m validate_one_epoch(val_loader, model, loss_fn, CONFIG[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     39\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m2d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 42\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | Val Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVal F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m val_ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m best_val_f1:\n\u001b[1;32m     46\u001b[0m     best_val_f1 \u001b[38;5;241m=\u001b[39m val_ret[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_f1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "# train_single_fold 함수 수정 - 데이터셋 epoch 업데이트 추가\n",
    "def train_single_fold(fold, train_idx, val_idx, train_df):\n",
    "    \"\"\"단일 Fold 학습\"\"\"\n",
    "    print(f\"\\n{'='*50}\\nFOLD {fold + 1}/{CONFIG['n_folds']}\\n{'='*50}\")\n",
    "    \n",
    "    # 데이터 분할\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 데이터셋 및 로더 생성\n",
    "    trn_dataset = ImageDataset(train_fold_df, CONFIG['data_path'] + \"train/\", \n",
    "                              total_epochs=CONFIG['epochs'], is_train=True)\n",
    "    val_dataset = ImageDataset(val_fold_df, CONFIG['data_path'] + \"train/\", \n",
    "                              total_epochs=CONFIG['epochs'], is_train=False)\n",
    "    \n",
    "    trn_loader = DataLoader(trn_dataset, batch_size=CONFIG['batch_size'], shuffle=True, \n",
    "                           num_workers=CONFIG['num_workers'], pin_memory=True, drop_last=False)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, \n",
    "                           num_workers=CONFIG['num_workers'], pin_memory=True)\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # 모델 및 최적화 설정\n",
    "    model = timm.create_model(CONFIG['model_name'], pretrained=True, num_classes=17).to(CONFIG['device'])\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=CONFIG['label_smoothing'])\n",
    "    optimizer = Adam(model.parameters(), lr=CONFIG['lr'])\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'])\n",
    "    \n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # 학습 루프\n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        # ★ 핵심: 매 에포크마다 데이터셋 업데이트\n",
    "        trn_dataset.set_epoch(epoch)\n",
    "        \n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, CONFIG['device'])\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, CONFIG['device'])\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # GPU 메모리 정리\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "    return best_val_f1, best_model\n",
    "\n",
    "# K-Fold 실행\n",
    "train_df = pd.read_csv(CONFIG['data_path'] + \"train.csv\")\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=SEED)\n",
    "\n",
    "fold_results = []\n",
    "fold_models = []\n",
    "\n",
    "print(f\"Starting {CONFIG['n_folds']}-Fold Cross Validation...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    best_f1, best_model = train_single_fold(fold, train_idx, val_idx, train_df)\n",
    "    fold_results.append(best_f1)\n",
    "    fold_models.append(best_model)\n",
    "\n",
    "# 결과 요약\n",
    "mean_f1, std_f1 = np.mean(fold_results), np.std(fold_results)\n",
    "print(f\"\\n{'='*60}\\nK-FOLD CROSS VALIDATION RESULTS\\n{'='*60}\")\n",
    "for i, f1 in enumerate(fold_results):\n",
    "    print(f\"Fold {i+1}: {f1:.4f}\")\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(fold_results):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TTA 추론 및 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 변형 정의\n",
    "tta_transforms = [\n",
    "    # 원본\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "        A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "        A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "        A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "        A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "        A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTADataset(Dataset):\n",
    "    \"\"\"TTA 추론용 데이터셋\"\"\"\n",
    "    def __init__(self, data, path, transforms):\n",
    "        self.df = pd.read_csv(data).values if isinstance(data, str) else data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target\n",
    "\n",
    "def ensemble_tta_inference(models, loader):\n",
    "    \"\"\"5-Fold 모델 앙상블 + TTA 추론\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(CONFIG['device'])\n",
    "        \n",
    "        # 각 fold 모델별 예측\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # 각 TTA 변형별 예측\n",
    "                for images in images_list:\n",
    "                    images = images.to(CONFIG['device'])\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ensemble of 5 fold models for inference\n",
      "TTA Dataset size: 3140\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "for state_dict in fold_models:\n",
    "    model = timm.create_model(CONFIG['model_name'], pretrained=False, num_classes=17).to(CONFIG['device'])\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "# TTA 데이터셋 및 로더 생성\n",
    "tta_dataset = TTADataset(CONFIG['data_path'] + \"sample_submission.csv\", \n",
    "                        CONFIG['data_path'] + \"test/\", tta_transforms)\n",
    "tta_loader = DataLoader(tta_dataset, batch_size=64, shuffle=False, \n",
    "                       num_workers=8, pin_memory=True, persistent_workers=True,\n",
    "                       worker_init_fn=_seed_worker, generator=g)\n",
    "\n",
    "print(f\"Using ensemble of {len(ensemble_models)} fold models for inference\")\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ensemble TTA inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 50/50 [09:25<00:00, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed in 9m 25s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TTA 추론 실행\n",
    "print(\"Starting Ensemble TTA inference...\")\n",
    "start_time = time.time()\n",
    "tta_predictions = ensemble_tta_inference(ensemble_models, tta_loader)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "print(f\"Inference completed in {inference_time//60:.0f}m {inference_time%60:.0f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 결과 저장 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Submission format verified\n"
     ]
    }
   ],
   "source": [
    "# 검증\n",
    "sample_submission_df = pd.read_csv(CONFIG['data_path'] + \"sample_submission.csv\")\n",
    "try:\n",
    "    assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()\n",
    "    print(\"✓ Submission format verified\")\n",
    "except AssertionError:\n",
    "    print(\"✗ Submission format error\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Final predictions saved to choice.csv\n",
      "✓ CV Performance: 0.9378 ± 0.0062\n",
      "✓ Inference Time: 9m 25s\n"
     ]
    }
   ],
   "source": [
    "# 최종 저장\n",
    "tta_pred_df.to_csv(\"../submission/choice.csv\", index=False)\n",
    "print(\"\\n✓ Final predictions saved to choice.csv\")\n",
    "print(f\"✓ CV Performance: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"✓ Inference Time: {inference_time//60:.0f}m {inference_time%60:.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 출력\n",
    "print(\"\\nPrediction sample:\")\n",
    "tta_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
