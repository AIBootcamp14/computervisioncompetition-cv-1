{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n",
    "* 필요한 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# # 필요한 라이브러리를 설치합니다.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna\n",
    "# !apt install -y libgl1-mesa-glx\n",
    "# !pip install albumentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precision용\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# 한글 폰트 설정 (시각화용)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# 데이터셋 클래스를 정의합니다. (Hard Augmentation 포함)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation 확률 계산\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "                A.Rotate(limit=[-15,15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # 배치별 증강 선택\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    scaler = GradScaler()  # Mixed Precision용\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Cutmix/Mixup 적용 (30% 확률)\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        scaler.scale(loss).backward()  # Mixed Precision용\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()  # Mixed Precision용\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation을 위한 함수 추가\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    한 에폭 검증을 수행하는 함수\n",
    "    - model.eval()로 모델을 평가 모드로 전환\n",
    "    - torch.no_grad()로 gradient 계산 비활성화하여 메모리 절약\n",
    "    - 검증 데이터에 대한 loss, accuracy, f1 score 계산\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 전환 (dropout, batchnorm 비활성화)\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():  # gradient 계산 비활성화로 메모리 절약\n",
    "        pbar = tqdm(loader, desc=\"Validating\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)  # 모델 예측\n",
    "            loss = loss_fn(preds, targets)  # 손실 계산\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())  # 예측 클래스 저장\n",
    "            targets_list.extend(targets.detach().cpu().numpy())  # 실제 클래스 저장\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)  # 평균 손실 계산\n",
    "    val_acc = accuracy_score(targets_list, preds_list)  # 정확도 계산\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')  # Macro F1 계산 (대회 평가지표)\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'tf_efficientnetv2_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "# model_name = 'swin_base_patch4_window12_384_in22k'\n",
    "model_name = 'convnext_base_384_in22ft1k'\n",
    "# model_name = 'convnextv2_base.fcmae_ft_in22k_in1k_384'\n",
    "# model_name = 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k' # openclip\n",
    "# model_name = 'vit_base_patch16_384.augreg_in1k' # augreg\n",
    "# model_name = 'eva02_enormous_patch14_plus_clip_224.laion2b_s9b_b144k' # eva-02 멀티모달\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 테스트용\n",
    "# model_name = 'vit_base_patch14_reg4_dinov2.lvd142m' # dinov2 reg4\n",
    "\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 테스트용\n",
    "\n",
    "# training config\n",
    "img_size = 384\n",
    "LR = 2e-4\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 24\n",
    "num_workers = 8\n",
    "EMA = True  # Exponential Moving Average 사용 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna를 사용한 하이퍼파라미터 튜닝 (선택적 실행)\n",
    "USE_OPTUNA = False  # True로 바꾸면 튜닝 실행\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # 간단한 3-fold CV로 빠른 평가\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf_simple.split(train_df, train_df['target'])):\n",
    "            # 모델 생성\n",
    "            model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "            optimizer = Adam(model.parameters(), lr=lr)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # 간단한 2 epoch 학습\n",
    "            for epoch in range(2):\n",
    "                train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "            \n",
    "            val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "            fold_scores.append(val_ret['val_f1'])\n",
    "        \n",
    "        return np.mean(fold_scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # 최적 파라미터 적용\n",
    "    LR = study.best_params['lr']\n",
    "    BATCH_SIZE = study.best_params['batch_size']\n",
    "    print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 튜닝 (선택적 실행)\n",
    "USE_OPTUNA = False  # True로 바꾸면 튜닝 실행\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    # 위의 objective 함수와 study 코드\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eedd7d9fa73843e6ad5576f0e6011662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/354M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4844: 100%|██████████| 53/53 [00:32<00:00,  1.63it/s]\n",
      "Val Loss: 1.1483: 100%|██████████| 14/14 [00:07<00:00,  1.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.0278 | Train F1: 0.3639 | Val Loss: 1.0524 | Val F1: 0.7090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4941: 100%|██████████| 53/53 [00:17<00:00,  3.08it/s]\n",
      "Val Loss: 1.2722: 100%|██████████| 14/14 [00:04<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.1143 | Train F1: 0.6805 | Val Loss: 0.7583 | Val F1: 0.7992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.8047: 100%|██████████| 53/53 [00:17<00:00,  3.12it/s]\n",
      "Val Loss: 0.9880: 100%|██████████| 14/14 [00:04<00:00,  3.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.9272 | Train F1: 0.7006 | Val Loss: 0.6594 | Val F1: 0.8715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7861: 100%|██████████| 53/53 [00:17<00:00,  3.06it/s]\n",
      "Val Loss: 1.1757: 100%|██████████| 14/14 [00:04<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8801 | Train F1: 0.7161 | Val Loss: 0.6459 | Val F1: 0.8660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6270: 100%|██████████| 53/53 [00:16<00:00,  3.15it/s]\n",
      "Val Loss: 1.0374: 100%|██████████| 14/14 [00:04<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8583 | Train F1: 0.7480 | Val Loss: 0.6074 | Val F1: 0.8907\n",
      "Fold 1 Best Validation F1: 0.8907\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6938: 100%|██████████| 53/53 [00:16<00:00,  3.13it/s]\n",
      "Val Loss: 1.2212: 100%|██████████| 14/14 [00:04<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.9057 | Train F1: 0.4031 | Val Loss: 0.9772 | Val F1: 0.7240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6777: 100%|██████████| 53/53 [00:17<00:00,  3.10it/s]\n",
      "Val Loss: 1.0060: 100%|██████████| 14/14 [00:04<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.0248 | Train F1: 0.6606 | Val Loss: 0.7386 | Val F1: 0.8006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6436: 100%|██████████| 53/53 [00:16<00:00,  3.12it/s]\n",
      "Val Loss: 0.9008: 100%|██████████| 14/14 [00:04<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.9662 | Train F1: 0.7368 | Val Loss: 0.6730 | Val F1: 0.8355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5112: 100%|██████████| 53/53 [00:16<00:00,  3.15it/s]\n",
      "Val Loss: 1.3265: 100%|██████████| 14/14 [00:04<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.9300 | Train F1: 0.7504 | Val Loss: 0.6227 | Val F1: 0.8765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4033: 100%|██████████| 53/53 [00:16<00:00,  3.12it/s]\n",
      "Val Loss: 1.0367: 100%|██████████| 14/14 [00:04<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8855 | Train F1: 0.7237 | Val Loss: 0.5946 | Val F1: 0.8953\n",
      "Fold 2 Best Validation F1: 0.8953\n",
      "\n",
      "==================================================\n",
      "FOLD 3/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6699: 100%|██████████| 53/53 [00:17<00:00,  3.09it/s]\n",
      "Val Loss: 0.3591: 100%|██████████| 14/14 [00:04<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.9285 | Train F1: 0.4174 | Val Loss: 1.0545 | Val F1: 0.6594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4395: 100%|██████████| 53/53 [00:17<00:00,  3.01it/s]\n",
      "Val Loss: 0.3795: 100%|██████████| 14/14 [00:04<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.2300 | Train F1: 0.5746 | Val Loss: 0.7447 | Val F1: 0.7970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4023: 100%|██████████| 53/53 [00:16<00:00,  3.13it/s]\n",
      "Val Loss: 0.3525: 100%|██████████| 14/14 [00:04<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.0171 | Train F1: 0.6492 | Val Loss: 0.6443 | Val F1: 0.8303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3662: 100%|██████████| 53/53 [00:16<00:00,  3.13it/s]\n",
      "Val Loss: 0.3394: 100%|██████████| 14/14 [00:05<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8133 | Train F1: 0.7649 | Val Loss: 0.5578 | Val F1: 0.8711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0156: 100%|██████████| 53/53 [00:16<00:00,  3.17it/s]\n",
      "Val Loss: 0.3350: 100%|██████████| 14/14 [00:04<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7556 | Train F1: 0.8150 | Val Loss: 0.5417 | Val F1: 0.8870\n",
      "Fold 3 Best Validation F1: 0.8870\n",
      "\n",
      "==================================================\n",
      "FOLD 4/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6895: 100%|██████████| 53/53 [00:17<00:00,  3.10it/s]\n",
      "Val Loss: 0.3607: 100%|██████████| 14/14 [00:04<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.7769 | Train F1: 0.4681 | Val Loss: 0.9370 | Val F1: 0.7603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9209: 100%|██████████| 53/53 [00:17<00:00,  3.06it/s]\n",
      "Val Loss: 0.4654: 100%|██████████| 14/14 [00:04<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.1348 | Train F1: 0.6690 | Val Loss: 0.7320 | Val F1: 0.8061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7715: 100%|██████████| 53/53 [00:17<00:00,  3.08it/s]\n",
      "Val Loss: 0.3563: 100%|██████████| 14/14 [00:04<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8591 | Train F1: 0.7636 | Val Loss: 0.6321 | Val F1: 0.8406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0254: 100%|██████████| 53/53 [00:17<00:00,  3.10it/s]\n",
      "Val Loss: 0.3322: 100%|██████████| 14/14 [00:05<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8368 | Train F1: 0.7859 | Val Loss: 0.5812 | Val F1: 0.8531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5205: 100%|██████████| 53/53 [00:16<00:00,  3.17it/s]\n",
      "Val Loss: 0.3405: 100%|██████████| 14/14 [00:04<00:00,  3.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8622 | Train F1: 0.7314 | Val Loss: 0.5743 | Val F1: 0.8686\n",
      "Fold 4 Best Validation F1: 0.8686\n",
      "\n",
      "==================================================\n",
      "FOLD 5/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7275: 100%|██████████| 53/53 [00:16<00:00,  3.12it/s]\n",
      "Val Loss: 0.3923: 100%|██████████| 14/14 [00:04<00:00,  2.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.7482 | Train F1: 0.4631 | Val Loss: 0.8837 | Val F1: 0.7557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6729: 100%|██████████| 53/53 [00:17<00:00,  3.10it/s]\n",
      "Val Loss: 0.3902: 100%|██████████| 14/14 [00:04<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.0734 | Train F1: 0.6383 | Val Loss: 0.7059 | Val F1: 0.8305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5234: 100%|██████████| 53/53 [00:17<00:00,  3.10it/s]\n",
      "Val Loss: 0.3690: 100%|██████████| 14/14 [00:04<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.9337 | Train F1: 0.7085 | Val Loss: 0.6141 | Val F1: 0.8522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3413: 100%|██████████| 53/53 [00:17<00:00,  3.12it/s]\n",
      "Val Loss: 0.3314: 100%|██████████| 14/14 [00:04<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8071 | Train F1: 0.7736 | Val Loss: 0.5792 | Val F1: 0.8862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6104: 100%|██████████| 53/53 [00:17<00:00,  3.08it/s]\n",
      "Val Loss: 0.3330: 100%|██████████| 14/14 [00:04<00:00,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8044 | Train F1: 0.7841 | Val Loss: 0.5823 | Val F1: 0.8667\n",
      "Fold 5 Best Validation F1: 0.8862\n",
      "\n",
      "============================================================\n",
      "K-FOLD CROSS VALIDATION RESULTS\n",
      "============================================================\n",
      "Fold 1: 0.8907\n",
      "Fold 2: 0.8953\n",
      "Fold 3: 0.8870\n",
      "Fold 4: 0.8686\n",
      "Fold 5: 0.8862\n",
      "\n",
      "Mean CV F1: 0.8855 ± 0.0091\n",
      "Best single fold: 0.8953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# K-Fold 설정\n",
    "N_FOLDS = 5  # 5-fold로 설정 (데이터가 적으므로)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# 클래스별 최소 샘플 보장 확인\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "#     assert len(np.unique(train_df.iloc[val_idx]['target'])) == 17\n",
    "\n",
    "# 전체 학습 데이터 로드\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# K-Fold 결과를 저장할 리스트\n",
    "fold_results = []\n",
    "fold_models = []  # 각 fold의 최고 성능 모델을 저장\n",
    "fold_class_accuracies = [] # 각 fold의 클래스별 정확도 저장\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# LR = best_params['lr']\n",
    "# BATCH_SIZE = best_params['batch_size']\n",
    "\n",
    "# K-Fold Cross Validation 시작\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    current_model = model_name\n",
    "    \n",
    "    # 현재 fold의 train/validation 데이터 분할\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 현재 fold의 Dataset 생성\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=trn_transform\n",
    "        epoch=0,  # 현재 epoch 전달\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=tst_transform  # 검증에는 증강 적용 안함\n",
    "        epoch=0,  # validation은 epoch 관계없음\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False  # validation이므로 hard augmentation 비활성화\n",
    "    )\n",
    "    \n",
    "    # 현재 fold의 DataLoader 생성\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # 모델 초기화 (각 fold마다 새로운 모델)\n",
    "    model = timm.create_model(\n",
    "        current_model,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)  # Label Smoothing 적용\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler 추가\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # 현재 fold의 최고 성능 추적\n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # 현재 fold 학습\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # Scheduler step 추가\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # Best 모델 분석\n",
    "            model.eval()\n",
    "            val_preds, val_targets = [], []\n",
    "            with torch.no_grad():\n",
    "                for image, targets in val_loader:\n",
    "                    preds = model(image.to(device)).argmax(dim=1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_targets.extend(targets.numpy())\n",
    "            \n",
    "            # 클래스별 정확도\n",
    "            fold_class_acc = {}\n",
    "            for c in range(17):\n",
    "                mask = np.array(val_targets) == c\n",
    "                if mask.sum() > 0:\n",
    "                    fold_class_acc[c] = (np.array(val_preds)[mask] == c).mean()\n",
    "    \n",
    "    # 현재 fold 결과 저장\n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset)\n",
    "    })\n",
    "    \n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "    fold_class_accuracies.append(fold_class_acc) # 각 fold의 클래스별 정확도 저장\n",
    "\n",
    "# K-Fold 결과 요약\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"K-FOLD CROSS VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(val_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 3 classes:\n",
      "Class 14: 22.0%\n",
      "Class 7: 45.0%\n",
      "Class 3: 64.0%\n"
     ]
    }
   ],
   "source": [
    "# 클래스별 성능 시각화\n",
    "meta_df = pd.read_csv(\"../data/meta.csv\")\n",
    "avg_acc = {c: np.mean([f.get(c,0) for f in fold_class_accuracies]) for c in range(17)}\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "classes = list(avg_acc.keys())\n",
    "accs = [avg_acc[c] * 100 for c in classes]\n",
    "names = [f\"C{c}\" for c in classes]\n",
    "\n",
    "plt.bar(range(17), accs)\n",
    "plt.xticks(range(17), names)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Class-wise Prediction Accuracy')\n",
    "for i, acc in enumerate(accs):\n",
    "    plt.text(i, acc + 1, f'{acc:.1f}%', ha='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Worst 3 classes:\")\n",
    "worst = sorted(avg_acc.items(), key=lambda x: x[1])[:3]\n",
    "for c, acc in worst:\n",
    "    print(f\"Class {c}: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving fold models...\n",
      "✓ Fold 1 model saved to models/fold_1_best.pth\n",
      "✓ Fold 2 model saved to models/fold_2_best.pth\n",
      "✓ Fold 3 model saved to models/fold_3_best.pth\n",
      "✓ Fold 4 model saved to models/fold_4_best.pth\n",
      "✓ Fold 5 model saved to models/fold_5_best.pth\n",
      "All 5 fold models saved!\n"
     ]
    }
   ],
   "source": [
    "# 디렉토리 생성\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "# fold_models 저장 (현재 메모리에 있다면 바로 실행 가능)\n",
    "print(\"Saving fold models...\")\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    save_path = f'models/fold_{i+1}_best.pth'\n",
    "    torch.save(state_dict, save_path)  # 그냥 직접 저장\n",
    "    print(f\"✓ Fold {i+1} model saved to {save_path}\")\n",
    "\n",
    "print(f\"All {len(fold_models)} fold models saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ensemble of all 5 fold models for inference\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "print(f\"Using ensemble of all {len(ensemble_models)} fold models for inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling 클래스 정의\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_tta_transforms = [\n",
    "    # 원본\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 추론을 위한 Dataset 클래스\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # 여러 transform을 리스트로 받음\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # 모든 transform을 적용한 결과를 리스트로 반환\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA Dataset size: 3140\n"
     ]
    }
   ],
   "source": [
    "# TTA Dataset 생성\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (배치 크기를 줄여서 메모리 절약)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=64,  # TTA는 메모리를 많이 사용하므로 배치 크기 줄임\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_tta_inference(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold 모델 앙상블 + TTA 추론\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # 각 fold 모델별 예측\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # 각 TTA 변형별 예측\n",
    "                for images in images_list:\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ensemble TTA inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 50/50 [17:13<00:00, 20.67s/it]\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 TTA 실행\n",
    "print(\"Starting Ensemble TTA inference...\")\n",
    "tta_predictions = ensemble_tta_inference(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 결과로 submission 파일 생성\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 submission과 동일한 순서인지 확인\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA predictions saved\n",
      "TTA Prediction sample:\n"
     ]
    }
   ],
   "source": [
    "# TTA 결과 저장\n",
    "tta_pred_df.to_csv(\"../submission/choice.csv\", index=False)\n",
    "print(\"TTA predictions saved\")\n",
    "\n",
    "print(\"TTA Prediction sample:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
