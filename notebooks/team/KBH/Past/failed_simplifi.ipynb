{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CV 문서분류 경진대회 - ConvNeXt Base 384 (간결화 버전)\n",
    "## 5-Fold Cross Validation + Ensemble TTA\n",
    "\n",
    "**성능 목표**: CV F1 0.95+ 유지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정 및 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "SEED = 42\n",
    "def seed_everything(seed: int = SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    # CUDNN 결정성\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "def _seed_worker(worker_id: int):\n",
    "    # 각 DataLoader worker에 고유 seed 부여\n",
    "    worker_seed = SEED + worker_id\n",
    "    random.seed(worker_seed)\n",
    "    np.random.seed(worker_seed)\n",
    "    torch.manual_seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 설정 및 데이터셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model: convnext_base_384_in22ft1k\n"
     ]
    }
   ],
   "source": [
    "# 설정 통합\n",
    "CONFIG = {\n",
    "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu'),\n",
    "    'data_path': '../data/',\n",
    "    'model_name': 'convnext_base_384_in22ft1k',\n",
    "    'img_size': 384,\n",
    "    'lr': 2e-4,\n",
    "    'epochs': 20,\n",
    "    'batch_size': 48,\n",
    "    'num_workers': 32,\n",
    "    'n_folds': 5,\n",
    "    'label_smoothing': 0.05\n",
    "}\n",
    "\n",
    "print(f\"Device: {CONFIG['device']}\")\n",
    "print(f\"Model: {CONFIG['model_name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0, device=None):\n",
    "    \"\"\"Mixup 데이터 증강 - 디바이스 하드코딩 제거\"\"\"\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    # 디바이스 하드코딩 제거\n",
    "    if device is None:\n",
    "        device = x.device\n",
    "    index = torch.randperm(batch_size, device=device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    \"\"\"적응형 Hard Augmentation + 검증 전용 Transform 분리\"\"\"\n",
    "    def __init__(self, data, path, total_epochs=10, is_train=True):\n",
    "        # 컬럼명 보존을 위해 DataFrame 형태 유지\n",
    "        if isinstance(data, (str, os.PathLike)):\n",
    "            self.df = pd.read_csv(data)\n",
    "        else:\n",
    "            self.df = data.copy()\n",
    "        self.df.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        self.path = path\n",
    "        self.is_train = is_train\n",
    "        self.total_epochs = int(total_epochs)\n",
    "        self.current_epoch = 0\n",
    "        self.p_hard = 0.2  # 초기값만 설정\n",
    "        \n",
    "        # 컬럼명 자동 탐지 (열 순서 바뀌어도 안전)\n",
    "        self.image_col = next((c for c in [\"image\",\"img_path\",\"image_path\",\"file\",\"filename\",\"name\"]\n",
    "                               if c in self.df.columns), self.df.columns[0])\n",
    "        self.target_col = next((c for c in [\"target\",\"label\",\"class\",\"y\"]\n",
    "                               if c in self.df.columns), self.df.columns[1])\n",
    "        \n",
    "        # 검증용 클린 Transform (증강 없음)\n",
    "        self.val_transforms = A.Compose([\n",
    "            A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "            A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # 학습용만 증강 Transform 초기화\n",
    "        self._update_transforms()  # 첫 배치 전 비지 않게 (검증일 땐 내부에서 no-op)\n",
    "\n",
    "    def set_epoch(self, epoch):\n",
    "        \"\"\"에포크 업데이트 메서드 (학습용만) - p_hard 계산 통합\"\"\"\n",
    "        if self.is_train:\n",
    "            epoch = int(epoch)\n",
    "            self.current_epoch = epoch\n",
    "            self.p_hard = 0.2 + 0.3 * (epoch / max(1, self.total_epochs - 1))\n",
    "            self.p_hard = float(min(1.0, max(0.0, self.p_hard)))  # 안전 클램프\n",
    "            self._update_transforms()\n",
    "            self._update_transforms()\n",
    "    \n",
    "    def _update_transforms(self):\n",
    "        \"\"\"에포크에 따른 증강 변환 업데이트 (학습용만) - p_hard 계산 제거\"\"\"\n",
    "        if not self.is_train:\n",
    "            self.normal_aug = None\n",
    "            self.hard_aug = None\n",
    "            return\n",
    "        \n",
    "        # p_hard는 set_epoch에서만 계산되므로 여기서는 제거\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "            A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "            A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "                A.Rotate(limit=[-15,15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # DataFrame 인덱싱으로 컬럼명 보존\n",
    "        row = self.df.iloc[idx]\n",
    "        name   = str(row[self.image_col])   # 이름/경로 문자열화\n",
    "        target = int(row[self.target_col])  # 라벨 정수화\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # 핵심 수정: 학습/검증 분리\n",
    "        if self.is_train:\n",
    "            # 학습: 적응형 증강 적용\n",
    "            if random.random() < self.p_hard:\n",
    "                img = self.hard_aug(image=img)['image']\n",
    "            else:\n",
    "                img = self.normal_aug(image=img)['image']\n",
    "        else:\n",
    "            # 검증: 클린한 전처리만 적용\n",
    "            aug = self.normal_aug or self.val_transforms  # 널가드\n",
    "            img = aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 학습 및 검증 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    \"\"\"한 에포크 학습\"\"\"\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    total_loss, preds_list, targets_list = 0, [], []\n",
    "\n",
    "    for image, targets in tqdm(loader, desc=\"Training\"):\n",
    "        image, targets = image.to(device), targets.to(device)\n",
    "        \n",
    "        # Mixup 적용 (30% 확률)\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): \n",
    "                preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": total_loss / len(loader),\n",
    "        \"train_acc\": accuracy_score(targets_list, preds_list),\n",
    "        \"train_f1\": f1_score(targets_list, preds_list, average='macro'),\n",
    "    }\n",
    "\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    \"\"\"한 에포크 검증\"\"\"\n",
    "    model.eval()\n",
    "    total_loss, n_samples = 0.0, 0\n",
    "    preds_list, targets_list = [], []\n",
    "    use_amp = torch.cuda.is_available()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for images, targets in tqdm(loader, desc=\"Validating\", leave=False):\n",
    "            images = images.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                logits = model(images)\n",
    "                loss = loss_fn(logits, targets)\n",
    "\n",
    "            bsz = images.size(0)\n",
    "            total_loss += loss.item() * bsz\n",
    "            n_samples += bsz\n",
    "\n",
    "            preds_list.extend(logits.argmax(dim=1).detach().cpu().tolist())\n",
    "            targets_list.extend(targets.detach().cpu().tolist())\n",
    "\n",
    "    avg_loss = total_loss / max(1, n_samples)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1  = f1_score(targets_list, preds_list, average=\"macro\")\n",
    "\n",
    "    return {\"val_loss\": avg_loss, \"val_acc\": val_acc, \"val_f1\": val_f1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:22<00:00,  1.21it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.2499 | Train F1: 0.3452 | Val Loss: 1.2059 | Val F1: 0.6476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.3915 | Train F1: 0.5154 | Val Loss: 0.8083 | Val F1: 0.7822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.0304 | Train F1: 0.7132 | Val Loss: 0.6775 | Val F1: 0.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.9682 | Train F1: 0.6701 | Val Loss: 0.6064 | Val F1: 0.8845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8933 | Train F1: 0.7262 | Val Loss: 0.5740 | Val F1: 0.8807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.8943 | Train F1: 0.7380 | Val Loss: 0.6163 | Val F1: 0.8343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.8108 | Train F1: 0.7582 | Val Loss: 0.5933 | Val F1: 0.8623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7544 | Train F1: 0.7604 | Val Loss: 0.5076 | Val F1: 0.9302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.7635 | Train F1: 0.7796 | Val Loss: 0.5044 | Val F1: 0.9281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.7750 | Train F1: 0.7975 | Val Loss: 0.4969 | Val F1: 0.9164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.7299 | Train F1: 0.7570 | Val Loss: 0.5100 | Val F1: 0.9192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6863 | Train F1: 0.8141 | Val Loss: 0.4868 | Val F1: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6553 | Train F1: 0.7938 | Val Loss: 0.4826 | Val F1: 0.9309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.56it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.5825 | Train F1: 0.7233 | Val Loss: 0.4938 | Val F1: 0.9269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6145 | Train F1: 0.9157 | Val Loss: 0.4640 | Val F1: 0.9429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.59it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.7766 | Train F1: 0.8020 | Val Loss: 0.4771 | Val F1: 0.9465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6182 | Train F1: 0.8983 | Val Loss: 0.4673 | Val F1: 0.9397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.7272 | Train F1: 0.7937 | Val Loss: 0.4632 | Val F1: 0.9507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.56it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.7441 | Train F1: 0.7456 | Val Loss: 0.4651 | Val F1: 0.9431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.7660 | Train F1: 0.7774 | Val Loss: 0.4648 | Val F1: 0.9397\n",
      "Fold 1 Best Validation F1: 0.9507\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.53it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.1938 | Train F1: 0.3754 | Val Loss: 1.2923 | Val F1: 0.6215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.3497 | Train F1: 0.6074 | Val Loss: 0.9096 | Val F1: 0.7696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.0401 | Train F1: 0.6647 | Val Loss: 0.6601 | Val F1: 0.8341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.1597 | Train F1: 0.5338 | Val Loss: 0.6087 | Val F1: 0.8867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8462 | Train F1: 0.7643 | Val Loss: 0.5676 | Val F1: 0.8559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.59it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.8976 | Train F1: 0.6909 | Val Loss: 0.5321 | Val F1: 0.9080\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.59it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.8907 | Train F1: 0.7021 | Val Loss: 0.5422 | Val F1: 0.9028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.6643 | Train F1: 0.8594 | Val Loss: 0.5204 | Val F1: 0.9124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.7798 | Train F1: 0.7861 | Val Loss: 0.5276 | Val F1: 0.9144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.7196 | Train F1: 0.8164 | Val Loss: 0.4987 | Val F1: 0.9237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.5724 | Train F1: 0.8455 | Val Loss: 0.4738 | Val F1: 0.9454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.5950 | Train F1: 0.8606 | Val Loss: 0.4759 | Val F1: 0.9374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.7896 | Train F1: 0.7674 | Val Loss: 0.4704 | Val F1: 0.9458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.58it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6388 | Train F1: 0.7994 | Val Loss: 0.4749 | Val F1: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6086 | Train F1: 0.9022 | Val Loss: 0.4784 | Val F1: 0.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.7324 | Train F1: 0.8864 | Val Loss: 0.4649 | Val F1: 0.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6040 | Train F1: 0.8491 | Val Loss: 0.4693 | Val F1: 0.9466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.65it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6238 | Train F1: 0.7898 | Val Loss: 0.4614 | Val F1: 0.9509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.7699 | Train F1: 0.7909 | Val Loss: 0.4587 | Val F1: 0.9471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.6360 | Train F1: 0.8228 | Val Loss: 0.4588 | Val F1: 0.9471\n",
      "Fold 2 Best Validation F1: 0.9524\n",
      "\n",
      "==================================================\n",
      "FOLD 3/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:18<00:00,  1.48it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.1636 | Train F1: 0.3085 | Val Loss: 1.1159 | Val F1: 0.6723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.68it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.2692 | Train F1: 0.6123 | Val Loss: 0.7622 | Val F1: 0.8070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1868 | Train F1: 0.6358 | Val Loss: 0.6759 | Val F1: 0.8471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.58it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 1.0921 | Train F1: 0.6745 | Val Loss: 0.5994 | Val F1: 0.8456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8563 | Train F1: 0.7334 | Val Loss: 0.5819 | Val F1: 0.8637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.8226 | Train F1: 0.7236 | Val Loss: 0.5559 | Val F1: 0.8859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7774 | Train F1: 0.8065 | Val Loss: 0.5837 | Val F1: 0.8719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.68it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7717 | Train F1: 0.8112 | Val Loss: 0.5992 | Val F1: 0.8554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.7567 | Train F1: 0.8069 | Val Loss: 0.5188 | Val F1: 0.8976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.7075 | Train F1: 0.8525 | Val Loss: 0.5155 | Val F1: 0.8777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.7917 | Train F1: 0.7321 | Val Loss: 0.5247 | Val F1: 0.8851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.66it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.7943 | Train F1: 0.6808 | Val Loss: 0.4957 | Val F1: 0.9109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.7260 | Train F1: 0.7275 | Val Loss: 0.4837 | Val F1: 0.9186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.7250 | Train F1: 0.8712 | Val Loss: 0.4866 | Val F1: 0.8989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.65it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.5868 | Train F1: 0.9122 | Val Loss: 0.4782 | Val F1: 0.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.6159 | Train F1: 0.8315 | Val Loss: 0.4745 | Val F1: 0.9117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6498 | Train F1: 0.7682 | Val Loss: 0.4707 | Val F1: 0.9179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6012 | Train F1: 0.9206 | Val Loss: 0.4705 | Val F1: 0.9093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.7005 | Train F1: 0.8130 | Val Loss: 0.4696 | Val F1: 0.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5893 | Train F1: 0.8300 | Val Loss: 0.4694 | Val F1: 0.9122\n",
      "Fold 3 Best Validation F1: 0.9326\n",
      "\n",
      "==================================================\n",
      "FOLD 4/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.52it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.1963 | Train F1: 0.3456 | Val Loss: 1.1747 | Val F1: 0.6685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.2277 | Train F1: 0.6305 | Val Loss: 0.7907 | Val F1: 0.8205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.0560 | Train F1: 0.6618 | Val Loss: 0.6855 | Val F1: 0.8278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8743 | Train F1: 0.7913 | Val Loss: 0.6250 | Val F1: 0.8680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.9801 | Train F1: 0.6756 | Val Loss: 0.6011 | Val F1: 0.8923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.8711 | Train F1: 0.7545 | Val Loss: 0.5776 | Val F1: 0.8913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.8875 | Train F1: 0.6573 | Val Loss: 0.5829 | Val F1: 0.8782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.59it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.6499 | Train F1: 0.8585 | Val Loss: 0.5512 | Val F1: 0.8834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.59it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.8614 | Train F1: 0.7638 | Val Loss: 0.5305 | Val F1: 0.9153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.65it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.7864 | Train F1: 0.7461 | Val Loss: 0.5341 | Val F1: 0.9077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.7519 | Train F1: 0.7817 | Val Loss: 0.5603 | Val F1: 0.8873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.7203 | Train F1: 0.8427 | Val Loss: 0.5293 | Val F1: 0.9137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6999 | Train F1: 0.7969 | Val Loss: 0.5171 | Val F1: 0.9024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6786 | Train F1: 0.8296 | Val Loss: 0.5094 | Val F1: 0.9102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.65it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.5398 | Train F1: 0.8890 | Val Loss: 0.5066 | Val F1: 0.9129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.7001 | Train F1: 0.8522 | Val Loss: 0.5030 | Val F1: 0.9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.66it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6306 | Train F1: 0.8932 | Val Loss: 0.5053 | Val F1: 0.9178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.65it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6520 | Train F1: 0.8787 | Val Loss: 0.5006 | Val F1: 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.6673 | Train F1: 0.8573 | Val Loss: 0.5003 | Val F1: 0.9242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.6474 | Train F1: 0.8396 | Val Loss: 0.5001 | Val F1: 0.9242\n",
      "Fold 4 Best Validation F1: 0.9247\n",
      "\n",
      "==================================================\n",
      "FOLD 5/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:18<00:00,  1.48it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 2.2617 | Train F1: 0.3062 | Val Loss: 1.3473 | Val F1: 0.6348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.64it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 1.3279 | Train F1: 0.5833 | Val Loss: 0.8536 | Val F1: 0.7541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 1.1300 | Train F1: 0.6383 | Val Loss: 0.7093 | Val F1: 0.8450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.9670 | Train F1: 0.6877 | Val Loss: 0.6295 | Val F1: 0.8763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.59it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8594 | Train F1: 0.7635 | Val Loss: 0.6018 | Val F1: 0.8746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.57it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.6780 | Train F1: 0.8106 | Val Loss: 0.5549 | Val F1: 0.8961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7796 | Train F1: 0.7787 | Val Loss: 0.5710 | Val F1: 0.8586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.8333 | Train F1: 0.7494 | Val Loss: 0.5594 | Val F1: 0.8616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.63it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.7690 | Train F1: 0.8329 | Val Loss: 0.5336 | Val F1: 0.9066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:15<00:00,  1.70it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.8096 | Train F1: 0.7529 | Val Loss: 0.5549 | Val F1: 0.8783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.7432 | Train F1: 0.8350 | Val Loss: 0.5146 | Val F1: 0.9237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.7805 | Train F1: 0.8077 | Val Loss: 0.5101 | Val F1: 0.9096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.61it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6325 | Train F1: 0.8403 | Val Loss: 0.5377 | Val F1: 0.8851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.59it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6831 | Train F1: 0.8522 | Val Loss: 0.5272 | Val F1: 0.8942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.56it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6743 | Train F1: 0.7764 | Val Loss: 0.5156 | Val F1: 0.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.60it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.7738 | Train F1: 0.7563 | Val Loss: 0.5046 | Val F1: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.53it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.7110 | Train F1: 0.8408 | Val Loss: 0.5024 | Val F1: 0.9113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:15<00:00,  1.72it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6074 | Train F1: 0.8168 | Val Loss: 0.5043 | Val F1: 0.9087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:17<00:00,  1.56it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5719 | Train F1: 0.8569 | Val Loss: 0.5090 | Val F1: 0.9113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 27/27 [00:16<00:00,  1.62it/s]\n",
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.7087 | Train F1: 0.8363 | Val Loss: 0.5071 | Val F1: 0.9079\n",
      "Fold 5 Best Validation F1: 0.9244\n",
      "\n",
      "============================================================\n",
      "K-FOLD CROSS VALIDATION RESULTS\n",
      "============================================================\n",
      "Fold 1: 0.9507\n",
      "Fold 2: 0.9524\n",
      "Fold 3: 0.9326\n",
      "Fold 4: 0.9247\n",
      "Fold 5: 0.9244\n",
      "\n",
      "Mean CV F1: 0.9369 ± 0.0123\n",
      "Best single fold: 0.9524\n"
     ]
    }
   ],
   "source": [
    "# train_single_fold 함수 수정 - 데이터셋 epoch 업데이트 추가\n",
    "def train_single_fold(fold, train_idx, val_idx, train_df):\n",
    "    \"\"\"단일 Fold 학습\"\"\"\n",
    "    print(f\"\\n{'='*50}\\nFOLD {fold + 1}/{CONFIG['n_folds']}\\n{'='*50}\")\n",
    "    \n",
    "    # 데이터 분할\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 데이터셋 및 로더 생성\n",
    "    trn_dataset = ImageDataset(train_fold_df, CONFIG['data_path'] + \"train/\", \n",
    "                              total_epochs=CONFIG['epochs'], is_train=True)\n",
    "    val_dataset = ImageDataset(val_fold_df, CONFIG['data_path'] + \"train/\", \n",
    "                              total_epochs=CONFIG['epochs'], is_train=False)\n",
    "    \n",
    "    trn_loader = DataLoader(trn_dataset, batch_size=CONFIG['batch_size'], shuffle=True, \n",
    "                           num_workers=CONFIG['num_workers'], pin_memory=True, drop_last=False,\n",
    "                           persistent_workers=True, worker_init_fn=_seed_worker, generator=g)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, \n",
    "                           num_workers=CONFIG['num_workers'], pin_memory=True, persistent_workers=True,\n",
    "                           worker_init_fn=_seed_worker, generator=g)\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # 모델 및 최적화 설정\n",
    "    model = timm.create_model(CONFIG['model_name'], pretrained=True, num_classes=17).to(CONFIG['device'])\n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=CONFIG['label_smoothing'])\n",
    "    optimizer = Adam(model.parameters(), lr=CONFIG['lr'])\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=CONFIG['epochs'])\n",
    "    \n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # 학습 루프\n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        # ★ 핵심: 매 에포크마다 데이터셋 업데이트\n",
    "        trn_dataset.set_epoch(epoch)\n",
    "        \n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, CONFIG['device'])\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, CONFIG['device'])\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # GPU 메모리 정리\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "    return best_val_f1, best_model\n",
    "\n",
    "# K-Fold 실행\n",
    "train_df = pd.read_csv(CONFIG['data_path'] + \"train.csv\")\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_folds'], shuffle=True, random_state=SEED)\n",
    "\n",
    "fold_results = []\n",
    "fold_models = []\n",
    "\n",
    "print(f\"Starting {CONFIG['n_folds']}-Fold Cross Validation...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    best_f1, best_model = train_single_fold(fold, train_idx, val_idx, train_df)\n",
    "    fold_results.append(best_f1)\n",
    "    fold_models.append(best_model)\n",
    "\n",
    "# 결과 요약\n",
    "mean_f1, std_f1 = np.mean(fold_results), np.std(fold_results)\n",
    "print(f\"\\n{'='*60}\\nK-FOLD CROSS VALIDATION RESULTS\\n{'='*60}\")\n",
    "for i, f1 in enumerate(fold_results):\n",
    "    print(f\"Fold {i+1}: {f1:.4f}\")\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(fold_results):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스별 성능 시각화\n",
    "def classwise_accuracy(model, loader, device, num_classes=None):\n",
    "    model.eval()\n",
    "    use_amp = torch.cuda.is_available()\n",
    "    C = None\n",
    "    correct = None\n",
    "    counts  = None\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for images, targets in loader:\n",
    "            images  = images.to(device, non_blocking=True)\n",
    "            targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "            with torch.cuda.amp.autocast(enabled=use_amp):\n",
    "                logits = model(images)\n",
    "            preds = logits.argmax(1)\n",
    "\n",
    "            if C is None:\n",
    "                C = num_classes if num_classes is not None else logits.shape[1]\n",
    "                correct = torch.zeros(C, dtype=torch.long, device=targets.device)\n",
    "                counts  = torch.zeros(C, dtype=torch.long, device=targets.device)\n",
    "\n",
    "            # 클래스별 개수 / 정답 개수 집계 (벡터화)\n",
    "            counts  += torch.bincount(targets, minlength=C)\n",
    "            correct += torch.bincount(targets[preds == targets], minlength=C)\n",
    "\n",
    "    acc = (correct.float() / counts.clamp(min=1).float()).cpu().numpy()\n",
    "    return acc, counts.cpu().numpy()\n",
    "\n",
    "# 평가 대상: 현재 검증 로더와 모델 사용\n",
    "num_classes = CONFIG.get(\"num_classes\", 17)\n",
    "acc, counts = classwise_accuracy(model, val_loader, CONFIG[\"device\"], num_classes=num_classes)\n",
    "\n",
    "# 라벨 (원하는 이름이 있으면 여기서 교체: 예) CLASS_NAMES)\n",
    "class_names = [f\"C{i}\" for i in range(len(acc))]\n",
    "\n",
    "# --- Plot ---\n",
    "plt.figure(figsize=(16, 6))\n",
    "bars = plt.bar(range(len(acc)), acc * 100)\n",
    "plt.xticks(range(len(acc)), class_names)\n",
    "plt.ylim(0, 105)\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.title(\"Class-wise Prediction Accuracy\")\n",
    "\n",
    "# 막대 위에 퍼센트 표시\n",
    "for b, a in zip(bars, acc):\n",
    "    h = (a * 100)\n",
    "    plt.text(b.get_x() + b.get_width()/2, h + 1, f\"{h:.1f}%\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==== FULL/샘플 스캔로 EDA (취약클래스 보강용) ====\n",
    "\n",
    "# # 0) 경로/칼럼명 정합\n",
    "# IMG_COL = img  # 너의 DF 칼럼명에 맞게: 'img_path' 등으로 교체\n",
    "# TARGET_COL = \"target\"\n",
    "\n",
    "# # 1) 스캔 (전수 권장. 느리면 SAMPLE_N=5000 등으로 제한)\n",
    "# SAMPLE_N = None  # None이면 전수, 정수면 샘플 수\n",
    "# df_scan = train_df.sample(SAMPLE_N, random_state=42) if SAMPLE_N else train_df\n",
    "\n",
    "# stats = []\n",
    "# for p, y in tqdm(zip(df_scan[IMG_COL].values, df_scan[TARGET_COL].values), total=len(df_scan), desc=\"Scanning\"):\n",
    "#     img = cv2.imdecode(np.fromfile(p, dtype=np.uint8), cv2.IMREAD_COLOR)  # 한글 경로 호환\n",
    "#     if img is None: \n",
    "#         continue\n",
    "#     h, w = img.shape[:2]\n",
    "#     gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # 밝기(평균), 대비(표준편차), 블러(라플라시안 분산) — 간단하지만 강력\n",
    "#     bright = float(gray.mean())\n",
    "#     contrast = float(gray.std())\n",
    "#     blur = float(cv2.Laplacian(gray, cv2.CV_64F).var())\n",
    "\n",
    "#     stats.append((p, y, w, h, w/h, bright, contrast, blur))\n",
    "\n",
    "# eda_df = pd.DataFrame(stats, columns=[IMG_COL, TARGET_COL, \"w\", \"h\", \"ar\", \"bright\", \"contrast\", \"blur\"])\n",
    "\n",
    "# # 2) 클래스 분포 + 품질지표 요약\n",
    "# class_counts = eda_df[TARGET_COL].value_counts().sort_index()\n",
    "# per_class = eda_df.groupby(TARGET_COL)[[\"w\",\"h\",\"ar\",\"bright\",\"contrast\",\"blur\"]].agg([\"median\",\"mean\",\"std\"]).round(2)\n",
    "\n",
    "# print(\"클래스 분포(개수):\")\n",
    "# display(class_counts.to_frame(\"count\"))\n",
    "\n",
    "# print(\"\\n클래스별 화질/밝기/블러 통계:\")\n",
    "# display(per_class)\n",
    "\n",
    "# # 3) 취약 후보 탐색 규칙 (예시: 블러 중앙값이 낮거나 밝기가 낮은 클래스 TOP k)\n",
    "# weak_by_blur = eda_df.groupby(TARGET_COL)[\"blur\"].median().sort_values().head(5)\n",
    "# weak_by_dark = eda_df.groupby(TARGET_COL)[\"bright\"].median().sort_values().head(5)\n",
    "\n",
    "# print(\"\\n블러 취약(중앙값 낮은 순) TOP5:\")\n",
    "# display(weak_by_blur)\n",
    "\n",
    "# print(\"\\n저조도 취약(밝기 중앙값 낮은 순) TOP5:\")\n",
    "# display(weak_by_dark)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ==== Confusion Matrix & Hard Samples ====\n",
    "# model.eval()\n",
    "# all_preds, all_targets, all_paths = [], [], []\n",
    "\n",
    "# with torch.inference_mode(), torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
    "#     for (images, targets, *maybe_paths) in tqdm(val_loader, desc=\"Eval/CM\"):\n",
    "#         images = images.to(CONFIG[\"device\"], non_blocking=True)\n",
    "#         logits = model(images)\n",
    "#         preds = logits.argmax(1).detach().cpu().numpy()\n",
    "#         all_preds.extend(preds)\n",
    "#         all_targets.extend(targets.numpy())\n",
    "#         # Dataset에서 이미지 경로를 반환하지 않는다면, 아래는 생략\n",
    "#         if maybe_paths:\n",
    "#             all_paths.extend(maybe_paths[0])\n",
    "\n",
    "# all_preds = np.array(all_preds)\n",
    "# all_targets = np.array(all_targets)\n",
    "# labels = np.arange(CONFIG.get(\"num_classes\", all_preds.max()+1))\n",
    "\n",
    "# # 1) 혼동행렬\n",
    "# cm = confusion_matrix(all_targets, all_preds, labels=labels, normalize=None)\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[f\"C{i}\" for i in labels])\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# disp.plot(ax=ax, cmap=\"Blues\", colorbar=False, xticks_rotation=45)\n",
    "# plt.title(\"Confusion Matrix (counts)\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "\n",
    "# print(\"\\nClassification Report (macro avg 확인):\")\n",
    "# print(classification_report(all_targets, all_preds, digits=4))\n",
    "\n",
    "# # 2) 클래스별 최악 샘플 저장 (정답 y, 예측 yhat가 다른 케이스)\n",
    "# os.makedirs(\"hard_samples\", exist_ok=True)\n",
    "# TOP_K = 24  # 클래스별 저장 개수\n",
    "# if len(all_paths) == len(all_targets):  # 경로가 있는 경우에만\n",
    "#     for c in labels:\n",
    "#         bad_idx = np.where((all_targets == c) & (all_preds != c))[0][:TOP_K]\n",
    "#         grid = []\n",
    "#         for i in bad_idx:\n",
    "#             p = all_paths[i]\n",
    "#             img = cv2.imdecode(np.fromfile(p, dtype=np.uint8), cv2.IMREAD_COLOR)\n",
    "#             if img is None: \n",
    "#                 continue\n",
    "#             img = cv2.resize(img, (224, 224))\n",
    "#             grid.append(img)\n",
    "#         if grid:\n",
    "#             rows = int(np.ceil(len(grid)/6))\n",
    "#             canvas = np.zeros((rows*224, 6*224, 3), dtype=np.uint8)\n",
    "#             for j, im in enumerate(grid):\n",
    "#                 r, c2 = divmod(j, 6)\n",
    "#                 canvas[r*224:(r+1)*224, c2*224:(c2+1)*224] = im\n",
    "#             cv2.imwrite(os.path.join(\"hard_samples\", f\"class_{c}_hard.jpg\"), canvas)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TTA 추론 및 앙상블"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 변형 정의\n",
    "tta_transforms = [\n",
    "    # 원본\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "        A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "        A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "        A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "        A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=CONFIG['img_size']),\n",
    "        A.PadIfNeeded(min_height=CONFIG['img_size'], min_width=CONFIG['img_size'], border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTADataset(Dataset):\n",
    "    \"\"\"TTA 추론용 데이터셋\"\"\"\n",
    "    def __init__(self, data, path, transforms):\n",
    "        self.df = pd.read_csv(data).values if isinstance(data, str) else data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert(\"RGB\"))\n",
    "        \n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target\n",
    "\n",
    "def ensemble_tta_inference(models, loader):\n",
    "    \"\"\"5-Fold 모델 앙상블 + TTA 추론\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(CONFIG['device'])\n",
    "        \n",
    "        # 각 fold 모델별 예측\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # 각 TTA 변형별 예측\n",
    "                for images in images_list:\n",
    "                    images = images.to(CONFIG['device'])\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ensemble of 5 fold models for inference\n",
      "TTA Dataset size: 3140\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "for state_dict in fold_models:\n",
    "    model = timm.create_model(CONFIG['model_name'], pretrained=False, num_classes=17).to(CONFIG['device'])\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.eval()\n",
    "    ensemble_models.append(model)\n",
    "\n",
    "# TTA 데이터셋 및 로더 생성\n",
    "tta_dataset = TTADataset(CONFIG['data_path'] + \"sample_submission.csv\", \n",
    "                        CONFIG['data_path'] + \"test/\", tta_transforms)\n",
    "tta_loader = DataLoader(tta_dataset, batch_size=64, shuffle=False, \n",
    "                       num_workers=8, pin_memory=True, persistent_workers=True,\n",
    "                       worker_init_fn=_seed_worker, generator=g)\n",
    "\n",
    "print(f\"Using ensemble of {len(ensemble_models)} fold models for inference\")\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ensemble TTA inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 50/50 [09:19<00:00, 11.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference completed in 9m 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# TTA 추론 실행\n",
    "print(\"Starting Ensemble TTA inference...\")\n",
    "start_time = time.time()\n",
    "tta_predictions = ensemble_tta_inference(ensemble_models, tta_loader)\n",
    "inference_time = time.time() - start_time\n",
    "\n",
    "print(f\"Inference completed in {inference_time//60:.0f}m {inference_time%60:.0f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 결과 저장 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Submission format verified\n"
     ]
    }
   ],
   "source": [
    "# 검증\n",
    "sample_submission_df = pd.read_csv(CONFIG['data_path'] + \"sample_submission.csv\")\n",
    "try:\n",
    "    assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()\n",
    "    print(\"✓ Submission format verified\")\n",
    "except AssertionError:\n",
    "    print(\"✗ Submission format error\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✓ Final predictions saved to choice.csv\n",
      "✓ CV Performance: 0.9369 ± 0.0123\n",
      "✓ Inference Time: 9m 20s\n"
     ]
    }
   ],
   "source": [
    "# 최종 저장\n",
    "tta_pred_df.to_csv(\"../submission/choice.csv\", index=False)\n",
    "print(\"\\n✓ Final predictions saved to choice.csv\")\n",
    "print(f\"✓ CV Performance: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"✓ Inference Time: {inference_time//60:.0f}m {inference_time%60:.0f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction sample:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 샘플 출력\n",
    "print(\"\\nPrediction sample:\")\n",
    "tta_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
