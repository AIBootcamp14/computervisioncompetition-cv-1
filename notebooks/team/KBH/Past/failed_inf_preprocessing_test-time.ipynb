{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n",
    "* 필요한 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# # 필요한 라이브러리를 설치합니다.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna\n",
    "# !apt install -y libgl1-mesa-glx\n",
    "# !pip install albumentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precision용\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# 한글 폰트 설정 (시각화용)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'tf_efficientnetv2_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "# model_name = 'swin_base_patch4_window12_384_in22k'\n",
    "model_name = 'convnext_base_384_in22ft1k'\n",
    "# model_name = 'convnextv2_base.fcmae_ft_in22k_in1k_384'\n",
    "# model_name = 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k' # openclip\n",
    "# model_name = 'vit_base_patch16_384.augreg_in1k' # augreg\n",
    "# model_name = 'eva02_enormous_patch14_plus_clip_224.laion2b_s9b_b144k' # eva-02 멀티모달\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 테스트용\n",
    "# model_name = 'vit_base_patch14_reg4_dinov2.lvd142m' # dinov2 reg4\n",
    "\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 테스트용\n",
    "\n",
    "# training config\n",
    "img_size = 384\n",
    "LR = 2e-4\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 24\n",
    "num_workers = 8\n",
    "EMA = True  # Exponential Moving Average 사용 여부"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold 적용"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Fold 1 model loaded from models/fold_1_best.pth\n",
      "✓ Fold 2 model loaded from models/fold_2_best.pth\n",
      "✓ Fold 3 model loaded from models/fold_3_best.pth\n",
      "✓ Fold 4 model loaded from models/fold_4_best.pth\n",
      "✓ Fold 5 model loaded from models/fold_5_best.pth\n",
      "Using ensemble of all 5 fold models for inference\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "for i in range(5):  # fold 개수만큼\n",
    "    fold_model = timm.create_model(model_name, pretrained=False, num_classes=17).to(device)  # pretrained=False로 변경\n",
    "    \n",
    "    # fold별 저장된 파일 로드\n",
    "    checkpoint = torch.load(f'models/fold_{i+1}_best.pth')  # fold별 파일 경로\n",
    "    fold_model.load_state_dict(checkpoint)\n",
    "    fold_model.eval()\n",
    "    \n",
    "    ensemble_models.append(fold_model)\n",
    "    print(f\"✓ Fold {i+1} model loaded from models/fold_{i+1}_best.pth\")\n",
    "\n",
    "print(f\"Using ensemble of all {len(ensemble_models)} fold models for inference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론 점수용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 1256\n",
      "Holdout validation samples: 314\n"
     ]
    }
   ],
   "source": [
    "# ==================== 로컬 F1 검증을 위한 Holdout Validation ====================\n",
    "# Holdout Validation Set 생성\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# 20% holdout validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_fold, holdout_val = train_test_split(\n",
    "    train_df, \n",
    "    test_size=0.2, \n",
    "    stratify=train_df['target'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train samples: {len(train_fold)}\")\n",
    "print(f\"Holdout validation samples: {len(holdout_val)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling 클래스 정의\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_tta_transforms = [\n",
    "    # 원본\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TTA 추론을 위한 Dataset 클래스\n",
    "# class TTAImageDataset(Dataset):\n",
    "#     def __init__(self, data, path, transforms):\n",
    "#         if isinstance(data, str):\n",
    "#             self.df = pd.read_csv(data).values\n",
    "#         else:\n",
    "#             self.df = data.values\n",
    "#         self.path = path\n",
    "#         self.transforms = transforms  # 여러 transform을 리스트로 받음\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.df)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         name, target = self.df[idx]\n",
    "#         img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "#         # 모든 transform을 적용한 결과를 리스트로 반환\n",
    "#         augmented_images = []\n",
    "#         for transform in self.transforms:\n",
    "#             aug_img = transform(image=img)['image']\n",
    "#             augmented_images.append(aug_img)\n",
    "        \n",
    "#         return augmented_images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_time_preprocessing(img_array):\n",
    "    \"\"\"Test-time 이미지 품질 개선 - 완전판\"\"\"\n",
    "    # RGB to Grayscale\n",
    "    if len(img_array.shape) == 3:\n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
    "    else:\n",
    "        gray = img_array\n",
    "    \n",
    "    # 1. 회전 보정 (문서 경계선 기반)\n",
    "    try:\n",
    "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
    "        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)\n",
    "        if lines is not None:\n",
    "            angles = []\n",
    "            for rho, theta in lines[:10]:  # 상위 10개 선만 사용\n",
    "                angle = np.degrees(theta) - 90\n",
    "                angles.append(angle)\n",
    "            \n",
    "            if angles:\n",
    "                median_angle = np.median(angles)\n",
    "                if abs(median_angle) > 1:  # 1도 이상 기울어진 경우만 보정\n",
    "                    h, w = gray.shape\n",
    "                    center = (w//2, h//2)\n",
    "                    M = cv2.getRotationMatrix2D(center, median_angle, 1.0)\n",
    "                    gray = cv2.warpAffine(gray, M, (w, h), borderValue=255)\n",
    "    except:\n",
    "        pass  # 회전 보정 실패 시 원본 유지\n",
    "    \n",
    "    # 2. CLAHE (대비 개선)\n",
    "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
    "    enhanced = clahe.apply(gray)\n",
    "    \n",
    "    # 3. Gamma 보정 (밝기 개선)\n",
    "    gamma = 1.3\n",
    "    enhanced = np.power(enhanced/255.0, gamma) * 255\n",
    "    enhanced = enhanced.astype(np.uint8)\n",
    "    \n",
    "    # 4. Deblur (언샤프 마스킹)\n",
    "    gaussian = cv2.GaussianBlur(enhanced, (0, 0), 2.0)\n",
    "    deblurred = cv2.addWeighted(enhanced, 1.5, gaussian, -0.5, 0)\n",
    "    \n",
    "    # 5. Denoising\n",
    "    denoised = cv2.fastNlMeansDenoising(deblurred)\n",
    "    \n",
    "    # 6. 최종 선명화\n",
    "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])\n",
    "    sharpened = cv2.filter2D(denoised, -1, kernel)\n",
    "    \n",
    "    # RGB로 변환\n",
    "    result = cv2.cvtColor(sharpened, cv2.COLOR_GRAY2RGB)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms, preprocessing=False):  # 옵션 추가\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms\n",
    "        self.preprocessing = preprocessing\n",
    "\n",
    "    def __len__(self):  # 이 메서드가 누락되어 있었음\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # 전처리 적용 여부\n",
    "        if self.preprocessing:\n",
    "            img = test_time_preprocessing(img)\n",
    "        \n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TTA Dataset 생성\n",
    "# tta_dataset = TTAImageDataset(\n",
    "#     \"../data/sample_submission.csv\",\n",
    "#     \"../data/test/\",\n",
    "#     essential_tta_transforms\n",
    "# )\n",
    "\n",
    "# # TTA DataLoader (배치 크기를 줄여서 메모리 절약)\n",
    "# tta_loader = DataLoader(\n",
    "#     tta_dataset,\n",
    "#     batch_size=64,  # TTA는 메모리를 많이 사용하므로 배치 크기 줄임\n",
    "#     shuffle=False,\n",
    "#     num_workers=num_workers,\n",
    "#     pin_memory=True\n",
    "# )\n",
    "\n",
    "# print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test TTA Dataset size: 3140\n",
      "Validation TTA Dataset size: 314\n"
     ]
    }
   ],
   "source": [
    "# TTA Dataset 생성 - 테스트용과 검증용 모두 생성\n",
    "test_tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# Holdout Validation Dataset 생성 (로컬 F1 검증용)\n",
    "val_tta_dataset = TTAImageDataset(\n",
    "    holdout_val,\n",
    "    \"../data/train/\",  # validation도 train 폴더에 있음\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# DataLoader들\n",
    "test_tta_loader = DataLoader(test_tta_dataset, batch_size=64, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "val_tta_loader = DataLoader(val_tta_dataset, batch_size=64, shuffle=False, num_workers=num_workers, pin_memory=True)\n",
    "\n",
    "print(f\"Test TTA Dataset size: {len(test_tta_dataset)}\")\n",
    "print(f\"Validation TTA Dataset size: {len(val_tta_dataset)}\")\n",
    "\n",
    "# 기존 변수명 호환성 유지\n",
    "tta_dataset = test_tta_dataset\n",
    "tta_loader = test_tta_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_tta_inference(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold 모델 앙상블 + TTA 추론\"\"\"\n",
    "    temp_scaling = TemperatureScaling().to(device)  # Temperature Scaling 추가\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # 각 fold 모델별 예측\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # 각 TTA 변형별 예측\n",
    "                for images in images_list:\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    \n",
    "                    # Temperature Scaling 적용\n",
    "                    scaled_preds = temp_scaling(preds)\n",
    "                    probs = torch.softmax(scaled_preds, dim=1)\n",
    "                    \n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Ensemble TTA inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 50/50 [09:48<00:00, 11.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 TTA 실행\n",
    "print(\"Starting Ensemble TTA inference...\")\n",
    "tta_predictions = ensemble_tta_inference(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로컬 F1 검증 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 5/5 [01:05<00:00, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "로컬 Holdout F1 점수: 0.9161\n",
      "이 점수가 실제 제출 점수와 유사할 가능성이 높습니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ==================== 로컬 F1 검증 ====================\n",
    "print(\"로컬 F1 검증 시작...\")\n",
    "val_predictions = ensemble_tta_inference(\n",
    "    models=ensemble_models, \n",
    "    loader=val_tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")\n",
    "\n",
    "# F1 점수 계산\n",
    "true_labels = holdout_val['target'].values\n",
    "local_f1 = f1_score(true_labels, val_predictions, average='macro')\n",
    "\n",
    "print(f\"로컬 Holdout F1 점수: {local_f1:.4f}\")\n",
    "print(\"이 점수가 실제 제출 점수와 유사할 가능성이 높습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 없음으로 검증 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 5/5 [01:09<00:00, 13.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 적용으로 검증 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 5/5 [02:40<00:00, 32.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 전: 0.9161\n",
      "전처리 후: 0.7949\n",
      "개선 효과: +-12.1%p\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 전처리 전후 비교\n",
    "print(\"전처리 없음으로 검증 중...\")\n",
    "val_dataset_without = TTAImageDataset(holdout_val, \"../data/train/\", essential_tta_transforms, preprocessing=False)\n",
    "val_loader_without = DataLoader(val_dataset_without, batch_size=64, shuffle=False)\n",
    "f1_without = f1_score(true_labels, ensemble_tta_inference(ensemble_models, val_loader_without, essential_tta_transforms), average='macro')\n",
    "\n",
    "print(\"전처리 적용으로 검증 중...\")\n",
    "val_dataset_with = TTAImageDataset(holdout_val, \"../data/train/\", essential_tta_transforms, preprocessing=True)\n",
    "val_loader_with = DataLoader(val_dataset_with, batch_size=64, shuffle=False)\n",
    "f1_with = f1_score(true_labels, ensemble_tta_inference(ensemble_models, val_loader_with, essential_tta_transforms), average='macro')\n",
    "\n",
    "print(f\"전처리 전: {f1_without:.4f}\")\n",
    "print(f\"전처리 후: {f1_with:.4f}\")\n",
    "print(f\"개선 효과: +{(f1_with - f1_without)*100:.1f}%p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 결과로 submission 파일 생성\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기존 submission과 동일한 순서인지 확인\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA predictions saved\n",
      "TTA Prediction sample:\n"
     ]
    }
   ],
   "source": [
    "# TTA 결과 저장\n",
    "tta_pred_df.to_csv(\"../submission/choice.csv\", index=False)\n",
    "print(\"TTA predictions saved\")\n",
    "\n",
    "print(\"TTA Prediction sample:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1700315247734,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "9yMO8s6GqAwZ",
    "outputId": "9a30616f-f0ea-439f-a906-dd806737ce00"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008fdb22ddce0ce.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091bffdffd83de.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00396fbc1f6cc21d.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00471f8038d9c4b6.jpg</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00901f504008d884.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     ID  target\n",
       "0  0008fdb22ddce0ce.jpg       2\n",
       "1  00091bffdffd83de.jpg      12\n",
       "2  00396fbc1f6cc21d.jpg       5\n",
       "3  00471f8038d9c4b6.jpg      12\n",
       "4  00901f504008d884.jpg       2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tta_pred_df.head()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
