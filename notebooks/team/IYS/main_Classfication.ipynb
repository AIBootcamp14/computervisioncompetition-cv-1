{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "zkH9T_86lDSS"
   },
   "source": [
    "## 1. Prepare Environments\n",
    "\n",
    "* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n",
    "* 필요한 라이브러리를 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8489,
     "status": "ok",
     "timestamp": 1700314558888,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "NC8V-D393wY4",
    "outputId": "e9927325-26c4-4b89-9c51-c1d6541388d6"
   },
   "outputs": [],
   "source": [
    "# # 필요한 라이브러리를 설치합니다.\n",
    "# !pip install timm\n",
    "# !pip install matplotlib\n",
    "# !pip install seaborn\n",
    "# !pip install optuna\n",
    "# !apt install -y libgl1-mesa-glx\n",
    "# !pip install albumentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "PXa_FPM73R9f"
   },
   "source": [
    "## 2. Import Library & Define Functions\n",
    "* 학습 및 추론에 필요한 라이브러리를 로드합니다.\n",
    "* 학습 및 추론에 필요한 함수와 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 9396,
     "status": "ok",
     "timestamp": 1700314592802,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "3BaoIkv5Xwa0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam, AdamW\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precision용\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# 한글 폰트 설정 (시각화용)\n",
    "plt.rcParams['font.family'] = ['DejaVu Sans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 241,
     "status": "ok",
     "timestamp": 1700314772722,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "Hyl8oAy6TZAu"
   },
   "outputs": [],
   "source": [
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# 계층적 모델 훈련 함수들 추가\n",
    "def train_weak_detector_fold(train_df, val_df, fold, device, data_path):\n",
    "    \"\"\"취약 클래스 탐지기 훈련 (1개 fold용)\"\"\"\n",
    "    print(f\"🔍 Training Weak Detector - Fold {fold+1}\")\n",
    "    \n",
    "    # 간단한 변환 (빠른 훈련을 위해)\n",
    "    train_transform = A.Compose([\n",
    "        A.LongestMaxSize(max_size=224),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    val_transform = A.Compose([\n",
    "        A.LongestMaxSize(max_size=224),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    train_dataset = WeakClassDataset(train_df, data_path, train_transform)\n",
    "    val_dataset = WeakClassDataset(val_df, data_path, val_transform)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # 클래스 가중치 (불균형 처리)\n",
    "    class_counts = train_dataset.df['binary_target'].value_counts()\n",
    "    weight_ratio = float(class_counts[0] / class_counts[1]) if 1 in class_counts else 1.0  # float() 추가\n",
    "    class_weights = torch.tensor([1.0, weight_ratio], dtype=torch.float32).to(device)      # dtype 명시\n",
    "    \n",
    "    model = WeakClassDetector().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-4, weight_decay=0.01)\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # 간단한 5 에포크 훈련\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for images, targets in train_loader:\n",
    "            images, targets = images.to(device), targets.long().to(device)  # .long() 추가\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 검증\n",
    "        model.eval()\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = images.to(device)\n",
    "                targets = targets.long()  # .long() 추가\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(targets.numpy())\n",
    "        \n",
    "        val_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    return best_model, best_f1\n",
    "\n",
    "def train_weak_specializer_fold(train_df, val_df, fold, device, data_path):\n",
    "    \"\"\"취약 클래스 전용 분류기 훈련 (1개 fold용)\"\"\"\n",
    "    print(f\"🎯 Training Weak Specializer - Fold {fold+1}\")\n",
    "    \n",
    "    train_transform = A.Compose([\n",
    "        A.LongestMaxSize(max_size=224),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=10, p=0.7),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    val_transform = A.Compose([\n",
    "        A.LongestMaxSize(max_size=224),\n",
    "        A.PadIfNeeded(min_height=224, min_width=224, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ])\n",
    "    \n",
    "    train_dataset = WeakClassSpecializerDataset(train_df, data_path, train_transform)\n",
    "    val_dataset = WeakClassSpecializerDataset(val_df, data_path, val_transform)\n",
    "    \n",
    "    if len(train_dataset) == 0 or len(val_dataset) == 0:\n",
    "        print(f\"⚠️ No weak class samples in fold {fold+1}, skipping specializer training\")\n",
    "        return None, 0.0\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # 클래스 가중치\n",
    "    class_dist = train_dataset.df['mapped_target'].value_counts().sort_index()\n",
    "    total_samples = len(train_dataset)\n",
    "    class_weights = []\n",
    "    for i in range(4):\n",
    "        if i in class_dist.index:\n",
    "            weight = float(total_samples / (4 * class_dist[i]))  # float() 추가\n",
    "            class_weights.append(weight)\n",
    "        else:\n",
    "            class_weights.append(1.0)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32).to(device)  # dtype 명시\n",
    "    \n",
    "    model = WeakClassSpecializer().to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=0.1)\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-4, weight_decay=0.01)\n",
    "    \n",
    "    best_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # 8 에포크 훈련\n",
    "    for epoch in range(8):\n",
    "        model.train()\n",
    "        for images, targets in train_loader:\n",
    "            images, targets = images.to(device), targets.long().to(device)  # .long() 추가\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 검증\n",
    "        model.eval()\n",
    "        val_preds, val_targets = [], []\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = images.to(device)\n",
    "                targets = targets.long()  # .long() 추가\n",
    "                outputs = model(images)\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                val_preds.extend(preds.cpu().numpy())\n",
    "                val_targets.extend(targets.numpy())\n",
    "        \n",
    "        if len(val_targets) > 0:\n",
    "            val_f1 = f1_score(val_targets, val_preds, average='macro')\n",
    "            if val_f1 > best_f1:\n",
    "                best_f1 = val_f1\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    return best_model, best_f1\n",
    "\n",
    "# 계층적 분류를 위한 모델 클래스들\n",
    "class WeakClassDetector(nn.Module):\n",
    "    \"\"\"취약 클래스(3,4,7,14) 탐지를 위한 이진 분류기\"\"\"\n",
    "    def __init__(self, model_name='convnext_tiny', img_size=224):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name, \n",
    "            pretrained=True, \n",
    "            num_classes=2,  # 취약클래스 vs 일반클래스\n",
    "            drop_rate=0.1\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "class WeakClassSpecializer(nn.Module):\n",
    "    \"\"\"취약 클래스(3,4,7,14) 전용 4-class 분류기\"\"\"\n",
    "    def __init__(self, model_name='convnext_small', img_size=224):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name,\n",
    "            pretrained=True,\n",
    "            num_classes=4,  # 클래스 3,4,7,14만 구분\n",
    "            drop_rate=0.15\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)\n",
    "\n",
    "class HierarchicalDocumentClassifier(nn.Module):\n",
    "    \"\"\"조건부 계층적 문서 분류 시스템\"\"\"\n",
    "    def __init__(self, main_model_name='convnext_base_384_in22ft1k'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.weak_classes = [3, 4, 7, 14]\n",
    "        self.class_mapping = {3: 0, 4: 1, 7: 2, 14: 3}\n",
    "        self.reverse_mapping = {0: 3, 1: 4, 2: 7, 3: 14}\n",
    "        \n",
    "        # 메인 분류기는 기존 모델과 동일\n",
    "        self.main_classifier = timm.create_model(\n",
    "            main_model_name, pretrained=True, num_classes=17\n",
    "        )\n",
    "        self.weak_detector = WeakClassDetector()  \n",
    "        self.weak_specializer = WeakClassSpecializer()\n",
    "        \n",
    "        # 조건부 실행을 위한 임계값들\n",
    "        self.confidence_threshold = 0.8  # 메인 분류기 신뢰도 임계값\n",
    "        self.weak_class_threshold = 0.6  # 탐지기 임계값\n",
    "        self.main_weak_confidence_threshold = 0.7  # 메인이 취약클래스 예측시 임계값\n",
    "        \n",
    "    def forward(self, x, mode='inference'):\n",
    "        if mode == 'main':\n",
    "            return self.main_classifier(x)\n",
    "        elif mode == 'detector':\n",
    "            return self.weak_detector(x)\n",
    "        elif mode == 'specializer':\n",
    "            return self.weak_specializer(x)\n",
    "        elif mode == 'inference':\n",
    "            return self.conditional_hierarchical_inference(x)\n",
    "            \n",
    "    def conditional_hierarchical_inference(self, x):\n",
    "        \"\"\"조건부 계층적 추론 - 필요할 때만 탐지기 실행\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        final_predictions = torch.zeros(batch_size, 17).to(x.device)\n",
    "        \n",
    "        # 1단계: 메인 분류기만 먼저 실행\n",
    "        main_logits = self.main_classifier(x)\n",
    "        main_probs = torch.softmax(main_logits, dim=1)\n",
    "        main_confidence, main_preds = torch.max(main_probs, dim=1)\n",
    "        \n",
    "        # 2단계: 조건 확인 - 탐지기 실행이 필요한 샘플들 찾기\n",
    "        needs_detection = torch.zeros(batch_size, dtype=torch.bool).to(x.device)\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            main_pred = main_preds[i].item()\n",
    "            main_conf = main_confidence[i].item()\n",
    "            \n",
    "            # 탐지기 실행 조건들\n",
    "            condition1 = main_pred in self.weak_classes and main_conf < self.main_weak_confidence_threshold\n",
    "            condition2 = main_conf < self.confidence_threshold\n",
    "            \n",
    "            needs_detection[i] = condition1 or condition2\n",
    "        \n",
    "        # 3단계: 조건부 탐지기 실행\n",
    "        detection_indices = torch.where(needs_detection)[0]\n",
    "        \n",
    "        if len(detection_indices) > 0:\n",
    "            # 필요한 샘플들만 탐지기에 입력\n",
    "            suspicious_samples = x[detection_indices]\n",
    "            detector_logits = self.weak_detector(suspicious_samples)\n",
    "            detector_probs = torch.softmax(detector_logits, dim=1)\n",
    "            weak_class_probs = detector_probs[:, 1]  # 취약클래스 확률\n",
    "            \n",
    "            # 4단계: 전용 분류기 사용 여부 결정\n",
    "            for idx_in_batch, sample_idx in enumerate(detection_indices):\n",
    "                main_pred = main_preds[sample_idx].item()\n",
    "                main_conf = main_confidence[sample_idx].item()\n",
    "                weak_prob = weak_class_probs[idx_in_batch].item()\n",
    "                \n",
    "                # 전용 분류기 사용 조건\n",
    "                use_specializer = (\n",
    "                    (main_pred in self.weak_classes and main_conf < self.main_weak_confidence_threshold) or\n",
    "                    (weak_prob > self.weak_class_threshold)\n",
    "                )\n",
    "                \n",
    "                if use_specializer:\n",
    "                    # 전용 분류기 실행 (단일 샘플)\n",
    "                    single_sample = x[sample_idx:sample_idx+1]\n",
    "                    specializer_logits = self.weak_specializer(single_sample)\n",
    "                    specializer_probs = torch.softmax(specializer_logits, dim=1)\n",
    "                    spec_pred = torch.argmax(specializer_probs, dim=1).item()\n",
    "                    final_class = self.reverse_mapping[spec_pred]\n",
    "                    final_predictions[sample_idx, final_class] = 1.0\n",
    "                else:\n",
    "                    # 메인 분류기 결과 사용\n",
    "                    final_predictions[sample_idx] = main_probs[sample_idx]\n",
    "        \n",
    "        # 5단계: 탐지가 필요없던 샘플들은 메인 결과 사용\n",
    "        no_detection_indices = torch.where(~needs_detection)[0]\n",
    "        for sample_idx in no_detection_indices:\n",
    "            final_predictions[sample_idx] = main_probs[sample_idx]\n",
    "                \n",
    "        return final_predictions\n",
    "    \n",
    "    def get_inference_stats(self, x):\n",
    "        \"\"\"추론 과정 통계 반환 (디버깅용)\"\"\"\n",
    "        batch_size = x.size(0)\n",
    "        \n",
    "        # 메인 분류기 실행\n",
    "        main_logits = self.main_classifier(x)\n",
    "        main_probs = torch.softmax(main_logits, dim=1)\n",
    "        main_confidence, main_preds = torch.max(main_probs, dim=1)\n",
    "        \n",
    "        # 조건 확인\n",
    "        needs_detection = torch.zeros(batch_size, dtype=torch.bool).to(x.device)\n",
    "        for i in range(batch_size):\n",
    "            main_pred = main_preds[i].item()\n",
    "            main_conf = main_confidence[i].item()\n",
    "            \n",
    "            condition1 = main_pred in self.weak_classes and main_conf < self.main_weak_confidence_threshold\n",
    "            condition2 = main_conf < self.confidence_threshold\n",
    "            needs_detection[i] = condition1 or condition2\n",
    "        \n",
    "        detection_count = needs_detection.sum().item()\n",
    "        \n",
    "        stats = {\n",
    "            'total_samples': batch_size,\n",
    "            'detection_needed': detection_count,\n",
    "            'detection_ratio': detection_count / batch_size if batch_size > 0 else 0,\n",
    "            'main_only_samples': batch_size - detection_count,\n",
    "            'avg_main_confidence': main_confidence.mean().item(),\n",
    "            'weak_class_predictions': sum(1 for pred in main_preds if pred.item() in self.weak_classes)\n",
    "        }\n",
    "        \n",
    "        return stats\n",
    "\n",
    "# 취약 클래스 탐지용 이진 분류 데이터셋\n",
    "class WeakClassDataset(Dataset):\n",
    "    \"\"\"취약 클래스 탐지용 이진 분류 데이터셋\"\"\"\n",
    "    def __init__(self, data, path, transform=None, weak_classes=[3, 4, 7, 14]):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data)\n",
    "        else:\n",
    "            self.df = data.copy()\n",
    "        \n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        self.weak_classes = weak_classes\n",
    "        \n",
    "        # 이진 레이블 생성 (취약클래스: 1, 나머지: 0)\n",
    "        self.df['binary_target'] = self.df['target'].apply(\n",
    "            lambda x: 1 if x in weak_classes else 0\n",
    "        ).astype(int)  # int 타입으로 명시적 변환\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.path, row['ID'])\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "            \n",
    "        return img, int(row['binary_target'])  # int()로 확실히 정수 타입으로 변환\n",
    "\n",
    "class WeakClassSpecializerDataset(Dataset):\n",
    "    \"\"\"취약 클래스 전용 4-class 데이터셋\"\"\"\n",
    "    def __init__(self, data, path, transform=None, weak_classes=[3, 4, 7, 14]):\n",
    "        if isinstance(data, str):\n",
    "            df = pd.read_csv(data)\n",
    "        else:\n",
    "            df = data.copy()\n",
    "        \n",
    "        # 취약 클래스만 필터링\n",
    "        self.df = df[df['target'].isin(weak_classes)].reset_index(drop=True)\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "        \n",
    "        # 클래스 매핑 (3->0, 4->1, 7->2, 14->3)\n",
    "        self.class_mapping = {3: 0, 4: 1, 7: 2, 14: 3}\n",
    "        self.df['mapped_target'] = self.df['target'].map(self.class_mapping).astype(int)  # int 타입으로 명시\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = os.path.join(self.path, row['ID'])\n",
    "        img = np.array(Image.open(img_path).convert('RGB'))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "            \n",
    "        return img, int(row['mapped_target'])\n",
    "\n",
    "# 데이터셋 클래스를 정의합니다. (Hard Augmentation 포함)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation 확률 계산\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90,90], p=1.0),\n",
    "                A.Rotate(limit=[180,180], p=1.0),\n",
    "                A.Rotate(limit=[270,270], p=1.0),\n",
    "                A.Rotate(limit=[-15,15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # 배치별 증강 선택\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 255,
     "status": "ok",
     "timestamp": 1700315066028,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "kTECBJfVTbdl"
   },
   "outputs": [],
   "source": [
    "# one epoch 학습을 위한 함수입니다.\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    scaler = GradScaler()  # Mixed Precision용\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Cutmix/Mixup 적용 (30% 확률)\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "\n",
    "        scaler.scale(loss).backward()  # Mixed Precision용\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer); scaler.update()  # Mixed Precision용\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation을 위한 함수 추가\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    \"\"\"\n",
    "    한 에폭 검증을 수행하는 함수\n",
    "    - model.eval()로 모델을 평가 모드로 전환\n",
    "    - torch.no_grad()로 gradient 계산 비활성화하여 메모리 절약\n",
    "    - 검증 데이터에 대한 loss, accuracy, f1 score 계산\n",
    "    \"\"\"\n",
    "    model.eval()  # 모델을 평가 모드로 전환 (dropout, batchnorm 비활성화)\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():  # gradient 계산 비활성화로 메모리 절약\n",
    "        pbar = tqdm(loader, desc=\"Validating\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)  # 모델 예측\n",
    "            loss = loss_fn(preds, targets)  # 손실 계산\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())  # 예측 클래스 저장\n",
    "            targets_list.extend(targets.detach().cpu().numpy())  # 실제 클래스 저장\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)  # 평균 손실 계산\n",
    "    val_acc = accuracy_score(targets_list, preds_list)  # 정확도 계산\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')  # Macro F1 계산 (대회 평가지표)\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjom43UvoXcx"
   },
   "source": [
    "## 3. Hyper-parameters\n",
    "* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 436,
     "status": "ok",
     "timestamp": 1700315112439,
     "user": {
      "displayName": "Ynot(송원호)",
      "userId": "16271863862696372773"
     },
     "user_tz": -540
    },
    "id": "KByfAeRmXwYk"
   },
   "outputs": [],
   "source": [
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "# model_name = 'tf_efficientnetv2_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "# model_name = 'swin_base_patch4_window12_384_in22k'\n",
    "model_name = 'convnext_base_384_in22ft1k'\n",
    "# model_name = 'convnextv2_base.fcmae_ft_in22k_in1k_384'\n",
    "# model_name = 'vit_base_patch16_clip_384.laion2b_ft_in12k_in1k' # openclip\n",
    "# model_name = 'vit_base_patch16_384.augreg_in1k' # augreg\n",
    "# model_name = 'eva02_enormous_patch14_plus_clip_224.laion2b_s9b_b144k' # eva-02 멀티모달\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 테스트용\n",
    "# model_name = 'vit_base_patch14_reg4_dinov2.lvd142m' # dinov2 reg4\n",
    "\n",
    "# model_name = 'eva02_large_patch14_448.mim_in22k_ft_in1k' #448 테스트용\n",
    "\n",
    "# training config\n",
    "img_size = 512\n",
    "LR = 2e-4\n",
    "EPOCHS = 64\n",
    "BATCH_SIZE = 10\n",
    "num_workers = 8\n",
    "EMA = True  # Exponential Moving Average 사용 여부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna를 사용한 하이퍼파라미터 튜닝 (선택적 실행)\n",
    "USE_OPTUNA = False  # True로 바꾸면 튜닝 실행\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # 간단한 3-fold CV로 빠른 평가\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf_simple.split(train_df, train_df['target'])):\n",
    "            # 모델 생성\n",
    "            model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "            optimizer = Adam(model.parameters(), lr=lr)\n",
    "            loss_fn = nn.CrossEntropyLoss()\n",
    "            \n",
    "            # 간단한 2 epoch 학습\n",
    "            for epoch in range(2):\n",
    "                train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "            \n",
    "            val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "            fold_scores.append(val_ret['val_f1'])\n",
    "        \n",
    "        return np.mean(fold_scores)\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # 최적 파라미터 적용\n",
    "    LR = study.best_params['lr']\n",
    "    BATCH_SIZE = study.best_params['batch_size']\n",
    "    print(f\"Best params: {study.best_params}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "amum-FlIojc6"
   },
   "source": [
    "## 4. Load Data\n",
    "* 학습, 테스트 데이터셋과 로더를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna 튜닝 (선택적 실행)\n",
    "USE_OPTUNA = False  # True로 바꾸면 튜닝 실행\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    # 위의 objective 함수와 study 코드\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Fold 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5-Fold Cross Validation...\n",
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1309: 100%|██████████| 126/126 [00:29<00:00,  4.31it/s]\n",
      "Val Loss: 1.3613: 100%|██████████| 32/32 [00:05<00:00,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.7130 | Train F1: 0.4807 | Val Loss: 0.8217 | Val F1: 0.7934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5000: 100%|██████████| 126/126 [00:22<00:00,  5.52it/s]\n",
      "Val Loss: 1.0099: 100%|██████████| 32/32 [00:04<00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.9988 | Train F1: 0.7023 | Val Loss: 0.8188 | Val F1: 0.8038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6895: 100%|██████████| 126/126 [00:22<00:00,  5.51it/s]\n",
      "Val Loss: 0.4577: 100%|██████████| 32/32 [00:04<00:00,  7.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8415 | Train F1: 0.7273 | Val Loss: 0.5630 | Val F1: 0.8967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7754: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.6486: 100%|██████████| 32/32 [00:04<00:00,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.7970 | Train F1: 0.7963 | Val Loss: 0.5402 | Val F1: 0.9058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5381: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.6730: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7655 | Train F1: 0.7802 | Val Loss: 0.5564 | Val F1: 0.8843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4976: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.4233: 100%|██████████| 32/32 [00:04<00:00,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.6979 | Train F1: 0.8002 | Val Loss: 0.4735 | Val F1: 0.9305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8799: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3824: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.6410 | Train F1: 0.8493 | Val Loss: 0.5261 | Val F1: 0.9318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1357: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.6067: 100%|██████████| 32/32 [00:04<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.6225 | Train F1: 0.8664 | Val Loss: 0.5164 | Val F1: 0.9304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9307: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.4127: 100%|██████████| 32/32 [00:04<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6434 | Train F1: 0.8111 | Val Loss: 0.4891 | Val F1: 0.9486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4155: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3620: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6645 | Train F1: 0.8252 | Val Loss: 0.4476 | Val F1: 0.9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.0625: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3483: 100%|██████████| 32/32 [00:04<00:00,  7.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6327 | Train F1: 0.8350 | Val Loss: 0.4670 | Val F1: 0.9491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3955: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3437: 100%|██████████| 32/32 [00:04<00:00,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6030 | Train F1: 0.8508 | Val Loss: 0.4539 | Val F1: 0.9521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3657: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.5647: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.5519 | Train F1: 0.8611 | Val Loss: 0.4333 | Val F1: 0.9616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.0742: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3383: 100%|██████████| 32/32 [00:04<00:00,  7.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6069 | Train F1: 0.8517 | Val Loss: 0.4661 | Val F1: 0.9561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3955: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3342: 100%|██████████| 32/32 [00:04<00:00,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.5849 | Train F1: 0.8180 | Val Loss: 0.4462 | Val F1: 0.9622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3328: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3366: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.5720 | Train F1: 0.8623 | Val Loss: 0.4395 | Val F1: 0.9568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3254: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3349: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.5412 | Train F1: 0.8953 | Val Loss: 0.4325 | Val F1: 0.9541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3389: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.4258: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5391 | Train F1: 0.8446 | Val Loss: 0.4764 | Val F1: 0.9525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3325: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3258: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5073 | Train F1: 0.8828 | Val Loss: 0.4187 | Val F1: 0.9637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3237: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3268: 100%|██████████| 32/32 [00:04<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5367 | Train F1: 0.8692 | Val Loss: 0.4319 | Val F1: 0.9596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3271: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3278: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5659 | Train F1: 0.8433 | Val Loss: 0.4328 | Val F1: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3230: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.3238: 100%|██████████| 32/32 [00:04<00:00,  7.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5416 | Train F1: 0.8693 | Val Loss: 0.4282 | Val F1: 0.9597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3274: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3222: 100%|██████████| 32/32 [00:04<00:00,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5799 | Train F1: 0.8381 | Val Loss: 0.4106 | Val F1: 0.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8750: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3435: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5558 | Train F1: 0.8418 | Val Loss: 0.4207 | Val F1: 0.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0312: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3315: 100%|██████████| 32/32 [00:04<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5549 | Train F1: 0.8731 | Val Loss: 0.4229 | Val F1: 0.9652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3384: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3227: 100%|██████████| 32/32 [00:04<00:00,  7.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.5499 | Train F1: 0.8752 | Val Loss: 0.4263 | Val F1: 0.9651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5537: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3270: 100%|██████████| 32/32 [00:04<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5509 | Train F1: 0.8390 | Val Loss: 0.4161 | Val F1: 0.9685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8711: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.3243: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5433 | Train F1: 0.8645 | Val Loss: 0.4123 | Val F1: 0.9734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3213: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3218: 100%|██████████| 32/32 [00:04<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.4954 | Train F1: 0.8825 | Val Loss: 0.4107 | Val F1: 0.9685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8711: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3219: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5182 | Train F1: 0.8646 | Val Loss: 0.4115 | Val F1: 0.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3235: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3218: 100%|██████████| 32/32 [00:04<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.4896 | Train F1: 0.8858 | Val Loss: 0.4197 | Val F1: 0.9673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3217: 100%|██████████| 32/32 [00:04<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.5286 | Train F1: 0.8737 | Val Loss: 0.4163 | Val F1: 0.9624\n",
      "\n",
      "🎯 Training hierarchical models for Fold 1\n",
      "🔍 Training Weak Detector - Fold 1\n",
      "🎯 Training Weak Specializer - Fold 1\n",
      "Fold 1 - Main F1: 0.9734, Detector F1: 0.9954, Specializer F1: 0.1111\n",
      "Fold 1 Best Validation F1: 0.9734\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2236: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.5980: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.6316 | Train F1: 0.4988 | Val Loss: 0.8222 | Val F1: 0.7914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5322: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.5275: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.9621 | Train F1: 0.7061 | Val Loss: 0.5938 | Val F1: 0.8422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.5713: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.7720: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.9213 | Train F1: 0.7395 | Val Loss: 0.6076 | Val F1: 0.8310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8413: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.7489: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8587 | Train F1: 0.7495 | Val Loss: 0.5376 | Val F1: 0.9004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1885: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.7176: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7549 | Train F1: 0.7966 | Val Loss: 0.5552 | Val F1: 0.9044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3589: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.6871: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7718 | Train F1: 0.7682 | Val Loss: 0.4730 | Val F1: 0.9272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9717: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.5108: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.6670 | Train F1: 0.8375 | Val Loss: 0.4862 | Val F1: 0.9270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3308: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.5690: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.6665 | Train F1: 0.8165 | Val Loss: 0.4959 | Val F1: 0.9289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9878: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.6170: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6271 | Train F1: 0.8665 | Val Loss: 0.4873 | Val F1: 0.9421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4172: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.7455: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6069 | Train F1: 0.8587 | Val Loss: 0.5201 | Val F1: 0.9229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5723: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.4302: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6336 | Train F1: 0.8273 | Val Loss: 0.4986 | Val F1: 0.9430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3547: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.4487: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6011 | Train F1: 0.8542 | Val Loss: 0.4631 | Val F1: 0.9538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4556: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3435: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6308 | Train F1: 0.8272 | Val Loss: 0.4690 | Val F1: 0.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3259: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3337: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6497 | Train F1: 0.8405 | Val Loss: 0.4437 | Val F1: 0.9549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.3271: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.4412: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.5881 | Train F1: 0.8853 | Val Loss: 0.4662 | Val F1: 0.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3264: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3412: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.5694 | Train F1: 0.8744 | Val Loss: 0.4519 | Val F1: 0.9614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1650: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3275: 100%|██████████| 32/32 [00:04<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.6454 | Train F1: 0.8161 | Val Loss: 0.4927 | Val F1: 0.9488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3232: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3282: 100%|██████████| 32/32 [00:04<00:00,  7.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5411 | Train F1: 0.8714 | Val Loss: 0.4800 | Val F1: 0.9607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8896: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 1.1989: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5745 | Train F1: 0.8706 | Val Loss: 0.5207 | Val F1: 0.9397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3677: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.5016: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5511 | Train F1: 0.8672 | Val Loss: 0.4456 | Val F1: 0.9620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3210: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3369: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5169 | Train F1: 0.8488 | Val Loss: 0.4305 | Val F1: 0.9602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3220: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3355: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5683 | Train F1: 0.8401 | Val Loss: 0.4336 | Val F1: 0.9678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3218: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3426: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5639 | Train F1: 0.8648 | Val Loss: 0.4350 | Val F1: 0.9568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3240: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3252: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5203 | Train F1: 0.8824 | Val Loss: 0.4100 | Val F1: 0.9719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3245: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3263: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.4866 | Train F1: 0.8653 | Val Loss: 0.4123 | Val F1: 0.9780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3218: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3345: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.5093 | Train F1: 0.8910 | Val Loss: 0.4099 | Val F1: 0.9639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7925: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3258: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5568 | Train F1: 0.8646 | Val Loss: 0.4036 | Val F1: 0.9702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9653: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3244: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5391 | Train F1: 0.8453 | Val Loss: 0.4167 | Val F1: 0.9688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3225: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3389: 100%|██████████| 32/32 [00:04<00:00,  6.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5041 | Train F1: 0.8739 | Val Loss: 0.4056 | Val F1: 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3225: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3227: 100%|██████████| 32/32 [00:04<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5275 | Train F1: 0.8671 | Val Loss: 0.4104 | Val F1: 0.9672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0977: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3260: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5382 | Train F1: 0.8414 | Val Loss: 0.4013 | Val F1: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3330: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3417: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.4922 | Train F1: 0.8824 | Val Loss: 0.4001 | Val F1: 0.9688\n",
      "\n",
      "🎯 Training hierarchical models for Fold 2\n",
      "🔍 Training Weak Detector - Fold 2\n",
      "🎯 Training Weak Specializer - Fold 2\n",
      "Fold 2 - Main F1: 0.9780, Detector F1: 0.9954, Specializer F1: 0.1111\n",
      "Fold 2 Best Validation F1: 0.9780\n",
      "\n",
      "==================================================\n",
      "FOLD 3/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0527: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3571: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.6058 | Train F1: 0.5124 | Val Loss: 0.7412 | Val F1: 0.8306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4146: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3401: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.9272 | Train F1: 0.7310 | Val Loss: 0.6023 | Val F1: 0.8758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6074: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3410: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8964 | Train F1: 0.7512 | Val Loss: 0.6490 | Val F1: 0.8640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6641: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3314: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.7792 | Train F1: 0.7743 | Val Loss: 0.5479 | Val F1: 0.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6318: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3408: 100%|██████████| 32/32 [00:04<00:00,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.7625 | Train F1: 0.8046 | Val Loss: 0.5314 | Val F1: 0.8890\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6201: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3353: 100%|██████████| 32/32 [00:04<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7642 | Train F1: 0.7808 | Val Loss: 0.4887 | Val F1: 0.9129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.3896: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3379: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7044 | Train F1: 0.8069 | Val Loss: 0.4767 | Val F1: 0.9329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3435: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3261: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7047 | Train F1: 0.8011 | Val Loss: 0.5180 | Val F1: 0.9207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5151: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3255: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6644 | Train F1: 0.8375 | Val Loss: 0.5134 | Val F1: 0.9166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8530: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3272: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6287 | Train F1: 0.8484 | Val Loss: 0.4420 | Val F1: 0.9399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3245: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3294: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6187 | Train F1: 0.8499 | Val Loss: 0.4697 | Val F1: 0.9387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3579: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3246: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6764 | Train F1: 0.7717 | Val Loss: 0.4516 | Val F1: 0.9478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1992: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3252: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6143 | Train F1: 0.8545 | Val Loss: 0.5215 | Val F1: 0.9240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3486: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3295: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6126 | Train F1: 0.8138 | Val Loss: 0.4473 | Val F1: 0.9577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3267: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.3262: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.5590 | Train F1: 0.8729 | Val Loss: 0.4191 | Val F1: 0.9621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 1.1885: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3225: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.6234 | Train F1: 0.8359 | Val Loss: 0.4444 | Val F1: 0.9455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3325: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3274: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.5807 | Train F1: 0.8715 | Val Loss: 0.4324 | Val F1: 0.9447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3447: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3256: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5510 | Train F1: 0.8754 | Val Loss: 0.4347 | Val F1: 0.9605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3237: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3245: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5948 | Train F1: 0.8393 | Val Loss: 0.4460 | Val F1: 0.9534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1514: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3227: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.6031 | Train F1: 0.8311 | Val Loss: 0.4075 | Val F1: 0.9552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3525: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3216: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5518 | Train F1: 0.8559 | Val Loss: 0.4092 | Val F1: 0.9618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3721: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3211: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5402 | Train F1: 0.8879 | Val Loss: 0.4748 | Val F1: 0.9490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3840: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3219: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5510 | Train F1: 0.8716 | Val Loss: 0.3967 | Val F1: 0.9650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3213: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3219: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5230 | Train F1: 0.8631 | Val Loss: 0.4194 | Val F1: 0.9585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3228: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3209: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5309 | Train F1: 0.8737 | Val Loss: 0.4028 | Val F1: 0.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3245: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.3211: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.5135 | Train F1: 0.8646 | Val Loss: 0.3978 | Val F1: 0.9676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0527: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5612 | Train F1: 0.8247 | Val Loss: 0.4022 | Val F1: 0.9650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3267: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.3212: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5544 | Train F1: 0.8519 | Val Loss: 0.4183 | Val F1: 0.9641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3223: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3211: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5030 | Train F1: 0.9169 | Val Loss: 0.3869 | Val F1: 0.9761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3354: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5464 | Train F1: 0.8968 | Val Loss: 0.4020 | Val F1: 0.9716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.8203: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3210: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5316 | Train F1: 0.8581 | Val Loss: 0.3992 | Val F1: 0.9730\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3906: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3207: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.4707 | Train F1: 0.9128 | Val Loss: 0.4056 | Val F1: 0.9699\n",
      "\n",
      "🎯 Training hierarchical models for Fold 3\n",
      "🔍 Training Weak Detector - Fold 3\n",
      "🎯 Training Weak Specializer - Fold 3\n",
      "Fold 3 - Main F1: 0.9761, Detector F1: 0.9908, Specializer F1: 0.1111\n",
      "Fold 3 Best Validation F1: 0.9761\n",
      "\n",
      "==================================================\n",
      "FOLD 4/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7515: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.5872: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.6703 | Train F1: 0.4796 | Val Loss: 0.8408 | Val F1: 0.7728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9136: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.8947: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.9401 | Train F1: 0.7203 | Val Loss: 0.6568 | Val F1: 0.8409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4009: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3540: 100%|██████████| 32/32 [00:04<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8775 | Train F1: 0.7377 | Val Loss: 0.6558 | Val F1: 0.8316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3550: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.5864: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8282 | Train F1: 0.7890 | Val Loss: 0.6810 | Val F1: 0.8337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7236: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3700: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.8120 | Train F1: 0.7658 | Val Loss: 0.5721 | Val F1: 0.8743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.8789: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.6343: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7304 | Train F1: 0.7806 | Val Loss: 0.5638 | Val F1: 0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3325: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.8095: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7201 | Train F1: 0.7922 | Val Loss: 0.5584 | Val F1: 0.8981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3936: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.7419: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.7064 | Train F1: 0.7799 | Val Loss: 0.5345 | Val F1: 0.9139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4014: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.4469: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6124 | Train F1: 0.8678 | Val Loss: 0.5756 | Val F1: 0.9195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3735: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.6759: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6746 | Train F1: 0.8280 | Val Loss: 0.5809 | Val F1: 0.9095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3281: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.6410: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6017 | Train F1: 0.8662 | Val Loss: 0.5232 | Val F1: 0.9356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3428: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3633: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.6477 | Train F1: 0.8187 | Val Loss: 0.4860 | Val F1: 0.9214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4609: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.7144: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.6437 | Train F1: 0.8516 | Val Loss: 0.5275 | Val F1: 0.9330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4392: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3323: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.6030 | Train F1: 0.8431 | Val Loss: 0.4550 | Val F1: 0.9519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3704: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.3326: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.6383 | Train F1: 0.7961 | Val Loss: 0.4668 | Val F1: 0.9490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3257: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3276: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.5153 | Train F1: 0.8691 | Val Loss: 0.4853 | Val F1: 0.9363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0801: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3251: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.5708 | Train F1: 0.8666 | Val Loss: 0.4391 | Val F1: 0.9682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3228: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.6521: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.5772 | Train F1: 0.8417 | Val Loss: 0.4993 | Val F1: 0.9394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.6606: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3283: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5606 | Train F1: 0.8767 | Val Loss: 0.4486 | Val F1: 0.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3271: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3406: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5535 | Train F1: 0.8307 | Val Loss: 0.4588 | Val F1: 0.9483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4321: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.4212: 100%|██████████| 32/32 [00:04<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.6009 | Train F1: 0.8164 | Val Loss: 0.4669 | Val F1: 0.9434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3271: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3236: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.5360 | Train F1: 0.8589 | Val Loss: 0.4540 | Val F1: 0.9444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3225: 100%|██████████| 126/126 [00:22<00:00,  5.49it/s]\n",
      "Val Loss: 0.3288: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5145 | Train F1: 0.8683 | Val Loss: 0.4448 | Val F1: 0.9520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3206: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3228: 100%|██████████| 32/32 [00:04<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5218 | Train F1: 0.8501 | Val Loss: 0.4281 | Val F1: 0.9560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5498: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3231: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.4918 | Train F1: 0.9021 | Val Loss: 0.4314 | Val F1: 0.9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3238: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.4955 | Train F1: 0.8967 | Val Loss: 0.4306 | Val F1: 0.9511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3215: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3255: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5247 | Train F1: 0.8415 | Val Loss: 0.4303 | Val F1: 0.9486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3218: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3220: 100%|██████████| 32/32 [00:04<00:00,  6.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.5254 | Train F1: 0.8629 | Val Loss: 0.4268 | Val F1: 0.9538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2783: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3595: 100%|██████████| 32/32 [00:04<00:00,  6.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5192 | Train F1: 0.8592 | Val Loss: 0.4362 | Val F1: 0.9528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2920: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3363: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.5747 | Train F1: 0.8081 | Val Loss: 0.4339 | Val F1: 0.9569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4424: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3228: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5102 | Train F1: 0.8646 | Val Loss: 0.4401 | Val F1: 0.9545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9141: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3236: 100%|██████████| 32/32 [00:04<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.5190 | Train F1: 0.8670 | Val Loss: 0.4259 | Val F1: 0.9615\n",
      "\n",
      "🎯 Training hierarchical models for Fold 4\n",
      "🔍 Training Weak Detector - Fold 4\n",
      "🎯 Training Weak Specializer - Fold 4\n",
      "Fold 4 - Main F1: 0.9682, Detector F1: 0.9860, Specializer F1: 0.1111\n",
      "Fold 4 Best Validation F1: 0.9682\n",
      "\n",
      "==================================================\n",
      "FOLD 5/5\n",
      "==================================================\n",
      "Train samples: 1256, Validation samples: 314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5859: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.9167: 100%|██████████| 32/32 [00:04<00:00,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1 | Train Loss: 1.6804 | Train F1: 0.4430 | Val Loss: 0.9331 | Val F1: 0.7017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6675: 100%|██████████| 126/126 [00:22<00:00,  5.50it/s]\n",
      "Val Loss: 0.9794: 100%|██████████| 32/32 [00:04<00:00,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  2 | Train Loss: 0.9862 | Train F1: 0.7099 | Val Loss: 0.7033 | Val F1: 0.8416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6826: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.5745: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  3 | Train Loss: 0.8527 | Train F1: 0.7666 | Val Loss: 0.6222 | Val F1: 0.8569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 2.0586: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.4539: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  4 | Train Loss: 0.8180 | Train F1: 0.7711 | Val Loss: 0.5215 | Val F1: 0.9084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3613: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.5161: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  5 | Train Loss: 0.6951 | Train F1: 0.8197 | Val Loss: 0.5153 | Val F1: 0.9333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4590: 100%|██████████| 126/126 [00:23<00:00,  5.44it/s]\n",
      "Val Loss: 0.6165: 100%|██████████| 32/32 [00:04<00:00,  6.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  6 | Train Loss: 0.7197 | Train F1: 0.8032 | Val Loss: 0.5236 | Val F1: 0.9030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.9463: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.8995: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  7 | Train Loss: 0.7733 | Train F1: 0.8174 | Val Loss: 0.5775 | Val F1: 0.8886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.7046: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.4733: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  8 | Train Loss: 0.6928 | Train F1: 0.8204 | Val Loss: 0.4924 | Val F1: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1035: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.4312: 100%|██████████| 32/32 [00:04<00:00,  6.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  9 | Train Loss: 0.6995 | Train F1: 0.8187 | Val Loss: 0.5168 | Val F1: 0.9298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3669: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.6621: 100%|██████████| 32/32 [00:04<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 0.6591 | Train F1: 0.8259 | Val Loss: 0.5098 | Val F1: 0.9312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3645: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3564: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 0.6078 | Train F1: 0.8467 | Val Loss: 0.5095 | Val F1: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.4192: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3379: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 0.5939 | Train F1: 0.8664 | Val Loss: 0.5018 | Val F1: 0.9409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3381: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3565: 100%|██████████| 32/32 [00:04<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 0.5703 | Train F1: 0.8702 | Val Loss: 0.4973 | Val F1: 0.9339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.5371: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 1.2666: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 0.5717 | Train F1: 0.8650 | Val Loss: 0.5319 | Val F1: 0.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3467: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3722: 100%|██████████| 32/32 [00:04<00:00,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 0.5655 | Train F1: 0.8481 | Val Loss: 0.4881 | Val F1: 0.9402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3337: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3905: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 0.5682 | Train F1: 0.8567 | Val Loss: 0.5292 | Val F1: 0.9199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3232: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3265: 100%|██████████| 32/32 [00:04<00:00,  6.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 0.5306 | Train F1: 0.8634 | Val Loss: 0.5328 | Val F1: 0.9313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3303: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 0.8505: 100%|██████████| 32/32 [00:04<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 0.6168 | Train F1: 0.8436 | Val Loss: 0.5036 | Val F1: 0.9416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.6362: 100%|██████████| 126/126 [00:23<00:00,  5.48it/s]\n",
      "Val Loss: 1.4116: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 0.5150 | Train F1: 0.8920 | Val Loss: 0.5220 | Val F1: 0.9420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3240: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3844: 100%|██████████| 32/32 [00:04<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 0.5453 | Train F1: 0.8648 | Val Loss: 0.4875 | Val F1: 0.9466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3240: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3264: 100%|██████████| 32/32 [00:04<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 | Train Loss: 0.5072 | Train F1: 0.8694 | Val Loss: 0.4891 | Val F1: 0.9491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3218: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.5431: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 | Train Loss: 0.4876 | Train F1: 0.9073 | Val Loss: 0.4764 | Val F1: 0.9467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3433: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3218: 100%|██████████| 32/32 [00:04<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 | Train Loss: 0.5381 | Train F1: 0.8967 | Val Loss: 0.4665 | Val F1: 0.9589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.7305: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3386: 100%|██████████| 32/32 [00:04<00:00,  6.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 | Train Loss: 0.5211 | Train F1: 0.8698 | Val Loss: 0.4666 | Val F1: 0.9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3965: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3226: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 | Train Loss: 0.5887 | Train F1: 0.8015 | Val Loss: 0.4695 | Val F1: 0.9493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3220: 100%|██████████| 126/126 [00:23<00:00,  5.46it/s]\n",
      "Val Loss: 0.3268: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 | Train Loss: 0.5585 | Train F1: 0.8494 | Val Loss: 0.4723 | Val F1: 0.9598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.9551: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3675: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 | Train Loss: 0.5673 | Train F1: 0.8188 | Val Loss: 0.4521 | Val F1: 0.9658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.3245: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.6204: 100%|██████████| 32/32 [00:04<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 | Train Loss: 0.4954 | Train F1: 0.8686 | Val Loss: 0.4839 | Val F1: 0.9481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3228: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3262: 100%|██████████| 32/32 [00:04<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 | Train Loss: 0.5457 | Train F1: 0.8703 | Val Loss: 0.4569 | Val F1: 0.9658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3210: 100%|██████████| 126/126 [00:22<00:00,  5.48it/s]\n",
      "Val Loss: 0.3492: 100%|██████████| 32/32 [00:04<00:00,  6.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 | Train Loss: 0.4877 | Train F1: 0.8921 | Val Loss: 0.4558 | Val F1: 0.9540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.3208: 100%|██████████| 126/126 [00:23<00:00,  5.47it/s]\n",
      "Val Loss: 0.3225: 100%|██████████| 32/32 [00:04<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31 | Train Loss: 0.5345 | Train F1: 0.8533 | Val Loss: 0.4575 | Val F1: 0.9614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 0.4546: 100%|██████████| 126/126 [00:23<00:00,  5.45it/s]\n",
      "Val Loss: 0.3243: 100%|██████████| 32/32 [00:04<00:00,  6.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32 | Train Loss: 0.5152 | Train F1: 0.8568 | Val Loss: 0.4808 | Val F1: 0.9525\n",
      "\n",
      "🎯 Training hierarchical models for Fold 5\n",
      "🔍 Training Weak Detector - Fold 5\n",
      "🎯 Training Weak Specializer - Fold 5\n",
      "Fold 5 - Main F1: 0.9658, Detector F1: 0.9954, Specializer F1: 0.1111\n",
      "Fold 5 Best Validation F1: 0.9658\n"
     ]
    }
   ],
   "source": [
    "# K-Fold 설정\n",
    "N_FOLDS = 5  # 5-fold로 설정 (데이터가 적으므로)\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# 클래스별 최소 샘플 보장 확인\n",
    "# for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "#     assert len(np.unique(train_df.iloc[val_idx]['target'])) == 17\n",
    "\n",
    "# 전체 학습 데이터 로드\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# K-Fold 결과를 저장할 리스트\n",
    "fold_results = []\n",
    "fold_models = []  # 각 fold의 최고 성능 모델을 저장\n",
    "fold_class_accuracies = [] # 각 fold의 클래스별 정확도 저장\n",
    "detector_models = []      #  각 fold의 탐지기 모델 저장\n",
    "specializer_models = []   #  각 fold의 전용 분류기 모델 저장\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation...\")\n",
    "\n",
    "# LR = best_params['lr']\n",
    "# BATCH_SIZE = best_params['batch_size']\n",
    "\n",
    "# K-Fold Cross Validation 시작\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    current_model = model_name\n",
    "    \n",
    "    # 현재 fold의 train/validation 데이터 분할\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 현재 fold의 Dataset 생성\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=trn_transform\n",
    "        epoch=0,  # 현재 epoch 전달\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        # transform=tst_transform  # 검증에는 증강 적용 안함\n",
    "        epoch=0,  # validation은 epoch 관계없음\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False  # validation이므로 hard augmentation 비활성화\n",
    "    )\n",
    "    \n",
    "    # 현재 fold의 DataLoader 생성\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # 모델 초기화 (각 fold마다 새로운 모델)\n",
    "    model = timm.create_model(\n",
    "        current_model,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)  # Label Smoothing 적용\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler 추가\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # 현재 fold의 최고 성능 추적\n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # 현재 fold 학습\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # Scheduler step 추가\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            \n",
    "            # Best 모델 분석\n",
    "            model.eval()\n",
    "            val_preds, val_targets = [], []\n",
    "            with torch.no_grad():\n",
    "                for image, targets in val_loader:\n",
    "                    preds = model(image.to(device)).argmax(dim=1)\n",
    "                    val_preds.extend(preds.cpu().numpy())\n",
    "                    val_targets.extend(targets.numpy())\n",
    "            \n",
    "            # 클래스별 정확도\n",
    "            fold_class_acc = {}\n",
    "            for c in range(17):\n",
    "                mask = np.array(val_targets) == c\n",
    "                if mask.sum() > 0:\n",
    "                    fold_class_acc[c] = (np.array(val_preds)[mask] == c).mean()\n",
    "    \n",
    "    print(f\"\\n🎯 Training hierarchical models for Fold {fold + 1}\")\n",
    "    \n",
    "    # 취약 클래스 탐지기 훈련\n",
    "    detector_state, detector_f1 = train_weak_detector_fold(\n",
    "        train_fold_df, val_fold_df, fold, device, \"../data/train/\"\n",
    "    )\n",
    "\n",
    "    # 취약 클래스 전용 분류기 훈련  \n",
    "    specializer_state, specializer_f1 = train_weak_specializer_fold(\n",
    "        train_fold_df, val_fold_df, fold, device, \"../data/train/\"\n",
    "    )\n",
    "    \n",
    "    # 계층적 모델 결과 저장\n",
    "    detector_models.append(detector_state)\n",
    "    specializer_models.append(specializer_state)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} - Main F1: {best_val_f1:.4f}, Detector F1: {detector_f1:.4f}, Specializer F1: {specializer_f1:.4f}\")\n",
    "\n",
    "    # 현재 fold 결과 저장 \n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'detector_f1': detector_f1,        # 새로 추가\n",
    "        'specializer_f1': specializer_f1,  # 새로 추가\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset)\n",
    "    })\n",
    "    \n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "    \n",
    "    fold_class_accuracies.append(fold_class_acc) # 각 fold의 클래스별 정확도 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "K-FOLD CROSS VALIDATION RESULTS\n",
      "============================================================\n",
      "Fold 1: 0.9734\n",
      "Fold 2: 0.9780\n",
      "Fold 3: 0.9761\n",
      "Fold 4: 0.9682\n",
      "Fold 5: 0.9658\n",
      "\n",
      "Mean CV F1: 0.9723 ± 0.0046\n",
      "Best single fold: 0.9780\n"
     ]
    }
   ],
   "source": [
    "# K-Fold 결과 요약\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"K-FOLD CROSS VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(val_f1_scores):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worst 3 classes:\n",
      "Class 3: 78.0%\n",
      "Class 7: 80.0%\n",
      "Class 14: 80.0%\n"
     ]
    }
   ],
   "source": [
    "# 클래스별 성능 시각화\n",
    "meta_df = pd.read_csv(\"../data/meta.csv\")\n",
    "avg_acc = {c: np.mean([f.get(c,0) for f in fold_class_accuracies]) for c in range(17)}\n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "classes = list(avg_acc.keys())\n",
    "accs = [avg_acc[c] * 100 for c in classes]\n",
    "names = [f\"C{c}\" for c in classes]\n",
    "\n",
    "plt.bar(range(17), accs)\n",
    "plt.xticks(range(17), names)\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Class-wise Prediction Accuracy')\n",
    "for i, acc in enumerate(accs):\n",
    "    plt.text(i, acc + 1, f'{acc:.1f}%', ha='center', fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Worst 3 classes:\")\n",
    "worst = sorted(avg_acc.items(), key=lambda x: x[1])[:3]\n",
    "for c, acc in worst:\n",
    "    print(f\"Class {c}: {acc*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장 - 현재 상태 그대로 저장\n",
    "def save_models():\n",
    "    \"\"\"학습한 모델들을 저장\"\"\"\n",
    "    \n",
    "    # 저장 디렉토리 생성\n",
    "    save_dir = \"models\"\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    print(\"🚨 모델 저장 시작...\")\n",
    "    \n",
    "    # 각 fold별 모델 저장 (fold_models 리스트가 있다고 가정)\n",
    "    try:\n",
    "        for fold in range(5):  # 5-fold라고 가정\n",
    "            model_path = f\"{save_dir}/fold_{fold}_model_{timestamp}.pth\"\n",
    "            \n",
    "            # fold_models[fold]가 존재한다면 저장\n",
    "            if 'fold_models' in globals() and len(fold_models) > fold:\n",
    "                torch.save({\n",
    "                    'model_state_dict': fold_models[fold].state_dict(),\n",
    "                    'fold': fold,\n",
    "                    'timestamp': timestamp,\n",
    "                    'epoch': 'unknown',  # 에포크 정보 모르면 unknown\n",
    "                }, model_path)\n",
    "                print(f\"✅ Fold {fold} 모델 저장 완료: {model_path}\")\n",
    "            \n",
    "            # 또는 best_models 리스트가 있다면\n",
    "            elif 'best_models' in globals() and len(best_models) > fold:\n",
    "                torch.save({\n",
    "                    'model_state_dict': best_models[fold].state_dict(),\n",
    "                    'fold': fold,\n",
    "                    'timestamp': timestamp,\n",
    "                    'epoch': 'unknown',\n",
    "                }, model_path)\n",
    "                print(f\"✅ Fold {fold} best 모델 저장 완료: {model_path}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Fold별 저장 실패: {e}\")\n",
    "    \n",
    "    # 전체 변수 상태 저장 (혹시 모르니까)\n",
    "    try:\n",
    "        state_path = f\"{save_dir}/full_state_{timestamp}.pth\"\n",
    "        \n",
    "        # 현재 글로벌 변수에서 모델 관련 객체들 찾아서 저장\n",
    "        save_dict = {}\n",
    "        \n",
    "        # 가능한 모델 변수명들 체크\n",
    "        possible_model_vars = ['model', 'models', 'fold_models', 'best_models', \n",
    "                              'tta_models', 'ensemble_models']\n",
    "        \n",
    "        for var_name in possible_model_vars:\n",
    "            if var_name in globals():\n",
    "                save_dict[var_name] = globals()[var_name]\n",
    "                print(f\"✅ {var_name} 변수 포함됨\")\n",
    "        \n",
    "        if save_dict:\n",
    "            torch.save(save_dict, state_path)\n",
    "            print(f\"✅ 전체 상태 저장 완료: {state_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 전체 상태 저장 실패: {e}\")\n",
    "    \n",
    "    print(f\"🎉 저장 완료! 저장 위치: {save_dir}/\")\n",
    "    print(f\"📁 파일 목록:\")\n",
    "    for file in os.listdir(save_dir):\n",
    "        print(f\"   - {file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚨 모델 저장 시작...\n",
      "❌ Fold별 저장 실패: 'collections.OrderedDict' object has no attribute 'state_dict'\n",
      "✅ model 변수 포함됨\n",
      "✅ fold_models 변수 포함됨\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 전체 상태 저장 완료: models/full_state_20250911_051817.pth\n",
      "🎉 저장 완료! 저장 위치: models/\n",
      "📁 파일 목록:\n",
      "   - full_state_20250911_015439.pth\n",
      "   - full_state_20250911_051817.pth\n",
      "   - full_state_20250910_113123.pth\n"
     ]
    }
   ],
   "source": [
    "save_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ensemble of all 5 fold models for inference\n"
     ]
    }
   ],
   "source": [
    "# 5-Fold 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "print(f\"Using ensemble of all {len(ensemble_models)} fold models for inference\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Nmm5h3J-pXNV"
   },
   "source": [
    "## 5. Train Model\n",
    "* 모델을 로드하고, 학습을 진행합니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "lkwxRXoBpbaX"
   },
   "source": [
    "# 6. Inference & Save File\n",
    "* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature Scaling 클래스 정의\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * 1.5)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_tta_transforms = [\n",
    "    # 원본\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TTA 추론을 위한 Dataset 클래스\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # 여러 transform을 리스트로 받음\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # 모든 transform을 적용한 결과를 리스트로 반환\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA Dataset size: 3140\n"
     ]
    }
   ],
   "source": [
    "# TTA Dataset 생성\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (배치 크기를 줄여서 메모리 절약)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=64,  # TTA는 메모리를 많이 사용하므로 배치 크기 줄임\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"TTA Dataset size: {len(tta_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_tta_inference(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold 모델 앙상블 + TTA 추론\"\"\"\n",
    "    all_predictions = []\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # 각 fold 모델별 예측\n",
    "        for model in models:\n",
    "            with torch.no_grad():\n",
    "                # 각 TTA 변형별 예측\n",
    "                for images in images_list:\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계층적 TTA 추론 함수\n",
    "def hierarchical_tta_inference(main_models, detector_models, specializer_models, loader, device):\n",
    "    \"\"\"계층적 모델들을 사용한 TTA 추론\"\"\"\n",
    "    print(\"🎯 Starting Hierarchical TTA Inference...\")\n",
    "    \n",
    "    n_folds = len(main_models)\n",
    "    fold_predictions = []\n",
    "    total_stats = {\n",
    "        'total_samples': 0,\n",
    "        'total_detection_needed': 0,\n",
    "        'total_specializer_used': 0\n",
    "    }\n",
    "    \n",
    "    for fold in range(n_folds):\n",
    "        print(f\"Processing Hierarchical Fold {fold + 1}/{n_folds}...\")\n",
    "        \n",
    "        # 계층적 분류기 구성\n",
    "        hierarchical_model = HierarchicalDocumentClassifier(main_model_name=model_name)\n",
    "        \n",
    "        # 메인 모델 로드 (기존 fold_models의 state_dict 사용)\n",
    "        hierarchical_model.main_classifier.load_state_dict(main_models[fold])\n",
    "        \n",
    "        # 탐지기와 전용 분류기 로드\n",
    "        if detector_models[fold] is not None:\n",
    "            try:\n",
    "                hierarchical_model.weak_detector.load_state_dict(detector_models[fold])\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to load detector for fold {fold}: {e}\")\n",
    "                # 백업 방법: 새 모델 생성해서 로드\n",
    "                temp_detector = WeakClassDetector().to(device)\n",
    "                temp_detector.load_state_dict(detector_models[fold])\n",
    "                hierarchical_model.weak_detector = temp_detector\n",
    "                \n",
    "        if specializer_models[fold] is not None:\n",
    "            try:\n",
    "                hierarchical_model.weak_specializer.load_state_dict(specializer_models[fold])\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Failed to load specializer for fold {fold}: {e}\")\n",
    "                # 백업 방법: 새 모델 생성해서 로드\n",
    "                temp_specializer = WeakClassSpecializer().to(device)\n",
    "                temp_specializer.load_state_dict(specializer_models[fold])\n",
    "                hierarchical_model.weak_specializer = temp_specializer\n",
    "            \n",
    "        hierarchical_model.eval()\n",
    "        hierarchical_model.to(device)\n",
    "        \n",
    "        fold_preds = []\n",
    "        fold_stats = {'detection_needed': 0, 'total': 0}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=f\"Hierarchical Fold {fold+1}\")):\n",
    "                batch_size = images_list[0].size(0)\n",
    "                batch_ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "                \n",
    "                # 각 TTA 변형에 대해 계층적 추론\n",
    "                for tta_idx, images in enumerate(images_list):\n",
    "                    images = images.to(device)\n",
    "                    \n",
    "                    # 조건부 계층적 추론 사용\n",
    "                    probs = hierarchical_model(images, mode='inference')\n",
    "                    batch_ensemble_probs += probs / len(images_list)\n",
    "                    \n",
    "                    # 통계 수집 (첫 번째 TTA에서만)\n",
    "                    if tta_idx == 0:  # 첫 번째 TTA 변형에서만 통계 수집\n",
    "                        stats = hierarchical_model.get_inference_stats(images)\n",
    "                        fold_stats['detection_needed'] += stats['detection_needed']\n",
    "                        fold_stats['total'] += stats['total_samples']\n",
    "                \n",
    "                final_preds = torch.argmax(batch_ensemble_probs, dim=1)\n",
    "                fold_preds.extend(final_preds.cpu().numpy())\n",
    "        \n",
    "        # 폴드 통계 출력- ZeroDivisionError 방지\n",
    "        if fold_stats['total'] > 0:\n",
    "            detection_ratio = fold_stats['detection_needed'] / fold_stats['total']\n",
    "            print(f\"  Fold {fold+1} - Detection needed: {fold_stats['detection_needed']}/{fold_stats['total']} ({detection_ratio:.1%})\")\n",
    "        else:\n",
    "            print(f\"  Fold {fold+1} - No samples processed (possible issue with stats collection)\")\n",
    "        \n",
    "        total_stats['total_samples'] += fold_stats['total']\n",
    "        total_stats['total_detection_needed'] += fold_stats['detection_needed']\n",
    "        \n",
    "        fold_predictions.append(fold_preds)\n",
    "    \n",
    "    # 전체 통계 출력\n",
    "    overall_detection_ratio = total_stats['total_detection_needed'] / total_stats['total_samples']\n",
    "    print(f\"\\n📊 Overall Detection Statistics:\")\n",
    "    print(f\"  Total samples: {total_stats['total_samples']}\")\n",
    "    print(f\"  Detection needed: {total_stats['total_detection_needed']} ({overall_detection_ratio:.1%})\")\n",
    "    print(f\"  Efficiency gain: {1-overall_detection_ratio:.1%} samples skipped detection\")\n",
    "    \n",
    "    # Fold 앙상블 (다수결)\n",
    "    final_predictions = []\n",
    "    for i in range(len(fold_predictions[0])):\n",
    "        votes = [fold_preds[i] for fold_preds in fold_predictions]\n",
    "        final_pred = Counter(votes).most_common(1)[0][0]\n",
    "        final_predictions.append(final_pred)\n",
    "    \n",
    "    return final_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Original Ensemble TTA inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 50/50 [16:36<00:00, 19.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting Hierarchical Ensemble TTA inference...\n",
      "🎯 Starting Hierarchical TTA Inference...\n",
      "Processing Hierarchical Fold 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hierarchical Fold 1: 100%|██████████| 50/50 [04:41<00:00,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 1 - Detection needed: 311/3140 (9.9%)\n",
      "Processing Hierarchical Fold 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hierarchical Fold 2: 100%|██████████| 50/50 [04:29<00:00,  5.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 2 - Detection needed: 382/3140 (12.2%)\n",
      "Processing Hierarchical Fold 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hierarchical Fold 3: 100%|██████████| 50/50 [04:26<00:00,  5.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 3 - Detection needed: 357/3140 (11.4%)\n",
      "Processing Hierarchical Fold 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hierarchical Fold 4: 100%|██████████| 50/50 [04:43<00:00,  5.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 4 - Detection needed: 494/3140 (15.7%)\n",
      "Processing Hierarchical Fold 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hierarchical Fold 5: 100%|██████████| 50/50 [04:23<00:00,  5.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Fold 5 - Detection needed: 348/3140 (11.1%)\n",
      "\n",
      "📊 Overall Detection Statistics:\n",
      "  Total samples: 15700\n",
      "  Detection needed: 1892 (12.1%)\n",
      "  Efficiency gain: 87.9% samples skipped detection\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 앙상블 TTA 실행 (기존 방법)\n",
    "print(\"Starting Original Ensemble TTA inference...\")\n",
    "tta_predictions = ensemble_tta_inference(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")\n",
    "\n",
    "# 계층적 앙상블 TTA 추가 실행\n",
    "print(\"\\nStarting Hierarchical Ensemble TTA inference...\")\n",
    "\n",
    "# 기존 모델들의 state_dict 추출\n",
    "main_model_states = [model.state_dict() for model in ensemble_models]\n",
    "\n",
    "hierarchical_predictions = hierarchical_tta_inference(\n",
    "    main_models=main_model_states,\n",
    "    detector_models=detector_models,\n",
    "    specializer_models=specializer_models,\n",
    "    loader=tta_loader,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Prediction Comparison:\n",
      "Original unique predictions: 17\n",
      "Hierarchical unique predictions: 17\n",
      "Prediction agreement: 3033/3140 (96.6%)\n",
      "Original weak class predictions: 688\n",
      "Hierarchical weak class predictions: 694\n",
      "Disagreement count: 107 samples\n",
      "Disagreement examples (first 10):\n",
      "  Sample 16: Original=4, Hierarchical=3\n",
      "  Sample 26: Original=7, Hierarchical=3\n",
      "  Sample 70: Original=14, Hierarchical=3\n",
      "  Sample 74: Original=7, Hierarchical=3\n",
      "  Sample 83: Original=7, Hierarchical=3\n",
      "  Sample 94: Original=7, Hierarchical=3\n",
      "  Sample 101: Original=7, Hierarchical=3\n",
      "  Sample 131: Original=4, Hierarchical=3\n",
      "  Sample 231: Original=7, Hierarchical=3\n",
      "  Sample 276: Original=4, Hierarchical=3\n",
      "✅ Both submissions saved:\n",
      "   - original_choice.csv (기존 방법)\n",
      "   - hierarchical_choice.csv (계층적 방법)\n",
      "\n",
      "📊 Final Analysis:\n",
      "Total test samples: 3140\n",
      "\n",
      "📋 클래스별 예측 분포 비교:\n",
      "  📋 Class 0: Original=200, Hierarchical=200, Diff=+0\n",
      "  📋 Class 1: Original=88, Hierarchical=88, Diff=+0\n",
      "  📋 Class 2: Original=200, Hierarchical=200, Diff=+0\n",
      "  🎯 Class 3: Original=210, Hierarchical=298, Diff=+88\n",
      "  🎯 Class 4: Original=205, Hierarchical=183, Diff=-22\n",
      "  📋 Class 5: Original=200, Hierarchical=200, Diff=+0\n",
      "  📋 Class 6: Original=208, Hierarchical=206, Diff=-2\n",
      "  🎯 Class 7: Original=193, Hierarchical=153, Diff=-40\n",
      "  📋 Class 8: Original=200, Hierarchical=200, Diff=+0\n",
      "  📋 Class 9: Original=200, Hierarchical=200, Diff=+0\n",
      "  📋 Class 10: Original=208, Hierarchical=206, Diff=-2\n",
      "  📋 Class 11: Original=191, Hierarchical=191, Diff=+0\n",
      "  📋 Class 12: Original=204, Hierarchical=201, Diff=-3\n",
      "  📋 Class 13: Original=153, Hierarchical=154, Diff=+1\n",
      "  🎯 Class 14: Original=80, Hierarchical=60, Diff=-20\n",
      "  📋 Class 15: Original=200, Hierarchical=200, Diff=+0\n",
      "  📋 Class 16: Original=200, Hierarchical=200, Diff=+0\n",
      "\n",
      "Hierarchical TTA Prediction sample:\n",
      "                     ID  target\n",
      "0  0008fdb22ddce0ce.jpg       2\n",
      "1  00091bffdffd83de.jpg      12\n",
      "2  00396fbc1f6cc21d.jpg       5\n",
      "3  00471f8038d9c4b6.jpg      12\n",
      "4  00901f504008d884.jpg       2\n"
     ]
    }
   ],
   "source": [
    "# 결과 비교 분석\n",
    "print(f\"\\n📊 Prediction Comparison:\")\n",
    "print(f\"Original unique predictions: {len(set(tta_predictions))}\")\n",
    "print(f\"Hierarchical unique predictions: {len(set(hierarchical_predictions))}\")\n",
    "\n",
    "# 예측 일치도 분석\n",
    "agreement_count = sum(1 for i, j in zip(tta_predictions, hierarchical_predictions) if i == j)\n",
    "total_count = len(tta_predictions)\n",
    "agreement_ratio = agreement_count / total_count\n",
    "\n",
    "print(f\"Prediction agreement: {agreement_count}/{total_count} ({agreement_ratio:.1%})\")\n",
    "\n",
    "# 취약 클래스 예측 분석\n",
    "weak_classes = [3, 4, 7, 14]\n",
    "original_weak_count = sum(1 for p in tta_predictions if p in weak_classes)\n",
    "hierarchical_weak_count = sum(1 for p in hierarchical_predictions if p in weak_classes)\n",
    "\n",
    "print(f\"Original weak class predictions: {original_weak_count}\")\n",
    "print(f\"Hierarchical weak class predictions: {hierarchical_weak_count}\")\n",
    "\n",
    "# 차이점 분석\n",
    "disagreement_indices = [i for i, (orig, hier) in enumerate(zip(tta_predictions, hierarchical_predictions)) if orig != hier]\n",
    "print(f\"Disagreement count: {len(disagreement_indices)} samples\")\n",
    "\n",
    "if len(disagreement_indices) > 0:\n",
    "    print(\"Disagreement examples (first 10):\")\n",
    "    for i in disagreement_indices[:10]:\n",
    "        print(f\"  Sample {i}: Original={tta_predictions[i]}, Hierarchical={hierarchical_predictions[i]}\")\n",
    "\n",
    "# 원본 TTA 결과로 submission 파일 생성\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions\n",
    "\n",
    "# 계층적 TTA 결과로 submission 파일 생성\n",
    "hierarchical_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "hierarchical_pred_df['target'] = hierarchical_predictions\n",
    "\n",
    "# 기존 submission과 동일한 순서인지 확인\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all()\n",
    "assert (sample_submission_df['ID'] == hierarchical_pred_df['ID']).all()\n",
    "\n",
    "# 두 결과 모두 저장\n",
    "tta_pred_df.to_csv(\"../submission/original_choice.csv\", index=False)\n",
    "hierarchical_pred_df.to_csv(\"../submission/hierarchical_choice.csv\", index=False)\n",
    "\n",
    "print(\"✅ Both submissions saved:\")\n",
    "print(\"   - original_choice.csv (기존 방법)\")\n",
    "print(\"   - hierarchical_choice.csv (계층적 방법)\")\n",
    "\n",
    "# 최종 분석\n",
    "print(f\"\\n📊 Final Analysis:\")\n",
    "print(f\"Total test samples: {len(hierarchical_predictions)}\")\n",
    "\n",
    "# 클래스별 예측 분포 비교\n",
    "original_dist = Counter(tta_predictions)\n",
    "hierarchical_dist = Counter(hierarchical_predictions)\n",
    "\n",
    "print(f\"\\n📋 클래스별 예측 분포 비교:\")\n",
    "for cls in sorted(set(list(original_dist.keys()) + list(hierarchical_dist.keys()))):\n",
    "    orig_count = original_dist.get(cls, 0)\n",
    "    hier_count = hierarchical_dist.get(cls, 0)\n",
    "    diff = hier_count - orig_count\n",
    "    marker = \"🎯\" if cls in [3, 4, 7, 14] else \"📋\"\n",
    "    print(f\"  {marker} Class {cls}: Original={orig_count}, Hierarchical={hier_count}, Diff={diff:+d}\")\n",
    "\n",
    "print(\"\\nHierarchical TTA Prediction sample:\")\n",
    "print(hierarchical_pred_df.head())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
