{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bbe02e",
   "metadata": {},
   "source": [
    "# 📄 Document type classification baseline code with WandB Integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dc69ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 0. Prepare Environments & Install Libraries\n",
    "# =============================================================================\n",
    "\n",
    "# 필요한 라이브러리를 설치합니다.\n",
    "#!pip install -r ../requirements.txt\n",
    "#!pip install transformers==4.44.0\n",
    "#!pip install easyocr\n",
    "#!pip install datasets\n",
    "#!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a366485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메모리 정리 완료\n"
     ]
    }
   ],
   "source": [
    "# 현재 노트북에서 바로 실행하세요\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def quick_cleanup():\n",
    "    \"\"\"즉시 사용 가능한 빠른 메모리 정리\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    print(\"메모리 정리 완료\")\n",
    "\n",
    "# 바로 실행\n",
    "quick_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cf3ee76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05a40f19952f4df790323004f4a42c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers.utils import move_cache\n",
    "move_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "773408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import json\n",
    "\n",
    "import optuna, math\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "#import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precision용\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# WandB 관련 import 추가\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# LayoutLMv3 관련 import\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForSequenceClassification\n",
    "import easyocr\n",
    "from datasets import Dataset as HFDataset  # Hugging Face Dataset (옵션)\n",
    "\n",
    "# OCR 초기화\n",
    "reader = easyocr.Reader(['en'], gpu=True)  # 영어 문서 가정\n",
    "\n",
    "# OCR 함수\n",
    "def extract_ocr(image_path, max_words=512):\n",
    "    \"\"\"이미지에서 텍스트와 바운딩 박스 추출\"\"\"\n",
    "    try:\n",
    "        results = reader.readtext(image_path)\n",
    "        words = []\n",
    "        boxes = []\n",
    "        for (bbox, text, conf) in results:\n",
    "            if conf > 0.5:  # 신뢰도 필터\n",
    "                words.append(text.strip())\n",
    "                # 바운딩 박스: [x0, y0, x1, y1] → LayoutLMv3 형식 (0-1000 스케일)\n",
    "                x0, y0 = bbox[0][0], bbox[0][1]\n",
    "                x1, y1 = bbox[2][0], bbox[2][1]\n",
    "                # 이미지 크기 기준 정규화 (0-1000)\n",
    "                img = Image.open(image_path)\n",
    "                w, h = img.size\n",
    "                box = [int(1000 * (x0 / w)), int(1000 * (y0 / h)), \n",
    "                       int(1000 * (x1 / w)), int(1000 * (y1 / h))]\n",
    "                boxes.append(box)\n",
    "                if len(words) >= max_words:\n",
    "                    break\n",
    "        return words, boxes\n",
    "    except Exception as e:\n",
    "        print(f\"OCR error for {image_path}: {e}\")\n",
    "        return [], []\n",
    "\n",
    "# OCR 캐싱 (훈련 전에 실행)\n",
    "def prepare_ocr_cache(df, img_path):\n",
    "    \"\"\"DataFrame에 OCR 결과를 추가하고 저장\"\"\"\n",
    "    ocr_cache = {}\n",
    "    for idx, row in df.iterrows():\n",
    "        image_id = row['ID']\n",
    "        img_full_path = os.path.join(img_path, image_id)\n",
    "        words, boxes = extract_ocr(img_full_path)\n",
    "        df.at[idx, 'words'] = json.dumps(words)\n",
    "        df.at[idx, 'boxes'] = json.dumps(boxes)\n",
    "        ocr_cache[image_id] = (words, boxes)\n",
    "    df.to_csv(os.path.join(img_path, 'with_ocr.csv'), index=False)\n",
    "    return ocr_cache\n",
    "\n",
    "# 프로세서 로드\n",
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e142354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB 로그인 상태: kimsunmin0227\n",
      "프로젝트: document-classification-team-CV\n",
      "실험명: layoutlmv3-baseline\n"
     ]
    }
   ],
   "source": [
    " \n",
    "\"\"\"\n",
    "🚀 팀원 사용 가이드:\n",
    "\n",
    "1. WandB 계정 생성: https://wandb.ai/signup\n",
    "2. 이 셀 실행 시 로그인 프롬프트가 나타나면 개인 API 키 입력\n",
    "3. EXPERIMENT_NAME을 다음과 같이 변경:\n",
    "   - \"member1-baseline\"\n",
    "   - \"member2-augmentation-test\"  \n",
    "   - \"member3-hyperparameter-tuning\"\n",
    "   등등 각자 다른 이름 사용\n",
    "\n",
    "4. 팀 대시보드 URL: [여기에 당신의 프로젝트 URL 추가]\n",
    "\n",
    "⚠️ 주의사항:\n",
    "- 절대 API 키를 코드에 하드코딩하지 마세요\n",
    "- EXPERIMENT_NAME만 변경하고 PROJECT_NAME은 그대로 두세요\n",
    "- 각자 개인 계정으로 로그인해서 실험을 추가하세요\n",
    "\"\"\"\n",
    "\n",
    "# WandB 로그인 (각자 실행)\n",
    "try:\n",
    "    if wandb.api.api_key is None:\n",
    "        print(\"WandB에 로그인이 필요합니다.\")\n",
    "        wandb.login()\n",
    "    else:\n",
    "        print(f\"WandB 로그인 상태: {wandb.api.viewer()['username']}\")\n",
    "except:\n",
    "    print(\"WandB 로그인을 진행합니다...\")\n",
    "    wandb.login()\n",
    "\n",
    "# 프로젝트 설정 (각자 수정할 부분)\n",
    "PROJECT_NAME = \"document-classification-team-CV\"  # 모든 팀원 동일\n",
    "ENTITY = None  # 각자 개인 계정 사용\n",
    "EXPERIMENT_NAME = \"layoutlmv3-baseline\"  # 팀원별로 변경 (예: \"member1-hyperopt\", \"member2-augmentation\")\n",
    "\n",
    "print(f\"프로젝트: {PROJECT_NAME}\")\n",
    "print(f\"실험명: {EXPERIMENT_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448a2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f9d1a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "Number of unique labels: 17\n",
      "Dataset size: 1570\n",
      "Using device: cuda\n",
      "Starting training...\n",
      "Starting epoch 0\n",
      "Epoch 0, Batch 0, Loss: 2.9736\n",
      "Epoch 0, Batch 1, Loss: 2.7821\n",
      "Epoch 0, Batch 2, Loss: 2.4954\n",
      "Epoch 0, Batch 3, Loss: 2.5653\n",
      "Epoch 0, Batch 4, Loss: 3.0934\n",
      "Epoch 0 completed. Average loss: 2.7819\n",
      "Starting epoch 1\n",
      "Epoch 1, Batch 0, Loss: 2.2907\n",
      "Epoch 1, Batch 1, Loss: 2.4921\n",
      "Epoch 1, Batch 2, Loss: 2.2888\n",
      "Epoch 1, Batch 3, Loss: 2.4479\n",
      "Epoch 1, Batch 4, Loss: 2.3286\n",
      "Epoch 1 completed. Average loss: 2.3696\n",
      "Training completed successfully!\n",
      "\n",
      "Testing inference...\n",
      "Batch 0 predictions: [16, 16]\n",
      "Batch 0 actual labels: [16, 4]\n",
      "Batch 1 predictions: [16, 16]\n",
      "Batch 1 actual labels: [15, 14]\n",
      "Batch 2 predictions: [16, 16]\n",
      "Batch 2 actual labels: [10, 15]\n",
      "Inference test completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForSequenceClassification\n",
    "from PIL import Image\n",
    "\n",
    "# 환경 변수 설정 (MKL/OpenMP 충돌 방지)\n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"] = \"1\"\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "\n",
    "# 데이터 경로\n",
    "DATA_ROOT = \"/root/computervisioncompetition-cv-1/mywork/data\"\n",
    "\n",
    "# 데이터셋 클래스\n",
    "class LayoutLMv3Dataset(Dataset):\n",
    "    def __init__(self, df, img_path, processor, max_length=512):\n",
    "        self.df = df\n",
    "        self.img_path = img_path\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.img_path, row['ID'])\n",
    "        \n",
    "        try:\n",
    "            words = json.loads(row['words']) if isinstance(row['words'], str) else row['words']\n",
    "            boxes = json.loads(row['boxes']) if isinstance(row['boxes'], str) else row['boxes']\n",
    "        except:\n",
    "            words, boxes = [], []\n",
    "        \n",
    "        # 빈 리스트 처리\n",
    "        if not words or not boxes:\n",
    "            words = [\"\"]\n",
    "            boxes = [[0, 0, 1, 1]]\n",
    "        \n",
    "        # 길이 맞추기\n",
    "        if len(words) != len(boxes):\n",
    "            min_len = min(len(words), len(boxes))\n",
    "            words = words[:min_len]\n",
    "            boxes = boxes[:min_len]\n",
    "        \n",
    "        label = int(row['target'])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        \n",
    "        # Processor에서 padding과 truncation 명시적 설정\n",
    "        encoding = self.processor(\n",
    "            image, \n",
    "            text=words, \n",
    "            boxes=boxes, \n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        \n",
    "        # 모든 tensor를 squeeze하여 배치 차원 제거\n",
    "        result = {}\n",
    "        for key, value in encoding.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                result[key] = value.squeeze(0)\n",
    "            else:\n",
    "                result[key] = value\n",
    "        \n",
    "        return result, label\n",
    "\n",
    "# Custom collate function\n",
    "def collate_fn(batch):\n",
    "    \"\"\"\n",
    "    Custom collate function for LayoutLMv3\n",
    "    \"\"\"\n",
    "    inputs = {}\n",
    "    labels = []\n",
    "    \n",
    "    # 첫 번째 샘플에서 키 확인\n",
    "    sample_keys = batch[0][0].keys()\n",
    "    \n",
    "    for key in sample_keys:\n",
    "        inputs[key] = torch.stack([item[0][key] for item in batch])\n",
    "    \n",
    "    labels = torch.tensor([item[1] for item in batch], dtype=torch.long)\n",
    "    \n",
    "    return inputs, labels\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 프로세서 및 모델\n",
    "    processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)\n",
    "    model = LayoutLMv3ForSequenceClassification.from_pretrained(\"microsoft/layoutlmv3-base\", num_labels=17)\n",
    "    \n",
    "    # 데이터셋\n",
    "    train_df = pd.read_csv(os.path.join(DATA_ROOT, 'train/with_ocr.csv'))\n",
    "    print(\"Unique labels:\", sorted(train_df['target'].unique()))\n",
    "    print(\"Number of unique labels:\", len(train_df['target'].unique()))\n",
    "    print(\"Dataset size:\", len(train_df))\n",
    "    \n",
    "    # 몇 개 샘플로 먼저 테스트\n",
    "    test_df = train_df.head(10).copy()  # 작은 샘플로 테스트\n",
    "    \n",
    "    train_dataset = LayoutLMv3Dataset(test_df, os.path.join(DATA_ROOT, 'train/'), processor)\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, \n",
    "        batch_size=2,  # 작은 배치 크기로 시작\n",
    "        shuffle=True, \n",
    "        num_workers=0,  # 디버깅을 위해 0으로 설정\n",
    "        collate_fn=collate_fn  # 커스텀 collate function 사용\n",
    "    )\n",
    "    \n",
    "    # GPU 설정\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # 학습 루프\n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(2):  # 테스트를 위해 2 에포크만\n",
    "        print(f\"Starting epoch {epoch}\")\n",
    "        total_loss = 0\n",
    "        num_batches = 0\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            try:\n",
    "                # 입력을 GPU로 이동\n",
    "                inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(**inputs, labels=labels)\n",
    "                loss = outputs.loss\n",
    "                \n",
    "                # Backward pass\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                \n",
    "                print(f\"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}\")\n",
    "                \n",
    "                # 메모리 정리\n",
    "                del inputs, labels, outputs, loss\n",
    "                torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error in batch {batch_idx}: {e}\")\n",
    "                print(\"Input shapes:\")\n",
    "                for k, v in inputs.items():\n",
    "                    print(f\"  {k}: {v.shape}\")\n",
    "                print(f\"Labels shape: {labels.shape}\")\n",
    "                break\n",
    "        \n",
    "        avg_loss = total_loss / num_batches if num_batches > 0 else 0\n",
    "        print(f\"Epoch {epoch} completed. Average loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    print(\"Training completed successfully!\")\n",
    "    \n",
    "    # 간단한 추론 테스트\n",
    "    print(\"\\nTesting inference...\")\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            print(f\"Batch {batch_idx} predictions: {predictions.cpu().tolist()}\")\n",
    "            print(f\"Batch {batch_idx} actual labels: {labels.tolist()}\")\n",
    "            if batch_idx >= 2:  # 몇 개 배치만 테스트\n",
    "                break\n",
    "    \n",
    "    print(\"Inference test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "403c7204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutout (Random Erasing) 함수 정의\n",
    "def random_erasing(image, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)):\n",
    "    if random.random() > p:\n",
    "        return image\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    area = img_h * img_w\n",
    "    \n",
    "    target_area = torch.tensor(random.uniform(scale[0], scale[1]), dtype=torch.float32) * area\n",
    "    aspect_ratio = torch.tensor(random.uniform(ratio[0], ratio[1]), dtype=torch.float32)\n",
    "    h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "    w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "    \n",
    "    # h, w가 이미지 크기 내에 있는지 확인\n",
    "    if w < img_w and h < img_h:\n",
    "        x = random.randint(0, img_w - w)\n",
    "        y = random.randint(0, img_h - h)\n",
    "        \n",
    "        # float32 마스크 생성\n",
    "        mask = torch.ones_like(image, dtype=torch.float32)\n",
    "        mask[:, y:y+h, x:x+w] = 0.0  # 또는 랜덤 값: torch.rand(3, h, w, dtype=torch.float32)\n",
    "        \n",
    "        # erasing 적용\n",
    "        erased = image * mask\n",
    "        return erased.float()  # float32 출력 보장\n",
    "    return image.float()\n",
    "\n",
    "# RandomCrop 함수 정의\n",
    "def random_crop(image, crop_size=0.7):\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    crop_h = int(img_h * crop_size)\n",
    "    crop_w = int(img_w * crop_size)\n",
    "    \n",
    "    if crop_h >= img_h or crop_w >= img_w:\n",
    "        return image\n",
    "    \n",
    "    x = random.randint(0, img_w - crop_w)\n",
    "    y = random.randint(0, img_h - crop_h)\n",
    "    cropped_image = image[:, :, y:y+crop_h, x:x+crop_w]\n",
    "    \n",
    "    # 패딩으로 원래 크기 복원\n",
    "    padded_image = torch.zeros_like(image)\n",
    "    padded_image[:, :, y:y+crop_h, x:x+crop_w] = cropped_image\n",
    "    return padded_image\n",
    "\n",
    "# Mixup 함수 정의\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0a693a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터에 OCR 추가 (한 번만 실행)\n",
    "#train_df = pd.read_csv('../data/train.csv')\n",
    "#train_ocr_cache = prepare_ocr_cache(train_df, '../data/train/')\n",
    "# 검증/테스트도 동일하게 처리\n",
    "#test_df = pd.read_csv('../data/sample_submission.csv')\n",
    "#test_ocr_cache = prepare_ocr_cache(test_df, '../data/test/')  # target은 -1로 설정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41682b9",
   "metadata": {},
   "source": [
    "병렬처리 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39335a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiprocessing start method set to 'spawn'\n",
      "GPU memory cleared\n",
      "Starting script execution\n",
      "Loading existing cache from /root/computervisioncompetition-cv-1/mywork/data/train/with_ocr.csv\n",
      "Loaded 1570 cached OCR results\n",
      "Train cache loaded, skipping OCR processing\n",
      "Loading existing cache from /root/computervisioncompetition-cv-1/mywork/data/test/with_ocr.csv\n",
      "Loaded 3140 cached OCR results\n",
      "Test cache loaded, skipping OCR processing\n",
      "Script execution completed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "from tqdm.notebook import tqdm  # Jupyter/Kaggle용 tqdm\n",
    "from PIL import Image\n",
    "import easyocr\n",
    "import multiprocessing as mp\n",
    "import torch\n",
    "\n",
    "# 데이터 경로 설정\n",
    "DATA_ROOT = \"/root/computervisioncompetition-cv-1/mywork/data\"  # 실제 경로 확인\n",
    "\n",
    "# 시작 방식을 'spawn'으로 설정\n",
    "try:\n",
    "    mp.set_start_method('spawn', force=True)\n",
    "    print(\"Multiprocessing start method set to 'spawn'\")\n",
    "except RuntimeError:\n",
    "    print(\"Multiprocessing start method already set\")\n",
    "\n",
    "# GPU 메모리 초기화\n",
    "torch.cuda.empty_cache()\n",
    "print(\"GPU memory cleared\")\n",
    "\n",
    "# EasyOCR 초기화\n",
    "def init_easyocr():\n",
    "    try:\n",
    "        reader = easyocr.Reader(['en'], gpu=True)\n",
    "        print(\"EasyOCR initialized with GPU\")\n",
    "        return reader\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to initialize EasyOCR with GPU: {e}. Falling back to CPU.\")\n",
    "        return easyocr.Reader(['en'], gpu=False)\n",
    "\n",
    "def extract_ocr(image_path, max_words=512):\n",
    "    try:\n",
    "        reader = init_easyocr()\n",
    "        results = reader.readtext(image_path)\n",
    "        words = []\n",
    "        boxes = []\n",
    "        for (bbox, text, conf) in results:\n",
    "            if conf > 0.5:\n",
    "                words.append(text.strip())\n",
    "                img = Image.open(image_path)\n",
    "                w, h = img.size\n",
    "                x0, y0 = bbox[0][0], bbox[0][1]\n",
    "                x1, y1 = bbox[2][0], bbox[2][1]\n",
    "                box = [int(1000 * (x0 / w)), int(1000 * (y0 / h)), \n",
    "                       int(1000 * (x1 / w)), int(1000 * (y1 / h))]\n",
    "                boxes.append(box)\n",
    "                if len(words) >= max_words:\n",
    "                    break\n",
    "        print(f\"OCR processed for {image_path}: {len(words)} words extracted\")\n",
    "        return words, boxes\n",
    "    except Exception as e:\n",
    "        print(f\"OCR error for {image_path}: {e}\")\n",
    "        return [], []\n",
    "    finally:\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "def process_image(args):\n",
    "    image_id, img_path = args\n",
    "    img_full_path = os.path.join(img_path, image_id)\n",
    "    words, boxes = extract_ocr(img_full_path)\n",
    "    return image_id, words, boxes\n",
    "\n",
    "def prepare_ocr_cache_parallel(df, img_path, num_workers=2):\n",
    "    print(f\"Starting OCR processing for {len(df)} images in {img_path}\")\n",
    "    ocr_cache = {}\n",
    "    df = df.copy()\n",
    "    \n",
    "    num_workers = min(num_workers, mp.cpu_count())\n",
    "    print(f\"Using {num_workers} workers for parallel processing\")\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=num_workers) as executor:\n",
    "        futures = [executor.submit(process_image, (row['ID'], img_path)) for _, row in df.iterrows()]\n",
    "        for future in tqdm(futures, total=len(df), desc=\"OCR Processing\"):\n",
    "            try:\n",
    "                image_id, words, boxes = future.result()\n",
    "                ocr_cache[image_id] = (words, boxes)\n",
    "                df.loc[df['ID'] == image_id, 'words'] = json.dumps(words)\n",
    "                df.loc[df['ID'] == image_id, 'boxes'] = json.dumps(boxes)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing image {image_id if 'image_id' in locals() else 'unknown'}: {e}\")\n",
    "                continue\n",
    "    \n",
    "    output_path = os.path.join(img_path, 'with_ocr.csv')\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"OCR results saved to {output_path}\")\n",
    "    return ocr_cache\n",
    "\n",
    "def load_existing_cache(df, img_path):\n",
    "    cache_path = os.path.join(img_path, 'with_ocr.csv')\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading existing cache from {cache_path}\")\n",
    "        cached_df = pd.read_csv(cache_path)\n",
    "        ocr_cache = {row['ID']: (json.loads(row['words']), json.loads(row['boxes'])) \n",
    "                     for _, row in cached_df.iterrows()}\n",
    "        print(f\"Loaded {len(ocr_cache)} cached OCR results\")\n",
    "        return cached_df, ocr_cache\n",
    "    print(f\"No cache found at {cache_path}\")\n",
    "    return df, {}\n",
    "\n",
    "# 실행\n",
    "print(\"Starting script execution\")\n",
    "train_df, train_ocr_cache = load_existing_cache(\n",
    "    pd.read_csv(os.path.join(DATA_ROOT, 'train.csv')), \n",
    "    os.path.join(DATA_ROOT, 'train/')\n",
    ")\n",
    "if not train_ocr_cache:\n",
    "    print(\"No train cache found, running OCR processing\")\n",
    "    train_ocr_cache = prepare_ocr_cache_parallel(\n",
    "        train_df, os.path.join(DATA_ROOT, 'train/'), num_workers=2\n",
    "    )\n",
    "else:\n",
    "    print(\"Train cache loaded, skipping OCR processing\")\n",
    "\n",
    "test_df, test_ocr_cache = load_existing_cache(\n",
    "    pd.read_csv(os.path.join(DATA_ROOT, 'sample_submission.csv')), \n",
    "    os.path.join(DATA_ROOT, 'test/')\n",
    ")\n",
    "if not test_ocr_cache:\n",
    "    print(\"No test cache found, running OCR processing\")\n",
    "    test_ocr_cache = prepare_ocr_cache_parallel(\n",
    "        test_df, os.path.join(DATA_ROOT, 'test/'), num_workers=2\n",
    "    )\n",
    "else:\n",
    "    print(\"Test cache loaded, skipping OCR processing\")\n",
    "print(\"Script execution completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cacecd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Batch size: 4\n",
      "Gradient accumulation steps: 8\n",
      "Effective batch size: 32\n",
      "Max sequence length: 256\n",
      "Dataset size: 1570\n",
      "Unique labels: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
      "\n",
      "============================================================\n",
      "Fold 1/2\n",
      "============================================================\n",
      "Train samples: 785, Validation samples: 785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>fold</td><td>▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▁</td></tr><tr><td>train/accuracy</td><td>▁█▁</td></tr><tr><td>train/f1</td><td>▂█▁</td></tr><tr><td>train/loss</td><td>█▃▁</td></tr><tr><td>val/accuracy</td><td>▁▁█</td></tr><tr><td>val/class_14_f1</td><td>▁▁▁</td></tr><tr><td>val/class_3_f1</td><td>▁▁▁</td></tr><tr><td>val/class_7_f1</td><td>▁▁▁</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>learning_rate</td><td>0.00025</td></tr><tr><td>train/accuracy</td><td>0.05711</td></tr><tr><td>train/f1</td><td>0.03199</td></tr><tr><td>train/loss</td><td>2.8499</td></tr><tr><td>val/accuracy</td><td>0.06599</td></tr><tr><td>val/class_14_f1</td><td>0</td></tr><tr><td>val/class_3_f1</td><td>0</td></tr><tr><td>val/class_7_f1</td><td>0</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">layoutlmv3-baseline-fold-1</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/pa6sryof' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/pa6sryof</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250909_041755-pa6sryof/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/computervisioncompetition-cv-1/mywork/experiments/wandb/run-20250909_042220-sjk38wnj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/sjk38wnj' target=\"_blank\">layoutlmv3-baseline-fold-1</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/sjk38wnj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/sjk38wnj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 시작 - Fold 1\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 Train Epoch 1: 100%|██████████| 197/197 [00:24<00:00,  8.19it/s, Loss=2.7988, F1=0.0000]\n",
      "Fold 0 Val Epoch 1: 100%|██████████| 197/197 [00:22<00:00,  8.88it/s, Loss=2.6777, F1=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.8543 | Train F1: 0.0379\n",
      "Val Loss: 2.8177 | Val F1: 0.0277\n",
      "Problem Classes Avg F1: 0.0000\n",
      "New best! F1: 0.0277\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 Train Epoch 2: 100%|██████████| 197/197 [00:24<00:00,  8.18it/s, Loss=2.7305, F1=0.0000]\n",
      "Fold 0 Val Epoch 2: 100%|██████████| 197/197 [00:22<00:00,  8.69it/s, Loss=2.7246, F1=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.8272 | Train F1: 0.0322\n",
      "Val Loss: 2.8148 | Val F1: 0.0280\n",
      "Problem Classes Avg F1: 0.0000\n",
      "New best! F1: 0.0280\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 0 Train Epoch 3: 100%|██████████| 197/197 [00:24<00:00,  8.19it/s, Loss=2.7656, F1=0.0000]\n",
      "Fold 0 Val Epoch 3: 100%|██████████| 197/197 [00:22<00:00,  8.86it/s, Loss=2.7773, F1=0.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.8239 | Train F1: 0.0385\n",
      "Val Loss: 2.8136 | Val F1: 0.0267\n",
      "Problem Classes Avg F1: 0.3333\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>fold</td><td>▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▁</td></tr><tr><td>train/accuracy</td><td>█▁▇</td></tr><tr><td>train/f1</td><td>▇▁█</td></tr><tr><td>train/loss</td><td>█▂▁</td></tr><tr><td>val/accuracy</td><td>▁▁▁</td></tr><tr><td>val/class_14_f1</td><td>▁▁▁</td></tr><tr><td>val/class_3_f1</td><td>▁▁▁</td></tr><tr><td>val/class_7_f1</td><td>▁▁█</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>train/accuracy</td><td>0.06472</td></tr><tr><td>train/f1</td><td>0.03847</td></tr><tr><td>train/loss</td><td>2.82386</td></tr><tr><td>val/accuracy</td><td>0.06345</td></tr><tr><td>val/class_14_f1</td><td>0</td></tr><tr><td>val/class_3_f1</td><td>0</td></tr><tr><td>val/class_7_f1</td><td>1</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">layoutlmv3-baseline-fold-1</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/sjk38wnj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/sjk38wnj</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250909_042220-sjk38wnj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 완료!\n",
      "\n",
      "============================================================\n",
      "Fold 2/2\n",
      "============================================================\n",
      "Train samples: 785, Validation samples: 785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/computervisioncompetition-cv-1/mywork/experiments/wandb/run-20250909_042445-v6ehrdcj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/v6ehrdcj' target=\"_blank\">layoutlmv3-baseline-fold-2</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/v6ehrdcj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/v6ehrdcj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 시작 - Fold 2\n",
      "\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Train Epoch 1: 100%|██████████| 197/197 [00:23<00:00,  8.21it/s, Loss=1.4160, F1=0.0000]\n",
      "Fold 1 Val Epoch 1: 100%|██████████| 197/197 [00:22<00:00,  8.90it/s, Loss=0.7031, F1=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 2.4838 | Train F1: 0.1220\n",
      "Val Loss: 2.0999 | Val F1: 0.1704\n",
      "Problem Classes Avg F1: 0.1395\n",
      "New best! F1: 0.1704\n",
      "\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Train Epoch 2: 100%|██████████| 197/197 [00:24<00:00,  8.12it/s, Loss=1.8320, F1=0.0000]\n",
      "Fold 1 Val Epoch 2: 100%|██████████| 197/197 [00:22<00:00,  8.57it/s, Loss=0.0996, F1=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.8629 | Train F1: 0.3160\n",
      "Val Loss: 1.6000 | Val F1: 0.3760\n",
      "Problem Classes Avg F1: 0.0733\n",
      "New best! F1: 0.3760\n",
      "\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fold 1 Train Epoch 3: 100%|██████████| 197/197 [00:23<00:00,  8.22it/s, Loss=1.7852, F1=0.0000]\n",
      "Fold 1 Val Epoch 3: 100%|██████████| 197/197 [00:22<00:00,  8.83it/s, Loss=0.0734, F1=1.0000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss: 1.4298 | Train F1: 0.4467\n",
      "Val Loss: 1.3589 | Val F1: 0.4462\n",
      "Problem Classes Avg F1: 0.0380\n",
      "New best! F1: 0.4462\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▅█</td></tr><tr><td>fold</td><td>▁▁▁</td></tr><tr><td>learning_rate</td><td>█▆▁</td></tr><tr><td>train/accuracy</td><td>▁▅█</td></tr><tr><td>train/f1</td><td>▁▅█</td></tr><tr><td>train/loss</td><td>█▄▁</td></tr><tr><td>val/accuracy</td><td>▁▆█</td></tr><tr><td>val/class_14_f1</td><td>▁▁▁</td></tr><tr><td>val/class_3_f1</td><td>█▃▁</td></tr><tr><td>val/class_7_f1</td><td>▁██</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>3</td></tr><tr><td>fold</td><td>2</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>train/accuracy</td><td>0.56091</td></tr><tr><td>train/f1</td><td>0.44675</td></tr><tr><td>train/loss</td><td>1.42977</td></tr><tr><td>val/accuracy</td><td>0.5736</td></tr><tr><td>val/class_14_f1</td><td>0</td></tr><tr><td>val/class_3_f1</td><td>0.0307</td></tr><tr><td>val/class_7_f1</td><td>0.08333</td></tr><tr><td>+3</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">layoutlmv3-baseline-fold-2</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/v6ehrdcj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/v6ehrdcj</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250909_042445-v6ehrdcj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 완료!\n",
      "\n",
      "앙상블 모델 준비 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 모델 로드 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 모델 로드 완료\n",
      "총 2개 모델로 앙상블 구성\n",
      "\n",
      "============================================================\n",
      " K-FOLD CROSS VALIDATION 최종 결과\n",
      "============================================================\n",
      "Fold 1: 0.0280 (3 epochs) Completed\n",
      "Fold 2: 0.4462 (3 epochs) Completed\n",
      "\n",
      "평균 CV F1: 0.2371 ± 0.2091\n",
      "최고 Fold: 0.4462\n",
      "최악 Fold: 0.0280\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import copy\n",
    "import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from transformers import LayoutLMv3Processor, LayoutLMv3ForSequenceClassification\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import wandb\n",
    "import torch.nn as nn\n",
    "\n",
    "# 환경 변수 설정\n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"] = \"1\"\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "\n",
    "# Dataset 클래스를 전역으로 정의 (multiprocessing 에러 방지)\n",
    "class LayoutLMv3Dataset(Dataset):\n",
    "    def __init__(self, df, img_path, processor, max_length=256):\n",
    "        self.df = df\n",
    "        self.img_path = img_path\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_path = os.path.join(self.img_path, row['ID'])\n",
    "        \n",
    "        try:\n",
    "            words = json.loads(row['words']) if isinstance(row['words'], str) else row['words']\n",
    "            boxes = json.loads(row['boxes']) if isinstance(row['boxes'], str) else row['boxes']  # 오타 수정: boxeås -> boxes\n",
    "        except:\n",
    "            words, boxes = [], []\n",
    "        \n",
    "        # 빈 리스트 처리\n",
    "        if not words or not boxes:\n",
    "            words = [\"\"]\n",
    "            boxes = [[0, 0, 1, 1]]\n",
    "        \n",
    "        # 길이 맞추기\n",
    "        if len(words) != len(boxes):\n",
    "            min_len = min(len(words), len(boxes))\n",
    "            words = words[:min_len]\n",
    "            boxes = boxes[:min_len]\n",
    "        \n",
    "        label = int(row['target'])\n",
    "        \n",
    "        # 이미지 크기 축소 (메모리 절약)\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = image.resize((224, 224))\n",
    "        \n",
    "        # Processor에서 padding과 truncation 명시적 설정\n",
    "        encoding = self.processor(\n",
    "            image, \n",
    "            text=words, \n",
    "            boxes=boxes, \n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            max_length=self.max_length\n",
    "        )\n",
    "        \n",
    "        # 모든 tensor를 squeeze하여 배치 차원 제거\n",
    "        result = {}\n",
    "        for key, value in encoding.items():\n",
    "            if isinstance(value, torch.Tensor):\n",
    "                result[key] = value.squeeze(0)\n",
    "            else:\n",
    "                result[key] = value\n",
    "        \n",
    "        return result, label\n",
    "\n",
    "# Collate function을 전역으로 정의\n",
    "def collate_fn(batch):\n",
    "    \"\"\"Custom collate function for LayoutLMv3\"\"\"\n",
    "    inputs = {}\n",
    "    labels = []\n",
    "    \n",
    "    # 첫 번째 샘플에서 키 확인\n",
    "    sample_keys = batch[0][0].keys()\n",
    "    \n",
    "    for key in sample_keys:\n",
    "        inputs[key] = torch.stack([item[0][key] for item in batch])\n",
    "    \n",
    "    labels = torch.tensor([item[1] for item in batch], dtype=torch.long)\n",
    "    \n",
    "    return inputs, labels\n",
    "\n",
    "# 메모리 정리 함수\n",
    "def clear_memory():\n",
    "    torch.cuda.empty_cache()\n",
    "    import gc\n",
    "    gc.collect()\n",
    "\n",
    "def train_one_epoch_with_grad_accumulation(train_loader, model, optimizer, loss_fn, device, scaler, epoch, fold, gradient_accumulation_steps=1):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    num_batches = len(train_loader)\n",
    "    \n",
    "    optimizer.zero_grad()  # 시작 시 gradient 초기화\n",
    "    \n",
    "    pbar = tqdm(train_loader, desc=f\"Fold {fold} Train Epoch {epoch+1}\")\n",
    "    for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, targets)\n",
    "            # Gradient accumulation을 위해 loss를 나눔\n",
    "            loss = loss / gradient_accumulation_steps\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        # Gradient accumulation\n",
    "        if (batch_idx + 1) % gradient_accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        acc = accuracy_score(targets.cpu(), preds.cpu())\n",
    "        f1 = f1_score(targets.cpu(), preds.cpu(), average='macro')\n",
    "        \n",
    "        total_loss += loss.item() * gradient_accumulation_steps  # 원래 loss로 복원\n",
    "        total_acc += acc\n",
    "        total_f1 += f1\n",
    "        \n",
    "        pbar.set_postfix({'Loss': f\"{loss.item() * gradient_accumulation_steps:.4f}\", 'F1': f\"{f1:.4f}\"})\n",
    "        \n",
    "        # 메모리 정리\n",
    "        del inputs, targets, outputs, logits, loss\n",
    "        if batch_idx % 10 == 0:\n",
    "            clear_memory()\n",
    "    \n",
    "    return {\n",
    "        'train_loss': total_loss / num_batches,\n",
    "        'train_acc': total_acc / num_batches,\n",
    "        'train_f1': total_f1 / num_batches\n",
    "    }\n",
    "\n",
    "def validate_one_epoch(val_loader, model, loss_fn, device, epoch, fold, log_confusion=False):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_acc = 0\n",
    "    total_f1 = 0\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    num_batches = len(val_loader)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc=f\"Fold {fold} Val Epoch {epoch+1}\")\n",
    "        for batch_idx, (inputs, targets) in enumerate(pbar):\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            with autocast():\n",
    "                outputs = model(**inputs)\n",
    "                logits = outputs.logits\n",
    "                loss = loss_fn(logits, targets)\n",
    "            \n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            acc = accuracy_score(targets.cpu(), preds.cpu())\n",
    "            f1 = f1_score(targets.cpu(), preds.cpu(), average='macro')\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            total_acc += acc\n",
    "            total_f1 += f1\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'Loss': f\"{loss.item():.4f}\", 'F1': f\"{f1:.4f}\"})\n",
    "            \n",
    "            # 메모리 정리\n",
    "            del inputs, targets, outputs, logits, loss\n",
    "            if batch_idx % 5 == 0:\n",
    "                clear_memory()\n",
    "    \n",
    "    # Problem classes (3,7,14) F1 계산\n",
    "    problem_f1 = {}\n",
    "    for cls in [3,7,14]:\n",
    "        cls_mask = np.array(all_targets) == cls\n",
    "        if np.sum(cls_mask) > 0:\n",
    "            cls_preds = np.array(all_preds)[cls_mask]\n",
    "            cls_targets = np.array(all_targets)[cls_mask]\n",
    "            problem_f1[f'class_{cls}_f1'] = f1_score(cls_targets, cls_preds, average='macro')\n",
    "    \n",
    "    avg_problem_f1 = np.mean(list(problem_f1.values())) if problem_f1 else 0\n",
    "    \n",
    "    return {\n",
    "        'val_loss': total_loss / num_batches,\n",
    "        'val_acc': total_acc / num_batches,\n",
    "        'val_f1': total_f1 / num_batches,\n",
    "        'problem_class_f1': problem_f1,\n",
    "        'avg_problem_f1': avg_problem_f1\n",
    "    }\n",
    "\n",
    "def main():\n",
    "    # 설정값들\n",
    "    DATA_ROOT = \"/root/computervisioncompetition-cv-1/mywork/data\"\n",
    "    model_name = \"microsoft/layoutlmv3-base\"\n",
    "    num_classes = 17\n",
    "    EPOCHS = 3\n",
    "    BATCH_SIZE = 4  # 메모리 고려\n",
    "    GRADIENT_ACCUMULATION_STEPS = 8  # 실질적 배치 크기 = 2 * 16 = 32\n",
    "    N_FOLDS = 2\n",
    "    LR = 0.0001\n",
    "    MAX_PATIENCE = 5\n",
    "    NUM_WORKERS = 0\n",
    "    SEED = 42\n",
    "    max_length = 256  # 메모리 절약을 위해 줄임\n",
    "    \n",
    "    # WandB 설정\n",
    "    PROJECT_NAME = \"document-classification-team-CV\"\n",
    "    EXPERIMENT_NAME = \"layoutlmv3-baseline\"\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    print(f\"Batch size: {BATCH_SIZE}\")\n",
    "    print(f\"Gradient accumulation steps: {GRADIENT_ACCUMULATION_STEPS}\")\n",
    "    print(f\"Effective batch size: {BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS}\")\n",
    "    print(f\"Max sequence length: {max_length}\")\n",
    "    \n",
    "    # 프로세서 로드\n",
    "    processor = LayoutLMv3Processor.from_pretrained(model_name, apply_ocr=False)\n",
    "    \n",
    "    # 데이터 로드\n",
    "    train_df = pd.read_csv(os.path.join(DATA_ROOT, 'train/with_ocr.csv'))\n",
    "    print(f\"Dataset size: {len(train_df)}\")\n",
    "    print(f\"Unique labels: {sorted(train_df['target'].unique())}\")\n",
    "    \n",
    "    # 작은 샘플로 테스트\n",
    "    #train_df = train_df.head(200).copy()  \n",
    "    #print(f\"Using {len(train_df)} samples for testing\")\n",
    "    \n",
    "    fold_results = []\n",
    "    fold_models = []\n",
    "    \n",
    "    # K-Fold 교차 검증\n",
    "    skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    for fold, (trn_idx, val_idx) in enumerate(skf.split(train_df['ID'], train_df['target'])):\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Fold {fold+1}/{N_FOLDS}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        # 시작 전 메모리 정리\n",
    "        clear_memory()\n",
    "        \n",
    "        # 데이터 분할\n",
    "        trn_df = train_df.iloc[trn_idx].reset_index(drop=True)\n",
    "        val_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "        \n",
    "        print(f\"Train samples: {len(trn_df)}, Validation samples: {len(val_df)}\")\n",
    "        \n",
    "        # 데이터셋 생성\n",
    "        trn_dataset = LayoutLMv3Dataset(trn_df, os.path.join(DATA_ROOT, 'train/'), processor, max_length=max_length)\n",
    "        val_dataset = LayoutLMv3Dataset(val_df, os.path.join(DATA_ROOT, 'train/'), processor, max_length=max_length)\n",
    "        \n",
    "        # DataLoader 생성\n",
    "        trn_loader = DataLoader(\n",
    "            trn_dataset, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=True, \n",
    "            collate_fn=collate_fn, \n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            val_dataset, \n",
    "            batch_size=BATCH_SIZE, \n",
    "            shuffle=False, \n",
    "            collate_fn=collate_fn, \n",
    "            num_workers=NUM_WORKERS,\n",
    "            pin_memory=False\n",
    "        )\n",
    "        \n",
    "        # 모델 생성\n",
    "        model = LayoutLMv3ForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=num_classes, ignore_mismatched_sizes=True\n",
    "        ).to(device)\n",
    "        \n",
    "        optimizer = Adam(model.parameters(), lr=LR)\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "        loss_fn = nn.CrossEntropyLoss()\n",
    "        scaler = GradScaler()\n",
    "        \n",
    "        best_val_f1 = 0\n",
    "        patience = 0\n",
    "        best_model = None\n",
    "        \n",
    "        # WandB 초기화\n",
    "        wandb.init(\n",
    "            project=PROJECT_NAME, \n",
    "            name=f\"{EXPERIMENT_NAME}-fold-{fold+1}\", \n",
    "            config={\n",
    "                'fold': fold+1,\n",
    "                'model_name': model_name,\n",
    "                'batch_size': BATCH_SIZE,\n",
    "                'gradient_accumulation_steps': GRADIENT_ACCUMULATION_STEPS,\n",
    "                'effective_batch_size': BATCH_SIZE * GRADIENT_ACCUMULATION_STEPS,\n",
    "                'learning_rate': LR,\n",
    "                'epochs': EPOCHS,\n",
    "                'max_length': max_length\n",
    "            },\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        print(f\"모델 학습 시작 - Fold {fold+1}\")\n",
    "        \n",
    "        for epoch in range(EPOCHS):\n",
    "            print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
    "            \n",
    "            # 훈련 (gradient accumulation 포함)\n",
    "            train_ret = train_one_epoch_with_grad_accumulation(\n",
    "                trn_loader, model, optimizer, loss_fn, device, scaler, \n",
    "                epoch, fold, GRADIENT_ACCUMULATION_STEPS\n",
    "            )\n",
    "            \n",
    "            # 검증\n",
    "            val_ret = validate_one_epoch(val_loader, model, loss_fn, device, epoch, fold)\n",
    "            \n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            # WandB 로깅\n",
    "            log_data = {\n",
    "                \"epoch\": epoch + 1,\n",
    "                \"fold\": fold + 1,\n",
    "                \"train/loss\": train_ret['train_loss'],\n",
    "                \"train/accuracy\": train_ret['train_acc'], \n",
    "                \"train/f1\": train_ret['train_f1'],\n",
    "                \"val/loss\": val_ret['val_loss'],\n",
    "                \"val/accuracy\": val_ret['val_acc'],\n",
    "                \"val/f1\": val_ret['val_f1'],\n",
    "                \"learning_rate\": current_lr,\n",
    "            }\n",
    "            \n",
    "            if 'avg_problem_f1' in val_ret:\n",
    "                log_data[\"val/problem_classes_avg_f1\"] = val_ret['avg_problem_f1']\n",
    "            \n",
    "            for cls in [3, 7, 14]:\n",
    "                if f\"class_{cls}_f1\" in val_ret['problem_class_f1']:\n",
    "                    log_data[f\"val/class_{cls}_f1\"] = val_ret['problem_class_f1'][f\"class_{cls}_f1\"]\n",
    "            \n",
    "            wandb.log(log_data)\n",
    "            \n",
    "            scheduler.step()\n",
    "            \n",
    "            # 출력\n",
    "            print(f\"Train Loss: {train_ret['train_loss']:.4f} | Train F1: {train_ret['train_f1']:.4f}\")\n",
    "            print(f\"Val Loss: {val_ret['val_loss']:.4f} | Val F1: {val_ret['val_f1']:.4f}\")\n",
    "            if 'avg_problem_f1' in val_ret:\n",
    "                print(f\"Problem Classes Avg F1: {val_ret['avg_problem_f1']:.4f}\")\n",
    "            \n",
    "            # 최고 모델 저장\n",
    "            if val_ret['val_f1'] > best_val_f1:\n",
    "                best_val_f1 = val_ret['val_f1']\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "                patience = 0\n",
    "                model_path = f'best_model_fold_{fold+1}.pth'\n",
    "                torch.save(best_model, model_path)\n",
    "                print(f\"New best! F1: {best_val_f1:.4f}\")\n",
    "            else:\n",
    "                patience += 1\n",
    "            \n",
    "            if patience >= MAX_PATIENCE and epoch > EPOCHS // 2:\n",
    "                print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "            \n",
    "            # 에포크 끝날 때마다 메모리 정리\n",
    "            clear_memory()\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold+1, \n",
    "            'best_val_f1': best_val_f1, \n",
    "            'epochs_trained': epoch+1,\n",
    "            'early_stopped': patience >= MAX_PATIENCE,\n",
    "            'final_train_f1': train_ret['train_f1'],\n",
    "            'train_samples': len(trn_df),\n",
    "            'val_samples': len(val_df)\n",
    "        })\n",
    "        fold_models.append(best_model)\n",
    "        \n",
    "        wandb.finish()\n",
    "        \n",
    "        # 메모리 정리\n",
    "        del model, optimizer, scheduler, trn_loader, val_loader\n",
    "        clear_memory()\n",
    "        \n",
    "        print(f\"Fold {fold+1} 완료!\")\n",
    "    \n",
    "    # 앙상블 모델 준비 (모든 fold가 끝난 후)\n",
    "    print(f\"\\n앙상블 모델 준비 중...\")\n",
    "    ensemble_models = []\n",
    "    \n",
    "    for i, state_dict in enumerate(fold_models):\n",
    "        fold_model = LayoutLMv3ForSequenceClassification.from_pretrained(\n",
    "            model_name, num_labels=num_classes, ignore_mismatched_sizes=True\n",
    "        ).to(device)\n",
    "        fold_model.load_state_dict(state_dict)\n",
    "        fold_model.eval()\n",
    "        ensemble_models.append(fold_model)\n",
    "        print(f\"Fold {i+1} 모델 로드 완료\")\n",
    "    \n",
    "    print(f\"총 {len(ensemble_models)}개 모델로 앙상블 구성\")\n",
    "    \n",
    "    # 결과 요약\n",
    "    val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "    mean_f1 = np.mean(val_f1_scores)\n",
    "    std_f1 = np.std(val_f1_scores)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\" K-FOLD CROSS VALIDATION 최종 결과\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    for result in fold_results:\n",
    "        status = \" Early Stopped\" if result['early_stopped'] else \" Completed\"\n",
    "        print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f} \"\n",
    "              f\"({result['epochs_trained']} epochs){status}\")\n",
    "    \n",
    "    print(f\"\\n평균 CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "    print(f\"최고 Fold: {max(val_f1_scores):.4f}\")\n",
    "    print(f\"최악 Fold: {min(val_f1_scores):.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f941711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메모리 정리 완료\n"
     ]
    }
   ],
   "source": [
    "# 현재 노트북에서 바로 실행하세요\n",
    "import torch\n",
    "import gc\n",
    "\n",
    "def quick_cleanup():\n",
    "    \"\"\"즉시 사용 가능한 빠른 메모리 정리\"\"\"\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "    print(\"메모리 정리 완료\")\n",
    "\n",
    "# 바로 실행\n",
    "quick_cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f420558",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m `start_method` is deprecated and will be removed in a future version of wandb. This setting is currently non-functional and safely ignored.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 WandB 연결 문제 해결 중...\n",
      "WandB 초기화 시도 1/3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkimsunmin0227\u001b[0m (\u001b[33mkimsunmin0227-hufs\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/computervisioncompetition-cv-1/mywork/experiments/wandb/run-20250909_021839-g7stly7w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w' target=\"_blank\">efficientnet-b3-baseline-0909-0218</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ WandB 초기화 성공!\n",
      "\n",
      "🚀 WandB 실험 시작!\n",
      "📊 대시보드: https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w\n",
      "📋 실험명: efficientnet-b3-baseline-0909-0218\n"
     ]
    }
   ],
   "source": [
    "# Essential TTA transforms (이미지 변형만)\n",
    "essential_tta_transforms = [\n",
    "    A.Compose([  # 원본\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "     \n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "print(f\"TTA 변환 {len(essential_tta_transforms)}개 준비 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6514acaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 데이터: 1570개 샘플\n",
      " 클래스 분포: {0: 100, 1: 46, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100, 10: 100, 11: 100, 12: 100, 13: 74, 14: 50, 15: 100, 16: 100}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficientnet-b3-baseline-0909-0218</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/g7stly7w</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250909_021839-g7stly7w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/computervisioncompetition-cv-1/mywork/experiments/wandb/run-20250909_021840-qaeb6wly</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly' target=\"_blank\">efficientnet-b3-baseline-0909-0218</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🚀 WandB 실험 시작!\n",
      "📊 대시보드: https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly\n",
      "📋 실험명: efficientnet-b3-baseline-0909-0218\n"
     ]
    }
   ],
   "source": [
    "class TTALayoutLMv3Dataset(Dataset):\n",
    "    def __init__(self, df, img_path, ocr_cache, transforms):\n",
    "        super().__init__(df, img_path, ocr_cache, transform=None)  # 기본 transform None\n",
    "        self.transforms = transforms  # TTA용\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        image_id = row['ID']\n",
    "        target = row['target']\n",
    "        img_full_path = os.path.join(self.img_path, image_id)\n",
    "        \n",
    "        image = Image.open(img_full_path).convert(\"RGB\")\n",
    "        words, boxes = self.ocr_cache[image_id] if self.ocr_cache else ([], [])\n",
    "        \n",
    "        # TTA: 여러 변형된 이미지 리스트 생성 (OCR 고정)\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            if transform is not None:  # 원본은 None 아님\n",
    "                image_np = np.array(image)\n",
    "                aug_img_np = transform(image=image_np)['image']\n",
    "                aug_img = Image.fromarray(aug_img_np).convert(\"RGB\")\n",
    "            else:\n",
    "                aug_img = image\n",
    "            # 각 aug_img에 동일 OCR 적용해 encoding 생성\n",
    "            encoding = processor(images=aug_img, words=words, boxes=boxes, return_tensors=\"pt\", truncation=True, padding=\"max_length\")\n",
    "            inputs = {\n",
    "                'input_ids': encoding['input_ids'].squeeze(),\n",
    "                'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "                'bbox': encoding['bbox'].squeeze() if 'bbox' in encoding else None,\n",
    "                'pixel_values': encoding['pixel_values'].squeeze(),\n",
    "            }\n",
    "            augmented_images.append(inputs)\n",
    "        \n",
    "        return augmented_images, target  # 리스트 반환\n",
    "\n",
    "# TTA Dataset\n",
    "tta_dataset = TTALayoutLMv3Dataset(test_df, '../data/test/', test_ocr_cache, essential_tta_transforms)\n",
    "tta_loader = DataLoader(tta_dataset, batch_size=4, shuffle=False, collate_fn=lambda b: collate_tta(b), num_workers=NUM_WORKERS)  # 배치 크기 줄임\n",
    "\n",
    "def collate_tta(batch):\n",
    "    # TTA 배치 처리 (각 샘플의 augmented_images 리스트 스택)\n",
    "    all_inputs = []\n",
    "    for sample in batch:\n",
    "        all_inputs.extend(sample[0])  # Flatten list of dicts\n",
    "    # Stack as usual\n",
    "    inputs = {}\n",
    "    for key in all_inputs[0].keys():\n",
    "        inputs[key] = torch.stack([inp[key] for inp in all_inputs])\n",
    "    targets = torch.tensor([s[1] for s in batch])\n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c320bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 1/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficientnet-b3-baseline-0909-0218</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/qaeb6wly</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250909_021840-qaeb6wly/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/computervisioncompetition-cv-1/mywork/experiments/wandb/run-20250909_021842-kyfo47f4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/kyfo47f4' target=\"_blank\">fold-1-efficientnet_b3-0218</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/kyfo47f4' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/kyfo47f4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 1 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team-CV/runs/kyfo47f4\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 1\n",
      "\n",
      "📈 Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.9053, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 20/20 [00:35<00:00,  1.80s/it]\n",
      "Val Loss: 2.3544: 100%|██████████| 5/5 [00:02<00:00,  1.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 3 F1: 0.1980\n",
      "  Class 7 F1: 0.2588\n",
      "  Class 14 F1: 0.2000\n",
      "  Problem Classes Avg F1: 0.2189\n",
      " Epoch  1 | Train Loss: 3.1569 | Train F1: 0.0707 | Val Loss: 2.2478 | Val F1: 0.2575 | LR: 2.00e-04\n",
      "         Problem Classes (3,7,14) Avg F1: 0.2189 | ✅ Problem classes performing well\n",
      "🎉 새로운 최고 성능! F1: 0.2575 (Problem Classes: 0.2189)\n",
      "\n",
      "📈 Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.6389, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 20/20 [00:16<00:00,  1.22it/s]\n",
      "Val Loss: 2.0480: 100%|██████████| 5/5 [00:02<00:00,  2.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 3 F1: 0.2336\n",
      "  Class 7 F1: 0.3103\n",
      "  Class 14 F1: 0.1111\n",
      "  Problem Classes Avg F1: 0.2183\n",
      " Epoch  2 | Train Loss: 2.5265 | Train F1: 0.1662 | Val Loss: 1.9551 | Val F1: 0.4072 | LR: 1.81e-04\n",
      "         Problem Classes (3,7,14) Avg F1: 0.2183 | ⚠️ Problem classes need attention\n",
      "🎉 새로운 최고 성능! F1: 0.4072 (Problem Classes: 0.2183)\n",
      "\n",
      "📈 Epoch 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3842, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 20/20 [00:16<00:00,  1.20it/s]\n",
      "Val Loss: 1.9502: 100%|██████████| 5/5 [00:01<00:00,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 3 F1: 0.2368\n",
      "  Class 7 F1: 0.0625\n",
      "  Class 14 F1: 0.0000\n",
      "  Problem Classes Avg F1: 0.0998\n",
      " Epoch  3 | Train Loss: 2.3387 | Train F1: 0.2710 | Val Loss: 1.8810 | Val F1: 0.4629 | LR: 1.31e-04\n",
      "         Problem Classes (3,7,14) Avg F1: 0.0998 | ⚠️ Problem classes need attention\n",
      "🎉 새로운 최고 성능! F1: 0.4629 (Problem Classes: 0.0998)\n",
      "\n",
      "📈 Epoch 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3648, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 20/20 [00:17<00:00,  1.16it/s]\n",
      "Val Loss: 1.7044: 100%|██████████| 5/5 [00:01<00:00,  2.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Class 3 F1: 0.2727\n",
      "  Class 7 F1: 0.2500\n",
      "  Class 14 F1: 0.1176\n",
      "  Problem Classes Avg F1: 0.2135\n",
      " Epoch  4 | Train Loss: 2.2945 | Train F1: 0.2921 | Val Loss: 1.7210 | Val F1: 0.5273 | LR: 6.91e-05\n",
      "         Problem Classes (3,7,14) Avg F1: 0.2135 | ⚠️ Problem classes need attention\n",
      "🎉 새로운 최고 성능! F1: 0.5273 (Problem Classes: 0.2135)\n",
      "\n",
      "📈 Epoch 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 5:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "def ensemble_tta_inference_with_logging(models, loader, confidence_threshold=0.9):\n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    print(f\"앙상블 TTA 추론 시작...\")\n",
    "    print(f\"{len(models)}개 모델 × {len(essential_tta_transforms)}개 TTA = {len(models)*len(essential_tta_transforms)} 예측 평균\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (aug_inputs_list, targets) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = len(targets)\n",
    "        ensemble_probs = torch.zeros(batch_size * len(aug_inputs_list[0]), num_classes).to(device)  # TTA 확장\n",
    "        \n",
    "        for model in models:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for aug_idx, inputs in enumerate(aug_inputs_list):  # TTA 루프\n",
    "                    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "                    outputs = model(**inputs)\n",
    "                    probs = torch.softmax(outputs.logits, dim=1)\n",
    "                    ensemble_probs[aug_idx::len(aug_inputs_list)] += probs / len(models)\n",
    "        \n",
    "        # 평균 후 원본 배치 크기로 reshape\n",
    "        ensemble_probs = ensemble_probs.view(batch_size, -1, num_classes).mean(dim=1)\n",
    "        \n",
    "        max_probs = torch.max(ensemble_probs, dim=1)[0]\n",
    "        batch_confidences = max_probs.cpu().numpy()\n",
    "        all_confidences.extend(batch_confidences)\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "        \n",
    "        # 로깅 (기존과 동일)\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    print(f\"\\n 앙상블 TTA 추론 완료! 총 소요시간: {total_time/60:.1f}분\")\n",
    "    return all_predictions, all_confidences\n",
    "\n",
    "tta_predictions, confidences = ensemble_tta_inference_with_logging(ensemble_models, tta_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " K-FOLD CROSS VALIDATION 최종 결과\n",
      "============================================================\n",
      " 기존 run을 사용합니다.\n",
      " CV 결과 로깅 완료!\n",
      "Fold 1: 0.9390 (70 epochs)  Completed\n",
      "Fold 2: 0.9319 (70 epochs)  Completed\n",
      "Fold 3: 0.9420 (70 epochs)  Completed\n",
      "Fold 4: 0.9376 (70 epochs)  Completed\n",
      "Fold 5: 0.9402 (70 epochs)  Completed\n",
      "\n",
      " 평균 CV F1: 0.9381 ± 0.0035\n",
      " 최고 Fold: 0.9420\n",
      " 최악 Fold: 0.9319\n",
      " 성능 범위: 0.0102\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 13. K-Fold Cross Validation Results Summary\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" K-FOLD CROSS VALIDATION 최종 결과\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "try:\n",
    "    # wandb.run이 현재 활성화된 run을 가리킴\n",
    "    if wandb.run is None:\n",
    "        print(\" 활성화된 run이 없어 새로운 summary run을 생성합니다.\")\n",
    "        active_run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "            config=config,\n",
    "            tags=[\"summary\", \"cv-results\", model_name],\n",
    "            group=\"k-fold-experiment\",\n",
    "            job_type=\"summary\",\n",
    "            reinit=True\n",
    "        )\n",
    "    else:\n",
    "        print(\" 기존 run을 사용합니다.\")\n",
    "        active_run = wandb.run\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Run 상태 확인 중 에러: {e}\")\n",
    "    # 새로운 run 생성\n",
    "    active_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"summary\", \"cv-results\", model_name],\n",
    "        group=\"k-fold-experiment\",\n",
    "        job_type=\"summary\",\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "# CV 요약 테이블 생성\n",
    "fold_table = wandb.Table(columns=[\n",
    "    \"Fold\", \"Best_Val_F1\", \"Final_Train_F1\", \"Train_Samples\", \n",
    "    \"Val_Samples\", \"Epochs_Trained\", \"Early_Stopped\"\n",
    "])\n",
    "\n",
    "for result in fold_results:\n",
    "    fold_table.add_data(\n",
    "        result['fold'], \n",
    "        result['best_val_f1'], \n",
    "        result['final_train_f1'],\n",
    "        result['train_samples'], \n",
    "        result['val_samples'],\n",
    "        result['epochs_trained'],\n",
    "        result['early_stopped']\n",
    "    )\n",
    "\n",
    "# 안전한 로깅\n",
    "try:\n",
    "    active_run.log({\n",
    "        \"cv_results/mean_f1\": mean_f1,\n",
    "        \"cv_results/std_f1\": std_f1,\n",
    "        \"cv_results/best_fold_f1\": max(val_f1_scores),\n",
    "        \"cv_results/worst_fold_f1\": min(val_f1_scores),\n",
    "        \"cv_results/f1_range\": max(val_f1_scores) - min(val_f1_scores),\n",
    "        \"cv_results/fold_results_table\": fold_table,\n",
    "        \"cv_results/n_folds\": N_FOLDS,\n",
    "        \"cv_results/total_epochs\": sum([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/avg_epochs_per_fold\": np.mean([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/early_stopped_folds\": sum([r['early_stopped'] for r in fold_results])\n",
    "    })\n",
    "    \n",
    "    # Fold별 성능 바차트 생성\n",
    "    fold_performance_data = [[f\"Fold {i+1}\", score] for i, score in enumerate(val_f1_scores)]\n",
    "    active_run.log({\n",
    "        \"cv_results/fold_performance_chart\": wandb.plot.bar(\n",
    "            wandb.Table(data=fold_performance_data, columns=[\"Fold\", \"F1_Score\"]),\n",
    "            \"Fold\", \"F1_Score\", \n",
    "            title=\"K-Fold Cross Validation Performance\"\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(\" CV 결과 로깅 완료!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" WandB 로깅 중 에러: {e}\")\n",
    "    print(\" 결과를 콘솔에 출력합니다:\")\n",
    "\n",
    "# 어떤 경우든 콘솔에는 결과 출력\n",
    "for result in fold_results:\n",
    "    status = \" Early Stopped\" if result['early_stopped'] else \" Completed\"\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f} \"\n",
    "          f\"({result['epochs_trained']} epochs) {status}\")\n",
    "\n",
    "print(f\"\\n 평균 CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\" 최고 Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\" 최악 Fold: {min(val_f1_scores):.4f}\")\n",
    "print(f\" 성능 범위: {max(val_f1_scores) - min(val_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb258fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 앙상블 모델 준비 중...\n",
      "Fold 1 모델 로드 완료\n",
      "Fold 2 모델 로드 완료\n",
      "Fold 3 모델 로드 완료\n",
      "Fold 4 모델 로드 완료\n",
      "Fold 5 모델 로드 완료\n",
      " 총 5개 모델로 앙상블 구성\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 14. Ensemble Models Preparation\n",
    "# =============================================================================\n",
    "\n",
    "# 5-Fold 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "print(f\"\\n🔧 앙상블 모델 준비 중...\")\n",
    "\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "    print(f\"Fold {i+1} 모델 로드 완료\")\n",
    "\n",
    "print(f\" 총 {len(ensemble_models)}개 모델로 앙상블 구성\")\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"ensemble/num_models\": len(ensemble_models),\n",
    "            \"ensemble/model_architecture\": model_name,\n",
    "            \"ensemble/ensemble_type\": \"simple_average\"\n",
    "        })\n",
    "    else:\n",
    "        print(\"📊 앙상블 정보:\")\n",
    "        print(f\"  - 모델 개수: {len(ensemble_models)}\")\n",
    "        print(f\"  - 아키텍처: {model_name}\")\n",
    "        print(f\"  - 앙상블 타입: simple_average\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 앙상블 정보 로깅 실패: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb2ab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TTA (Test Time Augmentation) 설정...\n",
      "TTA 변환 5개 준비 완료\n"
     ]
    }
   ],
   "source": [
    "tta_pred_df = pd.DataFrame(test_df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions\n",
    "tta_pred_df.to_csv('../data/output/layoutlmv3_ensemble.csv', index=False)\n",
    "\n",
    "# WandB 아티팩트 등 (기존)\n",
    "print(\"최종 결과 저장 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
