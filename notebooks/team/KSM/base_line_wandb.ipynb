{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bbe02e",
   "metadata": {},
   "source": [
    "# 📄 Document type classification baseline code with WandB Integration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92dc69ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '../requirements.txt'\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 0. Prepare Environments & Install Libraries\n",
    "# =============================================================================\n",
    "\n",
    "# 필요한 라이브러리를 설치합니다.\n",
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f264cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 노트북 작업 시작: base_line_wandb\n",
      "📝 로그 디렉토리: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/notebooks/team/KSM/base_line_wandb/20250908_100101\n",
      "✅ KSM WandB 베이스라인 노트북 로거 설정 완료!\n",
      "📁 로그 경로: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN/notebooks/team/KSM/base_line_wandb/20250908_100101/logs\n"
     ]
    }
   ],
   "source": [
    "# [추가] KSM 노트북 로거 설정\n",
    "# 결과 저장을 위한 로거 초기화\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../../../')  # 프로젝트 루트로 경로 추가\n",
    "\n",
    "from src.logging.notebook_logger import create_notebook_logger\n",
    "\n",
    "# 프로젝트 루트 디렉토리 찾기\n",
    "current_dir = os.getcwd()\n",
    "if 'notebooks/team/KSM' in current_dir:\n",
    "    project_root = current_dir.replace('/notebooks/team/KSM', '')\n",
    "else:\n",
    "    project_root = os.path.abspath('../../../')\n",
    "\n",
    "# 절대 경로로 팀 노트북 로거 초기화\n",
    "base_log_path = os.path.join(project_root, \"notebooks/team\")\n",
    "logger = create_notebook_logger(\n",
    "    base_log_dir=base_log_path,\n",
    "    folder_name=\"KSM\", \n",
    "    file_name=\"base_line_wandb\"\n",
    ")\n",
    "\n",
    "print(\"✅ KSM WandB 베이스라인 노트북 로거 설정 완료!\")\n",
    "print(f\"📁 로그 경로: {logger.log_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "773408ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. Import Libraries & Define Functions\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "\n",
    "import optuna, math\n",
    "import timm\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler  # Mixed Precision용\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# WandB 관련 import 추가\n",
    "import wandb\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e142354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB 로그인 상태: ieyeppo-job\n",
      "프로젝트: document-classification-team\n",
      "실험명: efficientnet-b3-baseline\n",
      "EXPERIMENT_NAME을 각자 다르게 변경해주세요!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 1-1. WandB Login and Configuration\n",
    "# =============================================================================\n",
    "\"\"\"\n",
    "🚀 사용 가이드:\n",
    "\n",
    "1. WandB 계정 생성: https://wandb.ai/signup\n",
    "2. 이 셀 실행 시 로그인 프롬프트가 나타나면 개인 API 키 입력\n",
    "3. EXPERIMENT_NAME을 다음과 같이 변경:\n",
    "   - \"member1-baseline\"\n",
    "   - \"member2-augmentation-test\"  \n",
    "   - \"member3-hyperparameter-tuning\"\n",
    "   등등 각자 다른 이름 사용\n",
    "\n",
    "4. 팀 대시보드 URL: [여기에 당신의 프로젝트 URL 추가]\n",
    "\n",
    "⚠️ 주의사항:\n",
    "- 절대 API 키를 코드에 하드코딩하지 마세요\n",
    "- EXPERIMENT_NAME만 변경하고 PROJECT_NAME은 그대로 두세요\n",
    "- 각자 개인 계정으로 로그인해서 실험을 추가하세요\n",
    "\"\"\"\n",
    "\n",
    "# WandB 로그인 (각자 실행)\n",
    "try:\n",
    "    if wandb.api.api_key is None:\n",
    "        print(\"WandB에 로그인이 필요합니다.\")\n",
    "        wandb.login()\n",
    "    else:\n",
    "        print(f\"WandB 로그인 상태: {wandb.api.viewer()['username']}\")\n",
    "except:\n",
    "    print(\"WandB 로그인을 진행합니다...\")\n",
    "    wandb.login()\n",
    "\n",
    "# 프로젝트 설정 (각자 수정할 부분)\n",
    "PROJECT_NAME = \"document-classification-team\"  # 모든 동일\n",
    "ENTITY = None  # 각자 개인 계정 사용\n",
    "EXPERIMENT_NAME = \"efficientnet-b3-baseline\"  # 팀원별로 변경 (예: \"member1-hyperopt\", \"member2-augmentation\")\n",
    "\n",
    "print(f\"프로젝트: {PROJECT_NAME}\")\n",
    "print(f\"실험명: {EXPERIMENT_NAME}\")\n",
    "print(\"EXPERIMENT_NAME을 각자 다르게 변경해주세요!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "448a2f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 3. Seed & basic augmentations (Mixup)\n",
    "# =============================================================================\n",
    "\n",
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f9d1a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 4. Dataset Class\n",
    "# =============================================================================\n",
    "\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transform=None):\n",
    "        # CSV 파일이면 읽고, DataFrame이면 그대로 사용\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values  # DataFrame을 numpy array로 변환\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cacecd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import wandb\n",
    "\n",
    "# Cutout (Random Erasing) 함수 정의\n",
    "def random_erasing(image, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3)):\n",
    "    if random.random() > p:\n",
    "        return image\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    area = img_h * img_w\n",
    "    \n",
    "    target_area = random.uniform(scale[0], scale[1]) * area\n",
    "    aspect_ratio = random.uniform(ratio[0], ratio[1])\n",
    "    h = int(round(math.sqrt(target_area * aspect_ratio)))\n",
    "    w = int(round(math.sqrt(target_area / aspect_ratio)))\n",
    "    \n",
    "    if h < img_h and w < img_w:\n",
    "        x = random.randint(0, img_w - w)\n",
    "        y = random.randint(0, img_h - h)\n",
    "        image[:, :, y:y+h, x:x+w] = 0.0  # 제거된 영역을 0으로 설정\n",
    "    return image\n",
    "\n",
    "# RandomCrop 함수 정의\n",
    "def random_crop(image, crop_size=0.8):\n",
    "    img_c, img_h, img_w = image.shape[1], image.shape[2], image.shape[3]\n",
    "    crop_h = int(img_h * crop_size)\n",
    "    crop_w = int(img_w * crop_size)\n",
    "    \n",
    "    if crop_h >= img_h or crop_w >= img_w:\n",
    "        return image\n",
    "    \n",
    "    x = random.randint(0, img_w - crop_w)\n",
    "    y = random.randint(0, img_h - crop_h)\n",
    "    cropped_image = image[:, :, y:y+crop_h, x:x+crop_w]\n",
    "    \n",
    "    # 원래 이미지 크기로 복원 (패딩 또는 리사이즈)\n",
    "    cropped_image = torch.nn.functional.interpolate(cropped_image, size=(img_h, img_w), mode='bilinear', align_corners=False)\n",
    "    return cropped_image\n",
    "\n",
    "# Mixup 함수 정의\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device, epoch=None, fold=None):\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader, desc=f\"Training Epoch {epoch+1 if epoch else '?'}\")\n",
    "    batch_count = 0\n",
    "    \n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # 증강 기법 선택 (Mixup 25%, Cutout 25%, RandomCrop 25%, None 25%)\n",
    "        aug_type = random.choices(['mixup', 'cutout', 'random_crop', 'none'], weights=[0.25, 0.25, 0.25, 0.25])[0]\n",
    "        mixup_applied = False\n",
    "        cutout_applied = False\n",
    "        random_crop_applied = False\n",
    "        \n",
    "        if aug_type == 'mixup':\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): \n",
    "                preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "            mixup_applied = True\n",
    "        elif aug_type == 'cutout':\n",
    "            image = random_erasing(image, p=0.5, scale=(0.02, 0.33), ratio=(0.3, 3.3))\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            cutout_applied = True\n",
    "        elif aug_type == 'random_crop':\n",
    "            image = random_crop(image, crop_size=0.8)\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            random_crop_applied = True\n",
    "        else:\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        # 배치별 상세 로깅 (100 배치마다)\n",
    "        if batch_count % 100 == 0 and wandb.run is not None:\n",
    "            step = epoch * len(loader) + batch_count if epoch is not None else batch_count\n",
    "            wandb.log({\n",
    "                f\"fold_{fold}/train_batch_loss\": loss.item(),\n",
    "                f\"fold_{fold}/mixup_applied\": int(mixup_applied),\n",
    "                f\"fold_{fold}/cutout_applied\": int(cutout_applied),\n",
    "                f\"fold_{fold}/random_crop_applied\": int(random_crop_applied),\n",
    "                f\"fold_{fold}/batch_step\": step\n",
    "            })\n",
    "        \n",
    "        batch_count += 1\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}, Mixup: {mixup_applied}, Cutout: {cutout_applied}, RandomCrop: {random_crop_applied}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    ret = {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "    return ret\n",
    "\n",
    "def validate_one_epoch(loader, model, loss_fn, device, epoch=None, fold=None, log_confusion=False):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=f\"Validating Epoch {epoch+1 if epoch else '?'}\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    \n",
    "    # Confusion Matrix 로깅 (마지막 epoch에만)\n",
    "    if log_confusion and wandb.run is not None:\n",
    "        try:\n",
    "            wandb.log({\n",
    "                f\"fold_{fold}/confusion_matrix\": wandb.plot.confusion_matrix(\n",
    "                    probs=None,\n",
    "                    y_true=targets_list,\n",
    "                    preds=preds_list,\n",
    "                    class_names=[f\"Class_{i}\" for i in range(17)]\n",
    "                )\n",
    "            })\n",
    "            \n",
    "            # 클래스별 F1 스코어\n",
    "            class_f1_scores = f1_score(targets_list, preds_list, average=None)\n",
    "            for i, class_f1 in enumerate(class_f1_scores):\n",
    "                wandb.log({f\"fold_{fold}/class_{i}_f1\": class_f1})\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\" Confusion matrix 로깅 실패: {e}\")\n",
    "    \n",
    "    ret = {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,  \n",
    "        \"val_f1\": val_f1,\n",
    "    }\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "193dae06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Using device: cuda\n",
      " 하이퍼파라미터 설정 완료!\n",
      " 모델: efficientnet_b3\n",
      " 이미지 크기: 384x384\n",
      " 배치 크기: 32\n",
      " 학습률: 0.0005\n",
      " 에폭: 20\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 6. Hyper-parameters with WandB Config\n",
    "# =============================================================================\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\" Using device: {device}\")\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "model_name = 'efficientnet_b3' # 'resnet50' 'efficientnet-b0', ...\n",
    "\n",
    "# training config\n",
    "img_size = 384\n",
    "LR = 5e-4\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 32\n",
    "num_workers = 30\n",
    "\n",
    "# K-Fold config\n",
    "N_FOLDS = 5  # 5-fold로 설정\n",
    "\n",
    "# WandB Config 설정\n",
    "config = {\n",
    "    # Model config\n",
    "    \"model_name\": model_name,\n",
    "    \"img_size\": img_size,\n",
    "    \"num_classes\": 17,\n",
    "    \"architecture\": \"EfficientNet-B3\",\n",
    "    \n",
    "    # Training config  \n",
    "    \"lr\": LR,\n",
    "    \"epochs\": EPOCHS,\n",
    "    \"batch_size\": BATCH_SIZE,\n",
    "    \"num_workers\": num_workers,\n",
    "    \"device\": str(device),\n",
    "    \n",
    "    # K-Fold config\n",
    "    \"n_folds\": N_FOLDS,\n",
    "    \"seed\": SEED,\n",
    "    \"cv_strategy\": \"StratifiedKFold\",\n",
    "    \n",
    "    # Augmentation & Training techniques\n",
    "    \"mixup_alpha\": 1.0,\n",
    "    \"mixup_prob\": 0.3,\n",
    "    \"label_smoothing\": 0.2,\n",
    "    \"gradient_clipping\": 1.0,\n",
    "    \"mixed_precision\": True,\n",
    "    \n",
    "    # Optimizer & Scheduler\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"scheduler\": \"CosineAnnealingLR\",\n",
    "    \n",
    "    # Data\n",
    "    \"data_path\": data_path,\n",
    "    \"train_transforms\": \"Advanced\",\n",
    "    \"test_transforms\": \"Basic\",\n",
    "}\n",
    "\n",
    "print(\" 하이퍼파라미터 설정 완료!\")\n",
    "print(f\" 모델: {model_name}\")\n",
    "print(f\" 이미지 크기: {img_size}x{img_size}\")\n",
    "print(f\" 배치 크기: {BATCH_SIZE}\")\n",
    "print(f\" 학습률: {LR}\")\n",
    "print(f\" 에폭: {EPOCHS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a4e28f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏭️ Optuna 튜닝 건너뛰기 (USE_OPTUNA=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 7. Optuna Hyperparameter Tuning (선택적)\n",
    "# =============================================================================\n",
    "\n",
    "USE_OPTUNA = False  # True로 바꾸면 튜닝 실행\n",
    "\n",
    "if USE_OPTUNA:\n",
    "    print(\"🔍 Optuna 하이퍼파라미터 튜닝 시작...\")\n",
    "    \n",
    "    def objective(trial):\n",
    "        lr = trial.suggest_loguniform('lr', 1e-5, 1e-2)\n",
    "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
    "        \n",
    "        # WandB에 Optuna 시행 로깅\n",
    "        optuna_run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            entity=ENTITY,\n",
    "            name=f\"optuna-trial-{trial.number}\",\n",
    "            config={**config, \"lr\": lr, \"batch_size\": batch_size},\n",
    "            tags=[\"optuna\", \"hyperparameter-tuning\"],\n",
    "            group=\"optuna-study\",\n",
    "            job_type=\"hyperparameter-optimization\",\n",
    "            reinit=True\n",
    "        )\n",
    "        \n",
    "        # 간단한 3-fold CV로 빠른 평가\n",
    "        skf_simple = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        fold_scores = []\n",
    "        \n",
    "        # 간단한 평가 로직 (실제 구현에서는 더 단순화)\n",
    "        # ... (Optuna 로직은 복잡하므로 기본적으로 비활성화)\n",
    "        \n",
    "        optuna_run.finish()\n",
    "        return np.random.random()  # placeholder\n",
    "    \n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(objective, n_trials=10)\n",
    "    \n",
    "    # 최적 파라미터 적용\n",
    "    best_params = study.best_params\n",
    "    LR = best_params.get('lr', LR)\n",
    "    BATCH_SIZE = best_params.get('batch_size', BATCH_SIZE)\n",
    "    config.update(best_params)\n",
    "    print(f\"🎯 Optuna 최적 파라미터: {best_params}\")\n",
    "else:\n",
    "    print(\"⏭️ Optuna 튜닝 건너뛰기 (USE_OPTUNA=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6514acaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 데이터 변환 설정 완료!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 8. Data Transforms\n",
    "# =============================================================================\n",
    "\n",
    "# augmentation을 위한 transform 코드\n",
    "trn_transform = A.Compose([\n",
    "    # 비율 보존 리사이징 (핵심 개선)\n",
    "    A.LongestMaxSize(max_size=img_size),\n",
    "    A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "                  border_mode=0, value=0),\n",
    "    \n",
    "    # 문서 특화 회전 + 미세 회전 추가\n",
    "    A.OneOf([\n",
    "        A.Rotate(limit=[90,90], p=1.0),\n",
    "        A.Rotate(limit=[180,180], p=1.0),\n",
    "        A.Rotate(limit=[270,270], p=1.0),\n",
    "        A.Rotate(limit=(-15, 15), p=1.0),  # 미세 회전 추가\n",
    "    ], p=0.7),\n",
    "    \n",
    "    # 기하학적 변환 강화\n",
    "    A.OneOf([\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.2, rotate_limit=5, p=1.0),\n",
    "        A.ElasticTransform(alpha=50, sigma=5, p=1.0),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.2, p=1.0),\n",
    "        A.OpticalDistortion(distort_limit=0.2, shift_limit=0.1, p=1.0),\n",
    "    ], p=0.6),\n",
    "    \n",
    "    # 색상 및 조명 변환 강화\n",
    "    A.OneOf([\n",
    "        A.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3, hue=0.1, p=1.0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=1.0),\n",
    "        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=1.0),\n",
    "        A.RandomGamma(gamma_limit=(70, 130), p=1.0),\n",
    "    ], p=0.9),\n",
    "    \n",
    "    # 블러 및 노이즈 강화\n",
    "    A.OneOf([\n",
    "        A.MotionBlur(blur_limit=(5, 15), p=1.0),\n",
    "        A.GaussianBlur(blur_limit=(3, 15), p=1.0),\n",
    "        A.MedianBlur(blur_limit=7, p=1.0),\n",
    "        A.Blur(blur_limit=7, p=1.0),\n",
    "    ], p=0.8),\n",
    "    \n",
    "    # 다양한 노이즈 추가\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 150.0), p=1.0),\n",
    "        A.ISONoise(color_shift=(0.01, 0.08), intensity=(0.1, 0.8), p=1.0),\n",
    "        A.MultiplicativeNoise(multiplier=(0.9, 1.1), p=1.0),\n",
    "    ], p=0.8),\n",
    "    \n",
    "    # 문서 품질 시뮬레이션 (스캔/복사 효과)\n",
    "    A.OneOf([\n",
    "        A.Downscale(scale_min=0.7, scale_max=0.9, p=1.0),\n",
    "        A.ImageCompression(quality_lower=60, quality_upper=95, p=1.0),\n",
    "        A.Posterize(num_bits=6, p=1.0),\n",
    "    ], p=0.5),\n",
    "    \n",
    "    # 픽셀 레벨 변환\n",
    "    A.OneOf([\n",
    "        A.ChannelShuffle(p=1.0),\n",
    "        A.InvertImg(p=1.0),\n",
    "        A.Solarize(threshold=128, p=1.0),\n",
    "        A.Equalize(p=1.0),\n",
    "    ], p=0.3),\n",
    "    \n",
    "    # 공간 변환\n",
    "    A.OneOf([\n",
    "        A.HorizontalFlip(p=1.0),\n",
    "        A.VerticalFlip(p=1.0),  # 문서에서도 유용할 수 있음\n",
    "        A.Transpose(p=1.0),\n",
    "    ], p=0.6),\n",
    "    \n",
    "    # 조각 제거 (Cutout 계열)\n",
    "    A.OneOf([\n",
    "        A.CoarseDropout(max_holes=8, max_height=32, max_width=32, \n",
    "                       min_holes=1, min_height=8, min_width=8, \n",
    "                       fill_value=0, p=1.0),\n",
    "        A.GridDropout(ratio=0.3, unit_size_min=8, unit_size_max=32, \n",
    "                     holes_number_x=5, holes_number_y=5, p=1.0),\n",
    "    ], p=0.4),\n",
    "    \n",
    "    # 최종 정규화\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.LongestMaxSize(max_size=img_size),\n",
    "    A.PadIfNeeded(min_height=img_size, min_width=img_size, \n",
    "                  border_mode=0, value=0),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "print(\"✅ 데이터 변환 설정 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c320bb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/train.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# 9. Load Data & Start K-Fold Cross Validation with WandB\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# =============================================================================\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# 전체 학습 데이터 로드\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m train_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../data/train.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m📊 학습 데이터: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(train_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m개 샘플\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# 클래스 분포 확인\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/.pyenv/versions/cv_py3_11_9/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/train.csv'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 9. Load Data & Start K-Fold Cross Validation with WandB\n",
    "# =============================================================================\n",
    "\n",
    "# 전체 학습 데이터 로드\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "print(f\"📊 학습 데이터: {len(train_df)}개 샘플\")\n",
    "\n",
    "# 클래스 분포 확인\n",
    "class_counts = train_df['target'].value_counts().sort_index()\n",
    "print(f\"📊 클래스 분포: {dict(class_counts)}\")\n",
    "\n",
    "# K-Fold 설정\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=SEED)\n",
    "\n",
    "# K-Fold 결과를 저장할 리스트\n",
    "fold_results = []\n",
    "fold_models = []  # 각 fold의 최고 성능 모델을 저장\n",
    "\n",
    "# 🔥 WandB 메인 실험 시작\n",
    "main_run = wandb.init(\n",
    "    project=PROJECT_NAME,\n",
    "    entity=ENTITY,\n",
    "    name=f\"{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "    config=config,\n",
    "    tags=[\"k-fold-cv\", \"ensemble\", model_name, \"baseline\", \"main-experiment\"],\n",
    "    group=\"k-fold-experiment\",\n",
    "    job_type=\"cross-validation\",\n",
    "    notes=f\"{N_FOLDS}-Fold Cross Validation with {model_name}\"\n",
    ")\n",
    "\n",
    "print(f\"\\n🚀 WandB 실험 시작!\")\n",
    "print(f\"📊 대시보드: {main_run.url}\")\n",
    "print(f\"📋 실험명: {main_run.name}\")\n",
    "\n",
    "# 🔥 데이터셋 정보 로깅\n",
    "wandb.log({\n",
    "    \"dataset/total_samples\": len(train_df),\n",
    "    \"dataset/num_classes\": 17,\n",
    "    \"dataset/samples_per_fold\": len(train_df) // N_FOLDS,\n",
    "})\n",
    "\n",
    "# 클래스 분포 시각화\n",
    "class_dist_data = [[f\"Class_{i}\", count] for i, count in enumerate(class_counts)]\n",
    "wandb.log({\n",
    "    \"dataset/class_distribution\": wandb.plot.bar(\n",
    "        wandb.Table(data=class_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "        \"Class\", \"Count\", \n",
    "        title=\"Training Data Class Distribution\"\n",
    "    )\n",
    "})\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"🎯 {N_FOLDS}-FOLD CROSS VALIDATION 시작\")\n",
    "print(f\"{'='*60}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1675898e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 1/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing previous runs because reinit is set to True."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>dataset/num_classes</td><td>▁</td></tr><tr><td>dataset/samples_per_fold</td><td>▁</td></tr><tr><td>dataset/total_samples</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>dataset/num_classes</td><td>17</td></tr><tr><td>dataset/samples_per_fold</td><td>314</td></tr><tr><td>dataset/total_samples</td><td>1570</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">efficientnet-b3-baseline-0904-0754</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/33mcvmnd' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/33mcvmnd</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_075452-33mcvmnd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.0s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_075454-ntt230pg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg' target=\"_blank\">fold-1-efficientnet_b3-0754</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 1 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 1\n",
      "\n",
      "📈 Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0938, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:22<00:00,  1.80it/s] \n",
      "Val Loss: 1.9117: 100%|██████████| 10/10 [00:02<00:00,  4.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6401 | Train F1: 0.2732 | Val Loss: 1.7623 | Val F1: 0.6438 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6438\n",
      "\n",
      "📈 Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6455, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.5206: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 1.9741 | Train F1: 0.4973 | Val Loss: 1.4790 | Val F1: 0.7849 | LR: 4.97e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7849\n",
      "\n",
      "📈 Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4590, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.3645: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8228 | Train F1: 0.5685 | Val Loss: 1.3636 | Val F1: 0.8620 | LR: 4.88e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8620\n",
      "\n",
      "📈 Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4844, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.54it/s] \n",
      "Val Loss: 1.2827: 100%|██████████| 10/10 [00:01<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.7240 | Train F1: 0.6141 | Val Loss: 1.3204 | Val F1: 0.8541 | LR: 4.73e-04\n",
      "\n",
      "📈 Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3564, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.2952: 100%|██████████| 10/10 [00:01<00:00,  6.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.5353 | Train F1: 0.7256 | Val Loss: 1.3177 | Val F1: 0.8583 | LR: 4.52e-04\n",
      "\n",
      "📈 Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3896, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.54it/s] \n",
      "Val Loss: 1.2469: 100%|██████████| 10/10 [00:01<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5157 | Train F1: 0.7389 | Val Loss: 1.2839 | Val F1: 0.8861 | LR: 4.27e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8861\n",
      "\n",
      "📈 Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3828, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s] \n",
      "Val Loss: 1.2499: 100%|██████████| 10/10 [00:01<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5113 | Train F1: 0.7232 | Val Loss: 1.2654 | Val F1: 0.8769 | LR: 3.97e-04\n",
      "\n",
      "📈 Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4023, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s] \n",
      "Val Loss: 1.2177: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4392 | Train F1: 0.7772 | Val Loss: 1.2375 | Val F1: 0.9160 | LR: 3.63e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9160\n",
      "\n",
      "📈 Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6074, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.2170: 100%|██████████| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.4630 | Train F1: 0.7505 | Val Loss: 1.2220 | Val F1: 0.9192 | LR: 3.27e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9192\n",
      "\n",
      "📈 Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4307, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.50it/s]\n",
      "Val Loss: 1.2012: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.3925 | Train F1: 0.7538 | Val Loss: 1.2135 | Val F1: 0.9094 | LR: 2.89e-04\n",
      "\n",
      "📈 Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9121, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1859: 100%|██████████| 10/10 [00:01<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3645 | Train F1: 0.8073 | Val Loss: 1.2133 | Val F1: 0.9117 | LR: 2.50e-04\n",
      "\n",
      "📈 Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9707, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s] \n",
      "Val Loss: 1.1706: 100%|██████████| 10/10 [00:01<00:00,  6.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.3486 | Train F1: 0.8122 | Val Loss: 1.1891 | Val F1: 0.9112 | LR: 2.11e-04\n",
      "\n",
      "📈 Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3848, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.49it/s]\n",
      "Val Loss: 1.1733: 100%|██████████| 10/10 [00:01<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3942 | Train F1: 0.7625 | Val Loss: 1.1865 | Val F1: 0.9129 | LR: 1.73e-04\n",
      "\n",
      "📈 Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3848, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.57it/s] \n",
      "Val Loss: 1.1805: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.3367 | Train F1: 0.8155 | Val Loss: 1.1879 | Val F1: 0.9118 | LR: 1.37e-04\n",
      "⏸️ Early stopping at epoch 14 (patience: 5)\n",
      "\n",
      " Fold 1 완료!\n",
      " 최고 Validation F1: 0.9192\n",
      " 학습된 에폭: 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>▁▂▃▅▇█</td></tr><tr><td>best_performance/val_acc</td><td>▁▅▇▇██</td></tr><tr><td>best_performance/val_f1</td><td>▁▅▇▇██</td></tr><tr><td>best_performance/val_loss</td><td>█▄▃▂▁▁</td></tr><tr><td>early_stopping/epoch</td><td>▁</td></tr><tr><td>epoch</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_1/batch_step</td><td>▁▂▂▃▃▄▄▅▅▆▆▇▇█</td></tr><tr><td>fold_1/cutout_applied</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁█</td></tr><tr><td>fold_1/mixup_applied</td><td>▁█▁██▁██▁█▁▁█▁</td></tr><tr><td>+22</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>9</td></tr><tr><td>best_performance/val_acc</td><td>0.92038</td></tr><tr><td>best_performance/val_f1</td><td>0.91925</td></tr><tr><td>best_performance/val_loss</td><td>1.22202</td></tr><tr><td>early_stopping/epoch</td><td>14</td></tr><tr><td>epoch</td><td>14</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>fold_1/batch_step</td><td>520</td></tr><tr><td>fold_1/cutout_applied</td><td>1</td></tr><tr><td>fold_1/mixup_applied</td><td>0</td></tr><tr><td>+23</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-1-efficientnet_b3-0754</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/ntt230pg</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_075454-ntt230pg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 2/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_075817-7evzevji</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji' target=\"_blank\">fold-2-efficientnet_b3-0758</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 2 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 2\n",
      "\n",
      "📈 Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.7520, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.38it/s] \n",
      "Val Loss: 1.7706: 100%|██████████| 10/10 [00:01<00:00,  6.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6738 | Train F1: 0.2635 | Val Loss: 1.7295 | Val F1: 0.6444 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6444\n",
      "\n",
      "📈 Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.5371, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.4631: 100%|██████████| 10/10 [00:01<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0344 | Train F1: 0.4750 | Val Loss: 1.5403 | Val F1: 0.7463 | LR: 4.97e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7463\n",
      "\n",
      "📈 Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6445, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.3431: 100%|██████████| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8692 | Train F1: 0.5374 | Val Loss: 1.4240 | Val F1: 0.7881 | LR: 4.88e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7881\n",
      "\n",
      "📈 Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1758, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.2829: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.6638 | Train F1: 0.6592 | Val Loss: 1.3933 | Val F1: 0.7911 | LR: 4.73e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7911\n",
      "\n",
      "📈 Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5371, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.2342: 100%|██████████| 10/10 [00:01<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.5699 | Train F1: 0.6724 | Val Loss: 1.3434 | Val F1: 0.8136 | LR: 4.52e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8136\n",
      "\n",
      "📈 Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1621, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2431: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5816 | Train F1: 0.6486 | Val Loss: 1.2639 | Val F1: 0.8562 | LR: 4.27e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8562\n",
      "\n",
      "📈 Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4316, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.2097: 100%|██████████| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.4582 | Train F1: 0.7425 | Val Loss: 1.2582 | Val F1: 0.8401 | LR: 3.97e-04\n",
      "\n",
      "📈 Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1914, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.44it/s] \n",
      "Val Loss: 1.2060: 100%|██████████| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4659 | Train F1: 0.7609 | Val Loss: 1.2543 | Val F1: 0.8633 | LR: 3.63e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8633\n",
      "\n",
      "📈 Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4062, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s] \n",
      "Val Loss: 1.2070: 100%|██████████| 10/10 [00:01<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.3693 | Train F1: 0.7763 | Val Loss: 1.2246 | Val F1: 0.8793 | LR: 3.27e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8793\n",
      "\n",
      "📈 Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4062, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.46it/s] \n",
      "Val Loss: 1.1994: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4686 | Train F1: 0.7348 | Val Loss: 1.2243 | Val F1: 0.8833 | LR: 2.89e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8833\n",
      "\n",
      "📈 Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6064, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s] \n",
      "Val Loss: 1.1883: 100%|██████████| 10/10 [00:01<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.4028 | Train F1: 0.7998 | Val Loss: 1.2267 | Val F1: 0.8850 | LR: 2.50e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8850\n",
      "\n",
      "📈 Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4883, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.46it/s] \n",
      "Val Loss: 1.1917: 100%|██████████| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4041 | Train F1: 0.7761 | Val Loss: 1.2082 | Val F1: 0.8892 | LR: 2.11e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8892\n",
      "\n",
      "📈 Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1973, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.35it/s]\n",
      "Val Loss: 1.1864: 100%|██████████| 10/10 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.4141 | Train F1: 0.7496 | Val Loss: 1.2055 | Val F1: 0.8908 | LR: 1.73e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8908\n",
      "\n",
      "📈 Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1367, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.1915: 100%|██████████| 10/10 [00:01<00:00,  5.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.3296 | Train F1: 0.8128 | Val Loss: 1.2028 | Val F1: 0.8872 | LR: 1.37e-04\n",
      "\n",
      "📈 Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2207, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s]\n",
      "Val Loss: 1.1823: 100%|██████████| 10/10 [00:01<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3956 | Train F1: 0.8291 | Val Loss: 1.2018 | Val F1: 0.8900 | LR: 1.03e-04\n",
      "\n",
      "📈 Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1729, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s]\n",
      "Val Loss: 1.1807: 100%|██████████| 10/10 [00:01<00:00,  6.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3757 | Train F1: 0.8046 | Val Loss: 1.1951 | Val F1: 0.8932 | LR: 7.32e-05\n",
      "🎉 새로운 최고 성능! F1: 0.8932\n",
      "\n",
      "📈 Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1797, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.53it/s] \n",
      "Val Loss: 1.1887: 100%|██████████| 10/10 [00:01<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3500 | Train F1: 0.7719 | Val Loss: 1.1961 | Val F1: 0.9013 | LR: 4.77e-05\n",
      "🎉 새로운 최고 성능! F1: 0.9013\n",
      "\n",
      "📈 Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6318, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.1778: 100%|██████████| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3928 | Train F1: 0.7797 | Val Loss: 1.1935 | Val F1: 0.8894 | LR: 2.72e-05\n",
      "\n",
      "📈 Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4385, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.47it/s]\n",
      "Val Loss: 1.1823: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3652 | Train F1: 0.7895 | Val Loss: 1.1990 | Val F1: 0.8943 | LR: 1.22e-05\n",
      "\n",
      "📈 Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4355, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.44it/s] \n",
      "Val Loss: 1.1783: 100%|██████████| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3849 | Train F1: 0.7775 | Val Loss: 1.1906 | Val F1: 0.9044 | LR: 3.08e-06\n",
      "🎉 새로운 최고 성능! F1: 0.9044\n",
      "\n",
      " Fold 2 완료!\n",
      " 최고 Validation F1: 0.9044\n",
      " 학습된 에폭: 20/20\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>▁▁▂▂▂▃▄▄▄▅▅▅▇▇█</td></tr><tr><td>best_performance/val_acc</td><td>▁▃▅▆▆▇▇████████</td></tr><tr><td>best_performance/val_f1</td><td>▁▄▅▅▆▇▇▇▇▇█████</td></tr><tr><td>best_performance/val_loss</td><td>█▆▄▄▃▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_2/batch_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>fold_2/class_0_f1</td><td>▁</td></tr><tr><td>fold_2/class_10_f1</td><td>▁</td></tr><tr><td>fold_2/class_11_f1</td><td>▁</td></tr><tr><td>+38</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>20</td></tr><tr><td>best_performance/val_acc</td><td>0.91401</td></tr><tr><td>best_performance/val_f1</td><td>0.90444</td></tr><tr><td>best_performance/val_loss</td><td>1.19062</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>fold</td><td>2</td></tr><tr><td>fold_2/batch_step</td><td>760</td></tr><tr><td>fold_2/class_0_f1</td><td>1</td></tr><tr><td>fold_2/class_10_f1</td><td>0.97561</td></tr><tr><td>fold_2/class_11_f1</td><td>0.97436</td></tr><tr><td>+39</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-2-efficientnet_b3-0758</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/7evzevji</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_075817-7evzevji/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 3/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_080252-r4x6xv1j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j' target=\"_blank\">fold-3-efficientnet_b3-0802</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 3 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 3\n",
      "\n",
      "📈 Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4102, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.41it/s] \n",
      "Val Loss: 1.6706: 100%|██████████| 10/10 [00:01<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6402 | Train F1: 0.2743 | Val Loss: 1.8420 | Val F1: 0.6640 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6640\n",
      "\n",
      "📈 Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2852, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.44it/s] \n",
      "Val Loss: 1.5030: 100%|██████████| 10/10 [00:01<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0035 | Train F1: 0.4779 | Val Loss: 1.5414 | Val F1: 0.7738 | LR: 4.97e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7738\n",
      "\n",
      "📈 Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6328, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s]\n",
      "Val Loss: 1.3036: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8453 | Train F1: 0.5796 | Val Loss: 1.4037 | Val F1: 0.8275 | LR: 4.88e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8275\n",
      "\n",
      "📈 Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7676, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s] \n",
      "Val Loss: 1.2570: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.6822 | Train F1: 0.6650 | Val Loss: 1.3447 | Val F1: 0.8335 | LR: 4.73e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8335\n",
      "\n",
      "📈 Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2129, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.33it/s] \n",
      "Val Loss: 1.2888: 100%|██████████| 10/10 [00:01<00:00,  5.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.6298 | Train F1: 0.6681 | Val Loss: 1.3003 | Val F1: 0.8494 | LR: 4.52e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8494\n",
      "\n",
      "📈 Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4727, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.2134: 100%|██████████| 10/10 [00:01<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5290 | Train F1: 0.6814 | Val Loss: 1.2893 | Val F1: 0.8502 | LR: 4.27e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8502\n",
      "\n",
      "📈 Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7129, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1917: 100%|██████████| 10/10 [00:01<00:00,  6.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5687 | Train F1: 0.6248 | Val Loss: 1.2784 | Val F1: 0.8742 | LR: 3.97e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8742\n",
      "\n",
      "📈 Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6123, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s] \n",
      "Val Loss: 1.1879: 100%|██████████| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4762 | Train F1: 0.7810 | Val Loss: 1.3029 | Val F1: 0.8301 | LR: 3.63e-04\n",
      "\n",
      "📈 Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3418, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.41it/s] \n",
      "Val Loss: 1.1923: 100%|██████████| 10/10 [00:01<00:00,  5.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.3884 | Train F1: 0.8296 | Val Loss: 1.2429 | Val F1: 0.8873 | LR: 3.27e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8873\n",
      "\n",
      "📈 Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4336, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.27it/s] \n",
      "Val Loss: 1.1728: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.3858 | Train F1: 0.8131 | Val Loss: 1.2224 | Val F1: 0.9110 | LR: 2.89e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9110\n",
      "\n",
      "📈 Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1914, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.46it/s]\n",
      "Val Loss: 1.1582: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3786 | Train F1: 0.7365 | Val Loss: 1.2069 | Val F1: 0.9008 | LR: 2.50e-04\n",
      "\n",
      "📈 Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2480, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.48it/s]\n",
      "Val Loss: 1.1326: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.4666 | Train F1: 0.7583 | Val Loss: 1.2023 | Val F1: 0.9058 | LR: 2.11e-04\n",
      "\n",
      "📈 Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7109, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.33it/s] \n",
      "Val Loss: 1.1337: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3352 | Train F1: 0.8182 | Val Loss: 1.1997 | Val F1: 0.8947 | LR: 1.73e-04\n",
      "\n",
      "📈 Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1836, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.41it/s] \n",
      "Val Loss: 1.1592: 100%|██████████| 10/10 [00:01<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.3543 | Train F1: 0.8598 | Val Loss: 1.2030 | Val F1: 0.8923 | LR: 1.37e-04\n",
      "\n",
      "📈 Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2490, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1135: 100%|██████████| 10/10 [00:01<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3207 | Train F1: 0.8179 | Val Loss: 1.1900 | Val F1: 0.9265 | LR: 1.03e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9265\n",
      "\n",
      "📈 Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6074, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.1307: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3486 | Train F1: 0.8386 | Val Loss: 1.1832 | Val F1: 0.9254 | LR: 7.32e-05\n",
      "\n",
      "📈 Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2119, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s]\n",
      "Val Loss: 1.1164: 100%|██████████| 10/10 [00:01<00:00,  5.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3418 | Train F1: 0.8049 | Val Loss: 1.1879 | Val F1: 0.9197 | LR: 4.77e-05\n",
      "\n",
      "📈 Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3184, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1211: 100%|██████████| 10/10 [00:01<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.4034 | Train F1: 0.7640 | Val Loss: 1.1828 | Val F1: 0.9172 | LR: 2.72e-05\n",
      "\n",
      "📈 Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9990, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s] \n",
      "Val Loss: 1.1241: 100%|██████████| 10/10 [00:01<00:00,  6.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.4034 | Train F1: 0.7406 | Val Loss: 1.1869 | Val F1: 0.9125 | LR: 1.22e-05\n",
      "\n",
      "📈 Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3359, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s] \n",
      "Val Loss: 1.1189: 100%|██████████| 10/10 [00:01<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3301 | Train F1: 0.8194 | Val Loss: 1.1881 | Val F1: 0.9254 | LR: 3.08e-06\n",
      "⏸️ Early stopping at epoch 20 (patience: 5)\n",
      "\n",
      " Fold 3 완료!\n",
      " 최고 Validation F1: 0.9265\n",
      " 학습된 에폭: 20/20\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>▁▁▂▃▃▃▄▅▅█</td></tr><tr><td>best_performance/val_acc</td><td>▁▅▅▆▆▆▇▇██</td></tr><tr><td>best_performance/val_f1</td><td>▁▄▅▆▆▆▇▇██</td></tr><tr><td>best_performance/val_loss</td><td>█▅▃▃▂▂▂▂▁▁</td></tr><tr><td>early_stopping/epoch</td><td>▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_3/batch_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>fold_3/class_0_f1</td><td>▁</td></tr><tr><td>fold_3/class_10_f1</td><td>▁</td></tr><tr><td>+39</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>15</td></tr><tr><td>best_performance/val_acc</td><td>0.92994</td></tr><tr><td>best_performance/val_f1</td><td>0.92646</td></tr><tr><td>best_performance/val_loss</td><td>1.19002</td></tr><tr><td>early_stopping/epoch</td><td>20</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>fold</td><td>3</td></tr><tr><td>fold_3/batch_step</td><td>760</td></tr><tr><td>fold_3/class_0_f1</td><td>1</td></tr><tr><td>fold_3/class_10_f1</td><td>0.97561</td></tr><tr><td>+40</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-3-efficientnet_b3-0802</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/r4x6xv1j</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_080252-r4x6xv1j/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 4/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.2s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_080726-163vzl9h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h' target=\"_blank\">fold-4-efficientnet_b3-0807</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 4 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 4\n",
      "\n",
      "📈 Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.1406, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.41it/s] \n",
      "Val Loss: 1.6792: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6917 | Train F1: 0.2255 | Val Loss: 1.8451 | Val F1: 0.6301 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6301\n",
      "\n",
      "📈 Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.0449, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.4110: 100%|██████████| 10/10 [00:01<00:00,  5.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0737 | Train F1: 0.4742 | Val Loss: 1.5523 | Val F1: 0.7422 | LR: 4.97e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7422\n",
      "\n",
      "📈 Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.4883, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.3267: 100%|██████████| 10/10 [00:01<00:00,  5.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.8374 | Train F1: 0.5897 | Val Loss: 1.4371 | Val F1: 0.8072 | LR: 4.88e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8072\n",
      "\n",
      "📈 Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9893, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s] \n",
      "Val Loss: 1.3116: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.5992 | Train F1: 0.7112 | Val Loss: 1.3592 | Val F1: 0.8242 | LR: 4.73e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8242\n",
      "\n",
      "📈 Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.3281, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s] \n",
      "Val Loss: 1.2396: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.5490 | Train F1: 0.7364 | Val Loss: 1.3080 | Val F1: 0.8528 | LR: 4.52e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8528\n",
      "\n",
      "📈 Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1934, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s] \n",
      "Val Loss: 1.2123: 100%|██████████| 10/10 [00:01<00:00,  5.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.5487 | Train F1: 0.7681 | Val Loss: 1.3052 | Val F1: 0.8433 | LR: 4.27e-04\n",
      "\n",
      "📈 Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7500, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1508: 100%|██████████| 10/10 [00:01<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.5261 | Train F1: 0.7736 | Val Loss: 1.2868 | Val F1: 0.8729 | LR: 3.97e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8729\n",
      "\n",
      "📈 Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5684, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s]\n",
      "Val Loss: 1.1705: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4707 | Train F1: 0.7543 | Val Loss: 1.2541 | Val F1: 0.8730 | LR: 3.63e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8730\n",
      "\n",
      "📈 Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1240, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s]\n",
      "Val Loss: 1.1497: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.3894 | Train F1: 0.8111 | Val Loss: 1.2536 | Val F1: 0.8643 | LR: 3.27e-04\n",
      "\n",
      "📈 Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3945, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:12<00:00,  3.26it/s] \n",
      "Val Loss: 1.1505: 100%|██████████| 10/10 [00:01<00:00,  5.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4487 | Train F1: 0.7726 | Val Loss: 1.2585 | Val F1: 0.8779 | LR: 2.89e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8779\n",
      "\n",
      "📈 Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1064, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.1334: 100%|██████████| 10/10 [00:01<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.3683 | Train F1: 0.7620 | Val Loss: 1.2478 | Val F1: 0.8844 | LR: 2.50e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8844\n",
      "\n",
      "📈 Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2324, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.35it/s] \n",
      "Val Loss: 1.1087: 100%|██████████| 10/10 [00:01<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.3586 | Train F1: 0.7946 | Val Loss: 1.2240 | Val F1: 0.8792 | LR: 2.11e-04\n",
      "\n",
      "📈 Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0820, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.0997: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3780 | Train F1: 0.7871 | Val Loss: 1.2172 | Val F1: 0.8921 | LR: 1.73e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8921\n",
      "\n",
      "📈 Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1650, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s] \n",
      "Val Loss: 1.1342: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.3663 | Train F1: 0.7710 | Val Loss: 1.2123 | Val F1: 0.8968 | LR: 1.37e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8968\n",
      "\n",
      "📈 Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9727, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.1040: 100%|██████████| 10/10 [00:01<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.3880 | Train F1: 0.8063 | Val Loss: 1.2114 | Val F1: 0.8948 | LR: 1.03e-04\n",
      "\n",
      "📈 Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1543, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s]\n",
      "Val Loss: 1.0868: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.3710 | Train F1: 0.7617 | Val Loss: 1.2044 | Val F1: 0.8840 | LR: 7.32e-05\n",
      "\n",
      "📈 Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1504, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s] \n",
      "Val Loss: 1.0826: 100%|██████████| 10/10 [00:01<00:00,  5.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3151 | Train F1: 0.8399 | Val Loss: 1.2002 | Val F1: 0.8862 | LR: 4.77e-05\n",
      "\n",
      "📈 Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2246, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.0825: 100%|██████████| 10/10 [00:01<00:00,  5.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3750 | Train F1: 0.8142 | Val Loss: 1.2096 | Val F1: 0.9018 | LR: 2.72e-05\n",
      "🎉 새로운 최고 성능! F1: 0.9018\n",
      "\n",
      "📈 Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4648, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.32it/s] \n",
      "Val Loss: 1.0845: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3540 | Train F1: 0.8152 | Val Loss: 1.2041 | Val F1: 0.8925 | LR: 1.22e-05\n",
      "\n",
      "📈 Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3057, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s] \n",
      "Val Loss: 1.0833: 100%|██████████| 10/10 [00:01<00:00,  5.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3095 | Train F1: 0.7919 | Val Loss: 1.1991 | Val F1: 0.8957 | LR: 3.08e-06\n",
      "\n",
      " Fold 4 완료!\n",
      " 최고 Validation F1: 0.9018\n",
      " 학습된 에폭: 20/20\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>▁▁▂▂▃▃▄▅▅▆▆█</td></tr><tr><td>best_performance/val_acc</td><td>▁▄▆▇▇▇▇█████</td></tr><tr><td>best_performance/val_f1</td><td>▁▄▆▆▇▇▇▇████</td></tr><tr><td>best_performance/val_loss</td><td>█▅▄▃▂▂▁▂▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_4/batch_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>fold_4/class_0_f1</td><td>▁</td></tr><tr><td>fold_4/class_10_f1</td><td>▁</td></tr><tr><td>fold_4/class_11_f1</td><td>▁</td></tr><tr><td>+38</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>18</td></tr><tr><td>best_performance/val_acc</td><td>0.91083</td></tr><tr><td>best_performance/val_f1</td><td>0.90183</td></tr><tr><td>best_performance/val_loss</td><td>1.20964</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>fold</td><td>4</td></tr><tr><td>fold_4/batch_step</td><td>760</td></tr><tr><td>fold_4/class_0_f1</td><td>1</td></tr><tr><td>fold_4/class_10_f1</td><td>0.95238</td></tr><tr><td>fold_4/class_11_f1</td><td>0.97436</td></tr><tr><td>+39</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-4-efficientnet_b3-0807</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/163vzl9h</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_080726-163vzl9h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      " FOLD 5/5\n",
      "==================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_081204-8yksq1wj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj' target=\"_blank\">fold-5-efficientnet_b3-0812</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Fold 5 Dashboard: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj\n",
      "Train samples: 1256, Validation samples: 314\n",
      " 모델 학습 시작 - Fold 5\n",
      "\n",
      "📈 Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 2.2012, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.38it/s]\n",
      "Val Loss: 1.5064: 100%|██████████| 10/10 [00:01<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  1 | Train Loss: 2.6446 | Train F1: 0.2751 | Val Loss: 1.7031 | Val F1: 0.6697 | LR: 5.00e-04\n",
      "🎉 새로운 최고 성능! F1: 0.6697\n",
      "\n",
      "📈 Epoch 2/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6357, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s] \n",
      "Val Loss: 1.4501: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  2 | Train Loss: 2.0776 | Train F1: 0.4621 | Val Loss: 1.4837 | Val F1: 0.7563 | LR: 4.97e-04\n",
      "🎉 새로운 최고 성능! F1: 0.7563\n",
      "\n",
      "📈 Epoch 3/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4199, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.43it/s]\n",
      "Val Loss: 1.3335: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  3 | Train Loss: 1.7302 | Train F1: 0.6339 | Val Loss: 1.4094 | Val F1: 0.8046 | LR: 4.88e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8046\n",
      "\n",
      "📈 Epoch 4/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9062, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.34it/s] \n",
      "Val Loss: 1.2759: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  4 | Train Loss: 1.6755 | Train F1: 0.6616 | Val Loss: 1.3467 | Val F1: 0.8449 | LR: 4.73e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8449\n",
      "\n",
      "📈 Epoch 5/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4424, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.41it/s] \n",
      "Val Loss: 1.3042: 100%|██████████| 10/10 [00:01<00:00,  5.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  5 | Train Loss: 1.6271 | Train F1: 0.6825 | Val Loss: 1.3463 | Val F1: 0.8140 | LR: 4.52e-04\n",
      "\n",
      "📈 Epoch 6/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3477, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.36it/s] \n",
      "Val Loss: 1.2070: 100%|██████████| 10/10 [00:01<00:00,  5.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  6 | Train Loss: 1.6422 | Train F1: 0.7196 | Val Loss: 1.2879 | Val F1: 0.8673 | LR: 4.27e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8673\n",
      "\n",
      "📈 Epoch 7/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5049, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.38it/s] \n",
      "Val Loss: 1.2214: 100%|██████████| 10/10 [00:01<00:00,  5.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  7 | Train Loss: 1.4339 | Train F1: 0.8043 | Val Loss: 1.2782 | Val F1: 0.8714 | LR: 3.97e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8714\n",
      "\n",
      "📈 Epoch 8/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6260, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.49it/s] \n",
      "Val Loss: 1.1724: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  8 | Train Loss: 1.4801 | Train F1: 0.7811 | Val Loss: 1.2626 | Val F1: 0.8646 | LR: 3.63e-04\n",
      "\n",
      "📈 Epoch 9/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.3730, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.1226: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch  9 | Train Loss: 1.4188 | Train F1: 0.8018 | Val Loss: 1.2430 | Val F1: 0.8848 | LR: 3.27e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8848\n",
      "\n",
      "📈 Epoch 10/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.4727, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.1518: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 1.4720 | Train F1: 0.7429 | Val Loss: 1.2294 | Val F1: 0.8900 | LR: 2.89e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8900\n",
      "\n",
      "📈 Epoch 11/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.7383, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.2056: 100%|██████████| 10/10 [00:01<00:00,  5.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 1.4065 | Train F1: 0.7534 | Val Loss: 1.2264 | Val F1: 0.8820 | LR: 2.50e-04\n",
      "\n",
      "📈 Epoch 12/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.9287, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.42it/s] \n",
      "Val Loss: 1.1097: 100%|██████████| 10/10 [00:01<00:00,  6.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 1.3601 | Train F1: 0.7947 | Val Loss: 1.2159 | Val F1: 0.8903 | LR: 2.11e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8903\n",
      "\n",
      "📈 Epoch 13/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0596, Mixup: False, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.44it/s]\n",
      "Val Loss: 1.0938: 100%|██████████| 10/10 [00:01<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 1.3048 | Train F1: 0.8415 | Val Loss: 1.2032 | Val F1: 0.8974 | LR: 1.73e-04\n",
      "🎉 새로운 최고 성능! F1: 0.8974\n",
      "\n",
      "📈 Epoch 14/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1016, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.38it/s] \n",
      "Val Loss: 1.0985: 100%|██████████| 10/10 [00:01<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 1.4739 | Train F1: 0.6990 | Val Loss: 1.2045 | Val F1: 0.9051 | LR: 1.37e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9051\n",
      "\n",
      "📈 Epoch 15/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.1621, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.40it/s] \n",
      "Val Loss: 1.1045: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 1.4612 | Train F1: 0.7266 | Val Loss: 1.1888 | Val F1: 0.9069 | LR: 1.03e-04\n",
      "🎉 새로운 최고 성능! F1: 0.9069\n",
      "\n",
      "📈 Epoch 16/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2637, Mixup: False, Cutout: True, RandomCrop: False: 100%|██████████| 40/40 [00:12<00:00,  3.25it/s] \n",
      "Val Loss: 1.1070: 100%|██████████| 10/10 [00:01<00:00,  5.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 1.4022 | Train F1: 0.8060 | Val Loss: 1.1809 | Val F1: 0.9217 | LR: 7.32e-05\n",
      "🎉 새로운 최고 성능! F1: 0.9217\n",
      "\n",
      "📈 Epoch 17/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5713, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.1048: 100%|██████████| 10/10 [00:01<00:00,  5.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 1.3484 | Train F1: 0.8238 | Val Loss: 1.1816 | Val F1: 0.9198 | LR: 4.77e-05\n",
      "\n",
      "📈 Epoch 18/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.6270, Mixup: True, Cutout: False, RandomCrop: False: 100%|██████████| 40/40 [00:11<00:00,  3.37it/s] \n",
      "Val Loss: 1.0994: 100%|██████████| 10/10 [00:01<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 1.3664 | Train F1: 0.8020 | Val Loss: 1.1775 | Val F1: 0.9157 | LR: 2.72e-05\n",
      "\n",
      "📈 Epoch 19/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.5947, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.39it/s] \n",
      "Val Loss: 1.1034: 100%|██████████| 10/10 [00:01<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 1.3957 | Train F1: 0.7767 | Val Loss: 1.1849 | Val F1: 0.9341 | LR: 1.22e-05\n",
      "🎉 새로운 최고 성능! F1: 0.9341\n",
      "\n",
      "📈 Epoch 20/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.2988, Mixup: False, Cutout: False, RandomCrop: True: 100%|██████████| 40/40 [00:11<00:00,  3.45it/s] \n",
      "Val Loss: 1.0994: 100%|██████████| 10/10 [00:01<00:00,  5.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 1.3864 | Train F1: 0.8222 | Val Loss: 1.1757 | Val F1: 0.9126 | LR: 3.08e-06\n",
      "\n",
      " Fold 5 완료!\n",
      " 최고 Validation F1: 0.9341\n",
      " 학습된 에폭: 20/20\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>▁▁▂▂▃▃▄▅▅▆▆▆▇█</td></tr><tr><td>best_performance/val_acc</td><td>▁▄▅▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>best_performance/val_f1</td><td>▁▃▅▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>best_performance/val_loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>fold_5/batch_step</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>fold_5/class_0_f1</td><td>▁</td></tr><tr><td>fold_5/class_10_f1</td><td>▁</td></tr><tr><td>fold_5/class_11_f1</td><td>▁</td></tr><tr><td>+38</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_performance/epoch</td><td>19</td></tr><tr><td>best_performance/val_acc</td><td>0.93631</td></tr><tr><td>best_performance/val_f1</td><td>0.93409</td></tr><tr><td>best_performance/val_loss</td><td>1.1849</td></tr><tr><td>epoch</td><td>20</td></tr><tr><td>fold</td><td>5</td></tr><tr><td>fold_5/batch_step</td><td>760</td></tr><tr><td>fold_5/class_0_f1</td><td>1</td></tr><tr><td>fold_5/class_10_f1</td><td>1</td></tr><tr><td>fold_5/class_11_f1</td><td>1</td></tr><tr><td>+39</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold-5-efficientnet_b3-0812</strong> at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/8yksq1wj</a><br> View project at: <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a><br>Synced 5 W&B file(s), 1 media file(s), 2 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250904_081204-8yksq1wj/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 10. K-Fold Cross Validation Loop with WandB\n",
    "# =============================================================================\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\" FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 각 fold별 child run 생성\n",
    "    fold_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        entity=ENTITY,\n",
    "        name=f\"fold-{fold+1}-{model_name}-{datetime.now().strftime('%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"fold\", f\"fold-{fold+1}\", model_name, \"child-run\"],\n",
    "        group=\"k-fold-experiment\",\n",
    "        job_type=f\"fold-{fold+1}\",\n",
    "        reinit=True  # 새로운 run 시작 허용\n",
    "    )\n",
    "    \n",
    "    print(f\"📊 Fold {fold+1} Dashboard: {fold_run.url}\")\n",
    "    \n",
    "    # 현재 fold의 train/validation 데이터 분할\n",
    "    train_fold_df = train_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 데이터 분할 정보 로깅\n",
    "    wandb.log({\n",
    "        \"fold_info/fold_number\": fold + 1,\n",
    "        \"fold_info/train_samples\": len(train_fold_df),\n",
    "        \"fold_info/val_samples\": len(val_fold_df),\n",
    "        \"fold_info/train_ratio\": len(train_fold_df) / len(train_df),\n",
    "        \"fold_info/val_ratio\": len(val_fold_df) / len(train_df)\n",
    "    })\n",
    "    \n",
    "    # 현재 fold의 Dataset 생성\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        transform=trn_transform\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        transform=tst_transform  # 검증에는 증강 적용 안함\n",
    "    )\n",
    "    \n",
    "    # 현재 fold의 DataLoader 생성\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # 모델 초기화 (각 fold마다 새로운 모델)\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=17\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.2)  # Label Smoothing 적용\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    \n",
    "    # Learning Rate Scheduler 추가\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # 현재 fold의 최고 성능 추적\n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    patience = 0\n",
    "    max_patience = 5\n",
    "    \n",
    "    print(f\" 모델 학습 시작 - Fold {fold+1}\")\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 11. Training Loop for Current Fold\n",
    "    # =============================================================================\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"\\n📈 Epoch {epoch+1}/{EPOCHS}\")\n",
    "        \n",
    "        # Training\n",
    "        train_ret = train_one_epoch(\n",
    "            trn_loader, model, optimizer, loss_fn, device, \n",
    "            epoch=epoch, fold=fold+1\n",
    "        )\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(\n",
    "            val_loader, model, loss_fn, device, \n",
    "            epoch=epoch, fold=fold+1,\n",
    "            log_confusion=(epoch == EPOCHS-1)  # 마지막 epoch에만 confusion matrix\n",
    "        )\n",
    "        \n",
    "        # Learning rate 로깅\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # WandB에 metrics 로깅\n",
    "        log_data = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"fold\": fold + 1,\n",
    "            \"train/loss\": train_ret['train_loss'],\n",
    "            \"train/accuracy\": train_ret['train_acc'], \n",
    "            \"train/f1\": train_ret['train_f1'],\n",
    "            \"val/loss\": val_ret['val_loss'],\n",
    "            \"val/accuracy\": val_ret['val_acc'],\n",
    "            \"val/f1\": val_ret['val_f1'],\n",
    "            \"learning_rate\": current_lr,\n",
    "            \"optimizer/lr\": current_lr\n",
    "        }\n",
    "        \n",
    "        # GPU 메모리 사용량 로깅\n",
    "        if torch.cuda.is_available():\n",
    "            gpu_memory_used = torch.cuda.memory_allocated(0) / 1e9\n",
    "            gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "            log_data.update({\n",
    "                \"system/gpu_memory_used_gb\": gpu_memory_used,\n",
    "                \"system/gpu_memory_total_gb\": gpu_memory_total,\n",
    "                \"system/gpu_utilization_pct\": (gpu_memory_used / gpu_memory_total) * 100\n",
    "            })\n",
    "        \n",
    "        wandb.log(log_data)\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\" Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f} | \"\n",
    "              f\"LR: {current_lr:.2e}\")\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "            patience = 0\n",
    "            \n",
    "            # 최고 성능 모델 아티팩트로 저장\n",
    "            model_path = f'best_model_fold_{fold+1}.pth'\n",
    "            torch.save(best_model, model_path)\n",
    "            wandb.save(model_path, policy=\"now\")\n",
    "            \n",
    "            # 새로운 최고 성능 로깅\n",
    "            wandb.log({\n",
    "                f\"best_performance/epoch\": epoch + 1,\n",
    "                f\"best_performance/val_f1\": best_val_f1,\n",
    "                f\"best_performance/val_acc\": val_ret['val_acc'],\n",
    "                f\"best_performance/val_loss\": val_ret['val_loss'],\n",
    "            })\n",
    "            \n",
    "            print(f\"🎉 새로운 최고 성능! F1: {best_val_f1:.4f}\")\n",
    "        else:\n",
    "            patience += 1\n",
    "            \n",
    "        # Early stopping (선택적)\n",
    "        if patience >= max_patience and epoch > EPOCHS // 2:\n",
    "            print(f\"⏸️ Early stopping at epoch {epoch+1} (patience: {patience})\")\n",
    "            wandb.log({\"early_stopping/epoch\": epoch + 1})\n",
    "            break\n",
    "    \n",
    "    # =============================================================================\n",
    "    # 12. Fold Results Summary\n",
    "    # =============================================================================\n",
    "    \n",
    "    # 현재 fold 결과 저장\n",
    "    fold_result = {\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'final_train_f1': train_ret['train_f1'],\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset),\n",
    "        'epochs_trained': epoch + 1,\n",
    "        'early_stopped': patience >= max_patience\n",
    "    }\n",
    "    \n",
    "    fold_results.append(fold_result)\n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    # Fold 최종 요약 로깅\n",
    "    wandb.log({\n",
    "        \"fold_summary/best_val_f1\": best_val_f1,\n",
    "        \"fold_summary/final_train_f1\": train_ret['train_f1'],\n",
    "        \"fold_summary/epochs_trained\": epoch + 1,\n",
    "        \"fold_summary/improvement\": best_val_f1 - val_ret['val_f1'],\n",
    "        \"fold_summary/early_stopped\": patience >= max_patience\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n Fold {fold + 1} 완료!\")\n",
    "    print(f\" 최고 Validation F1: {best_val_f1:.4f}\")\n",
    "    print(f\" 학습된 에폭: {epoch + 1}/{EPOCHS}\")\n",
    "    \n",
    "    # Fold run 종료\n",
    "    wandb.finish()\n",
    "    \n",
    "    # 메모리 정리\n",
    "    del model, optimizer, scheduler, trn_loader, val_loader\n",
    "    torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545246d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " K-FOLD CROSS VALIDATION 최종 결과\n",
      "============================================================\n",
      " 활성화된 run이 없어 새로운 summary run을 생성합니다.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "creating run (0.1s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/data/ephemeral/home/computervisioncompetition-cv-1/wandb/wandb/run-20250904_081641-1y8ppzz2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/1y8ppzz2' target=\"_blank\">SUMMARY-efficientnet-b3-baseline-0904-0816</a></strong> to <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/1y8ppzz2' target=\"_blank\">https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/1y8ppzz2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " CV 결과 로깅 완료!\n",
      "Fold 1: 0.9192 (14 epochs)  Early Stopped\n",
      "Fold 2: 0.9044 (20 epochs)  Completed\n",
      "Fold 3: 0.9265 (20 epochs)  Early Stopped\n",
      "Fold 4: 0.9018 (20 epochs)  Completed\n",
      "Fold 5: 0.9341 (20 epochs)  Completed\n",
      "\n",
      " 평균 CV F1: 0.9172 ± 0.0124\n",
      " 최고 Fold: 0.9341\n",
      " 최악 Fold: 0.9018\n",
      " 성능 범위: 0.0323\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 13. K-Fold Cross Validation Results Summary\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" K-FOLD CROSS VALIDATION 최종 결과\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "try:\n",
    "    # wandb.run이 현재 활성화된 run을 가리킴\n",
    "    if wandb.run is None:\n",
    "        print(\" 활성화된 run이 없어 새로운 summary run을 생성합니다.\")\n",
    "        active_run = wandb.init(\n",
    "            project=PROJECT_NAME,\n",
    "            name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "            config=config,\n",
    "            tags=[\"summary\", \"cv-results\", model_name],\n",
    "            group=\"k-fold-experiment\",\n",
    "            job_type=\"summary\",\n",
    "            reinit=True\n",
    "        )\n",
    "    else:\n",
    "        print(\" 기존 run을 사용합니다.\")\n",
    "        active_run = wandb.run\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\" Run 상태 확인 중 에러: {e}\")\n",
    "    # 새로운 run 생성\n",
    "    active_run = wandb.init(\n",
    "        project=PROJECT_NAME,\n",
    "        name=f\"SUMMARY-{EXPERIMENT_NAME}-{datetime.now().strftime('%m%d-%H%M')}\",\n",
    "        config=config,\n",
    "        tags=[\"summary\", \"cv-results\", model_name],\n",
    "        group=\"k-fold-experiment\",\n",
    "        job_type=\"summary\",\n",
    "        reinit=True\n",
    "    )\n",
    "\n",
    "# CV 요약 테이블 생성\n",
    "fold_table = wandb.Table(columns=[\n",
    "    \"Fold\", \"Best_Val_F1\", \"Final_Train_F1\", \"Train_Samples\", \n",
    "    \"Val_Samples\", \"Epochs_Trained\", \"Early_Stopped\"\n",
    "])\n",
    "\n",
    "for result in fold_results:\n",
    "    fold_table.add_data(\n",
    "        result['fold'], \n",
    "        result['best_val_f1'], \n",
    "        result['final_train_f1'],\n",
    "        result['train_samples'], \n",
    "        result['val_samples'],\n",
    "        result['epochs_trained'],\n",
    "        result['early_stopped']\n",
    "    )\n",
    "\n",
    "# 안전한 로깅\n",
    "try:\n",
    "    active_run.log({\n",
    "        \"cv_results/mean_f1\": mean_f1,\n",
    "        \"cv_results/std_f1\": std_f1,\n",
    "        \"cv_results/best_fold_f1\": max(val_f1_scores),\n",
    "        \"cv_results/worst_fold_f1\": min(val_f1_scores),\n",
    "        \"cv_results/f1_range\": max(val_f1_scores) - min(val_f1_scores),\n",
    "        \"cv_results/fold_results_table\": fold_table,\n",
    "        \"cv_results/n_folds\": N_FOLDS,\n",
    "        \"cv_results/total_epochs\": sum([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/avg_epochs_per_fold\": np.mean([r['epochs_trained'] for r in fold_results]),\n",
    "        \"cv_results/early_stopped_folds\": sum([r['early_stopped'] for r in fold_results])\n",
    "    })\n",
    "    \n",
    "    # Fold별 성능 바차트 생성\n",
    "    fold_performance_data = [[f\"Fold {i+1}\", score] for i, score in enumerate(val_f1_scores)]\n",
    "    active_run.log({\n",
    "        \"cv_results/fold_performance_chart\": wandb.plot.bar(\n",
    "            wandb.Table(data=fold_performance_data, columns=[\"Fold\", \"F1_Score\"]),\n",
    "            \"Fold\", \"F1_Score\", \n",
    "            title=\"K-Fold Cross Validation Performance\"\n",
    "        )\n",
    "    })\n",
    "    \n",
    "    print(\" CV 결과 로깅 완료!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" WandB 로깅 중 에러: {e}\")\n",
    "    print(\" 결과를 콘솔에 출력합니다:\")\n",
    "\n",
    "# 어떤 경우든 콘솔에는 결과 출력\n",
    "for result in fold_results:\n",
    "    status = \" Early Stopped\" if result['early_stopped'] else \" Completed\"\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f} \"\n",
    "          f\"({result['epochs_trained']} epochs) {status}\")\n",
    "\n",
    "print(f\"\\n 평균 CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\" 최고 Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\" 최악 Fold: {min(val_f1_scores):.4f}\")\n",
    "print(f\" 성능 범위: {max(val_f1_scores) - min(val_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c1ddb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 앙상블 모델 준비 중...\n",
      "Fold 1 모델 로드 완료\n",
      "Fold 2 모델 로드 완료\n",
      "Fold 3 모델 로드 완료\n",
      "Fold 4 모델 로드 완료\n",
      "Fold 5 모델 로드 완료\n",
      " 총 5개 모델로 앙상블 구성\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 14. Ensemble Models Preparation\n",
    "# =============================================================================\n",
    "\n",
    "# 5-Fold 앙상블 모델 준비\n",
    "ensemble_models = []\n",
    "print(f\"\\n🔧 앙상블 모델 준비 중...\")\n",
    "\n",
    "for i, state_dict in enumerate(fold_models):\n",
    "    fold_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "    fold_model.load_state_dict(state_dict)\n",
    "    fold_model.eval()\n",
    "    ensemble_models.append(fold_model)\n",
    "    print(f\"Fold {i+1} 모델 로드 완료\")\n",
    "\n",
    "print(f\" 총 {len(ensemble_models)}개 모델로 앙상블 구성\")\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"ensemble/num_models\": len(ensemble_models),\n",
    "            \"ensemble/model_architecture\": model_name,\n",
    "            \"ensemble/ensemble_type\": \"simple_average\"\n",
    "        })\n",
    "    else:\n",
    "        print(\"📊 앙상블 정보:\")\n",
    "        print(f\"  - 모델 개수: {len(ensemble_models)}\")\n",
    "        print(f\"  - 아키텍처: {model_name}\")\n",
    "        print(f\"  - 앙상블 타입: simple_average\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 앙상블 정보 로깅 실패: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98e388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " TTA (Test Time Augmentation) 설정...\n",
      "TTA 변환 5개 준비 완료\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 15. TTA (Test Time Augmentation) Setup\n",
    "# =============================================================================\n",
    "\n",
    "# Temperature Scaling 클래스 정의\n",
    "class TemperatureScaling(nn.Module):\n",
    "    def __init__(self, temperature=1.5):\n",
    "        super().__init__()\n",
    "        self.temperature = nn.Parameter(torch.ones(1) * temperature)\n",
    "    \n",
    "    def forward(self, logits):\n",
    "        return logits / self.temperature\n",
    "\n",
    "print(f\"\\n TTA (Test Time Augmentation) 설정...\")\n",
    "\n",
    "# Essential TTA transforms\n",
    "essential_tta_transforms = [\n",
    "    # 원본\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 90도 회전들\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[90, 90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[180, 180], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.Rotate(limit=[-90, -90], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "    # 밝기 개선\n",
    "    A.Compose([\n",
    "        A.LongestMaxSize(max_size=img_size),\n",
    "        A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "        A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ToTensorV2(),\n",
    "    ]),\n",
    "]\n",
    "\n",
    "print(f\"TTA 변환 {len(essential_tta_transforms)}개 준비 완료\")\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"tta/num_transforms\": len(essential_tta_transforms),\n",
    "            \"tta/transforms_used\": [\"original\", \"rot_90\", \"rot_180\", \"rot_270\", \"brightness\"],\n",
    "            \"tta/batch_size\": 64  # TTA용 배치 크기\n",
    "        })\n",
    "    else:\n",
    "        print(\"📊 TTA 설정 정보:\")\n",
    "        print(f\"  - 변형 개수: {len(essential_tta_transforms)}\")\n",
    "        print(f\"  - 변형 종류: original, rot_90, rot_180, rot_270, brightness\")\n",
    "        print(f\"  - 배치 크기: 64\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ TTA 설정 로깅 실패: {e}\")\n",
    "    print(\"📊 TTA 설정 정보:\")\n",
    "    print(f\"  - 변형 개수: {len(essential_tta_transforms)}\")\n",
    "    print(f\"  - 배치 크기: 64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f6fc07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TTA Dataset: 3140개 테스트 샘플\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 16. TTA Dataset and DataLoader\n",
    "# =============================================================================\n",
    "\n",
    "class TTAImageDataset(Dataset):\n",
    "    def __init__(self, data, path, transforms):\n",
    "        if isinstance(data, str):\n",
    "            self.df = pd.read_csv(data).values\n",
    "        else:\n",
    "            self.df = data.values\n",
    "        self.path = path\n",
    "        self.transforms = transforms  # 여러 transform을 리스트로 받음\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        \n",
    "        # 모든 transform을 적용한 결과를 리스트로 반환\n",
    "        augmented_images = []\n",
    "        for transform in self.transforms:\n",
    "            aug_img = transform(image=img)['image']\n",
    "            augmented_images.append(aug_img)\n",
    "        \n",
    "        return augmented_images, target\n",
    "\n",
    "# TTA Dataset 생성\n",
    "tta_dataset = TTAImageDataset(\n",
    "    \"../data/sample_submission.csv\",\n",
    "    \"../data/test/\",\n",
    "    essential_tta_transforms\n",
    ")\n",
    "\n",
    "# TTA DataLoader (배치 크기를 줄여서 메모리 절약)\n",
    "tta_loader = DataLoader(\n",
    "    tta_dataset,\n",
    "    batch_size=64,  # TTA는 메모리를 많이 사용하므로 배치 크기 줄임\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\" TTA Dataset: {len(tta_dataset)}개 테스트 샘플\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45382398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " 최종 추론 - 앙상블 + TTA\n",
      "============================================================\n",
      "앙상블 TTA 추론 시작...\n",
      "5개 모델 × 5개 TTA 변형 = 25개 예측 평균\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ensemble TTA: 100%|██████████| 50/50 [02:50<00:00,  3.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 앙상블 TTA 추론 완료!\n",
      "총 소요시간: 2.8분\n",
      " 평균 신뢰도: 0.3960 ± 0.1080\n",
      " 고신뢰도 샘플: 0/3140 (0.0%)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =============================================================================\n",
    "# 17. Ensemble + TTA Inference with WandB Logging\n",
    "# =============================================================================\n",
    "\n",
    "def ensemble_tta_inference_with_logging(models, loader, transforms, confidence_threshold=0.9):\n",
    "    \"\"\"5-Fold 모델 앙상블 + TTA 추론 with WandB 로깅\"\"\"\n",
    "    all_predictions = []\n",
    "    all_confidences = []\n",
    "    \n",
    "    # TTA 진행상황 로깅을 위한 테이블\n",
    "    tta_progress = wandb.Table(columns=[\"Batch\", \"Avg_Confidence\", \"Low_Conf_Count\", \"High_Conf_Count\"])\n",
    "    \n",
    "    # Temperature scaling 초기화\n",
    "    temp_scaling = TemperatureScaling().to(device)\n",
    "    \n",
    "    print(f\"앙상블 TTA 추론 시작...\")\n",
    "    print(f\"{len(models)}개 모델 × {len(transforms)}개 TTA 변형 = {len(models) * len(transforms)}개 예측 평균\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (images_list, _) in enumerate(tqdm(loader, desc=\"Ensemble TTA\")):\n",
    "        batch_size = images_list[0].size(0)\n",
    "        ensemble_probs = torch.zeros(batch_size, 17).to(device)\n",
    "        \n",
    "        # 각 fold 모델별 예측\n",
    "        for model_idx, model in enumerate(models):\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                # 각 TTA 변형별 예측\n",
    "                for tta_idx, images in enumerate(images_list):\n",
    "                    images = images.to(device)\n",
    "                    preds = model(images)\n",
    "                    \n",
    "                    # Temperature scaling 적용\n",
    "                    preds = temp_scaling(preds)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    \n",
    "                    # 앙상블 확률에 누적 (평균)\n",
    "                    ensemble_probs += probs / (len(models) * len(images_list))\n",
    "        \n",
    "        # 신뢰도 계산\n",
    "        max_probs = torch.max(ensemble_probs, dim=1)[0]\n",
    "        batch_confidences = max_probs.cpu().numpy()\n",
    "        all_confidences.extend(batch_confidences)\n",
    "        \n",
    "        final_preds = torch.argmax(ensemble_probs, dim=1)\n",
    "        all_predictions.extend(final_preds.cpu().numpy())\n",
    "        \n",
    "        # 배치별 신뢰도 분석\n",
    "        high_conf_count = np.sum(batch_confidences >= confidence_threshold)\n",
    "        low_conf_count = batch_size - high_conf_count\n",
    "        avg_confidence = np.mean(batch_confidences)\n",
    "        \n",
    "        # 진행상황 테이블에 추가\n",
    "        tta_progress.add_data(batch_idx, avg_confidence, low_conf_count, high_conf_count)\n",
    "        \n",
    "        # 배치별 상세 로깅 (20배치마다)\n",
    "        if batch_idx % 20 == 0:\n",
    "            elapsed_time = time.time() - start_time\n",
    "            estimated_total = elapsed_time * len(loader) / (batch_idx + 1)\n",
    "            remaining_time = estimated_total - elapsed_time\n",
    "            \n",
    "            wandb.log({\n",
    "                \"tta_progress/batch\": batch_idx,\n",
    "                \"tta_progress/avg_confidence\": avg_confidence,\n",
    "                \"tta_progress/high_confidence_ratio\": high_conf_count / batch_size,\n",
    "                \"tta_progress/low_confidence_count\": low_conf_count,\n",
    "                \"tta_progress/elapsed_time_min\": elapsed_time / 60,\n",
    "                \"tta_progress/estimated_remaining_min\": remaining_time / 60,\n",
    "                \"tta_progress/samples_processed\": (batch_idx + 1) * batch_size,\n",
    "            })\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # TTA 최종 결과 로깅\n",
    "    final_avg_confidence = np.mean(all_confidences)\n",
    "    confidence_std = np.std(all_confidences)\n",
    "    high_conf_samples = np.sum(np.array(all_confidences) >= confidence_threshold)\n",
    "    \n",
    "    wandb.log({\n",
    "        \"tta_results/total_time_min\": total_time / 60,\n",
    "        \"tta_results/samples_per_second\": len(all_predictions) / total_time,\n",
    "        \"tta_results/final_avg_confidence\": final_avg_confidence,\n",
    "        \"tta_results/confidence_std\": confidence_std,\n",
    "        \"tta_results/high_confidence_samples\": high_conf_samples,\n",
    "        \"tta_results/high_confidence_ratio\": high_conf_samples / len(all_predictions),\n",
    "        \"tta_results/total_predictions\": len(all_predictions),\n",
    "        \"tta_results/confidence_histogram\": wandb.Histogram(all_confidences),\n",
    "        \"tta_results/progress_table\": tta_progress\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n 앙상블 TTA 추론 완료!\")\n",
    "    print(f\"총 소요시간: {total_time/60:.1f}분\")\n",
    "    print(f\" 평균 신뢰도: {final_avg_confidence:.4f} ± {confidence_std:.4f}\")\n",
    "    print(f\" 고신뢰도 샘플: {high_conf_samples}/{len(all_predictions)} ({high_conf_samples/len(all_predictions)*100:.1f}%)\")\n",
    "    \n",
    "    return all_predictions, all_confidences\n",
    "\n",
    "# 앙상블 TTA 실행\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\" 최종 추론 - 앙상블 + TTA\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "tta_predictions, confidences = ensemble_tta_inference_with_logging(\n",
    "    models=ensemble_models, \n",
    "    loader=tta_loader, \n",
    "    transforms=essential_tta_transforms,\n",
    "    confidence_threshold=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9072c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 최종 결과 정리 중...\n",
      "\n",
      "📊 예측 결과 분포:\n",
      "Class  0:  202 (  6.4%)\n",
      "Class  1:   93 (  3.0%)\n",
      "Class  2:  200 (  6.4%)\n",
      "Class  3:  242 (  7.7%)\n",
      "Class  4:  189 (  6.0%)\n",
      "Class  5:  200 (  6.4%)\n",
      "Class  6:  204 (  6.5%)\n",
      "Class  7:  160 (  5.1%)\n",
      "Class  8:  200 (  6.4%)\n",
      "Class  9:  200 (  6.4%)\n",
      "Class 10:  222 (  7.1%)\n",
      "Class 11:  188 (  6.0%)\n",
      "Class 12:  198 (  6.3%)\n",
      "Class 13:  160 (  5.1%)\n",
      "Class 14:   81 (  2.6%)\n",
      "Class 15:  201 (  6.4%)\n",
      "Class 16:  200 (  6.4%)\n",
      "최종 결과 WandB 로깅 완료!\n",
      "총 예측 수: 3140\n",
      "예측된 클래스 수: 17\n",
      "평균 신뢰도: 0.3960\n",
      "신뢰도 범위: 0.0968 ~ 0.6622\n",
      "예측 분포 차트 로깅 완료!\n",
      "실험 요약 로깅 완료!\n",
      "\n",
      " 최종 결과 저장 완료!\n",
      " 파일 위치: ../output/choice2.csv\n",
      " 총 예측 수: 3140\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 18. Final Results and Submission\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n 최종 결과 정리 중...\")\n",
    "\n",
    "# TTA 결과로 submission 파일 생성\n",
    "tta_pred_df = pd.DataFrame(tta_dataset.df, columns=['ID', 'target'])\n",
    "tta_pred_df['target'] = tta_predictions\n",
    "\n",
    "# 기존 submission과 동일한 순서인지 확인\n",
    "sample_submission_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "assert (sample_submission_df['ID'] == tta_pred_df['ID']).all(), \"ID 순서 불일치!\"\n",
    "\n",
    "# 예측 분포 분석\n",
    "pred_distribution = tta_pred_df['target'].value_counts().sort_index()\n",
    "pred_table = wandb.Table(columns=[\"Class\", \"Count\", \"Percentage\"])\n",
    "\n",
    "print(f\"\\n📊 예측 결과 분포:\")\n",
    "for class_id in range(17):\n",
    "    count = pred_distribution.get(class_id, 0)\n",
    "    percentage = count / len(tta_pred_df) * 100\n",
    "    pred_table.add_data(class_id, count, percentage)\n",
    "    print(f\"Class {class_id:2d}: {count:4d} ({percentage:5.1f}%)\")\n",
    "\n",
    "# 신뢰도 분석\n",
    "confidence_bins = [0.5, 0.7, 0.8, 0.9, 0.95, 1.0]\n",
    "confidence_analysis = {}\n",
    "for i, threshold in enumerate(confidence_bins):\n",
    "    if i == 0:\n",
    "        count = np.sum(np.array(confidences) >= threshold)\n",
    "    else:\n",
    "        prev_threshold = confidence_bins[i-1]\n",
    "        count = np.sum((np.array(confidences) >= prev_threshold) & (np.array(confidences) < threshold))\n",
    "    confidence_analysis[f\"conf_{threshold}\"] = count\n",
    "\n",
    "# 최종 결과 로깅\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"final_results/total_predictions\": len(tta_predictions),\n",
    "            \"final_results/unique_classes_predicted\": len(np.unique(tta_predictions)),\n",
    "            \"final_results/prediction_distribution_table\": pred_table,\n",
    "            \"final_results/avg_confidence\": np.mean(confidences),\n",
    "            \"final_results/median_confidence\": np.median(confidences),\n",
    "            \"final_results/min_confidence\": np.min(confidences),\n",
    "            \"final_results/max_confidence\": np.max(confidences),\n",
    "            \"final_results/confidence_distribution\": wandb.Histogram(confidences),\n",
    "            **confidence_analysis\n",
    "        })\n",
    "        print(\"최종 결과 WandB 로깅 완료!\")\n",
    "    else:\n",
    "        print(\"활성화된 run이 없어 로깅을 건너뜁니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"WandB 로깅 중 에러: {e}\")\n",
    "\n",
    "# 콘솔 출력은 항상 실행\n",
    "print(f\"총 예측 수: {len(tta_predictions)}\")\n",
    "print(f\"예측된 클래스 수: {len(np.unique(tta_predictions))}\")\n",
    "print(f\"평균 신뢰도: {np.mean(confidences):.4f}\")\n",
    "print(f\"신뢰도 범위: {np.min(confidences):.4f} ~ {np.max(confidences):.4f}\")\n",
    "\n",
    "\n",
    "# 예측 분포 바차트\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        pred_dist_data = [[f\"Class_{i}\", pred_distribution.get(i, 0)] for i in range(17)]\n",
    "        wandb.run.log({\n",
    "            \"final_results/prediction_distribution_chart\": wandb.plot.bar(\n",
    "                wandb.Table(data=pred_dist_data, columns=[\"Class\", \"Count\"]),\n",
    "                \"Class\", \"Count\", \n",
    "                title=\"Final Prediction Distribution\"\n",
    "            )\n",
    "        })\n",
    "        print(\"예측 분포 차트 로깅 완료!\")\n",
    "    else:\n",
    "        print(\"차트 로깅을 건너뜁니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"차트 로깅 중 에러: {e}\")\n",
    "\n",
    "# 결과 저장\n",
    "output_path = \"../output/choice2.csv\"\n",
    "tta_pred_df.to_csv(output_path, index=False)\n",
    "\n",
    "# 결과 파일을 WandB 아티팩트로 저장\n",
    "artifact = wandb.Artifact(\n",
    "    name=\"final_predictions\",\n",
    "    type=\"predictions\",\n",
    "    description=f\"Final ensemble predictions with {N_FOLDS}-fold CV + TTA\"\n",
    ")\n",
    "artifact.add_file(output_path)\n",
    "\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log_artifact(artifact)\n",
    "        print(\"실험 요약 로깅 완료!\")\n",
    "    else:\n",
    "        print(\"활성화된 run이 없어 실험 요약 로깅을 건너뜁니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"실험 요약 로깅 중 에러: {e}\")\n",
    "\n",
    "\n",
    "print(f\"\\n 최종 결과 저장 완료!\")\n",
    "print(f\" 파일 위치: {output_path}\")\n",
    "print(f\" 총 예측 수: {len(tta_predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30990203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실험 요약 로깅 완료!\n",
      "최종 상태 업데이트 완료!\n",
      "\n",
      "실험 완료 시간: 2025-09-04 08:20:45\n",
      "\n",
      "============================================================\n",
      "실험 완료!\n",
      "============================================================\n",
      " K-Fold CV 결과: 0.9172 ± 0.0124\n",
      " 최고 성능 Fold: 0.9341\n",
      " 앙상블 모델: 5개\n",
      " TTA 변형: 5개\n",
      " 평균 예측 신뢰도: 0.3960\n",
      " WandB 대시보드: https://wandb.ai/kimsunmin0227-hufs/document-classification-team/runs/33mcvmnd\n",
      "\n",
      " 예측 결과 샘플:\n",
      "                     ID  target\n",
      "0  0008fdb22ddce0ce.jpg       2\n",
      "1  00091bffdffd83de.jpg      12\n",
      "2  00396fbc1f6cc21d.jpg       5\n",
      "3  00471f8038d9c4b6.jpg      12\n",
      "4  00901f504008d884.jpg       2\n",
      "5  009b22decbc7220c.jpg      15\n",
      "6  00b33e0ee6d59427.jpg       0\n",
      "7  00bbdcfbbdb3e131.jpg       8\n",
      "8  00c03047e0fbef40.jpg      15\n",
      "9  00c0dabb63ca7a16.jpg      11\n",
      "\n",
      " 모든 작업 완료!\n",
      " 결과 파일: ../output/choice2.csv\n",
      " WandB에서 전체 실험 결과를 확인하세요!\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# 19. Experiment Summary and Cleanup\n",
    "# =============================================================================\n",
    "\n",
    "# 실험 요약 생성\n",
    "experiment_summary = {\n",
    "    \"experiment_name\": main_run.name,\n",
    "    \"model_architecture\": model_name,\n",
    "    \"image_size\": img_size,\n",
    "    \"cv_strategy\": f\"{N_FOLDS}-Fold StratifiedKFold\",\n",
    "    \"cv_mean_f1\": mean_f1,\n",
    "    \"cv_std_f1\": std_f1,\n",
    "    \"cv_best_fold\": max(val_f1_scores),\n",
    "    \"ensemble_models\": len(ensemble_models),\n",
    "    \"tta_transforms\": len(essential_tta_transforms),\n",
    "    \"total_training_time_min\": sum([r['epochs_trained'] for r in fold_results]) * 2,  # 추정치\n",
    "    \"avg_prediction_confidence\": np.mean(confidences),\n",
    "    \"high_confidence_predictions\": np.sum(np.array(confidences) >= 0.9),\n",
    "    \"experiment_tags\": [\"baseline\", \"efficientnet-b3\", \"k-fold-cv\", \"tta\", \"ensemble\"]\n",
    "}\n",
    "\n",
    "# 실험 요약\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\"experiment_summary\": experiment_summary})\n",
    "        print(\"실험 요약 로깅 완료!\")\n",
    "    else:\n",
    "        print(\"활성화된 run이 없어 실험 요약 로깅을 건너뜁니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"실험 요약 로깅 중 에러: {e}\")\n",
    "\n",
    "\n",
    "# 마지막 상태 업데이트\n",
    "try:\n",
    "    if wandb.run is not None:\n",
    "        wandb.run.log({\n",
    "            \"status\": \"completed\",\n",
    "            \"completion_time\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "            \"total_runtime_hours\": 0  # start_time 속성 문제로 일단 0으로 설정\n",
    "        })\n",
    "        print(\"최종 상태 업데이트 완료!\")\n",
    "    else:\n",
    "        print(\"활성화된 run이 없어 상태 업데이트를 건너뜁니다.\")\n",
    "except Exception as e:\n",
    "    print(f\"상태 업데이트 중 에러: {e}\")\n",
    "\n",
    "print(f\"\\n실험 완료 시간: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"실험 완료!\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "print(f\" K-Fold CV 결과: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\" 최고 성능 Fold: {max(val_f1_scores):.4f}\")\n",
    "print(f\" 앙상블 모델: {len(ensemble_models)}개\")\n",
    "print(f\" TTA 변형: {len(essential_tta_transforms)}개\")\n",
    "print(f\" 평균 예측 신뢰도: {np.mean(confidences):.4f}\")\n",
    "print(f\" WandB 대시보드: {main_run.url}\")\n",
    "\n",
    "# Sample predictions 출력\n",
    "print(f\"\\n 예측 결과 샘플:\")\n",
    "print(tta_pred_df.head(10))\n",
    "\n",
    "# 메인 run 종료\n",
    "main_run.finish()\n",
    "\n",
    "print(f\"\\n 모든 작업 완료!\")\n",
    "print(f\" 결과 파일: {output_path}\")\n",
    "print(f\" WandB에서 전체 실험 결과를 확인하세요!\")\n",
    "\n",
    "# 메모리 정리\n",
    "del ensemble_models\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b07f9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0eca2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [추가] KSM WandB 베이스라인 실험 결과 저장\n",
    "try:\n",
    "    # 실험 설정 정보 저장\n",
    "    experiment_info = {\n",
    "        'notebook_type': 'baseline_wandb',\n",
    "        'team_member': 'KSM',\n",
    "        'wandb_integration': True,\n",
    "        'timestamp': pd.Timestamp.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    logger.save_json(experiment_info, 'experiment_info', 'KSM WandB 베이스라인 실험 정보')\n",
    "    \n",
    "    print(\"✅ KSM WandB 베이스라인 실험 정보 저장 완료!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ 결과 저장 중 오류: {e}\")\n",
    "\n",
    "# 노트북 작업 완료 요약\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🏁 KSM WandB 베이스라인 노트북 작업 완료!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 로거 정보 출력\n",
    "logger.print_summary()\n",
    "\n",
    "print(\"\\n📄 생성된 결과:\")\n",
    "print(\"   ✅ WandB 연동 베이스라인 실험\")\n",
    "print(\"   ✅ 실험 정보 및 설정\")\n",
    "\n",
    "print(f\"\\n💾 모든 결과는 다음 디렉토리에 저장되었습니다:\")\n",
    "print(f\"   📁 {logger.log_dir}\")\n",
    "\n",
    "print(\"\\n🎯 이 노트북은 팀 노트북 통합 모듈화 프로젝트의 일환으로 업데이트되었습니다.\")\n",
    "print(\"📊 WandB 연동을 통한 실험 추적 기능 포함\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
