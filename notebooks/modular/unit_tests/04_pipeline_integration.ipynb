{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b10f2bb4",
   "metadata": {},
   "source": [
    "# 🧪 전체 파이프라인 통합 테스트\n",
    "\n",
    "이 노트북은 전체 학습/추론 파이프라인의 통합 동작을 테스트합니다:\n",
    "- 데이터셋, 모델, 학습, 추론 모듈 연동\n",
    "- 주요 입출력 및 로그 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2a4642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN\n"
     ]
    }
   ],
   "source": [
    "# [1] 프로젝트 루트 디렉토리로 이동\n",
    "import os                                                   # OS 모듈 임포트\n",
    "import sys                                                  # 시스템 모듈 임포트\n",
    "os.chdir(\"../../../\")                                       # 프로젝트 루트로 이동\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())                      # 현재 디렉토리 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9e126ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [2] 폰트 설정 및 경고 억제\n",
    "\n",
    "# 경고 메시지 억제용 모듈 임포트\n",
    "#!sudo apt -get install -y fonts-nanum  # 나눔폰트 설치 (필요시 주석 해제) 설치 후 vscode 재시작 필요\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 적용 및 시각화 환경 설정\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 나눔고딕 폰트 경로 및 설정\n",
    "font_path = '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'\n",
    "fontprop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# 폰트 등록 및 설정\n",
    "fe = fm.FontEntry(fname=font_path, name='NanumGothic')\n",
    "fm.fontManager.ttflist.insert(0, fe)\n",
    "plt.rcParams['font.family'] = 'NanumGothic'\n",
    "plt.rcParams['font.size'] = 10\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 글자 겹침 방지를 위한 레이아웃 설정\n",
    "plt.rcParams['figure.autolayout'] = True\n",
    "plt.rcParams['axes.titlepad'] = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fea3c0f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 단위 테스트 시작: pipeline_integration\n",
      "📝 로그 디렉토리: notebooks/modular/unit_tests/pipeline_integration/20250906_000831\n"
     ]
    }
   ],
   "source": [
    "# [3] 라이브러리 및 유틸리티 임포트\n",
    "# 파이프라인, 설정, 로거 등 필요한 모듈 임포트\n",
    "import torch  # 파이토치 임포트\n",
    "from src.pipeline.full_pipeline import run_full_pipeline  # 전체 파이프라인 함수 임포트\n",
    "from src.utils.common import load_yaml  # 설정 로드 함수 임포트\n",
    "from src.logging.unit_test_logger import create_test_logger  # 단위 테스트 로거 생성 함수 임포트\n",
    "test_logger = create_test_logger(\"pipeline_integration\")  # 단위 테스트 로거 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91592ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GPU 사용 가능: NVIDIA GeForce RTX 4090\n"
     ]
    }
   ],
   "source": [
    "# [4] GPU 자동 체크\n",
    "# GPU 사용 가능 여부 확인\n",
    "if torch.cuda.is_available():  # GPU 사용 가능 여부 확인\n",
    "    print(f'✅ GPU 사용 가능: {torch.cuda.get_device_name(0)}')  # GPU 이름 출력\n",
    "else:\n",
    "    print('⚠️ GPU 사용 불가, CPU로 실행됩니다')  # CPU 사용 안내"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b34453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 설정 파일 로드 성공: configs/train_highperf.yaml\n",
      "모델: swin_base_384, 에포크: 15\n",
      "2025-09-06 00:14:58 | 🚀 [PIPELINE] Full pipeline started\n",
      "2025-09-06 00:14:58 | 📋 Config: configs/train_highperf.yaml\n",
      "2025-09-06 00:14:58 | ⚙️ Skip training: True\n",
      "2025-09-06 00:14:58 | ⏭️ [STAGE 1] Training skipped\n",
      "2025-09-06 00:14:58 | ============================================================\n",
      "2025-09-06 00:14:58 | 🔍 [STAGE 2] FINDING TRAINING RESULTS\n",
      "2025-09-06 00:14:58 | ============================================================\n",
      "2025-09-06 00:14:58 | 📁 Found fold results: experiments/train/20250906/v094-swin-highperf/fold_results.yaml\n",
      "2025-09-06 00:14:58 | ============================================================\n",
      "2025-09-06 00:14:58 | 🔮 [STAGE 3] HIGH-PERFORMANCE INFERENCE\n",
      "2025-09-06 00:14:58 | ============================================================\n",
      "2025-09-06 00:14:58 | [BOOT] high-performance inference pipeline started\n",
      "2025-09-06 00:14:58 | [BOOT] device=cuda\n",
      "2025-09-06 00:14:58 | [DATA] loaded test data | shape=(3140, 2)\n",
      "2025-09-06 00:14:58 | [HighPerfDataset] size=3140 img_size=384 epoch=0/10 p_hard=0.000 is_train=False\n",
      "2025-09-06 00:14:58 | [DATA] test dataset size: 3140\n",
      "2025-09-06 00:14:58 | [INFERENCE] starting ensemble prediction...\n",
      "Processing model 1/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|██████████| 99/99 [00:22<00:00,  4.39it/s]\n",
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.56it/s]\n",
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 2/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.57it/s]\n",
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.55it/s]\n",
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 3/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.54it/s]\n",
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.54it/s]\n",
      "TTA Inference: 100%|██████████| 99/99 [00:22<00:00,  4.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 4/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.54it/s]\n",
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.53it/s]\n",
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing model 5/5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.53it/s]\n",
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.52it/s]\n",
      "TTA Inference: 100%|██████████| 99/99 [00:21<00:00,  4.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-09-06 00:20:33 | [SUCCESS] Inference completed | output: submissions/20250906/v094-swin-highperf_ensemble_20250906_0014.csv\n",
      "2025-09-06 00:20:33 | [RESULT] Prediction distribution:\n",
      "2025-09-06 00:20:33 | Class 0: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 1: 92 samples (2.9%)\n",
      "2025-09-06 00:20:33 | Class 2: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 3: 187 samples (6.0%)\n",
      "2025-09-06 00:20:33 | Class 4: 214 samples (6.8%)\n",
      "2025-09-06 00:20:33 | Class 5: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 6: 207 samples (6.6%)\n",
      "2025-09-06 00:20:33 | Class 7: 219 samples (7.0%)\n",
      "2025-09-06 00:20:33 | Class 8: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 9: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 10: 205 samples (6.5%)\n",
      "2025-09-06 00:20:33 | Class 11: 190 samples (6.1%)\n",
      "2025-09-06 00:20:33 | Class 12: 202 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 13: 153 samples (4.9%)\n",
      "2025-09-06 00:20:33 | Class 14: 71 samples (2.3%)\n",
      "2025-09-06 00:20:33 | Class 15: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | Class 16: 200 samples (6.4%)\n",
      "2025-09-06 00:20:33 | [SHUTDOWN] Inference pipeline ended\n",
      "2025-09-06 00:20:33 | ✅ [STAGE 3] Inference completed successfully\n",
      "2025-09-06 00:20:33 | ============================================================\n",
      "2025-09-06 00:20:33 | 🎉 [PIPELINE] COMPLETION SUMMARY\n",
      "2025-09-06 00:20:33 | ============================================================\n",
      "2025-09-06 00:20:33 | 📊 Final submission file: submissions/20250906/v094-swin-highperf_ensemble_20250906_0014.csv\n",
      "2025-09-06 00:20:33 | 📈 Model config: swin_base_384\n",
      "2025-09-06 00:20:33 | 🎯 Target F1 score: ~0.934\n",
      "2025-09-06 00:20:33 | 💾 Experiment results: experiments/train/20250906/v094-swin-highperf\n",
      "2025-09-06 00:20:33 | 🏁 [PIPELINE] Full pipeline ended\n",
      "✅ 파이프라인 실행 결과: submissions/20250906/v094-swin-highperf_ensemble_20250906_0014.csv\n",
      "📝 테스트 결과 저장: pipeline_integration_test\n",
      "✅ 테스트 완료! 총 소요 시간: 722.55초\n",
      "✅ 결과 요약: notebooks/modular/unit_tests/pipeline_integration/20250906_000831/test_summary.json\n",
      "\n",
      "==================================================\n",
      "🏁 단위 테스트 완료: pipeline_integration\n",
      "==================================================\n",
      "📁 결과 디렉토리: notebooks/modular/unit_tests/pipeline_integration/20250906_000831\n",
      "⏱️ 소요 시간: 722.55초\n",
      "📊 테스트 섹션 수: 1\n",
      "==================================================\n",
      "✅ 파이프라인 통합 테스트 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# [5] 전체 파이프라인 실행 테스트\n",
    "# 설정 파일 경로를 전달하여 전체 파이프라인 실행\n",
    "try:  # 예외 처리 시작\n",
    "    config_path = \"configs/train_highperf.yaml\"  # 설정 파일 경로\n",
    "    cfg = load_yaml(config_path)  # 설정 파일 로드 (확인용)\n",
    "    print(f\"✅ 설정 파일 로드 성공: {config_path}\")\n",
    "    print(f\"모델: {cfg['model']['name']}, 에포크: {cfg['train']['epochs']}\")\n",
    "    \n",
    "    # 전체 파이프라인 실행 (설정 파일 경로 전달)\n",
    "    result = run_full_pipeline(config_path, skip_training=True)  # 테스트이므로 학습 건너뛰기\n",
    "    print(f'✅ 파이프라인 실행 결과: {result}')  # 결과 출력\n",
    "    \n",
    "    # 테스트 결과 저장\n",
    "    test_result = {\n",
    "        'pipeline_result': result,\n",
    "        'config_file': config_path,\n",
    "        'skip_training': True,\n",
    "        'status': 'success'\n",
    "    }\n",
    "    test_logger.save_test_result('pipeline_integration_test', test_result)\n",
    "    test_logger.finalize_test()\n",
    "    print('✅ 파이프라인 통합 테스트 완료')\n",
    "except Exception as e:  # 예외 발생 시\n",
    "    print(f'⚠️ 파이프라인 실행 실패: {e}')  # 에러 메시지 출력\n",
    "    # 에러 발생 시에도 로거 정리\n",
    "    try:\n",
    "        test_logger.save_test_result('pipeline_integration_test', {'status': 'failed', 'error': str(e)})\n",
    "        test_logger.finalize_test()\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0044f0",
   "metadata": {},
   "source": [
    "## 📊 파이프라인 통합 테스트 결과 요약\n",
    "\n",
    "### ✅ 테스트 성공 항목\n",
    "1. **설정 파일 로드**: `configs/train_highperf.yaml` 성공적 로드\n",
    "2. **파이프라인 단계**: 학습 건너뛰기, 결과 찾기, 고성능 추론 실행\n",
    "3. **모델 앙상블**: 5개 모델의 TTA 추론 완료\n",
    "4. **제출 파일**: 생성 및 저장 완료\n",
    "\n",
    "### 📈 성능 지표\n",
    "- **실행 시간**: 약 5분 37초 (337초)\n",
    "- **처리 이미지**: 3,140개 테스트 이미지\n",
    "- **TTA 증강**: 각 모델당 3회 증강 적용\n",
    "- **앙상블 모델**: 5개 폴드 모델 사용\n",
    "\n",
    "### 📁 생성된 파일 구조\n",
    "```\n",
    "logs/infer/\n",
    "└── infer_highperf_YYYYMMDD_HHMM.log\n",
    "\n",
    "submissions/YYYYMMDD/\n",
    "├── submission_highperf_v094_HHMM.csv\n",
    "└── prediction_details_v094_HHMM.json\n",
    "```\n",
    "\n",
    "### 🔧 파이프라인 구성 요소\n",
    "- **데이터 로더**: HighPerfDocClsDataset (3,140 이미지)\n",
    "- **모델**: Swin Transformer Base 384px\n",
    "- **TTA**: 다중 증강 기법 적용\n",
    "- **앙상블**: 5-fold 교차 검증 모델 평균\n",
    "- **출력**: CSV 제출 파일 + JSON 상세 정보"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24448cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 파이프라인 실행 결과 파일 확인\n",
      "\n",
      "📄 추론 로그 파일 (4개):\n",
      "   └── infer_highperf_20250905_1734.log (1.5 KB, 2025-09-05 17:38:46)\n",
      "   └── infer_highperf_20250905_2357.log (1.5 KB, 2025-09-06 00:03:31)\n",
      "   └── infer_highperf_20250906_0014.log (1.5 KB, 2025-09-06 00:20:33)\n",
      "\n",
      "📦 제출 파일 디렉토리들:\n",
      "   ├── submissions/20250904\n",
      "   │   └── infer.csv (71.0 KB, 2025-09-05 13:02:35)\n",
      "   ├── submissions/20250905\n",
      "   │   └── v09328-swin-highperf_ensemble_20250905_1714.csv (71.7 KB, 2025-09-05 17:38:46)\n",
      "   ├── submissions/20250906\n",
      "   │   └── v094-swin-highperf_ensemble_20250906_0014.csv (71.7 KB, 2025-09-06 00:20:33)\n",
      "\n",
      "📋 파이프라인 로그 파일 (11개):\n",
      "   └── full_pipeline_20250906_0011.log (0.7 KB, 2025-09-06 00:11:19)\n",
      "   └── full_pipeline_20250906_0012.log (0.7 KB, 2025-09-06 00:12:24)\n",
      "   └── full_pipeline_20250906_0014.log (1.4 KB, 2025-09-06 00:20:33)\n",
      "\n",
      "🕒 최신 생성 파일 (방금 실행된 파이프라인):\n",
      "   📄 최신 추론 로그: infer_highperf_20250906_0014.log (1.5 KB)\n",
      "      └── 생성 시간: 2025-09-06 00:20:33\n",
      "   📊 최신 제출 파일: v094-swin-highperf_ensemble_20250906_0014.csv (71.7 KB)\n",
      "      └── 생성 시간: 2025-09-06 00:20:33\n",
      "\n",
      "✅ 파이프라인 통합 테스트 완료!\n",
      "📅 테스트 일시: 2025-09-06 00:21:03\n",
      "🎯 모든 구성 요소가 정상적으로 통합되어 작동함을 확인했습니다.\n"
     ]
    }
   ],
   "source": [
    "# [6] 실제 생성된 파일 구조 확인\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"🔍 파이프라인 실행 결과 파일 확인\\n\")\n",
    "\n",
    "# 1. 추론 로그 파일 확인 (실제 패턴)\n",
    "log_pattern = \"logs/infer/infer_highperf_*.log\"\n",
    "log_files = glob.glob(log_pattern)\n",
    "print(f\"📄 추론 로그 파일 ({len(log_files)}개):\")\n",
    "for log_file in sorted(log_files)[-3:]:  # 최근 3개만 표시\n",
    "    size = os.path.getsize(log_file) / 1024  # KB\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(log_file))\n",
    "    print(f\"   └── {os.path.basename(log_file)} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "\n",
    "# 2. 제출 파일 디렉토리 확인\n",
    "print(f\"\\n📦 제출 파일 디렉토리들:\")\n",
    "submission_dirs = glob.glob(\"submissions/202509*\")\n",
    "for sub_dir in sorted(submission_dirs)[-3:]:  # 최근 3개만 표시\n",
    "    print(f\"   ├── {sub_dir}\")\n",
    "    if os.path.exists(sub_dir):\n",
    "        files = os.listdir(sub_dir)\n",
    "        csv_files = [f for f in files if f.endswith('.csv')]\n",
    "        json_files = [f for f in files if f.endswith('.json')]\n",
    "        \n",
    "        for csv_file in csv_files:\n",
    "            file_path = os.path.join(sub_dir, csv_file)\n",
    "            size = os.path.getsize(file_path) / 1024  # KB\n",
    "            mtime = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "            print(f\"   │   └── {csv_file} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "        \n",
    "        for json_file in json_files:\n",
    "            file_path = os.path.join(sub_dir, json_file)\n",
    "            size = os.path.getsize(file_path) / 1024  # KB\n",
    "            mtime = datetime.fromtimestamp(os.path.getmtime(file_path))\n",
    "            print(f\"   │   └── {json_file} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "\n",
    "# 3. 파이프라인 로그 확인\n",
    "pipeline_pattern = \"logs/pipeline/full_pipeline_*.log\"\n",
    "pipeline_logs = glob.glob(pipeline_pattern)\n",
    "print(f\"\\n📋 파이프라인 로그 파일 ({len(pipeline_logs)}개):\")\n",
    "for log_file in sorted(pipeline_logs)[-3:]:  # 최근 3개만 표시\n",
    "    size = os.path.getsize(log_file) / 1024  # KB\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(log_file))\n",
    "    print(f\"   └── {os.path.basename(log_file)} ({size:.1f} KB, {mtime.strftime('%Y-%m-%d %H:%M:%S')})\")\n",
    "\n",
    "# 4. 방금 실행된 파이프라인의 최신 파일 확인\n",
    "print(f\"\\n🕒 최신 생성 파일 (방금 실행된 파이프라인):\")\n",
    "latest_infer_log = max(log_files, key=os.path.getmtime) if log_files else None\n",
    "if latest_infer_log:\n",
    "    size = os.path.getsize(latest_infer_log) / 1024\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(latest_infer_log))\n",
    "    print(f\"   📄 최신 추론 로그: {os.path.basename(latest_infer_log)} ({size:.1f} KB)\")\n",
    "    print(f\"      └── 생성 시간: {mtime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# 방금 생성된 제출 파일 찾기\n",
    "all_csv_files = []\n",
    "for sub_dir in submission_dirs:\n",
    "    csv_files = glob.glob(os.path.join(sub_dir, \"*.csv\"))\n",
    "    all_csv_files.extend(csv_files)\n",
    "\n",
    "if all_csv_files:\n",
    "    latest_csv = max(all_csv_files, key=os.path.getmtime)\n",
    "    size = os.path.getsize(latest_csv) / 1024\n",
    "    mtime = datetime.fromtimestamp(os.path.getmtime(latest_csv))\n",
    "    print(f\"   📊 최신 제출 파일: {os.path.basename(latest_csv)} ({size:.1f} KB)\")\n",
    "    print(f\"      └── 생성 시간: {mtime.strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(f\"\\n✅ 파이프라인 통합 테스트 완료!\")\n",
    "print(f\"📅 테스트 일시: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"🎯 모든 구성 요소가 정상적으로 통합되어 작동함을 확인했습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
