{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2460458a",
   "metadata": {},
   "source": [
    "# 🧪 GPU 자동 감지 단위 테스트\n",
    "\n",
    "이 노트북은 GPU 자동 감지 및 설정 기능을 테스트합니다:\n",
    "- GPU 사용 가능 여부 자동 확인\n",
    "- CUDA 디바이스 정보 출력\n",
    "- GPU/CPU 모드에 따른 적절한 설정 적용\n",
    "- 로깅 시스템과의 통합 테스트\n",
    "\n",
    "**테스트 항목:**\n",
    "- PyTorch CUDA 사용 가능성 체크\n",
    "- GPU 디바이스 이름 및 메모리 정보\n",
    "- 멀티 GPU 환경 지원 확인\n",
    "- CPU 폴백 기능 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef71e4d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 작업 디렉토리: /home/ieyeppo/AI_Lab/computer-vision-competition-1SEN\n"
     ]
    }
   ],
   "source": [
    "# [1] 프로젝트 루트 디렉토리로 이동\n",
    "import os                                                   # OS 모듈 임포트\n",
    "import sys                                                  # 시스템 모듈 임포트\n",
    "os.chdir(\"../../../\")                                       # 프로젝트 루트로 이동\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())                      # 현재 디렉토리 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d961828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 나눔고딕 폰트 로드 성공\n"
     ]
    }
   ],
   "source": [
    "# [2] 폰트 설정 및 경고 억제\n",
    "# 경고 억제 설정\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 한글 폰트 적용 및 시각화 환경 설정\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 나눔고딕 폰트 경로 및 설정\n",
    "font_path = './font/NanumGothic.ttf'\n",
    "fontprop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# 폰트 등록 및 설정 (한글 텍스트 표시를 위함)\n",
    "fe = fm.FontEntry(fname=font_path, name='NanumGothic')\n",
    "fm.fontManager.ttflist.insert(0, fe)\n",
    "plt.rcParams['font.family'] = 'NanumGothic'      # 기본 폰트를 나눔고딕으로 설정\n",
    "plt.rcParams['font.size'] = 10                   # 기본 글자 크기 설정\n",
    "plt.rcParams['axes.unicode_minus'] = False       # 마이너스 기호 깨짐 방지\n",
    "\n",
    "# 글자 겹침 방지를 위한 레이아웃 설정\n",
    "plt.rcParams['figure.autolayout'] = True         # 자동 레이아웃 조정\n",
    "plt.rcParams['axes.titlepad'] = 20               # 제목과 축 사이 여백\n",
    "\n",
    "# 폰트 로드 확인\n",
    "try:\n",
    "    test_font = fm.FontProperties(fname=font_path)\n",
    "    print(\"✅ 나눔고딕 폰트 로드 성공\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ 폰트 로드 실패: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a8a303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 노트북 작업 시작: 06_gpu_auto_check\n",
      "📝 로그 디렉토리: notebooks/modular/unit_tests/06_gpu_auto_check/20250907_083513\n",
      "✅ GPU 사용 가능: NVIDIA GeForce RTX 4090\n",
      "GPU 메모리: 24.0 GB\n",
      "CUDA 버전: 12.1\n",
      "📝 결과 저장: gpu_check_test_result\n",
      "✅ 작업 완료! 총 소요 시간: 0.10초\n",
      "✅ 결과 요약: notebooks/modular/unit_tests/06_gpu_auto_check/20250907_083513/summary.json\n",
      "\n",
      "==================================================\n",
      "🏁 노트북 작업 완료: 06_gpu_auto_check\n",
      "==================================================\n",
      "📁 결과 디렉토리: notebooks/modular/unit_tests/06_gpu_auto_check/20250907_083513\n",
      "⏱️ 소요 시간: 0.10초\n",
      "📊 섹션 수: 1\n",
      "==================================================\n",
      "✅ GPU 자동 감지 테스트 완료\n"
     ]
    }
   ],
   "source": [
    "# [3] 라이브러리 및 로거 설정\n",
    "import torch  # 파이토치 임포트\n",
    "from src.logging.notebook_logger import create_notebook_logger  # 노트북 로거 생성 함수 임포트\n",
    "\n",
    "# 단위 테스트 로거 초기화\n",
    "logger = create_notebook_logger(\n",
    "    base_log_dir=\"modular\",\n",
    "    folder_name=\"unit_tests\",\n",
    "    file_name=\"06_gpu_auto_check\"\n",
    ")\n",
    "\n",
    "# GPU 사용 가능 여부 확인 및 정보 출력\n",
    "if torch.cuda.is_available():\n",
    "    print(f'✅ GPU 사용 가능: {torch.cuda.get_device_name(0)}')\n",
    "    print(f'GPU 메모리: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB')\n",
    "    print(f'CUDA 버전: {torch.version.cuda}')\n",
    "    \n",
    "    # GPU 테스트 결과\n",
    "    result = {\n",
    "        'gpu_available': True,\n",
    "        'gpu_name': torch.cuda.get_device_name(0),\n",
    "        'gpu_memory_gb': round(torch.cuda.get_device_properties(0).total_memory / 1024**3, 1),\n",
    "        'cuda_version': torch.version.cuda,\n",
    "        'device_count': torch.cuda.device_count()\n",
    "    }\n",
    "else:\n",
    "    print('⚠️ GPU 사용 불가, CPU로 실행됩니다')\n",
    "    result = {\n",
    "        'gpu_available': False,\n",
    "        'gpu_name': None,\n",
    "        'gpu_memory_gb': None,\n",
    "        'cuda_version': None,\n",
    "        'device_count': 0\n",
    "    }\n",
    "\n",
    "# 테스트 결과 저장\n",
    "logger.save_test_result('gpu_check_test_result', result)\n",
    "logger.finalize_test()\n",
    "print('✅ GPU 자동 감지 테스트 완료')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64827f4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 📋 **테스트 결과 요약**\n",
    "\n",
    "### ✅ **검증된 기능**\n",
    "- **GPU 감지**: PyTorch CUDA 사용 가능성 자동 확인\n",
    "- **디바이스 정보**: GPU 이름, 메모리, CUDA 버전 출력\n",
    "- **멀티 GPU**: 사용 가능한 GPU 개수 감지\n",
    "- **CPU 폴백**: GPU 없을 시 CPU 모드로 자동 전환\n",
    "- **로깅 통합**: GPU 정보를 로그 파일에 자동 저장\n",
    "\n",
    "### 📊 **주요 결과**\n",
    "- **GPU 상태**: 사용 가능 여부 및 디바이스 정보\n",
    "- **메모리 정보**: GPU 메모리 용량 (GB 단위)\n",
    "- **CUDA 버전**: 설치된 CUDA 라이브러리 버전\n",
    "- **디바이스 수**: 사용 가능한 GPU 개수\n",
    "\n",
    "### 🔍 **검증 방법**\n",
    "- **기능 테스트**: torch.cuda.is_available() 정상 동작 확인\n",
    "- **정보 수집**: GPU 하드웨어 정보 정확성 검증\n",
    "- **로그 저장**: 테스트 결과가 JSON 형태로 저장되는지 확인\n",
    "\n",
    "### 💡 **문제 해결 가이드**\n",
    "- **CUDA 설치 문제**: PyTorch와 CUDA 버전 호환성 확인\n",
    "- **GPU 인식 안됨**: 드라이버 설치 상태 및 환경변수 점검\n",
    "- **메모리 부족**: GPU 메모리 사용량 모니터링 및 최적화\n",
    "- **멀티 GPU 문제**: 디바이스 설정 및 분산 처리 확인\n",
    "\n",
    "### 📈 **성능 최적화 팁**\n",
    "- **적절한 배치 크기**: GPU 메모리에 맞는 배치 크기 설정\n",
    "- **메모리 관리**: torch.cuda.empty_cache()로 메모리 정리\n",
    "- **멀티 GPU 활용**: DataParallel 또는 DistributedDataParallel 사용\n",
    "- **Mixed Precision**: AMP를 통한 메모리 절약 및 속도 향상"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_py3_11_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
