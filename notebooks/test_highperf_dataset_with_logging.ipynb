{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e2a01e9",
   "metadata": {},
   "source": [
    "# 🗂️ 고성능 데이터셋 단위 테스트 (로깅 통합 버전)\n",
    "\n",
    "이 노트북은 로깅 시스템이 통합된 고성능 데이터셋 테스트의 예시입니다.\n",
    "모든 출력, 시각화, 결과가 체계적으로 `logs/unit_test/` 디렉토리에 저장됩니다.\n",
    "\n",
    "## 📁 로그 저장 구조\n",
    "```\n",
    "logs/unit_test/highperf_dataset/20250905_143052/\n",
    "├── logs/           # 텍스트 로그 및 출력\n",
    "├── images/         # 시각화 결과\n",
    "├── data/           # 처리된 데이터\n",
    "├── results/        # 테스트 결과 JSON\n",
    "└── test_summary.json\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f70080",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 프로젝트 루트로 이동\n",
    "print(\"현재 작업 디렉토리:\", os.getcwd())\n",
    "if 'notebooks' in os.getcwd():\n",
    "    os.chdir(\"../\")\n",
    "print(\"변경 후 작업 디렉토리:\", os.getcwd())\n",
    "\n",
    "# 단위 테스트 로거 초기화\n",
    "from src.utils.unit_test_logger import create_test_logger\n",
    "test_logger = create_test_logger(\"highperf_dataset\")\n",
    "test_logger.log_info(\"고성능 데이터셋 단위 테스트 시작\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4efb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필수 라이브러리 import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 프로젝트 모듈 import\n",
    "try:\n",
    "    from src.data.dataset import HighPerfDocClsDataset\n",
    "    from src.utils.common import load_yaml\n",
    "    test_logger.log_success(\"모든 모듈 import 성공\")\n",
    "except Exception as e:\n",
    "    test_logger.log_error(\"모듈 import 실패\", e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb8381",
   "metadata": {},
   "source": [
    "## 1. 📊 기본 데이터 분석\n",
    "\n",
    "원본 데이터의 기본 정보를 분석하고 결과를 로깅합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d92b392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 출력 캡처를 사용하여 모든 print문을 로그 파일에 저장\n",
    "with test_logger.capture_output(\"basic_data_analysis\") as (output, error):\n",
    "    print(\"=== 기본 데이터 분석 시작 ===\")\n",
    "    \n",
    "    try:\n",
    "        # 데이터 로드\n",
    "        train_df = pd.read_csv(\"data/raw/train.csv\")\n",
    "        test_df = pd.read_csv(\"data/raw/meta.csv\")\n",
    "        \n",
    "        print(f\"✅ 학습 데이터: {len(train_df):,} 샘플\")\n",
    "        print(f\"✅ 테스트 데이터: {len(test_df):,} 샘플\")\n",
    "        print(f\"📊 클래스 수: {train_df['target'].nunique()}\")\n",
    "        \n",
    "        # 클래스 분포 분석\n",
    "        class_dist = train_df['target'].value_counts().sort_index()\n",
    "        print(f\"\\n📊 클래스 분포:\")\n",
    "        for class_id, count in class_dist.head(10).items():\n",
    "            print(f\"   Class {class_id}: {count:,} 샘플 ({count/len(train_df)*100:.1f}%)\")\n",
    "        \n",
    "        if len(class_dist) > 10:\n",
    "            print(f\"   ... 외 {len(class_dist)-10}개 클래스\")\n",
    "        \n",
    "        # 기본 통계 저장\n",
    "        basic_stats = {\n",
    "            \"train_samples\": len(train_df),\n",
    "            \"test_samples\": len(test_df),\n",
    "            \"num_classes\": train_df['target'].nunique(),\n",
    "            \"class_distribution\": dict(class_dist),\n",
    "            \"data_balance\": {\n",
    "                \"min_samples\": int(class_dist.min()),\n",
    "                \"max_samples\": int(class_dist.max()),\n",
    "                \"std_samples\": float(class_dist.std())\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        test_logger.save_test_result(\"basic_data_analysis\", {\n",
    "            \"status\": \"success\",\n",
    "            \"stats\": basic_stats\n",
    "        })\n",
    "        \n",
    "        print(\"\\n✅ 기본 데이터 분석 완료\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 데이터 분석 실패: {e}\")\n",
    "        test_logger.save_test_result(\"basic_data_analysis\", {\n",
    "            \"status\": \"failed\",\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        raise\n",
    "\n",
    "# 데이터프레임을 파일로 저장\n",
    "test_logger.save_dataframe(train_df.head(100), \"sample_train_data\", \"학습 데이터 샘플 (100개)\")\n",
    "test_logger.save_dataframe(class_dist.to_frame('count'), \"class_distribution\", \"클래스별 샘플 수\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8e2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 분포 시각화\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# 클래스 분포 바 차트\n",
    "class_dist.plot(kind='bar', ax=axes[0], color='skyblue', alpha=0.7)\n",
    "axes[0].set_title('클래스별 샘플 수 분포', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('클래스 ID')\n",
    "axes[0].set_ylabel('샘플 수')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 클래스 불균형 정도 시각화\n",
    "class_percentages = (class_dist / len(train_df) * 100).sort_values(ascending=False)\n",
    "axes[1].pie(class_percentages.head(8), labels=[f'Class {i}' for i in class_percentages.head(8).index], \n",
    "           autopct='%1.1f%%', startangle=90)\n",
    "axes[1].set_title('상위 8개 클래스 비율', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 그림을 로그 디렉토리에 저장\n",
    "test_logger.save_figure(fig, \"class_distribution_analysis\", \"클래스 분포 분석\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca1ac43",
   "metadata": {},
   "source": [
    "## 2. 🧪 데이터셋 클래스 테스트\n",
    "\n",
    "HighPerfDocClsDataset 클래스의 기본 동작을 테스트합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "251d3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "with test_logger.capture_output(\"dataset_class_test\") as (output, error):\n",
    "    print(\"=== 데이터셋 클래스 테스트 시작 ===\")\n",
    "    \n",
    "    try:\n",
    "        # 설정 로드\n",
    "        cfg = load_yaml(\"configs/train_highperf.yaml\")\n",
    "        print(f\"✅ 설정 파일 로드 성공\")\n",
    "        \n",
    "        # 테스트용 소규모 데이터셋 생성\n",
    "        mini_train = train_df.groupby('target').head(3).reset_index(drop=True)\n",
    "        mini_train_path = \"temp_mini_train.csv\"\n",
    "        mini_train.to_csv(mini_train_path, index=False)\n",
    "        \n",
    "        print(f\"📝 소규모 테스트 데이터셋 생성: {len(mini_train)} 샘플\")\n",
    "        \n",
    "        # 테스트용 설정 수정\n",
    "        test_cfg = cfg.copy()\n",
    "        test_cfg['model']['img_size'] = 224\n",
    "        test_cfg['training']['batch_size'] = 4\n",
    "        \n",
    "        # 데이터셋 생성 테스트\n",
    "        dataset = HighPerfDocClsDataset(\n",
    "            csv_file=mini_train_path,\n",
    "            img_dir=\"data/raw/train\",\n",
    "            config=test_cfg,\n",
    "            mode='train',\n",
    "            fold=0,\n",
    "            epoch=1\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ 데이터셋 생성 성공: {len(dataset)} 샘플\")\n",
    "        \n",
    "        # 샘플 데이터 로딩 테스트\n",
    "        if len(dataset) > 0:\n",
    "            sample_img, sample_label = dataset[0]\n",
    "            print(f\"✅ 샘플 데이터 로딩 성공\")\n",
    "            print(f\"   이미지 크기: {sample_img.shape}\")\n",
    "            print(f\"   이미지 타입: {type(sample_img)}\")\n",
    "            print(f\"   레이블: {sample_label} (타입: {type(sample_label)})\")\n",
    "            \n",
    "            # 이미지 텐서를 numpy로 변환하여 저장\n",
    "            if isinstance(sample_img, torch.Tensor):\n",
    "                img_np = sample_img.permute(1, 2, 0).numpy()\n",
    "                # 정규화 해제 (0-1 범위로)\n",
    "                img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "                test_logger.save_numpy_array(img_np, \"sample_image\", \"데이터셋에서 로드된 샘플 이미지\")\n",
    "        \n",
    "        # DataLoader 테스트\n",
    "        dataloader = DataLoader(dataset, batch_size=2, shuffle=True, num_workers=0)\n",
    "        batch_img, batch_label = next(iter(dataloader))\n",
    "        \n",
    "        print(f\"✅ DataLoader 테스트 성공\")\n",
    "        print(f\"   배치 이미지 크기: {batch_img.shape}\")\n",
    "        print(f\"   배치 레이블 크기: {batch_label.shape}\")\n",
    "        print(f\"   배치 레이블: {batch_label.tolist()}\")\n",
    "        \n",
    "        # 성능 메트릭 측정\n",
    "        start_time = time.time()\n",
    "        for i, (img, label) in enumerate(dataloader):\n",
    "            if i >= 5:  # 5개 배치만 테스트\n",
    "                break\n",
    "        end_time = time.time()\n",
    "        \n",
    "        avg_time_per_batch = (end_time - start_time) / 5\n",
    "        print(f\"📊 평균 배치 로딩 시간: {avg_time_per_batch:.4f}초\")\n",
    "        \n",
    "        # 테스트 결과 저장\n",
    "        dataset_test_result = {\n",
    "            \"status\": \"success\",\n",
    "            \"dataset_size\": len(dataset),\n",
    "            \"sample_image_shape\": list(sample_img.shape) if 'sample_img' in locals() else None,\n",
    "            \"batch_loading_time_sec\": avg_time_per_batch,\n",
    "            \"config_used\": {\n",
    "                \"img_size\": test_cfg['model']['img_size'],\n",
    "                \"batch_size\": test_cfg['training']['batch_size']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        test_logger.save_test_result(\"dataset_class_test\", dataset_test_result)\n",
    "        print(\"\\n✅ 데이터셋 클래스 테스트 완료\")\n",
    "        \n",
    "        # 임시 파일 정리\n",
    "        os.remove(mini_train_path)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ 데이터셋 클래스 테스트 실패: {e}\")\n",
    "        test_logger.save_test_result(\"dataset_class_test\", {\n",
    "            \"status\": \"failed\",\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        # 정리\n",
    "        if os.path.exists(mini_train_path):\n",
    "            os.remove(mini_train_path)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95771f4d",
   "metadata": {},
   "source": [
    "## 3. 🎨 Hard Augmentation 효과 분석\n",
    "\n",
    "에포크별 Hard Augmentation 강도 변화를 분석하고 시각화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d067f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with test_logger.capture_output(\"hard_augmentation_analysis\") as (output, error):\n",
    "    print(\"=== Hard Augmentation 분석 시작 ===\")\n",
    "    \n",
    "    try:\n",
    "        # 에포크별 증강 확률 계산\n",
    "        total_epochs = 30\n",
    "        epochs = list(range(1, total_epochs + 1))\n",
    "        \n",
    "        # 설정에서 증강 파라미터 가져오기\n",
    "        aug_config = cfg.get('augmentation', {}).get('hard_augmentation', {})\n",
    "        initial_prob = aug_config.get('initial_prob', 0.1)\n",
    "        final_prob = aug_config.get('final_prob', 0.8)\n",
    "        \n",
    "        print(f\"📊 Hard Augmentation 설정:\")\n",
    "        print(f\"   초기 확률: {initial_prob}\")\n",
    "        print(f\"   최종 확률: {final_prob}\")\n",
    "        print(f\"   총 에포크: {total_epochs}\")\n",
    "        \n",
    "        # 에포크별 확률 계산 (선형 증가)\n",
    "        hard_aug_probs = []\n",
    "        for epoch in epochs:\n",
    "            progress = (epoch - 1) / (total_epochs - 1)\n",
    "            prob = initial_prob + (final_prob - initial_prob) * progress\n",
    "            hard_aug_probs.append(prob)\n",
    "        \n",
    "        print(f\"\\n📈 주요 에포크별 증강 확률:\")\n",
    "        for epoch in [1, 5, 10, 15, 20, 25, 30]:\n",
    "            if epoch <= total_epochs:\n",
    "                prob = hard_aug_probs[epoch-1]\n",
    "                print(f\"   Epoch {epoch:2d}: {prob:.3f} ({prob*100:.1f}%)\")\n",
    "        \n",
    "        # 증강 확률 데이터 저장\n",
    "        aug_prob_df = pd.DataFrame({\n",
    "            'epoch': epochs,\n",
    "            'hard_aug_probability': hard_aug_probs\n",
    "        })\n",
    "        \n",
    "        test_logger.save_dataframe(aug_prob_df, \"hard_augmentation_schedule\", \n",
    "                                   \"에포크별 Hard Augmentation 확률 스케줄\")\n",
    "        \n",
    "        # 증강 강도 효과 분석\n",
    "        intensity_analysis = {\n",
    "            \"initial_intensity\": initial_prob,\n",
    "            \"final_intensity\": final_prob,\n",
    "            \"intensity_increase\": final_prob - initial_prob,\n",
    "            \"midpoint_epoch\": total_epochs // 2,\n",
    "            \"midpoint_intensity\": hard_aug_probs[total_epochs // 2 - 1]\n",
    "        }\n",
    "        \n",
    "        test_logger.save_test_result(\"hard_augmentation_analysis\", {\n",
    "            \"status\": \"success\",\n",
    "            \"analysis\": intensity_analysis,\n",
    "            \"schedule_type\": \"linear_progression\"\n",
    "        })\n",
    "        \n",
    "        print(\"\\n✅ Hard Augmentation 분석 완료\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Hard Augmentation 분석 실패: {e}\")\n",
    "        test_logger.save_test_result(\"hard_augmentation_analysis\", {\n",
    "            \"status\": \"failed\",\n",
    "            \"error\": str(e)\n",
    "        })\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fd7b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hard Augmentation 스케줄 시각화\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# 1. 에포크별 증강 확률 변화\n",
    "axes[0, 0].plot(epochs, hard_aug_probs, 'b-', linewidth=2, marker='o', markersize=4)\n",
    "axes[0, 0].set_title('에포크별 Hard Augmentation 확률 변화', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Epoch')\n",
    "axes[0, 0].set_ylabel('Augmentation Probability')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "axes[0, 0].axhline(y=0.5, color='r', linestyle='--', alpha=0.7, label='50% 기준선')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. 증강 강도 구간별 분포\n",
    "intensity_ranges = ['Low (0-0.3)', 'Medium (0.3-0.6)', 'High (0.6-1.0)']\n",
    "range_counts = [\n",
    "    sum(1 for p in hard_aug_probs if p < 0.3),\n",
    "    sum(1 for p in hard_aug_probs if 0.3 <= p < 0.6),\n",
    "    sum(1 for p in hard_aug_probs if p >= 0.6)\n",
    "]\n",
    "\n",
    "axes[0, 1].bar(intensity_ranges, range_counts, color=['lightgreen', 'orange', 'red'], alpha=0.7)\n",
    "axes[0, 1].set_title('증강 강도별 에포크 분포', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('에포크 수')\n",
    "for i, count in enumerate(range_counts):\n",
    "    axes[0, 1].text(i, count + 0.5, str(count), ha='center', fontweight='bold')\n",
    "\n",
    "# 3. 누적 증강 효과\n",
    "cumulative_effect = np.cumsum(hard_aug_probs)\n",
    "axes[1, 0].fill_between(epochs, cumulative_effect, alpha=0.5, color='purple')\n",
    "axes[1, 0].plot(epochs, cumulative_effect, 'purple', linewidth=2)\n",
    "axes[1, 0].set_title('누적 증강 효과', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Cumulative Augmentation Effect')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. 증강 강도 히트맵\n",
    "intensity_matrix = np.array(hard_aug_probs).reshape(6, 5)  # 30 에포크를 6x5 격자로\n",
    "im = axes[1, 1].imshow(intensity_matrix, cmap='viridis', aspect='auto')\n",
    "axes[1, 1].set_title('증강 강도 히트맵 (6주 x 5일)', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('일 (Day)')\n",
    "axes[1, 1].set_ylabel('주 (Week)')\n",
    "\n",
    "# 컬러바 추가\n",
    "cbar = plt.colorbar(im, ax=axes[1, 1], shrink=0.8)\n",
    "cbar.set_label('Augmentation Probability')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# 시각화 결과 저장\n",
    "test_logger.save_figure(fig, \"hard_augmentation_schedule_visualization\", \n",
    "                       \"Hard Augmentation 스케줄 종합 분석\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21aaec0b",
   "metadata": {},
   "source": [
    "## 4. 📊 성능 메트릭 및 최종 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef07f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 성능 메트릭 수집\n",
    "performance_metrics = {\n",
    "    \"data_loading\": {\n",
    "        \"dataset_size\": len(dataset) if 'dataset' in locals() else 0,\n",
    "        \"avg_batch_time_sec\": avg_time_per_batch if 'avg_time_per_batch' in locals() else 0,\n",
    "        \"estimated_epoch_time_min\": (avg_time_per_batch * len(train_df) / 4 / 60) if 'avg_time_per_batch' in locals() else 0\n",
    "    },\n",
    "    \"augmentation\": {\n",
    "        \"hard_aug_enabled\": aug_config.get('enabled', False),\n",
    "        \"initial_prob\": initial_prob if 'initial_prob' in locals() else 0,\n",
    "        \"final_prob\": final_prob if 'final_prob' in locals() else 0,\n",
    "        \"avg_intensity\": np.mean(hard_aug_probs) if 'hard_aug_probs' in locals() else 0\n",
    "    },\n",
    "    \"data_quality\": {\n",
    "        \"class_balance_std\": float(class_dist.std()) if 'class_dist' in locals() else 0,\n",
    "        \"min_class_samples\": int(class_dist.min()) if 'class_dist' in locals() else 0,\n",
    "        \"max_class_samples\": int(class_dist.max()) if 'class_dist' in locals() else 0\n",
    "    }\n",
    "}\n",
    "\n",
    "test_logger.save_performance_metrics(performance_metrics, \"dataset_performance\")\n",
    "\n",
    "with test_logger.capture_output(\"final_summary\") as (output, error):\n",
    "    print(\"=== 최종 테스트 요약 ===\")\n",
    "    print(f\"✅ 기본 데이터 분석: 완료\")\n",
    "    print(f\"✅ 데이터셋 클래스 테스트: 완료\")\n",
    "    print(f\"✅ Hard Augmentation 분석: 완료\")\n",
    "    print(f\"✅ 성능 메트릭 수집: 완료\")\n",
    "    \n",
    "    print(f\"\\n📊 주요 결과:\")\n",
    "    print(f\"   총 학습 샘플: {len(train_df):,}개\")\n",
    "    print(f\"   클래스 수: {train_df['target'].nunique()}개\")\n",
    "    print(f\"   평균 배치 로딩 시간: {performance_metrics['data_loading']['avg_batch_time_sec']:.4f}초\")\n",
    "    print(f\"   Hard Augmentation 평균 강도: {performance_metrics['augmentation']['avg_intensity']:.3f}\")\n",
    "    \n",
    "    print(f\"\\n💡 권장사항:\")\n",
    "    if performance_metrics['data_quality']['class_balance_std'] > 500:\n",
    "        print(f\"   ⚠️ 클래스 불균형이 큽니다. 가중 샘플링 고려\")\n",
    "    if performance_metrics['data_loading']['avg_batch_time_sec'] > 0.1:\n",
    "        print(f\"   ⚠️ 데이터 로딩이 느립니다. num_workers 증가 고려\")\n",
    "    if performance_metrics['augmentation']['avg_intensity'] < 0.3:\n",
    "        print(f\"   💡 증강 강도가 낮습니다. 더 강한 증강 고려\")\n",
    "    \n",
    "    print(f\"\\n🎯 다음 단계:\")\n",
    "    print(f\"   1. test_mixup_augmentation.ipynb - Mixup 파라미터 최적화\")\n",
    "    print(f\"   2. test_swin_model.ipynb - 모델 성능 벤치마크\")\n",
    "    print(f\"   3. 실제 학습 파이프라인 실행\")\n",
    "\n",
    "# 테스트 완료\n",
    "final_summary = test_logger.finalize_test()\n",
    "\n",
    "print(f\"\\n🎉 모든 테스트 완료!\")\n",
    "print(f\"📁 상세 결과: {test_logger.base_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a34ffc",
   "metadata": {},
   "source": [
    "## 🏆 테스트 결과 요약\n",
    "\n",
    "### ✅ 완료된 테스트\n",
    "1. **기본 데이터 분석**: 학습/테스트 데이터 크기, 클래스 분포 확인\n",
    "2. **데이터셋 클래스 테스트**: HighPerfDocClsDataset 동작 검증\n",
    "3. **Hard Augmentation 분석**: 에포크별 증강 강도 스케줄 분석\n",
    "4. **성능 메트릭 수집**: 데이터 로딩 속도, 증강 효과 측정\n",
    "\n",
    "### 📁 저장된 결과\n",
    "- **로그 파일**: 모든 출력과 에러 메시지\n",
    "- **시각화**: 클래스 분포, 증강 스케줄 차트\n",
    "- **데이터**: 처리된 데이터프레임과 NumPy 배열\n",
    "- **메트릭**: JSON 형태의 성능 지표\n",
    "\n",
    "### 🔗 로그 디렉토리 접근\n",
    "```bash\n",
    "# 결과 확인\n",
    "ls -la logs/unit_test/highperf_dataset/[timestamp]/\n",
    "\n",
    "# 이미지 확인\n",
    "ls logs/unit_test/highperf_dataset/[timestamp]/images/\n",
    "\n",
    "# 테스트 요약 확인\n",
    "cat logs/unit_test/highperf_dataset/[timestamp]/test_summary.json\n",
    "```\n",
    "\n",
    "이제 모든 테스트 결과가 체계적으로 저장되어 추후 분석과 비교가 가능합니다! 🎯"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
