2025-09-10 16:38:09 | [BOOT] high-performance training pipeline started
2025-09-10 16:38:09 | [BOOT] device=cuda
2025-09-10 16:38:09 | [DATA] loaded train data | shape=(1570, 2)
2025-09-10 16:38:09 | [DATA] Single fold mode: all data assigned to fold 0
2025-09-10 16:38:09 | ==================================================
2025-09-10 16:38:09 | FOLD 1/1 START
2025-09-10 16:38:09 | ==================================================
2025-09-10 16:38:09 | [SINGLE FOLD] Using 80:20 train/val split
2025-09-10 16:38:09 | [FOLD 0] train=1256 valid=314
2025-09-10 16:38:12 | [SINGLE-MODEL] All folds using model: swin_base_patch4_window12_384_in22k
2025-09-10 16:38:12 | [SCHEDULER] Single fold: Warmup(10) + CosineAnnealing
2025-09-10 16:38:12 | [DATA] build highperf loaders | img_size=384 bs=124
2025-09-10 16:38:12 | [DATA] augmentation: baseline-advanced (normal + hard augmentation)
2025-09-10 16:38:12 | [HighPerfDataset] size=1256 img_size=384 epoch=0/80 p_hard=0.200 is_train=True
2025-09-10 16:38:12 | [HighPerfDataset] size=314 img_size=384 epoch=0/80 p_hard=0.000 is_train=False
2025-09-10 16:38:12 | [DATA] dataset sizes | train=1256 valid=314
2025-09-10 16:38:12 | [HighPerfDataset] updated epoch=1, p_hard=0.204
2025-09-10 16:38:12 | [EPOCH 1] >>> TRAIN start | steps=11 mixup=True
2025-09-10 16:38:21 | [ERROR] Training failed: CUDA out of memory. Tried to allocate 628.00 MiB. GPU 0 has a total capacity of 23.99 GiB of which 0 bytes is free. Including non-PyTorch memory, this process has 17179869184.00 GiB memory in use. Of the allocated memory 42.79 GiB is allocated by PyTorch, and 61.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
2025-09-10 16:38:21 | [SHUTDOWN] Training pipeline ended
