{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b33696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 import\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import copy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torchvision.transforms as transforms\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# 시드 고정\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c278793",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "def free_cuda():\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33cc277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "free_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58fcc030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target vulnerable classes: [3, 4, 7, 14]\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "model_name = 'convnext_base_384_in22ft1k'  # 기존과 동일한 모델\n",
    "img_size = 512\n",
    "LR = 2e-4\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 10\n",
    "num_workers = 8\n",
    "\n",
    "# 취약 클래스 설정\n",
    "vulnerable_classes = [3, 4, 7, 14]\n",
    "print(f\"Target vulnerable classes: {vulnerable_classes}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fcf816a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스 정의 (기존과 동일, __init__만 수정)\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, data, path, epoch=0, total_epochs=10, is_train=True):\n",
    "        if isinstance(data, str):\n",
    "            df_temp = pd.read_csv(data)\n",
    "        else:\n",
    "            df_temp = data\n",
    "        \n",
    "        # 수정: 항상 ['ID', 'target'] 컬럼만 선택하여 self.df 초기화\n",
    "        self.df = df_temp[['ID', 'target']].values\n",
    "        self.path = path\n",
    "        self.epoch = epoch\n",
    "        self.total_epochs = total_epochs\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Hard augmentation 확률 계산\n",
    "        self.p_hard = 0.2 + 0.3 * (epoch / total_epochs) if is_train else 0\n",
    "        \n",
    "        # Normal augmentation\n",
    "        self.normal_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90, 90], p=1.0),\n",
    "                A.Rotate(limit=[180, 180], p=1.0),\n",
    "                A.Rotate(limit=[270, 270], p=1.0),\n",
    "            ], p=0.6),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.8),\n",
    "            A.GaussNoise(var_limit=(30.0, 100.0), p=0.7),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "        \n",
    "        # Hard augmentation\n",
    "        self.hard_aug = A.Compose([\n",
    "            A.LongestMaxSize(max_size=img_size),\n",
    "            A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "            A.OneOf([\n",
    "                A.Rotate(limit=[90, 90], p=1.0),\n",
    "                A.Rotate(limit=[180, 180], p=1.0),\n",
    "                A.Rotate(limit=[270, 270], p=1.0),\n",
    "                A.Rotate(limit=[-15, 15], p=1.0),\n",
    "            ], p=0.8),\n",
    "            A.OneOf([\n",
    "                A.MotionBlur(blur_limit=15, p=1.0),\n",
    "                A.GaussianBlur(blur_limit=15, p=1.0),\n",
    "            ], p=0.95),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.5, contrast_limit=0.5, p=0.9),\n",
    "            A.GaussNoise(var_limit=(50.0, 150.0), p=0.8),\n",
    "            A.JpegCompression(quality_lower=70, quality_upper=100, p=0.5),\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "            ToTensorV2(),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)).convert('RGB'))\n",
    "        \n",
    "        # 배치별 증강 선택\n",
    "        if self.is_train and random.random() < self.p_hard:\n",
    "            img = self.hard_aug(image=img)['image']\n",
    "        else:\n",
    "            img = self.normal_aug(image=img)['image']\n",
    "        \n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83201539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mixup 함수 정의\n",
    "def mixup_data(x, y, alpha=1.0):\n",
    "    if alpha > 0:\n",
    "        lam = np.random.beta(alpha, alpha)\n",
    "    else:\n",
    "        lam = 1\n",
    "    batch_size = x.size()[0]\n",
    "    index = torch.randperm(batch_size).cuda()\n",
    "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "# 학습 함수\n",
    "def train_one_epoch(loader, model, optimizer, loss_fn, device):\n",
    "    scaler = GradScaler()\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "\n",
    "    pbar = tqdm(loader)\n",
    "    for image, targets in pbar:\n",
    "        image = image.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        # Cutmix/Mixup 적용 (30% 확률)\n",
    "        if random.random() < 0.3:\n",
    "            mixed_x, y_a, y_b, lam = mixup_data(image, targets, alpha=1.0)\n",
    "            with autocast(): \n",
    "                preds = model(mixed_x)\n",
    "            loss = lam * loss_fn(preds, y_a) + (1 - lam) * loss_fn(preds, y_b)\n",
    "        else:\n",
    "            with autocast(): \n",
    "                preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "\n",
    "        model.zero_grad(set_to_none=True)\n",
    "        scaler.scale(loss).backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "        targets_list.extend(targets.detach().cpu().numpy())\n",
    "\n",
    "        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n",
    "\n",
    "    train_loss /= len(loader)\n",
    "    train_acc = accuracy_score(targets_list, preds_list)\n",
    "    train_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "\n",
    "    return {\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_acc\": train_acc,\n",
    "        \"train_f1\": train_f1,\n",
    "    }\n",
    "\n",
    "# 검증 함수\n",
    "def validate_one_epoch(loader, model, loss_fn, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds_list = []\n",
    "    targets_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Validating\")\n",
    "        for image, targets in pbar:\n",
    "            image = image.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            preds = model(image)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n",
    "            targets_list.extend(targets.detach().cpu().numpy())\n",
    "            \n",
    "            pbar.set_description(f\"Val Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    val_loss /= len(loader)\n",
    "    val_acc = accuracy_score(targets_list, preds_list)\n",
    "    val_f1 = f1_score(targets_list, preds_list, average='macro')\n",
    "    \n",
    "    return {\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_acc\": val_acc,\n",
    "        \"val_f1\": val_f1,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57d0d490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset size: 1570\n",
      "Filtered dataset size: 350\n",
      "\n",
      "Class distribution:\n",
      "Class 3: 100 samples\n",
      "Class 4: 100 samples\n",
      "Class 7: 100 samples\n",
      "Class 14: 50 samples\n",
      "\n",
      "Label mapping:\n",
      "Original class 3 -> New class 0\n",
      "Original class 4 -> New class 1\n",
      "Original class 7 -> New class 2\n",
      "Original class 14 -> New class 3\n",
      "\n",
      "New class distribution:\n",
      "New class 0: 100 samples\n",
      "New class 1: 100 samples\n",
      "New class 2: 100 samples\n",
      "New class 3: 50 samples\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 1. 취약 클래스 데이터 준비\n",
    "# ========================================\n",
    "\n",
    "# 원본 데이터 로드\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "print(f\"Original dataset size: {len(train_df)}\")\n",
    "\n",
    "# 취약 클래스만 필터링\n",
    "filtered_df = train_df[train_df['target'].isin(vulnerable_classes)].copy()\n",
    "print(f\"Filtered dataset size: {len(filtered_df)}\")\n",
    "\n",
    "# 클래스별 샘플 수 확인\n",
    "print(\"\\nClass distribution:\")\n",
    "for cls in vulnerable_classes:\n",
    "    count = len(filtered_df[filtered_df['target'] == cls])\n",
    "    print(f\"Class {cls}: {count} samples\")\n",
    "\n",
    "# 라벨 재매핑 (3->0, 4->1, 7->2, 14->3)\n",
    "label_mapping = {3: 0, 4: 1, 7: 2, 14: 3}\n",
    "filtered_df['original_target'] = filtered_df['target']  # 원본 라벨 보존\n",
    "filtered_df['target'] = filtered_df['target'].map(label_mapping)\n",
    "\n",
    "print(\"\\nLabel mapping:\")\n",
    "for orig, new in label_mapping.items():\n",
    "    print(f\"Original class {orig} -> New class {new}\")\n",
    "\n",
    "# 클래스 불균형 확인\n",
    "print(\"\\nNew class distribution:\")\n",
    "for new_cls in range(4):\n",
    "    count = len(filtered_df[filtered_df['target'] == new_cls])\n",
    "    print(f\"New class {new_cls}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba8a120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 2. 3-Fold Cross Validation으로 서브셋 모델 학습\n",
    "# ========================================\n",
    "\n",
    "# 3-Fold 설정\n",
    "N_FOLDS = 5\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "# 결과 저장용 리스트\n",
    "fold_results = []\n",
    "fold_models = []\n",
    "\n",
    "print(f\"Starting {N_FOLDS}-Fold Cross Validation for Subset Model...\")\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(filtered_df, filtered_df['target'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"SUBSET FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # 현재 fold의 train/validation 데이터 분할\n",
    "    train_fold_df = filtered_df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = filtered_df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    # 현재 fold의 Dataset 생성\n",
    "    trn_dataset = ImageDataset(\n",
    "        train_fold_df,\n",
    "        \"../data/train/\",\n",
    "        epoch=0,\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=True\n",
    "    )\n",
    "    \n",
    "    val_dataset = ImageDataset(\n",
    "        val_fold_df,\n",
    "        \"../data/train/\",\n",
    "        epoch=0,\n",
    "        total_epochs=EPOCHS,\n",
    "        is_train=False\n",
    "    )\n",
    "    \n",
    "    # 현재 fold의 DataLoader 생성\n",
    "    trn_loader = DataLoader(\n",
    "        trn_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "        drop_last=False\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"Train samples: {len(trn_dataset)}, Validation samples: {len(val_dataset)}\")\n",
    "    \n",
    "    # 모델 초기화 (4개 클래스)\n",
    "    model = timm.create_model(\n",
    "        model_name,\n",
    "        pretrained=True,\n",
    "        num_classes=4  # 취약 클래스 4개\n",
    "    ).to(device)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss(label_smoothing=0.05)\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "    \n",
    "    # 현재 fold의 최고 성능 추적\n",
    "    best_val_f1 = 0.0\n",
    "    best_model = None\n",
    "    \n",
    "    # 현재 fold 학습\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Training\n",
    "        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device)\n",
    "        \n",
    "        # Validation\n",
    "        val_ret = validate_one_epoch(val_loader, model, loss_fn, device)\n",
    "        \n",
    "        # Scheduler step\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1:2d} | \"\n",
    "              f\"Train Loss: {train_ret['train_loss']:.4f} | \"\n",
    "              f\"Train F1: {train_ret['train_f1']:.4f} | \"\n",
    "              f\"Val Loss: {val_ret['val_loss']:.4f} | \"\n",
    "              f\"Val F1: {val_ret['val_f1']:.4f}\")\n",
    "        \n",
    "        # 최고 성능 모델 저장\n",
    "        if val_ret['val_f1'] > best_val_f1:\n",
    "            best_val_f1 = val_ret['val_f1']\n",
    "            best_model = copy.deepcopy(model.state_dict())\n",
    "    \n",
    "    # 현재 fold 결과 저장\n",
    "    fold_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'best_val_f1': best_val_f1,\n",
    "        'train_samples': len(trn_dataset),\n",
    "        'val_samples': len(val_dataset)\n",
    "    })\n",
    "    \n",
    "    fold_models.append(best_model)\n",
    "    \n",
    "    print(f\"Subset Fold {fold + 1} Best Validation F1: {best_val_f1:.4f}\")\n",
    "\n",
    "# 결과 요약\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"SUBSET MODEL CROSS VALIDATION RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "val_f1_scores = [result['best_val_f1'] for result in fold_results]\n",
    "mean_f1 = np.mean(val_f1_scores)\n",
    "std_f1 = np.std(val_f1_scores)\n",
    "\n",
    "for result in fold_results:\n",
    "    print(f\"Fold {result['fold']}: {result['best_val_f1']:.4f}\")\n",
    "\n",
    "print(f\"\\nMean CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"Best single fold: {max(val_f1_scores):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d030b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 3. 서브셋 모델 저장\n",
    "# ========================================\n",
    "\n",
    "# 서브셋 모델들 저장\n",
    "save_dir = \"subset_models\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\nSaving subset models to {save_dir}/\")\n",
    "for fold, state_dict in enumerate(fold_models):\n",
    "    model_path = f\"{save_dir}/subset_fold_{fold}_model.pth\"\n",
    "    torch.save({\n",
    "        'model_state_dict': state_dict,\n",
    "        'fold': fold,\n",
    "        'classes': vulnerable_classes,\n",
    "        'label_mapping': label_mapping,\n",
    "        'model_name': model_name,\n",
    "        'img_size': img_size,\n",
    "        'num_classes': 4,\n",
    "        'best_f1': fold_results[fold]['best_val_f1']\n",
    "    }, model_path)\n",
    "    print(f\"✅ Fold {fold} model saved: {model_path}\")\n",
    "\n",
    "print(\"\\n🎉 4-Class subset training completed!\")\n",
    "print(f\"📊 Final Results Summary:\")\n",
    "print(f\"   - Target classes: {vulnerable_classes}\")\n",
    "print(f\"   - Training samples: {len(filtered_df)}\")\n",
    "print(f\"   - Mean CV F1: {mean_f1:.4f} ± {std_f1:.4f}\")\n",
    "print(f\"   - Models saved in: {save_dir}/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f64e3c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# 노트북 셀 4 수정: 기존 CascadeClassifier에 TTA만 추가\n",
    "# ========================================\n",
    "\n",
    "\n",
    "class CascadeClassifier:\n",
    "    \"\"\"\n",
    "    TTA가 추가된 2단계 캐스케이드 분류 시스템\n",
    "    \n",
    "    1단계: 분류기 A (17개 클래스 전체 분류) → TTA + K-fold 앙상블\n",
    "    2단계: 분류기 B (취약 클래스 3,4,7,14만 분류) → TTA + K-fold 앙상블\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, main_models, subset_models, vulnerable_classes=[3,4,7,14], \n",
    "                 confidence_threshold=0.7):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            main_models: 분류기 A의 앙상블 모델들 (17개 클래스)\n",
    "            subset_models: 분류기 B의 앙상블 모델들 (4개 클래스)\n",
    "            vulnerable_classes: 취약 클래스 리스트\n",
    "            confidence_threshold: 2단계 분류기로 넘어갈 신뢰도 임계값\n",
    "        \"\"\"\n",
    "        self.main_models = main_models\n",
    "        self.subset_models = subset_models\n",
    "        self.vulnerable_classes = vulnerable_classes\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        \n",
    "        # 취약 클래스 매핑 (원본 클래스 -> 서브셋 클래스)\n",
    "        self.class_mapping = {cls: idx for idx, cls in enumerate(vulnerable_classes)}\n",
    "        \n",
    "        # 기존 사용자의 TTA 변환들 설정\n",
    "        self.essential_tta_transforms = self._setup_tta_transforms()\n",
    "        \n",
    "        print(f\"TTA 캐스케이드 분류기 초기화 완료\")\n",
    "        print(f\"- 취약 클래스: {vulnerable_classes}\")\n",
    "        print(f\"- 신뢰도 임계값: {confidence_threshold}\")\n",
    "        print(f\"- 메인 모델 수: {len(main_models)}\")\n",
    "        print(f\"- 서브셋 모델 수: {len(subset_models)}\")\n",
    "        print(f\"- TTA 변환 수: {len(self.essential_tta_transforms)}\")\n",
    "    \n",
    "    def _setup_tta_transforms(self):\n",
    "        \"\"\"사용자의 기존 TTA 변환들 설정\"\"\"\n",
    "        img_size = 512\n",
    "        \n",
    "        return [\n",
    "            # 원본\n",
    "            A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            # 90도 회전\n",
    "            A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.Rotate(limit=[90, 90], p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            # 180도 회전\n",
    "            A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.Rotate(limit=[180, 180], p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            # -90도 회전 (270도)\n",
    "            A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.Rotate(limit=[-90, -90], p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "            # 밝기 개선\n",
    "            A.Compose([\n",
    "                A.LongestMaxSize(max_size=img_size),\n",
    "                A.PadIfNeeded(min_height=img_size, min_width=img_size, border_mode=0, value=0),\n",
    "                A.RandomBrightnessContrast(brightness_limit=[0.3, 0.3], contrast_limit=[0.3, 0.3], p=1.0),\n",
    "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                ToTensorV2(),\n",
    "            ]),\n",
    "        ]\n",
    "    \n",
    "    def _apply_tta_to_image(self, image_array):\n",
    "        \"\"\"numpy 이미지 배열에 모든 TTA 변환 적용\"\"\"\n",
    "        tta_tensors = []\n",
    "        for transform in self.essential_tta_transforms:\n",
    "            transformed = transform(image=image_array)['image']\n",
    "            tta_tensors.append(transformed)\n",
    "        return tta_tensors\n",
    "    \n",
    "    def predict_single(self, image, device):\n",
    "        \"\"\"\n",
    "        단일 이미지에 대한 캐스케이드 예측\n",
    "        \n",
    "        Args:\n",
    "            image: 전처리된 이미지 텐서 [C, H, W] 또는 numpy 배열\n",
    "            device: GPU/CPU 디바이스\n",
    "            \n",
    "        Returns:\n",
    "            final_prediction: 최종 예측 클래스\n",
    "            confidence: 예측 신뢰도\n",
    "            used_cascade: 사용된 분류기 ('main' 또는 'cascade')\n",
    "        \"\"\"\n",
    "        # 입력이 텐서인 경우 numpy로 변환 (TTA를 위해)\n",
    "        if isinstance(image, torch.Tensor):\n",
    "            # 텐서를 다시 PIL -> numpy로 변환해야 함 (비효율적이지만 TTA 적용을 위해)\n",
    "            # 실제로는 원본 이미지 파일에서 직접 로드하는 것이 좋음\n",
    "            # 여기서는 기존 인터페이스 유지를 위한 임시 처리\n",
    "            image_np = image.permute(1, 2, 0).cpu().numpy()\n",
    "            # 정규화 역변환 (대략적)\n",
    "            image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "            image_np = (image_np * 255).astype(np.uint8)\n",
    "        else:\n",
    "            image_np = image\n",
    "        \n",
    "        # 1단계: 메인 분류기로 TTA + K-fold 앙상블 예측\n",
    "        main_probs = self._predict_main_ensemble(image_np, device)\n",
    "        main_pred = torch.argmax(main_probs).item()\n",
    "        main_confidence = torch.max(main_probs).item()\n",
    "        \n",
    "        # 1단계 예측이 취약 클래스이고 신뢰도가 낮으면 2단계로\n",
    "        if (main_pred in self.vulnerable_classes and \n",
    "            main_confidence < self.confidence_threshold):\n",
    "            \n",
    "            # 2단계: 서브셋 분류기로 TTA + K-fold 앙상블 예측\n",
    "            subset_probs = self._predict_subset_ensemble(image_np, device)\n",
    "            subset_pred_idx = torch.argmax(subset_probs).item()\n",
    "            subset_confidence = torch.max(subset_probs).item()\n",
    "            \n",
    "            # 서브셋 예측을 원본 클래스로 변환\n",
    "            final_prediction = self.vulnerable_classes[subset_pred_idx]\n",
    "            final_confidence = subset_confidence\n",
    "            used_cascade = 'cascade'\n",
    "            \n",
    "            print(f\"캐스케이드 사용: {main_pred}({main_confidence:.3f}) -> {final_prediction}({subset_confidence:.3f})\")\n",
    "            \n",
    "        else:\n",
    "            # 1단계 예측 그대로 사용\n",
    "            final_prediction = main_pred\n",
    "            final_confidence = main_confidence\n",
    "            used_cascade = 'main'\n",
    "        \n",
    "        return final_prediction, final_confidence, used_cascade\n",
    "    \n",
    "    def _predict_main_ensemble(self, image_array, device):\n",
    "        \"\"\"메인 분류기 TTA + K-fold 앙상블 예측\"\"\"\n",
    "        # TTA 적용\n",
    "        tta_tensors = self._apply_tta_to_image(image_array)\n",
    "        all_predictions = []\n",
    "        \n",
    "        # 각 TTA 변환에 대해 K-fold 앙상블\n",
    "        for tta_tensor in tta_tensors:\n",
    "            tta_tensor = tta_tensor.unsqueeze(0).to(device)  # 배치 차원 추가\n",
    "            \n",
    "            # K-fold 앙상블\n",
    "            fold_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for model in self.main_models:\n",
    "                    model.eval()\n",
    "                    preds = model(tta_tensor)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    fold_predictions.append(probs)\n",
    "            \n",
    "            # K-fold 평균\n",
    "            fold_ensemble = torch.mean(torch.stack(fold_predictions), dim=0)\n",
    "            all_predictions.append(fold_ensemble)\n",
    "        \n",
    "        # TTA 평균\n",
    "        final_prediction = torch.mean(torch.stack(all_predictions), dim=0).squeeze()\n",
    "        return final_prediction\n",
    "    \n",
    "    def _predict_subset_ensemble(self, image_array, device):\n",
    "        \"\"\"서브셋 분류기 TTA + K-fold 앙상블 예측\"\"\"\n",
    "        # TTA 적용\n",
    "        tta_tensors = self._apply_tta_to_image(image_array)\n",
    "        all_predictions = []\n",
    "        \n",
    "        # 각 TTA 변환에 대해 K-fold 앙상블\n",
    "        for tta_tensor in tta_tensors:\n",
    "            tta_tensor = tta_tensor.unsqueeze(0).to(device)  # 배치 차원 추가\n",
    "            \n",
    "            # K-fold 앙상블\n",
    "            fold_predictions = []\n",
    "            with torch.no_grad():\n",
    "                for model in self.subset_models:\n",
    "                    model.eval()\n",
    "                    preds = model(tta_tensor)\n",
    "                    probs = torch.softmax(preds, dim=1)\n",
    "                    fold_predictions.append(probs)\n",
    "            \n",
    "            # K-fold 평균\n",
    "            fold_ensemble = torch.mean(torch.stack(fold_predictions), dim=0)\n",
    "            all_predictions.append(fold_ensemble)\n",
    "        \n",
    "        # TTA 평균\n",
    "        final_prediction = torch.mean(torch.stack(all_predictions), dim=0).squeeze()\n",
    "        return final_prediction\n",
    "    \n",
    "    def predict_batch(self, dataloader, device):\n",
    "        \"\"\"\n",
    "        배치 데이터에 대한 캐스케이드 예측\n",
    "        \n",
    "        Args:\n",
    "            dataloader: 테스트 데이터로더\n",
    "            device: GPU/CPU 디바이스\n",
    "            \n",
    "        Returns:\n",
    "            predictions: 최종 예측 리스트\n",
    "            confidences: 예측 신뢰도 리스트\n",
    "            cascade_usage: 캐스케이드 사용 통계\n",
    "        \"\"\"\n",
    "        all_predictions = []\n",
    "        all_confidences = []\n",
    "        cascade_usage = {'main': 0, 'cascade': 0}\n",
    "        \n",
    "        for images, _ in tqdm(dataloader, desc=\"TTA Cascade Prediction\"):\n",
    "            batch_predictions = []\n",
    "            batch_confidences = []\n",
    "            \n",
    "            for i in range(images.size(0)):\n",
    "                single_image = images[i]\n",
    "                pred, conf, used = self.predict_single(single_image, device)\n",
    "                \n",
    "                batch_predictions.append(pred)\n",
    "                batch_confidences.append(conf)\n",
    "                cascade_usage[used] += 1\n",
    "            \n",
    "            all_predictions.extend(batch_predictions)\n",
    "            all_confidences.extend(batch_confidences)\n",
    "        \n",
    "        return all_predictions, all_confidences, cascade_usage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5057054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메인 모델들 로드 중...\n",
      "✅ 메인 모델 1 로드 완료\n",
      "✅ 메인 모델 2 로드 완료\n",
      "✅ 메인 모델 3 로드 완료\n",
      "✅ 메인 모델 4 로드 완료\n",
      "✅ 메인 모델 5 로드 완료\n",
      "총 5개의 메인 모델 로드 완료\n",
      "\n",
      "서브셋 모델들 로드 중...\n",
      "✅ 서브셋 모델 0 로드 완료 (F1: 0.8820)\n",
      "✅ 서브셋 모델 1 로드 완료 (F1: 0.9059)\n",
      "✅ 서브셋 모델 2 로드 완료 (F1: 0.8886)\n",
      "✅ 서브셋 모델 3 로드 완료 (F1: 0.9750)\n",
      "✅ 서브셋 모델 4 로드 완료 (F1: 0.8390)\n",
      "총 5개의 서브셋 모델 로드 완료\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 5. 메인 모델과 서브셋 모델 로드\n",
    "# ========================================\n",
    "\n",
    "# 메인 모델들 로드 (17개 클래스)\n",
    "print(\"메인 모델들 로드 중...\")\n",
    "main_models = []\n",
    "for fold in range(5):\n",
    "\n",
    "    #model_path = f\"best_model_fold_{fold+1}.pth\"\n",
    "    #model_path = f\"fold_{fold+1}_best.pth\"\n",
    "    model_path = f\"BH_512_base_best_model_fold_{fold+1}.pth\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        # 메인 모델 생성 (17개 클래스)\n",
    "        main_model = timm.create_model(model_name, pretrained=True, num_classes=17).to(device)\n",
    "        main_model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        main_model.eval()\n",
    "        \n",
    "        main_models.append(main_model)\n",
    "        print(f\"✅ 메인 모델 {fold+1} 로드 완료\")\n",
    "    else:\n",
    "        print(f\"❌ 메인 모델 {fold+1} 파일을 찾을 수 없습니다: {model_path}\")\n",
    "\n",
    "print(f\"총 {len(main_models)}개의 메인 모델 로드 완료\")\n",
    "\n",
    "save_dir = 'subset_models'\n",
    "\n",
    "# 서브셋 모델들 로드 (4개 클래스)\n",
    "print(\"\\n서브셋 모델들 로드 중...\")\n",
    "subset_models = []\n",
    "for fold in range(5):\n",
    "    model_path = f\"{save_dir}/subset_fold_{fold}_model.pth\"\n",
    "    \n",
    "    if os.path.exists(model_path):\n",
    "        # 서브셋 모델 생성 (4개 클래스)\n",
    "        subset_model = timm.create_model(model_name, pretrained=True, num_classes=4).to(device)\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        subset_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        subset_model.eval()\n",
    "        \n",
    "        subset_models.append(subset_model)\n",
    "        print(f\"✅ 서브셋 모델 {fold} 로드 완료 (F1: {checkpoint['best_f1']:.4f})\")\n",
    "    else:\n",
    "        print(f\"❌ 서브셋 모델 {fold} 파일을 찾을 수 없습니다: {model_path}\")\n",
    "\n",
    "print(f\"총 {len(subset_models)}개의 서브셋 모델 로드 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ea6b713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TTA 캐스케이드 분류기 초기화 완료\n",
      "- 취약 클래스: [3, 4, 7, 14]\n",
      "- 신뢰도 임계값: 0.4\n",
      "- 메인 모델 수: 5\n",
      "- 서브셋 모델 수: 5\n",
      "- TTA 변환 수: 5\n",
      "테스트 데이터 크기: 3140\n",
      "캐스케이드 시스템으로 테스트 데이터 예측 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.373) -> 7(0.329)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:   2%|▏         | 2/99 [00:26<20:53, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 4(0.231) -> 14(0.521)\n",
      "캐스케이드 사용: 3(0.280) -> 3(0.398)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  10%|█         | 10/99 [02:06<18:35, 12.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 3(0.289) -> 7(0.403)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  14%|█▍        | 14/99 [02:57<17:54, 12.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 4(0.281) -> 4(0.492)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  16%|█▌        | 16/99 [03:23<17:40, 12.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.356) -> 4(0.397)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  18%|█▊        | 18/99 [03:49<17:26, 12.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 4(0.260) -> 3(0.308)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  19%|█▉        | 19/99 [04:02<17:23, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.356) -> 7(0.404)\n",
      "캐스케이드 사용: 4(0.370) -> 3(0.347)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  30%|███       | 30/99 [06:25<14:54, 12.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 4(0.347) -> 4(0.464)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  33%|███▎      | 33/99 [07:05<14:19, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.360) -> 3(0.334)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  37%|███▋      | 37/99 [07:57<13:28, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.393) -> 3(0.506)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  39%|███▉      | 39/99 [08:23<13:04, 13.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.237) -> 14(0.360)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  43%|████▎     | 43/99 [09:16<12:10, 13.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.320) -> 7(0.372)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  49%|████▉     | 49/99 [10:34<10:48, 12.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 14(0.342) -> 14(0.372)\n",
      "캐스케이드 사용: 4(0.371) -> 3(0.320)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  59%|█████▊    | 58/99 [12:31<08:52, 12.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 3(0.298) -> 7(0.580)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  72%|███████▏  | 71/99 [15:20<06:02, 12.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.364) -> 7(0.473)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  76%|███████▌  | 75/99 [16:12<05:11, 12.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.235) -> 7(0.541)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  78%|███████▊  | 77/99 [16:38<04:46, 13.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.374) -> 7(0.416)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  79%|███████▉  | 78/99 [16:52<04:35, 13.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 4(0.384) -> 3(0.478)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  82%|████████▏ | 81/99 [17:31<03:54, 13.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 4(0.347) -> 7(0.390)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  89%|████████▉ | 88/99 [19:02<02:22, 12.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.380) -> 7(0.488)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  92%|█████████▏| 91/99 [19:41<01:44, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 7(0.235) -> 3(0.373)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction:  97%|█████████▋| 96/99 [20:46<00:39, 13.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "캐스케이드 사용: 3(0.344) -> 7(0.456)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TTA Cascade Prediction: 100%|██████████| 99/99 [21:14<00:00, 12.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "캐스케이드 사용 통계:\n",
      "- 메인 분류기만 사용: 3115개 (99.2%)\n",
      "- 캐스케이드 사용: 25개 (0.8%)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# 6. 캐스케이드 분류기 초기화 및 테스트 데이터 예측\n",
    "# ========================================\n",
    "\n",
    "# 캐스케이드 분류기 인스턴스 생성\n",
    "cascade_classifier = CascadeClassifier(\n",
    "    main_models=main_models,      # 분류기 A (17개 클래스)\n",
    "    subset_models=subset_models,  # 분류기 B (4개 클래스)\n",
    "    vulnerable_classes=vulnerable_classes, # [3, 4, 7, 14]\n",
    "    confidence_threshold=0.4      # 신뢰도 임계값\n",
    ")\n",
    "\n",
    "# 테스트 데이터 로드\n",
    "test_df = pd.read_csv(\"../data/sample_submission.csv\")\n",
    "print(f\"테스트 데이터 크기: {len(test_df)}\")\n",
    "\n",
    "# 테스트 데이터셋 생성\n",
    "test_dataset = ImageDataset(\n",
    "    test_df,\n",
    "    \"../data/test/\",\n",
    "    epoch=0,\n",
    "    total_epochs=EPOCHS,\n",
    "    is_train=False  # 테스트이므로 증강 없음\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,  # 배치 크기 줄임\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"캐스케이드 시스템으로 테스트 데이터 예측 시작...\")\n",
    "\n",
    "# 올바른 코드 - 인스턴스에서 메서드 호출\n",
    "test_predictions, test_confidences, cascade_usage = cascade_classifier.predict_batch(\n",
    "    test_loader, device\n",
    ")\n",
    "\n",
    "print(f\"\\n캐스케이드 사용 통계:\")\n",
    "print(f\"- 메인 분류기만 사용: {cascade_usage['main']}개 ({cascade_usage['main']/len(test_predictions)*100:.1f}%)\")\n",
    "print(f\"- 캐스케이드 사용: {cascade_usage['cascade']}개 ({cascade_usage['cascade']/len(test_predictions)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a602d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 결과 저장: ../data/output/cascade_submission_CSW_5.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 결과 저장\n",
    "result_df = test_df.copy()\n",
    "result_df['target'] = test_predictions\n",
    "result_df['confidence'] = test_confidences\n",
    "\n",
    "# submission 파일 저장\n",
    "output_path = \"../data/output/cascade_submission_CSW_5.csv\"\n",
    "print(f\"📁 결과 저장: {output_path}\")\n",
    "result_df[['ID', 'target']].to_csv(output_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f6c53c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Sep 11 05:23:44 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.86.10              Driver Version: 535.86.10    CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:21:00.0 Off |                  N/A |\n",
      "| 30%   40C    P8              19W / 350W |   4288MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9342ead5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
